{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCGAN.3D.test",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjvA1S9S5APo",
        "colab_type": "text"
      },
      "source": [
        "# Mount the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geEb2FFt35To",
        "colab_type": "code",
        "outputId": "c25c3fb0-56d7-462d-d603-80d64957c740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxXCtJBN4CJy",
        "colab_type": "code",
        "outputId": "d270bc7d-815e-49f5-98d9-664ce0a559f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!ls drive/'My Drive'/'Colab Notebooks'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 03_CGAN_MNIST.ipynb\t\t    mean-teacher-master\n",
            "'Chapter_7_SGAN (1).ipynb'\t   'mean teacher.v0.mine.ipynb'\n",
            "'Chapter_7_SGAN (2).ipynb'\t   'Mean Teacher.v1.ipynb'\n",
            " Chapter_7_SGAN.ipynb\t\t   'SCGAN (1).v1.ipynb'\n",
            " Chapter_8_CGAN.ipynb\t\t    SCGAN.3D.test\n",
            "'Chapter_8_CGAN - 副本 (1).ipynb'   SCGAN.3D.v0.ipynb\n",
            "'Chapter_8_CGAN - 副本.ipynb'\t    SCGAN.v1.ipynb\n",
            " dcgan.ipynb\t\t\t    SSGAN-Tensorflow-master\n",
            " full_dataset_vectors.h5\t    Untitled0.ipynb\n",
            " GAN-tmp.ipynb\t\t\t    Untitled1.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfvLZqwH44OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import h5py\n",
        "import math\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "from matplotlib.pyplot import cm\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import (Activation, BatchNormalization, Concatenate, Dense,\n",
        "                          Dropout, Flatten, Input, Lambda, Reshape, Embedding,\n",
        "                          Multiply, MaxPool3D)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose, Conv3D, Conv3DTranspose\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.backend import epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g--HLXJ15Fxn",
        "colab_type": "text"
      },
      "source": [
        "# Process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuNrisY75DXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File('drive/My Drive/Colab Notebooks/full_dataset_vectors.h5', 'r') as mnist3d:\n",
        "    x_train = mnist3d[\"X_train\"][:]\n",
        "    x_test = mnist3d[\"X_test\"][:]\n",
        "    y_train = mnist3d[\"y_train\"][:]\n",
        "    y_test = mnist3d[\"y_test\"][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq6fcKi647zt",
        "colab_type": "code",
        "outputId": "5ce38bd5-dcd2-4ec7-aa12-3c12d1883233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print (\"x_train shape: \"+str(x_train.shape))\n",
        "print (\"y_train shape: \"+str(y_train.shape))\n",
        "print (\"x_test shape:  \"+str(x_test.shape))\n",
        "print (\"y_test shape:  \"+str(y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (10000, 4096)\n",
            "y_train shape: (10000,)\n",
            "x_test shape:  (2000, 4096)\n",
            "y_test shape:  (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i76ooN2_5jXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4f5b9aeb-6767-4183-bb96-c9fc2dac3e0d"
      },
      "source": [
        "# Split the data\n",
        "x = np.vstack((x_train, x_test))\n",
        "y = np.hstack((y_train, y_test))\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9600, 4096)\n",
            "(9600,)\n",
            "(2400, 4096)\n",
            "(2400,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDffge7i5Iz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Introduce the channel dimension in the input dataset , just shape, no data\n",
        "xtrain = np.ndarray((x_train.shape[0], 4096, 3))\n",
        "xtest = np.ndarray((x_test.shape[0], 4096, 3))\n",
        "\n",
        "## iterate in train and test, add the rgb dimention \n",
        "def add_rgb_dimention(array):\n",
        "    scaler_map = cm.ScalarMappable(cmap=\"Oranges\")\n",
        "    array = scaler_map.to_rgba(array)[:, : -1]\n",
        "    return array\n",
        "for i in range(x_train.shape[0]):\n",
        "    xtrain[i] = add_rgb_dimention(x_train[i])\n",
        "for i in range(x_test.shape[0]):\n",
        "    xtest[i] = add_rgb_dimention(x_test[i])\n",
        "\n",
        "## convert to 1 + 4D space (1st argument represents number of rows in the dataset)\n",
        "xtrain = xtrain.reshape(x_train.shape[0], 16, 16, 16, 3)\n",
        "xtest = xtest.reshape(x_test.shape[0], 16, 16, 16, 3)\n",
        "\n",
        "## convert target variable into one-hot\n",
        "ytrain = to_categorical(y_train, num_classes=10)\n",
        "ytest = to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_QrkRx65Lf3",
        "colab_type": "code",
        "outputId": "495b7a1a-5dbe-492a-8dd8-04711fb79fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print (\"xtrain shape: \"+str(xtrain.shape))\n",
        "print (\"ytrain shape: \"+str(ytrain.shape))\n",
        "print (\"xtest shape:  \"+str(xtest.shape))\n",
        "print (\"ytest shape:  \"+str(ytest.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xtrain shape: (9600, 16, 16, 16, 3)\n",
            "ytrain shape: (9600, 10)\n",
            "xtest shape:  (2400, 16, 16, 16, 3)\n",
            "ytest shape:  (2400, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf4icNcw5pIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, num_labeled):\n",
        "        self.num_labeled = num_labeled\n",
        "        self.x_train = xtrain\n",
        "        self.y_train = ytrain\n",
        "        self.x_test = xtest\n",
        "        self.y_test = ytest\n",
        "\n",
        "    def batch_labeled(self, batch_size):\n",
        "        # Get a random batch of labeled images and their labels\n",
        "        idx = np.random.randint(0, self.num_labeled, batch_size)\n",
        "        imgs = self.x_train[idx]\n",
        "        labels = self.y_train[idx]\n",
        "        return imgs, labels\n",
        "\n",
        "    def batch_unlabeled(self, batch_size):\n",
        "        # Get a random batch of unlabeled images\n",
        "        idx = np.random.randint(self.num_labeled, self.x_train.shape[0],\n",
        "                                batch_size)\n",
        "        imgs = self.x_train[idx]\n",
        "        return imgs\n",
        "\n",
        "    def training_set(self):\n",
        "        # x_train = self.x_train[range(self.num_labeled)]\n",
        "        # y_train = self.y_train[range(self.num_labeled)]\n",
        "        return self.x_train, self.y_train\n",
        "\n",
        "    def test_set(self):\n",
        "        return self.x_test, self.y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU6znRDQ6VuY",
        "colab_type": "text"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUtWIfvP6QG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows = 16\n",
        "img_cols = 16\n",
        "img_deps = 16\n",
        "channels = 3\n",
        "\n",
        "# Input image dimensions\n",
        "img_shape = (img_rows, img_cols, img_deps, channels)\n",
        "\n",
        "# Size of the noise vector, used as input to the Generator\n",
        "z_dim = 100\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-mcolX16QiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(z_dim):\n",
        "  \n",
        "    z = Input(shape=(z_dim, ))\n",
        "    label = Input(shape=(num_classes, ), dtype='float32')\n",
        "    label_embedding = Dense(z_dim, input_dim=num_classes)(label)\n",
        "    joined_representation = Multiply()([z, label_embedding])\n",
        "    \n",
        "#     model = Sequential()\n",
        "\n",
        "    # Reshape input into 4x4x4x256 tensor via a fully connected layer\n",
        "    model = Dense(256 * 4 * 4 * 4, input_dim=z_dim)(joined_representation)\n",
        "    model = Reshape((4, 4, 4, 256))(model)\n",
        "\n",
        "    # Transposed convolution layer, from 4x4x4x256 into 8x8x8x128 tensor\n",
        "    model = Conv3DTranspose(128, kernel_size=3, strides=2, padding='same')(model)\n",
        "\n",
        "    # Batch normalization\n",
        "    model = BatchNormalization()(model)\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model = LeakyReLU(alpha=0.01)(model)\n",
        "\n",
        "    # Transposed convolution layer, from 8x8x8x128 to 8x8x8x64 tensor\n",
        "    model = Conv3DTranspose(64, kernel_size=3, strides=1, padding='same')(model)\n",
        "\n",
        "    # Batch normalization\n",
        "    model = BatchNormalization()(model)\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model = LeakyReLU(alpha=0.01)(model)\n",
        "\n",
        "    # Transposed convolution layer, from 8x8x8x64 to 16x16x16x3 tensor\n",
        "    model = Conv3DTranspose(3, kernel_size=3, strides=2, padding='same')(model)\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "    conditioned_img = Activation('tanh')(model)\n",
        "    \n",
        "#     conditioned_img = model(joined_representation)\n",
        "\n",
        "    model = Model([z, label], conditioned_img)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBfQ9G877Rb2",
        "colab_type": "code",
        "outputId": "36e9164b-09a0-4b14-c371-ee2c13e1b90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "build_generator(z_dim).summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 100)          1100        input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, 100)          0           input_9[0][0]                    \n",
            "                                                                 dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 16384)        1654784     multiply_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 4, 4, 4, 256) 0           dense_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_7 (Conv3DTrans (None, 8, 8, 8, 128) 884864      reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 8, 128) 512         conv3d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, 8, 8, 8, 128) 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_8 (Conv3DTrans (None, 8, 8, 8, 64)  221248      leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 8, 64)  256         conv3d_transpose_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, 8, 8, 8, 64)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_9 (Conv3DTrans (None, 16, 16, 16, 3 5187        leaky_re_lu_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 16, 3 0           conv3d_transpose_9[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 2,767,951\n",
            "Trainable params: 2,767,567\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiQfWOtS7Rto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_net(img_shape):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional layer, from 16x16x16x3 into 8x8x8x8 tensor\n",
        "    model.add(Conv3D(8, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "\n",
        "    # Convolutional layer, from 8x8x8x8 into 4x4x4x16 tensor\n",
        "    model.add(Conv3D(32, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Convolutional layer, from 4x4x4x16 tensor into 2x2x2x32 tensor\n",
        "    model.add(Conv3D(32, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Convolutional layer, from 2x2x2x32 tensor into 1x1x1x64 tensor\n",
        "    model.add(Conv3D(64, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(num_classes))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMNFR4kETAP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_net(img_shape):\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv3D(filters=8, kernel_size=(3, 3, 3), use_bias=False, , input_shape=img_shapepadding='Same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv3D(filters=16, kernel_size=(3, 3, 3), use_bias=False, padding='Same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(MaxPool3D(pool_size=(2, 2, 2))) # the pool_size (2, 2, 2) halves the size of its input\n",
        "\n",
        "    model.add(Conv3D(filters=32, kernel_size=(3, 3, 3), use_bias=False, padding='Same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), use_bias=False, padding='Same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    ## Pooling layer\n",
        "    model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
        "    model.add(Dropout(0.25)) #No more BatchNorm after this layer because we introduce Dropout\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    ## Dense layers\n",
        "    model.add(Dense(units=4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=1024, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ksw5kFk9Vbn",
        "colab_type": "code",
        "outputId": "e988b530-3951-40e7-a3fc-425c9775b4ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "build_discriminator_net(img_shape).summary()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_70 (Conv3D)           (None, 8, 8, 8, 8)        656       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_82 (LeakyReLU)   (None, 8, 8, 8, 8)        0         \n",
            "_________________________________________________________________\n",
            "conv3d_71 (Conv3D)           (None, 4, 4, 4, 32)       6944      \n",
            "_________________________________________________________________\n",
            "batch_normalization_60 (Batc (None, 4, 4, 4, 32)       128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_83 (LeakyReLU)   (None, 4, 4, 4, 32)       0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 4, 4, 4, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv3d_72 (Conv3D)           (None, 2, 2, 2, 32)       27680     \n",
            "_________________________________________________________________\n",
            "batch_normalization_61 (Batc (None, 2, 2, 2, 32)       128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_84 (LeakyReLU)   (None, 2, 2, 2, 32)       0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 2, 2, 2, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv3d_73 (Conv3D)           (None, 1, 1, 1, 64)       55360     \n",
            "_________________________________________________________________\n",
            "batch_normalization_62 (Batc (None, 1, 1, 1, 64)       256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_85 (LeakyReLU)   (None, 1, 1, 1, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 1, 1, 1, 64)       0         \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 91,802\n",
            "Trainable params: 91,546\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKHa7xnb8WH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_class(discriminator_net):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(discriminator_net)\n",
        "\n",
        "    # Softmax activation, giving predicted probability distribution over the real classes\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvVOGkGk8aEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_realOrFake(discriminator_net):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(discriminator_net)\n",
        "\n",
        "    def predict(x):\n",
        "        # Transform distribution over real classes into a binary real-vs-fake probability\n",
        "        prediction = 1.0 - (1.0 / (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.0))\n",
        "        return prediction\n",
        "\n",
        "    # 'Real-vs-fake' output neuron defined above\n",
        "    model.add(Lambda(predict))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbIyq3ki8bKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gan(generator, discriminator):\n",
        "    \n",
        "    z = Input(shape=(z_dim, ))\n",
        "    label = Input(shape=(num_classes, ))\n",
        "    img = generator([z, label])\n",
        "    output = discriminator(img)\n",
        "    model = Model([z, label], output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4usyJ--8c0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Core Discriminator network:\n",
        "# These layers are shared during supervised and unsupervised training\n",
        "\n",
        "discriminator_net = build_discriminator_net(img_shape)\n",
        "\n",
        "\n",
        "discriminator_realOrFake = build_discriminator_realOrFake(discriminator_net)\n",
        "discriminator_realOrFake.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam())\n",
        "\n",
        "discriminator_class = build_discriminator_class(discriminator_net)\n",
        "discriminator_class.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoPjAzog8gEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the Generator\n",
        "generator = build_generator(z_dim)\n",
        "\n",
        "discriminator_realOrFake.trainable = False\n",
        "discriminator_class.trainable = False\n",
        "\n",
        "gan_realOrFake = build_gan(generator, discriminator_realOrFake)\n",
        "# gan_realOrFake.compile(loss=loss_d_realOrFake, metrics=['accuracy'], optimizer=Adam())\n",
        "gan_realOrFake.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam())\n",
        "\n",
        "gan_class = build_gan(generator, discriminator_class)\n",
        "# gan_class.compile(loss=loss_d_class, metrics=['accuracy'], optimizer=Adam())\n",
        "gan_class.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOpdjTsJ9yAs",
        "colab_type": "code",
        "outputId": "fea2649d-8161-451e-e315-606b0be3bc58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "discriminator_realOrFake.summary()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_39 (Sequential)   (None, 10)                91802     \n",
            "_________________________________________________________________\n",
            "lambda_15 (Lambda)           (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 183,348\n",
            "Trainable params: 91,546\n",
            "Non-trainable params: 91,802\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning:\n",
            "\n",
            "Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t-he66192A6",
        "colab_type": "code",
        "outputId": "3f316e7d-c88f-4c69-80c8-7d2ba4bdf88e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "discriminator_class.summary()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_39 (Sequential)   (None, 10)                91802     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 183,348\n",
            "Trainable params: 91,546\n",
            "Non-trainable params: 91,802\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning:\n",
            "\n",
            "Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLylJqrz95iT",
        "colab_type": "code",
        "outputId": "fcf9d98f-4511-4f5f-81ed-3a3d7dababb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "gan_realOrFake.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_25 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_26 (InputLayer)           (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_12 (Model)                (None, 16, 16, 16, 3 2767951     input_25[0][0]                   \n",
            "                                                                 input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_40 (Sequential)      (None, 1)            91802       model_12[1][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,859,753\n",
            "Trainable params: 2,767,567\n",
            "Non-trainable params: 92,186\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bqI5vrG992-",
        "colab_type": "code",
        "outputId": "478c29b7-87cb-47e1-eb86-60dd7ff7fc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "gan_class.summary()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_28 (InputLayer)           (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_12 (Model)                (None, 16, 16, 16, 3 2767951     input_27[0][0]                   \n",
            "                                                                 input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_41 (Sequential)      (None, 10)           91802       model_12[2][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,859,753\n",
            "Trainable params: 2,767,567\n",
            "Non-trainable params: 92,186\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHC7Nw2e-GF_",
        "colab_type": "code",
        "outputId": "8afb62d2-f790-449b-d298-f4c2431d2f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "generator.summary()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_24 (InputLayer)           (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 100)          1100        input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_6 (Multiply)           (None, 100)          0           input_23[0][0]                   \n",
            "                                                                 dense_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 16384)        1654784     multiply_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 4, 4, 4, 256) 0           dense_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_16 (Conv3DTran (None, 8, 8, 8, 128) 884864      reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 8, 8, 8, 128) 512         conv3d_transpose_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_67 (LeakyReLU)      (None, 8, 8, 8, 128) 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_17 (Conv3DTran (None, 8, 8, 8, 64)  221248      leaky_re_lu_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 8, 8, 8, 64)  256         conv3d_transpose_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_68 (LeakyReLU)      (None, 8, 8, 8, 64)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_18 (Conv3DTran (None, 16, 16, 16, 3 5187        leaky_re_lu_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 16, 3 0           conv3d_transpose_18[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 2,767,951\n",
            "Trainable params: 2,767,567\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KytZLwPR8ktt",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRhnlkou8ipa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c400e637-f5ba-4c44-c4f7-1179b61502e7"
      },
      "source": [
        "%mkdir models\n",
        "%mkdir losses\n",
        "%mkdir models/models-label-1000\n",
        "%mkdir losses/losses-label-1000"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n",
            "mkdir: cannot create directory ‘losses’: File exists\n",
            "mkdir: cannot create directory ‘models/models-label-1000’: File exists\n",
            "mkdir: cannot create directory ‘losses/losses-label-1000’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPr1u9etLx4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretrain(iterations_pre, batch_size, save_interval):\n",
        "  for iteration in range(iterations_pre):\n",
        "      imgs_labeled, labels = dataset.training_set()\n",
        "      # imgs_labeled, labels = dataset.batch_labeled(1000)\n",
        "      loss_d_labeled_class, acc_d_labeled_class = discriminator_class.train_on_batch(imgs_labeled, labels)\n",
        "      if (iteration + 1) % save_interval == 0:\n",
        "          \n",
        "          # Output training progress\n",
        "          print(\n",
        "              \"%d [D loss class: %.4f, acc: %.2f%%]\"\n",
        "              % (iteration + 1, loss_d_labeled_class, 100 * acc_d_labeled_class))\n",
        "          \n",
        "          discriminator_class.save(\"./models/discriminator_class.h5\")\n",
        "          x, y = dataset.training_set()\n",
        "          _, accuracy = discriminator_class.evaluate(x, y)\n",
        "          print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whicr7KXM_nx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36edb5fa-742e-4bc9-caa5-52cf352b58ab"
      },
      "source": [
        "# Set hyperparameters\n",
        "iterations_pre = 2000\n",
        "batch_size = 32\n",
        "save_interval = 100\n",
        "\n",
        "dataset = Dataset(num_labeled)\n",
        "\n",
        "pretrain(iterations_pre, batch_size, save_interval)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 [D loss class: 1.1383, acc: 61.46%]\n",
            "9600/9600 [==============================] - 1s 136us/step\n",
            "Training Accuracy: 70.32%\n",
            "200 [D loss class: 1.1363, acc: 61.18%]\n",
            "9600/9600 [==============================] - 1s 136us/step\n",
            "Training Accuracy: 71.03%\n",
            "300 [D loss class: 1.1165, acc: 62.04%]\n",
            "9600/9600 [==============================] - 1s 137us/step\n",
            "Training Accuracy: 71.41%\n",
            "400 [D loss class: 1.1007, acc: 62.36%]\n",
            "9600/9600 [==============================] - 1s 136us/step\n",
            "Training Accuracy: 71.70%\n",
            "500 [D loss class: 1.0922, acc: 62.77%]\n",
            "9600/9600 [==============================] - 1s 140us/step\n",
            "Training Accuracy: 72.58%\n",
            "600 [D loss class: 1.0695, acc: 63.00%]\n",
            "9600/9600 [==============================] - 1s 142us/step\n",
            "Training Accuracy: 73.09%\n",
            "700 [D loss class: 1.0833, acc: 63.10%]\n",
            "9600/9600 [==============================] - 1s 144us/step\n",
            "Training Accuracy: 73.44%\n",
            "800 [D loss class: 1.0577, acc: 64.16%]\n",
            "9600/9600 [==============================] - 1s 133us/step\n",
            "Training Accuracy: 74.49%\n",
            "900 [D loss class: 1.0584, acc: 63.76%]\n",
            "9600/9600 [==============================] - 1s 138us/step\n",
            "Training Accuracy: 74.88%\n",
            "1000 [D loss class: 1.0360, acc: 64.76%]\n",
            "9600/9600 [==============================] - 1s 154us/step\n",
            "Training Accuracy: 75.07%\n",
            "1100 [D loss class: 1.0416, acc: 64.51%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "Training Accuracy: 76.10%\n",
            "1200 [D loss class: 1.0120, acc: 65.80%]\n",
            "9600/9600 [==============================] - 1s 135us/step\n",
            "Training Accuracy: 76.51%\n",
            "1300 [D loss class: 1.0158, acc: 65.33%]\n",
            "9600/9600 [==============================] - 1s 137us/step\n",
            "Training Accuracy: 76.95%\n",
            "1400 [D loss class: 1.0071, acc: 65.73%]\n",
            "9600/9600 [==============================] - 1s 155us/step\n",
            "Training Accuracy: 76.40%\n",
            "1500 [D loss class: 0.9968, acc: 65.82%]\n",
            "9600/9600 [==============================] - 1s 142us/step\n",
            "Training Accuracy: 77.81%\n",
            "1600 [D loss class: 0.9776, acc: 66.85%]\n",
            "9600/9600 [==============================] - 1s 138us/step\n",
            "Training Accuracy: 78.51%\n",
            "1700 [D loss class: 0.9580, acc: 67.17%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "Training Accuracy: 79.30%\n",
            "1800 [D loss class: 0.9663, acc: 66.89%]\n",
            "9600/9600 [==============================] - 1s 144us/step\n",
            "Training Accuracy: 79.78%\n",
            "1900 [D loss class: 0.9578, acc: 67.19%]\n",
            "9600/9600 [==============================] - 1s 146us/step\n",
            "Training Accuracy: 79.64%\n",
            "2000 [D loss class: 0.9354, acc: 67.85%]\n",
            "9600/9600 [==============================] - 1s 143us/step\n",
            "Training Accuracy: 79.99%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LxBBGWOSMaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5fe6c9c4-6a56-4ecb-f121-7d8e8eabfe24"
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "_, accuracy = discriminator_class.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2400/2400 [==============================] - 0s 176us/step\n",
            "Test Accuracy: 65.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rxCPwSC8pMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(iterations, batch_size, save_interval, m, n):\n",
        "\n",
        "\n",
        "    # Labels for real images: all ones\n",
        "    real = np.ones((batch_size, 1))\n",
        "\n",
        "    # Labels for fake images: all zeros\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        for _ in range(m):\n",
        "\n",
        "            # -------------------------\n",
        "            #  Train the Discriminator\n",
        "            # -------------------------\n",
        "\n",
        "\n",
        "            # Get labeled examples\n",
        "            imgs_labeled, labels = dataset.batch_labeled(batch_size)\n",
        "\n",
        "            # Get unlabeled examples\n",
        "            imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
        "\n",
        "            # Generate a batch of fake images\n",
        "            z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "            fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "            fake_labels = to_categorical(fake_labels, num_classes=num_classes)\n",
        "            imgs_gen = generator.predict([z, fake_labels])\n",
        "\n",
        "            # Train discriminator\n",
        "            loss_d_labeled_realOrFake, acc_d_labeled_realOrFake = discriminator_realOrFake.train_on_batch(imgs_labeled, real)\n",
        "            loss_d_unlabeled_realOrFake, acc_d_unlabeled_realOrFake = discriminator_realOrFake.train_on_batch(imgs_unlabeled, real)\n",
        "            loss_d_gen_realOrFake, acc_d_gen_realOrFake = discriminator_realOrFake.train_on_batch(imgs_gen, fake)\n",
        "            loss_d_labeled_class, acc_d_labeled_class = discriminator_class.train_on_batch(imgs_labeled, labels)\n",
        "            loss_d_gen_class, acc_d_gen_class = discriminator_class.train_on_batch(imgs_gen, fake_labels)\n",
        "\n",
        "            # Calculate loss and acc\n",
        "            loss_d_train_realOrFake = np.add(loss_d_labeled_realOrFake, loss_d_unlabeled_realOrFake)\n",
        "            loss_d_class = np.add(loss_d_labeled_class, loss_d_gen_class)\n",
        "            loss_d_class = loss_d_labeled_class\n",
        "            loss_d_realOrFake = np.add(loss_d_gen_realOrFake, np.add(loss_d_labeled_realOrFake, loss_d_unlabeled_realOrFake))\n",
        "            loss_d = np.add(loss_d_class, loss_d_realOrFake)\n",
        "            acc_d_class = np.add(acc_d_labeled_class, acc_d_gen_class)/2.0\n",
        "            acc_d_class = acc_d_labeled_class\n",
        "            acc_d_realOrFake = np.add(acc_d_gen_realOrFake, np.add(acc_d_labeled_realOrFake, acc_d_unlabeled_realOrFake))/3.0\n",
        "            acc_d = np.add(acc_d_class, acc_d_realOrFake)/2.0\n",
        "\n",
        "        for _ in range(n):\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train the Generator\n",
        "            # ---------------------\n",
        "\n",
        "            # Generate a batch of fake images\n",
        "            z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "            fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "            fake_labels = to_categorical(fake_labels, num_classes=num_classes)\n",
        "\n",
        "            # Train Generator\n",
        "            loss_g_realOrFake, acc_g_realOrFake = gan_realOrFake.train_on_batch([z, fake_labels], fake)\n",
        "            # loss_g_class, acc_g_class = gan_class.train_on_batch([z, fake_labels], fake_labels)\n",
        "\n",
        "            # Calculate loss\n",
        "            # loss_g = np.add(loss_g_realOrFake, loss_g_class)\n",
        "            loss_g = losses_g_realOrFake\n",
        "\n",
        "        if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "            # Save Discriminator supervised classification loss to be plotted after training\n",
        "            losses_d_class.append(loss_d_class)\n",
        "            losses_d_realOrFake.append(loss_d_realOrFake)\n",
        "            # losses_g_class.append(loss_g_class)\n",
        "            losses_g_realOrFake.append(loss_g_realOrFake)\n",
        "            \n",
        "            iteration_checkpoints.append(iteration + 1)\n",
        "\n",
        "            # Output training progress\n",
        "            print(\n",
        "                \"%d [D loss class: %.4f, acc: %.2f%%] [D loss realOrFake: %.4f, acc:%.2f%%] [G loss realOrFake: %.4f, acc: %.2f%%]\"\n",
        "                % (iteration + 1, \n",
        "                    loss_d_class, 100 * acc_d_class,\n",
        "                    loss_d_realOrFake, 100 * acc_d_realOrFake, \n",
        "                    # loss_g_class, 100 * acc_g_class,\n",
        "                    loss_g_realOrFake, 100 * acc_g_realOrFake))\n",
        "            \n",
        "            discriminator_class.save(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_class-\" + str(iteration+1) + \".h5\")\n",
        "            discriminator_realOrFake.save(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_realOrFake-\" + str(iteration+1) + \".h5\")\n",
        "            generator.save(\"./models/models-label-\" + str(num_labeled) + \"/generator-\" + str(iteration+1) + \".h5\")\n",
        "            file1 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_d_class.json\"\n",
        "            file2 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_d_realOrFake.json\"\n",
        "            # file3 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_g_class.json\"\n",
        "            file4 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_g_realOrFake.json\"\n",
        "            with open(file1, 'w') as json_file:\n",
        "                  json.dump(str(losses_d_class), json_file)\n",
        "            with open(file2, 'w') as json_file:\n",
        "                  json.dump(str(losses_d_realOrFake), json_file)\n",
        "            # with open(file3, 'w') as json_file:\n",
        "            #       json.dump(str(losses_g_class), json_file)\n",
        "            with open(file4, 'w') as json_file:\n",
        "                  json.dump(str(losses_g_realOrFake), json_file)\n",
        "            \n",
        "            x,y = dataset.training_set()\n",
        "            _, acc = discriminator_class.evaluate(x,y)\n",
        "            print(str(100*acc)+\"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk81F4pc8wUk",
        "colab_type": "code",
        "outputId": "fcf4d1fd-b6ab-4282-f23d-85aac8afecbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set hyperparameters\n",
        "iterations = 8000 # 8000\n",
        "batch_size = 32\n",
        "save_interval = 100\n",
        "num_labeled = 1000  # Number of labeled examples to use (rest will be used as unlabeled)\n",
        "m = 1 # iteration of Discriminator\n",
        "n = 1 # iteration of Generator\n",
        "\n",
        "# dataset = Dataset(num_labeled)\n",
        "\n",
        "# losses_d_labeled_realOrFake = []\n",
        "# losses_d_unlabeled_realOrFake = []\n",
        "# losses_d_gen_realOrFake = []\n",
        "# losses_d_labeled_class = []\n",
        "# losses_d_gen_class = []\n",
        "# losses_d_train_realOrFake = []\n",
        "losses_d_class = []\n",
        "losses_d_realOrFake = []\n",
        "losses_d = []\n",
        "losses_g_realOrFake = []\n",
        "losses_g_class = []\n",
        "losses_g = []\n",
        "\n",
        "iteration_checkpoints = []\n",
        "\n",
        "starttime = time.clock()\n",
        "\n",
        "# Train the SGAN for the specified number of iterations\n",
        "train(iterations, batch_size, save_interval, m, n)\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Training time: %.4fs\" % (endtime - starttime))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 [D loss class: 1.0212, acc: 84.38%] [D loss realOrFake: 1.0365, acc:87.50%] [G loss realOrFake: 2.0127, acc: 9.38%]\n",
            "9600/9600 [==============================] - 1s 144us/step\n",
            "48.354166666666664%\n",
            "200 [D loss class: 1.3116, acc: 53.12%] [D loss realOrFake: 0.7176, acc:95.83%] [G loss realOrFake: 1.6556, acc: 3.12%]\n",
            "9600/9600 [==============================] - 1s 139us/step\n",
            "57.69791666666667%\n",
            "300 [D loss class: 1.3318, acc: 56.25%] [D loss realOrFake: 0.5190, acc:98.96%] [G loss realOrFake: 1.7475, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 140us/step\n",
            "26.447916666666664%\n",
            "400 [D loss class: 0.9919, acc: 68.75%] [D loss realOrFake: 0.3736, acc:98.96%] [G loss realOrFake: 1.3394, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 136us/step\n",
            "49.604166666666664%\n",
            "500 [D loss class: 1.0817, acc: 62.50%] [D loss realOrFake: 0.3263, acc:98.96%] [G loss realOrFake: 1.3385, acc: 59.38%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "52.416666666666664%\n",
            "600 [D loss class: 0.7571, acc: 81.25%] [D loss realOrFake: 0.3139, acc:98.96%] [G loss realOrFake: 1.2862, acc: 53.12%]\n",
            "9600/9600 [==============================] - 1s 129us/step\n",
            "50.145833333333336%\n",
            "700 [D loss class: 0.9743, acc: 59.38%] [D loss realOrFake: 0.2552, acc:100.00%] [G loss realOrFake: 1.3830, acc: 65.62%]\n",
            "9600/9600 [==============================] - 1s 140us/step\n",
            "33.875%\n",
            "800 [D loss class: 1.0901, acc: 71.88%] [D loss realOrFake: 0.2983, acc:98.96%] [G loss realOrFake: 1.3763, acc: 31.25%]\n",
            "9600/9600 [==============================] - 1s 136us/step\n",
            "18.229166666666664%\n",
            "900 [D loss class: 1.1104, acc: 71.88%] [D loss realOrFake: 0.2613, acc:100.00%] [G loss realOrFake: 1.3822, acc: 65.62%]\n",
            "9600/9600 [==============================] - 1s 143us/step\n",
            "12.375%\n",
            "1000 [D loss class: 1.6512, acc: 50.00%] [D loss realOrFake: 0.1424, acc:100.00%] [G loss realOrFake: 1.1363, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 142us/step\n",
            "44.59375%\n",
            "1100 [D loss class: 1.2038, acc: 62.50%] [D loss realOrFake: 0.2049, acc:98.96%] [G loss realOrFake: 1.3730, acc: 3.12%]\n",
            "9600/9600 [==============================] - 1s 140us/step\n",
            "50.479166666666664%\n",
            "1200 [D loss class: 1.4914, acc: 46.88%] [D loss realOrFake: 0.1941, acc:100.00%] [G loss realOrFake: 1.3856, acc: 65.62%]\n",
            "9600/9600 [==============================] - 1s 131us/step\n",
            "16.53125%\n",
            "1300 [D loss class: 1.1967, acc: 62.50%] [D loss realOrFake: 0.1476, acc:98.96%] [G loss realOrFake: 1.3763, acc: 62.50%]\n",
            "9600/9600 [==============================] - 1s 138us/step\n",
            "32.416666666666664%\n",
            "1400 [D loss class: 1.1298, acc: 53.12%] [D loss realOrFake: 0.1329, acc:100.00%] [G loss realOrFake: 1.2066, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 150us/step\n",
            "47.89583333333333%\n",
            "1500 [D loss class: 0.8668, acc: 71.88%] [D loss realOrFake: 0.1573, acc:98.96%] [G loss realOrFake: 1.3300, acc: 56.25%]\n",
            "9600/9600 [==============================] - 1s 138us/step\n",
            "19.770833333333336%\n",
            "1600 [D loss class: 0.7974, acc: 75.00%] [D loss realOrFake: 0.1500, acc:100.00%] [G loss realOrFake: 1.2365, acc: 68.75%]\n",
            "9600/9600 [==============================] - 1s 134us/step\n",
            "16.302083333333332%\n",
            "1700 [D loss class: 1.8955, acc: 43.75%] [D loss realOrFake: 0.1068, acc:100.00%] [G loss realOrFake: 1.2122, acc: 68.75%]\n",
            "9600/9600 [==============================] - 1s 132us/step\n",
            "57.70833333333333%\n",
            "1800 [D loss class: 1.2810, acc: 53.12%] [D loss realOrFake: 0.1089, acc:100.00%] [G loss realOrFake: 1.1052, acc: 78.12%]\n",
            "9600/9600 [==============================] - 1s 139us/step\n",
            "14.552083333333332%\n",
            "1900 [D loss class: 1.2654, acc: 46.88%] [D loss realOrFake: 0.1124, acc:100.00%] [G loss realOrFake: 1.3305, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 139us/step\n",
            "15.71875%\n",
            "2000 [D loss class: 0.8075, acc: 68.75%] [D loss realOrFake: 0.1559, acc:98.96%] [G loss realOrFake: 1.4521, acc: 59.38%]\n",
            "9600/9600 [==============================] - 1s 136us/step\n",
            "36.833333333333336%\n",
            "2100 [D loss class: 0.9676, acc: 65.62%] [D loss realOrFake: 0.0875, acc:100.00%] [G loss realOrFake: 1.3313, acc: 62.50%]\n",
            "9600/9600 [==============================] - 1s 131us/step\n",
            "26.458333333333332%\n",
            "2200 [D loss class: 2.2395, acc: 40.62%] [D loss realOrFake: 0.2627, acc:98.96%] [G loss realOrFake: 1.2052, acc: 65.62%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "45.260416666666664%\n",
            "2300 [D loss class: 1.4456, acc: 53.12%] [D loss realOrFake: 0.1003, acc:100.00%] [G loss realOrFake: 1.1603, acc: 65.62%]\n",
            "9600/9600 [==============================] - 1s 132us/step\n",
            "52.697916666666664%\n",
            "2400 [D loss class: 1.4463, acc: 59.38%] [D loss realOrFake: 0.1192, acc:100.00%] [G loss realOrFake: 1.0623, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 135us/step\n",
            "28.572916666666664%\n",
            "2500 [D loss class: 1.1963, acc: 59.38%] [D loss realOrFake: 0.0826, acc:100.00%] [G loss realOrFake: 1.3235, acc: 71.88%]\n",
            "9600/9600 [==============================] - 1s 132us/step\n",
            "43.552083333333336%\n",
            "2600 [D loss class: 0.8571, acc: 65.62%] [D loss realOrFake: 0.1092, acc:98.96%] [G loss realOrFake: 1.5059, acc: 56.25%]\n",
            "9600/9600 [==============================] - 1s 137us/step\n",
            "41.69791666666667%\n",
            "2700 [D loss class: 0.8072, acc: 75.00%] [D loss realOrFake: 0.1092, acc:100.00%] [G loss realOrFake: 1.0038, acc: 68.75%]\n",
            "9600/9600 [==============================] - 1s 136us/step\n",
            "40.59375%\n",
            "2800 [D loss class: 1.0038, acc: 62.50%] [D loss realOrFake: 0.0588, acc:100.00%] [G loss realOrFake: 1.3110, acc: 62.50%]\n",
            "9600/9600 [==============================] - 1s 139us/step\n",
            "18.40625%\n",
            "2900 [D loss class: 2.0616, acc: 56.25%] [D loss realOrFake: 0.0931, acc:98.96%] [G loss realOrFake: 1.3066, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 135us/step\n",
            "46.270833333333336%\n",
            "3000 [D loss class: 0.7269, acc: 75.00%] [D loss realOrFake: 0.1680, acc:96.88%] [G loss realOrFake: 1.1951, acc: 50.00%]\n",
            "9600/9600 [==============================] - 1s 136us/step\n",
            "17.083333333333332%\n",
            "3100 [D loss class: 2.3593, acc: 46.88%] [D loss realOrFake: 0.2310, acc:96.88%] [G loss realOrFake: 1.4518, acc: 28.12%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "21.375%\n",
            "3200 [D loss class: 1.8525, acc: 50.00%] [D loss realOrFake: 0.0577, acc:100.00%] [G loss realOrFake: 1.0794, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 138us/step\n",
            "19.239583333333332%\n",
            "3300 [D loss class: 1.3843, acc: 50.00%] [D loss realOrFake: 0.0593, acc:100.00%] [G loss realOrFake: 1.2108, acc: 75.00%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "54.364583333333336%\n",
            "3400 [D loss class: 1.0724, acc: 59.38%] [D loss realOrFake: 0.0776, acc:100.00%] [G loss realOrFake: 1.3531, acc: 75.00%]\n",
            "9600/9600 [==============================] - 1s 136us/step\n",
            "31.135416666666664%\n",
            "3500 [D loss class: 1.0892, acc: 56.25%] [D loss realOrFake: 0.1246, acc:97.92%] [G loss realOrFake: 1.4834, acc: 56.25%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "29.625%\n",
            "3600 [D loss class: 1.2673, acc: 56.25%] [D loss realOrFake: 0.0580, acc:100.00%] [G loss realOrFake: 1.2924, acc: 3.12%]\n",
            "9600/9600 [==============================] - 1s 135us/step\n",
            "48.375%\n",
            "3700 [D loss class: 1.1919, acc: 56.25%] [D loss realOrFake: 0.0592, acc:100.00%] [G loss realOrFake: 1.2778, acc: 68.75%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "27.90625%\n",
            "3800 [D loss class: 1.1041, acc: 62.50%] [D loss realOrFake: 0.0889, acc:100.00%] [G loss realOrFake: 1.4885, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 132us/step\n",
            "12.90625%\n",
            "3900 [D loss class: 1.4177, acc: 53.12%] [D loss realOrFake: 0.0868, acc:100.00%] [G loss realOrFake: 1.2829, acc: 62.50%]\n",
            "9600/9600 [==============================] - 1s 133us/step\n",
            "48.833333333333336%\n",
            "4000 [D loss class: 1.2491, acc: 65.62%] [D loss realOrFake: 0.1245, acc:98.96%] [G loss realOrFake: 1.1172, acc: 75.00%]\n",
            "9600/9600 [==============================] - 1s 137us/step\n",
            "38.96875%\n",
            "4100 [D loss class: 0.8896, acc: 78.12%] [D loss realOrFake: 0.0465, acc:100.00%] [G loss realOrFake: 1.4481, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "22.552083333333332%\n",
            "4200 [D loss class: 1.1503, acc: 56.25%] [D loss realOrFake: 0.0475, acc:100.00%] [G loss realOrFake: 1.2726, acc: 75.00%]\n",
            "9600/9600 [==============================] - 1s 138us/step\n",
            "47.39583333333333%\n",
            "4300 [D loss class: 1.4556, acc: 50.00%] [D loss realOrFake: 0.2713, acc:98.96%] [G loss realOrFake: 1.2076, acc: 62.50%]\n",
            "9600/9600 [==============================] - 1s 145us/step\n",
            "28.083333333333332%\n",
            "4400 [D loss class: 1.0623, acc: 68.75%] [D loss realOrFake: 0.0637, acc:100.00%] [G loss realOrFake: 1.0852, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 134us/step\n",
            "27.250000000000004%\n",
            "4500 [D loss class: 1.1745, acc: 59.38%] [D loss realOrFake: 0.0720, acc:98.96%] [G loss realOrFake: 1.2671, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 139us/step\n",
            "20.34375%\n",
            "4600 [D loss class: 1.0632, acc: 59.38%] [D loss realOrFake: 0.0500, acc:100.00%] [G loss realOrFake: 1.1196, acc: 3.12%]\n",
            "9600/9600 [==============================] - 1s 134us/step\n",
            "40.875%\n",
            "4700 [D loss class: 1.0970, acc: 71.88%] [D loss realOrFake: 0.0703, acc:100.00%] [G loss realOrFake: 1.2848, acc: 75.00%]\n",
            "9600/9600 [==============================] - 1s 137us/step\n",
            "50.61458333333333%\n",
            "4800 [D loss class: 1.2029, acc: 59.38%] [D loss realOrFake: 0.0858, acc:100.00%] [G loss realOrFake: 1.3717, acc: 68.75%]\n",
            "9600/9600 [==============================] - 1s 139us/step\n",
            "14.322916666666666%\n",
            "4900 [D loss class: 1.0544, acc: 68.75%] [D loss realOrFake: 0.2077, acc:96.88%] [G loss realOrFake: 1.3309, acc: 3.12%]\n",
            "9600/9600 [==============================] - 1s 131us/step\n",
            "48.614583333333336%\n",
            "5000 [D loss class: 0.9163, acc: 65.62%] [D loss realOrFake: 0.0565, acc:100.00%] [G loss realOrFake: 1.3324, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 152us/step\n",
            "45.927083333333336%\n",
            "5100 [D loss class: 1.0913, acc: 53.12%] [D loss realOrFake: 0.0505, acc:100.00%] [G loss realOrFake: 1.2937, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 147us/step\n",
            "52.53124999999999%\n",
            "5200 [D loss class: 1.2017, acc: 56.25%] [D loss realOrFake: 0.1518, acc:98.96%] [G loss realOrFake: 1.1473, acc: 37.50%]\n",
            "9600/9600 [==============================] - 1s 134us/step\n",
            "22.28125%\n",
            "5300 [D loss class: 0.7158, acc: 78.12%] [D loss realOrFake: 0.2775, acc:93.75%] [G loss realOrFake: 1.2929, acc: 71.88%]\n",
            "9600/9600 [==============================] - 1s 133us/step\n",
            "41.041666666666664%\n",
            "5400 [D loss class: 1.0831, acc: 84.38%] [D loss realOrFake: 0.0685, acc:100.00%] [G loss realOrFake: 1.1863, acc: 75.00%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "38.04166666666667%\n",
            "5500 [D loss class: 1.2717, acc: 62.50%] [D loss realOrFake: 0.0396, acc:100.00%] [G loss realOrFake: 1.4434, acc: 71.88%]\n",
            "9600/9600 [==============================] - 1s 139us/step\n",
            "40.14583333333333%\n",
            "5600 [D loss class: 1.2031, acc: 65.62%] [D loss realOrFake: 0.0908, acc:98.96%] [G loss realOrFake: 1.2648, acc: 71.88%]\n",
            "9600/9600 [==============================] - 1s 149us/step\n",
            "35.979166666666664%\n",
            "5700 [D loss class: 0.6402, acc: 84.38%] [D loss realOrFake: 0.0415, acc:100.00%] [G loss realOrFake: 1.2107, acc: 3.12%]\n",
            "9600/9600 [==============================] - 1s 139us/step\n",
            "53.145833333333336%\n",
            "5800 [D loss class: 1.3652, acc: 68.75%] [D loss realOrFake: 0.0421, acc:100.00%] [G loss realOrFake: 1.2067, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 138us/step\n",
            "51.322916666666664%\n",
            "5900 [D loss class: 1.5219, acc: 53.12%] [D loss realOrFake: 0.0587, acc:100.00%] [G loss realOrFake: 1.0980, acc: 71.88%]\n",
            "9600/9600 [==============================] - 1s 140us/step\n",
            "45.5625%\n",
            "6000 [D loss class: 1.0639, acc: 62.50%] [D loss realOrFake: 0.0538, acc:100.00%] [G loss realOrFake: 1.0303, acc: 68.75%]\n",
            "9600/9600 [==============================] - 1s 138us/step\n",
            "34.61458333333333%\n",
            "6100 [D loss class: 0.9986, acc: 62.50%] [D loss realOrFake: 0.1201, acc:97.92%] [G loss realOrFake: 1.1128, acc: 68.75%]\n",
            "9600/9600 [==============================] - 1s 135us/step\n",
            "30.489583333333332%\n",
            "6200 [D loss class: 1.1241, acc: 59.38%] [D loss realOrFake: 0.0394, acc:100.00%] [G loss realOrFake: 1.2258, acc: 75.00%]\n",
            "9600/9600 [==============================] - 1s 152us/step\n",
            "46.10416666666667%\n",
            "6300 [D loss class: 1.2139, acc: 68.75%] [D loss realOrFake: 0.2823, acc:97.92%] [G loss realOrFake: 1.2295, acc: 71.88%]\n",
            "9600/9600 [==============================] - 1s 137us/step\n",
            "15.083333333333334%\n",
            "6400 [D loss class: 1.1624, acc: 65.62%] [D loss realOrFake: 0.1210, acc:98.96%] [G loss realOrFake: 1.1746, acc: 75.00%]\n",
            "9600/9600 [==============================] - 1s 133us/step\n",
            "30.9375%\n",
            "6500 [D loss class: 0.8809, acc: 62.50%] [D loss realOrFake: 0.1095, acc:98.96%] [G loss realOrFake: 1.2589, acc: 62.50%]\n",
            "9600/9600 [==============================] - 1s 140us/step\n",
            "40.677083333333336%\n",
            "6600 [D loss class: 0.9089, acc: 68.75%] [D loss realOrFake: 0.0646, acc:100.00%] [G loss realOrFake: 1.2235, acc: 71.88%]\n",
            "9600/9600 [==============================] - 1s 135us/step\n",
            "39.739583333333336%\n",
            "6700 [D loss class: 1.2286, acc: 53.12%] [D loss realOrFake: 0.0301, acc:100.00%] [G loss realOrFake: 1.2243, acc: 65.62%]\n",
            "9600/9600 [==============================] - 1s 133us/step\n",
            "35.94791666666667%\n",
            "6800 [D loss class: 0.8684, acc: 75.00%] [D loss realOrFake: 0.0439, acc:100.00%] [G loss realOrFake: 1.1359, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 136us/step\n",
            "15.572916666666666%\n",
            "6900 [D loss class: 0.6751, acc: 75.00%] [D loss realOrFake: 0.0754, acc:100.00%] [G loss realOrFake: 1.6556, acc: 59.38%]\n",
            "9600/9600 [==============================] - 1s 140us/step\n",
            "39.895833333333336%\n",
            "7000 [D loss class: 0.7854, acc: 65.62%] [D loss realOrFake: 0.1075, acc:98.96%] [G loss realOrFake: 1.1068, acc: 3.12%]\n",
            "9600/9600 [==============================] - 1s 138us/step\n",
            "28.958333333333336%\n",
            "7100 [D loss class: 1.0742, acc: 62.50%] [D loss realOrFake: 0.0587, acc:100.00%] [G loss realOrFake: 1.1998, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 143us/step\n",
            "27.979166666666664%\n",
            "7200 [D loss class: 1.5356, acc: 65.62%] [D loss realOrFake: 0.1634, acc:98.96%] [G loss realOrFake: 1.3008, acc: 68.75%]\n",
            "9600/9600 [==============================] - 1s 144us/step\n",
            "24.333333333333336%\n",
            "7300 [D loss class: 1.2945, acc: 65.62%] [D loss realOrFake: 0.1044, acc:100.00%] [G loss realOrFake: 1.0299, acc: 25.00%]\n",
            "9600/9600 [==============================] - 1s 145us/step\n",
            "33.135416666666664%\n",
            "7400 [D loss class: 0.8703, acc: 65.62%] [D loss realOrFake: 0.0427, acc:100.00%] [G loss realOrFake: 1.1674, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 153us/step\n",
            "36.72916666666667%\n",
            "7500 [D loss class: 1.1967, acc: 62.50%] [D loss realOrFake: 0.1756, acc:98.96%] [G loss realOrFake: 1.2788, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 139us/step\n",
            "24.958333333333332%\n",
            "7600 [D loss class: 0.9569, acc: 53.12%] [D loss realOrFake: 0.0571, acc:100.00%] [G loss realOrFake: 1.1138, acc: 71.88%]\n",
            "9600/9600 [==============================] - 1s 140us/step\n",
            "27.354166666666668%\n",
            "7700 [D loss class: 0.9953, acc: 59.38%] [D loss realOrFake: 0.0521, acc:100.00%] [G loss realOrFake: 1.2916, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 138us/step\n",
            "33.09375%\n",
            "7800 [D loss class: 1.0971, acc: 68.75%] [D loss realOrFake: 0.0246, acc:100.00%] [G loss realOrFake: 1.2766, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 141us/step\n",
            "28.239583333333336%\n",
            "7900 [D loss class: 1.0797, acc: 65.62%] [D loss realOrFake: 0.0336, acc:100.00%] [G loss realOrFake: 1.3022, acc: 0.00%]\n",
            "9600/9600 [==============================] - 1s 143us/step\n",
            "25.833333333333336%\n",
            "8000 [D loss class: 0.7473, acc: 75.00%] [D loss realOrFake: 0.0419, acc:100.00%] [G loss realOrFake: 1.2092, acc: 65.62%]\n",
            "9600/9600 [==============================] - 1s 147us/step\n",
            "26.75%\n",
            "Training time: 1034.4122s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhXWbInEqCHm",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhMqoLhM8y4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c663b727-6b96-440c-e988-f02bb4a15e47"
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "tmodel = keras.models.load_model(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_class-5700.h5\")\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "# _, accuracy = discriminator_class.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9600/9600 [==============================] - 3s 322us/step\n",
            "Training Accuracy: 53.15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBaOjdtcqVki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6de34103-c13e-4a94-922d-504f72ee2815"
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "# tmodel = keras.models.load_model(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_class-5700.h5\")\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "# _, accuracy = discriminator_class.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2400/2400 [==============================] - 0s 139us/step\n",
            "Training Accuracy: 48.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQPwltXAqaBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}