{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_xDiTP_67MV",
        "colab_type": "code",
        "outputId": "44b967f4-b6ef-4c08-ffe4-2f82748c4be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import (Dense, Conv2D, BatchNormalization, Activation, \n",
        "                          AveragePooling2D, Input, Flatten, \n",
        "                          Concatenate, Dropout, Lambda, \n",
        "                          Reshape, Embedding, Multiply)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, Callback\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from __future__ import print_function\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSaEOfjG6ztu",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_hPw_jy8jea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset_CIFAR10:\n",
        "    def __init__(self, num_labeled):\n",
        "\n",
        "        def preprocess_imgs(x):\n",
        "            # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "            x = (x.astype(np.float32) - 127.5) / 127.5\n",
        "            return x\n",
        "\n",
        "        def preprocess_labels(y):\n",
        "            y = y.reshape(-1, 1)\n",
        "            y = to_categorical(y, num_classes = 10)\n",
        "            return y\n",
        "\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        x_train = preprocess_imgs(x_train)\n",
        "        y_train = preprocess_labels(y_train)\n",
        "        x_test = preprocess_imgs(x_test)\n",
        "        y_test = preprocess_labels(y_test)\n",
        "\n",
        "        # Number labeled examples to use for training\n",
        "        self.num_labeled = num_labeled\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "        del x_train, y_train, x_test, y_test\n",
        "\n",
        "    def batch_labeled(self, batch_size):\n",
        "        # Get a random batch of labeled images and their labels\n",
        "        idx = np.random.randint(0, self.num_labeled, batch_size)\n",
        "        imgs = self.x_train[idx]\n",
        "        labels = self.y_train[idx]\n",
        "        return imgs, labels\n",
        "\n",
        "    def batch_unlabeled(self, batch_size):\n",
        "        # Get a random batch of unlabeled images\n",
        "        idx = np.random.randint(self.num_labeled, self.x_train.shape[0], batch_size)\n",
        "        imgs = self.x_train[idx]\n",
        "        return imgs\n",
        "\n",
        "    def training_set(self):\n",
        "        return self.x_train, self.y_train\n",
        "\n",
        "    def test_set(self):\n",
        "        return self.x_test, self.y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5nWXxcZdgQb",
        "colab_type": "text"
      },
      "source": [
        "## Check the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf5jJexNdigk",
        "colab_type": "code",
        "outputId": "b08e22d1-1dac-4212-eede-bb6718c0d3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# CIFAR-10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Training set\n",
        "d_ytrain = {}\n",
        "for i in range(10):\n",
        "  d_ytrain[i] = 0\n",
        "for i in range(len(y_train)):\n",
        "  d_ytrain[y_train[i][0]] = d_ytrain.get(y_train[i][0]) + 1\n",
        "print(\"CIFAR-10 training set:\")\n",
        "print(d_ytrain)\n",
        "\n",
        "# Test set\n",
        "d_ytest = {}\n",
        "for i in range(10):\n",
        "  d_ytest[i] = 0\n",
        "for i in range(len(y_test)):\n",
        "  d_ytest[y_test[i][0]] = d_ytest.get(y_test[i][0]) + 1\n",
        "print(\"CIFAR-10 test set:\")\n",
        "print(d_ytest)\n",
        "\n",
        "del x_train, y_train, x_test, y_test"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CIFAR-10 training set:\n",
            "{0: 5000, 1: 5000, 2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000, 8: 5000, 9: 5000}\n",
            "CIFAR-10 test set:\n",
            "{0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwrpoGSKdmrp",
        "colab_type": "text"
      },
      "source": [
        "# Number of labeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvYSG5vKdoSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labeled = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjhxJulqdyFs",
        "colab_type": "text"
      },
      "source": [
        "# SCGAN-2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipcTHBiShR9m",
        "colab_type": "text"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA0DtW_2d14g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "input_shape = img_shape = (32, 32, 3)\n",
        "num_classes = 10\n",
        "z_dim = 100   # Size of the noise vector, used as input to the Generator\n",
        "n = 3\n",
        "depth = n * 6 + 2   # Depth of ResNet model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgzlORUA7eUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eZ2B42_7fiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abhpWtyBfaxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CIFAR-10\n",
        "\n",
        "def build_generator(z_dim):\n",
        "  \n",
        "    z = Input(shape=(z_dim, ))\n",
        "    label = Input(shape=(num_classes, ), dtype='float32')\n",
        "    label_embedding = Dense(z_dim, input_dim=num_classes)(label)\n",
        "    joined_representation = Multiply()([z, label_embedding])\n",
        "    \n",
        "#     model = Sequential()\n",
        "\n",
        "    # Reshape input into 8x8x256 tensor via a fully connected layer\n",
        "    model = Dense(256 * 8 * 8, input_dim=z_dim)(joined_representation)\n",
        "    model = Reshape((8, 8, 256))(model)\n",
        "\n",
        "    # Transposed convolution layer, from 8x8x256 into 16x16x128 tensor\n",
        "    model = Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(model)\n",
        "\n",
        "    # Batch normalization\n",
        "    model = BatchNormalization()(model)\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model = LeakyReLU(alpha=0.01)(model)\n",
        "\n",
        "    # Transposed convolution layer, from 16x16x128 to 16x16x64 tensor\n",
        "    model = Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')(model)\n",
        "\n",
        "    # Batch normalization\n",
        "    model = BatchNormalization()(model)\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model = LeakyReLU(alpha=0.01)(model)\n",
        "\n",
        "    # Transposed convolution layer, from 16x16x64 to 32x32x3 tensor\n",
        "    model = Conv2DTranspose(3, kernel_size=3, strides=2, padding='same')(model)\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "    conditioned_img = Activation('tanh')(model)\n",
        "    \n",
        "#     conditioned_img = model(joined_representation)\n",
        "\n",
        "    model = Model([z, label], conditioned_img)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ09_xGfffbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_net(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes, kernel_initializer='he_normal')(y)\n",
        "    # outputs = Dense(num_classes,\n",
        "    #                 activation='softmax',\n",
        "    #                 kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx6rxPK2hiqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61923916-4b3a-44e2-a230-b56393aa1280"
      },
      "source": [
        "build_discriminator_net(img_shape, depth).summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 32, 32, 16)   448         input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 32, 32, 16)   64          conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 32, 32, 16)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 32, 32, 16)   2320        activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 32, 32, 16)   64          conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 32, 32, 16)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 32, 32, 16)   2320        activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 32, 32, 16)   64          conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 32, 32, 16)   0           activation_123[0][0]             \n",
            "                                                                 batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 32, 32, 16)   0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 32, 32, 16)   2320        activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 32, 32, 16)   64          conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 32, 32, 16)   0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 32, 32, 16)   2320        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 32, 32, 16)   64          conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 32, 32, 16)   0           activation_125[0][0]             \n",
            "                                                                 batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 32, 32, 16)   0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 32, 32, 16)   2320        activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 32, 32, 16)   64          conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 32, 32, 16)   0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 32, 32, 16)   2320        activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 32, 32, 16)   64          conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 32, 32, 16)   0           activation_127[0][0]             \n",
            "                                                                 batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 32, 32, 16)   0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 16, 16, 32)   4640        activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 16, 16, 32)   128         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 16, 16, 32)   0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 16, 16, 32)   9248        activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 16, 16, 32)   544         activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 16, 16, 32)   128         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 16, 16, 32)   0           conv2d_136[0][0]                 \n",
            "                                                                 batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 16, 16, 32)   0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 16, 16, 32)   9248        activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 16, 16, 32)   128         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 16, 16, 32)   0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 16, 16, 32)   9248        activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 16, 16, 32)   128         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 16, 16, 32)   0           activation_131[0][0]             \n",
            "                                                                 batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 16, 16, 32)   0           add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 16, 16, 32)   9248        activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 16, 16, 32)   128         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 16, 16, 32)   0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 16, 16, 32)   9248        activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 16, 16, 32)   128         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 16, 16, 32)   0           activation_133[0][0]             \n",
            "                                                                 batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 16, 16, 32)   0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 8, 8, 64)     18496       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 8, 8, 64)     256         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 8, 8, 64)     0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 8, 8, 64)     36928       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 8, 8, 64)     2112        activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 8, 8, 64)     256         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 8, 8, 64)     0           conv2d_143[0][0]                 \n",
            "                                                                 batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 8, 8, 64)     0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 8, 8, 64)     36928       activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 8, 8, 64)     256         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 8, 8, 64)     0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 8, 8, 64)     36928       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 8, 8, 64)     256         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 8, 8, 64)     0           activation_137[0][0]             \n",
            "                                                                 batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 8, 8, 64)     0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 8, 8, 64)     36928       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 8, 8, 64)     256         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 8, 8, 64)     0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 8, 8, 64)     36928       activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 8, 8, 64)     256         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 8, 8, 64)     0           activation_139[0][0]             \n",
            "                                                                 batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 8, 8, 64)     0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 1, 1, 64)     0           activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 64)           0           average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 10)           650         flatten_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOTS0nBXhMhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_supervised(discriminator_net):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(discriminator_net)\n",
        "\n",
        "    # Softmax activation, giving predicted probability distribution over the real classes\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuxULq-IhOlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_unsupervised(discriminator_net):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(discriminator_net)\n",
        "\n",
        "    def predict(x):\n",
        "        # Transform distribution over real classes into a binary real-vs-fake probability\n",
        "        prediction = 1.0 - (1.0 / (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.0))\n",
        "        return prediction\n",
        "\n",
        "    # 'Real-vs-fake' output neuron defined above\n",
        "    model.add(Lambda(predict))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3LcMzjZhQFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gan(generator, discriminator):\n",
        "    \n",
        "    z = Input(shape=(z_dim, ))\n",
        "    label = Input(shape=(num_classes, ))\n",
        "    img = generator([z, label])\n",
        "    output = discriminator(img)\n",
        "    model = Model([z, label], output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X4FZirFhWA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Core Discriminator network:\n",
        "# These layers are shared during supervised and unsupervised training\n",
        "\n",
        "discriminator_net = build_discriminator_net(input_shape=img_shape, depth=depth)\n",
        "\n",
        "discriminator_supervised = build_discriminator_supervised(discriminator_net)\n",
        "discriminator_supervised.compile(loss='categorical_crossentropy',\n",
        "                                 metrics=['accuracy'],\n",
        "                                 optimizer=Adam())\n",
        "# discriminator_supervised.compile(loss='categorical_crossentropy',\n",
        "#                                  metrics=['accuracy'],\n",
        "#                                  optimizer=Adam(lr=lr_schedule(0)))\n",
        "\n",
        "discriminator_unsupervised = build_discriminator_unsupervised(discriminator_net)\n",
        "discriminator_unsupervised.compile(loss='binary_crossentropy',\n",
        "                                metrics=['accuracy'],\n",
        "                                optimizer=Adam())\n",
        "# discriminator_unsupervised.compile(loss='binary_crossentropy',\n",
        "#                                 metrics=['accuracy'],\n",
        "#                                 optimizer=Adam(lr=lr_schedule(0)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1nVA_1egKoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "086537e3-5a04-4b68-8b8e-22cf20ffb108"
      },
      "source": [
        "discriminator_unsupervised.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_1 (Model)              (None, 10)                274442    \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpsqRccThV02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f9c6fe23-c8d2-4879-ca98-8b98dbfced09"
      },
      "source": [
        "# Build the Generator\n",
        "generator = build_generator(z_dim)\n",
        "\n",
        "discriminator_supervised.trainable = False\n",
        "discriminator_unsupervised.trainable = False\n",
        "gan = build_gan(generator, discriminator_unsupervised)\n",
        "gan.compile(loss='binary_crossentropy', \n",
        "            metrics=['accuracy'], \n",
        "            optimizer=Adam())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yrZyUchhhER",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW25Txjghf7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1b3698dd-ec2c-44b6-f41f-6707b2ba4cc9"
      },
      "source": [
        "%mkdir models\n",
        "%mkdir losses\n",
        "%mkdir models/models-label-1000\n",
        "%mkdir losses/losses-label-1000"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n",
            "mkdir: cannot create directory ‘losses’: File exists\n",
            "mkdir: cannot create directory ‘losses/losses-label-1000’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNb1Q6IQkL-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'models')\n",
        "model_name = 'cifar10_model.{epoch:03d}.h5'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.accs = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.accs.append(logs.get('acc'))\n",
        "\n",
        "history = LossHistory()\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler, history]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF3q3OrbkUGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR2Hun3ChbSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretrain(iterations_pre, batch_size, save_interval, iter_epochs):\n",
        "  for iteration in range(iterations_pre):\n",
        "      imgs, labels = dataset.training_set()\n",
        "      # imgs, labels = dataset.batch_labeled(batch_size)\n",
        "      x_test, y_test = dataset.test_set()\n",
        "\n",
        "      # Compute quantities required for featurewise normalization (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(imgs)\n",
        "      discriminator_supervised.fit_generator(datagen.flow(imgs, labels, batch_size=batch_size),\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  epochs=iter_epochs, verbose=1, workers=4,\n",
        "                  callbacks=callbacks)\n",
        "      \n",
        "      if (iteration + 1) % save_interval == 0:\n",
        "          \n",
        "          # Output training progress\n",
        "          print(\n",
        "              \"%d [D loss class: %.4f, acc: %.2f%%]\"\n",
        "              % (iteration + 1, history.losses[-1], 100 * history.accs[-1]))\n",
        "          iteration_checkpoints.append(iteration + 1)\n",
        "          losses.append(history.losses[-1])\n",
        "          accs.append(history.accs[-1])\n",
        "          discriminator_supervised.save_weights(\"./models/discriminator_supervised-\" + str(iteration+1) + \".h5\")\n",
        "          \n",
        "          # x, y = dataset.training_set()\n",
        "          # _, accuracy = discriminator_supervised.evaluate(x, y)\n",
        "          # print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGIfXoRgW-0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def pretrain(iterations_pre, batch_size, save_interval):\n",
        "#   for iteration in range(iterations_pre):\n",
        "#       # imgs, labels = dataset.training_set()\n",
        "#       imgs, labels = dataset.batch_labeled(1000)\n",
        "      \n",
        "#       loss, acc = discriminator_supervised.train_on_batch(imgs, labels)\n",
        "      \n",
        "#       if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "#           losses.append(loss)\n",
        "#           accs.append(acc)\n",
        "#           iteration_checkpoints.append(iteration + 1)\n",
        "          \n",
        "#           # Output training progress\n",
        "#           print(\n",
        "#               \"%d [D loss class: %.4f, acc: %.2f%%]\"\n",
        "#               % (iteration + 1, loss, 100 * acc))\n",
        "#           discriminator_supervised.save(\"./models/discriminator_supervised-\" + str(iteration+1) + \".h5\")\n",
        "          \n",
        "#           # x, y = dataset.training_set()\n",
        "#           # _, accuracy = discriminator_supervised.evaluate(x, y)\n",
        "#           # print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nIEI7nOhsUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7be05d9-a0d8-4fd0-ce8d-67e7abb0b04a"
      },
      "source": [
        "# Set hyperparameters\n",
        "iterations_pre = 1\n",
        "iter_epochs = 10    # 20\n",
        "batch_size = 32\n",
        "save_interval = 1\n",
        "losses = []\n",
        "accs = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "dataset = Dataset_CIFAR10(num_labeled)\n",
        "\n",
        "discriminator_supervised.trainable = True\n",
        "\n",
        "starttime = time.clock()\n",
        "\n",
        "pretrain(iterations_pre, batch_size, save_interval\n",
        "         , iter_epochs\n",
        "         )\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Use time:\" + str(endtime-starttime) + \"s\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 97s 62ms/step - loss: 1.5701 - acc: 0.4472 - val_loss: 1.3243 - val_acc: 0.5593\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.55930, saving model to /content/useless_models/cifar10_model.001.h5\n",
            "Epoch 2/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 1.1708 - acc: 0.6105 - val_loss: 1.0860 - val_acc: 0.6451\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.55930 to 0.64510, saving model to /content/useless_models/cifar10_model.002.h5\n",
            "Epoch 3/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.9983 - acc: 0.6797 - val_loss: 1.1369 - val_acc: 0.6633\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.64510 to 0.66330, saving model to /content/useless_models/cifar10_model.003.h5\n",
            "Epoch 4/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 0.9064 - acc: 0.7191 - val_loss: 1.0271 - val_acc: 0.6893\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.66330 to 0.68930, saving model to /content/useless_models/cifar10_model.004.h5\n",
            "Epoch 5/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 0.8410 - acc: 0.7473 - val_loss: 0.9116 - val_acc: 0.7283\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.68930 to 0.72830, saving model to /content/useless_models/cifar10_model.005.h5\n",
            "Epoch 6/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 60ms/step - loss: 0.7989 - acc: 0.7652 - val_loss: 1.3589 - val_acc: 0.6076\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.72830\n",
            "Epoch 7/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 96s 61ms/step - loss: 0.7609 - acc: 0.7794 - val_loss: 0.9914 - val_acc: 0.7154\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.72830\n",
            "Epoch 8/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.7322 - acc: 0.7902 - val_loss: 0.9400 - val_acc: 0.7324\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.72830 to 0.73240, saving model to /content/useless_models/cifar10_model.008.h5\n",
            "Epoch 9/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 99s 63ms/step - loss: 0.7051 - acc: 0.8034 - val_loss: 0.8704 - val_acc: 0.7539\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.73240 to 0.75390, saving model to /content/useless_models/cifar10_model.009.h5\n",
            "Epoch 10/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.6869 - acc: 0.8101 - val_loss: 0.9557 - val_acc: 0.7458\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.75390\n",
            "Epoch 11/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6668 - acc: 0.8210 - val_loss: 0.7222 - val_acc: 0.8039\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.75390 to 0.80390, saving model to /content/useless_models/cifar10_model.011.h5\n",
            "Epoch 12/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.6544 - acc: 0.8250 - val_loss: 1.0627 - val_acc: 0.7256\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80390\n",
            "Epoch 13/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.6419 - acc: 0.8306 - val_loss: 0.8113 - val_acc: 0.7852\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80390\n",
            "Epoch 14/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 0.6252 - acc: 0.8359 - val_loss: 0.7379 - val_acc: 0.7989\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80390\n",
            "Epoch 15/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6185 - acc: 0.8403 - val_loss: 0.8563 - val_acc: 0.7781\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80390\n",
            "Epoch 16/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6148 - acc: 0.8436 - val_loss: 0.8010 - val_acc: 0.7962\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80390\n",
            "Epoch 17/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.6033 - acc: 0.8470 - val_loss: 0.7609 - val_acc: 0.8092\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.80390 to 0.80920, saving model to /content/useless_models/cifar10_model.017.h5\n",
            "Epoch 18/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 60ms/step - loss: 0.6003 - acc: 0.8510 - val_loss: 0.9563 - val_acc: 0.7539\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80920\n",
            "Epoch 19/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5932 - acc: 0.8524 - val_loss: 0.6544 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.80920 to 0.83450, saving model to /content/useless_models/cifar10_model.019.h5\n",
            "Epoch 20/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5845 - acc: 0.8560 - val_loss: 0.6874 - val_acc: 0.8290\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.83450\n",
            "1 [D loss class: 0.5393, acc: 93.75%]\n",
            "Epoch 1/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 60ms/step - loss: 0.5832 - acc: 0.8576 - val_loss: 0.7180 - val_acc: 0.8184\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.83450\n",
            "Epoch 2/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 98s 63ms/step - loss: 0.5706 - acc: 0.8621 - val_loss: 0.9259 - val_acc: 0.7709\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.83450\n",
            "Epoch 3/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.5686 - acc: 0.8621 - val_loss: 0.7211 - val_acc: 0.8139\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.83450\n",
            "Epoch 4/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 97s 62ms/step - loss: 0.5649 - acc: 0.8660 - val_loss: 0.7062 - val_acc: 0.8220\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.83450\n",
            "Epoch 5/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 97s 62ms/step - loss: 0.5638 - acc: 0.8654 - val_loss: 0.7460 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.83450\n",
            "Epoch 6/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 96s 62ms/step - loss: 0.5576 - acc: 0.8682 - val_loss: 0.7099 - val_acc: 0.8248\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.83450\n",
            "Epoch 7/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 97s 62ms/step - loss: 0.5533 - acc: 0.8703 - val_loss: 0.8390 - val_acc: 0.7768\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.83450\n",
            "Epoch 8/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 97s 62ms/step - loss: 0.5492 - acc: 0.8703 - val_loss: 0.7637 - val_acc: 0.8157\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.83450\n",
            "Epoch 9/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 97s 62ms/step - loss: 0.5438 - acc: 0.8729 - val_loss: 0.8840 - val_acc: 0.7815\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.83450\n",
            "Epoch 10/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.5402 - acc: 0.8743 - val_loss: 0.6279 - val_acc: 0.8452\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.83450 to 0.84520, saving model to /content/useless_models/cifar10_model.010.h5\n",
            "Epoch 11/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.5413 - acc: 0.8740 - val_loss: 0.8418 - val_acc: 0.8024\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.84520\n",
            "Epoch 12/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.5354 - acc: 0.8766 - val_loss: 0.6786 - val_acc: 0.8289\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.84520\n",
            "Epoch 13/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 0.5396 - acc: 0.8768 - val_loss: 0.7496 - val_acc: 0.8187\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.84520\n",
            "Epoch 14/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.5342 - acc: 0.8766 - val_loss: 0.7555 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.84520\n",
            "Epoch 15/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 100s 64ms/step - loss: 0.5275 - acc: 0.8801 - val_loss: 0.6755 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.84520\n",
            "Epoch 16/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.5293 - acc: 0.8800 - val_loss: 0.7003 - val_acc: 0.8298\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.84520\n",
            "Epoch 17/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.5252 - acc: 0.8813 - val_loss: 0.6244 - val_acc: 0.8554\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.84520 to 0.85540, saving model to /content/useless_models/cifar10_model.017.h5\n",
            "Epoch 18/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 0.5265 - acc: 0.8803 - val_loss: 0.7128 - val_acc: 0.8252\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.85540\n",
            "Epoch 19/20\n",
            "Learning rate:  0.001\n",
            " 747/1563 [=============>................] - ETA: 46s - loss: 0.5079 - acc: 0.8850Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lzo6IL5z9wE",
        "colab_type": "code",
        "outputId": "d354605f-c6b9-4753-b1fd-6e939bb0f17a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "tmodel.compile(loss='categorical_crossentropy',\n",
        "                                 metrics=['accuracy'],\n",
        "                                 optimizer=Adam())\n",
        "# tmodel.load_weights(\"./models/discriminator_supervised-2000.h5\", by_name=False)\n",
        "tmodel.load_weights(\"./models/cifar10_model.019.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 19s 375us/step\n",
            "Training Accuracy: 86.19%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etkdmP6Ez7Jy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dc853f23-977b-4194-f5eb-d15937cd9eae"
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "tmodel.load_weights(\"./models/cifar10_model.019.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the test set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 365us/step\n",
            "Test Accuracy: 83.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xEVpUqmWb90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "17aada3b-0ae4-46e7-c2d3-1001a211c0d3"
      },
      "source": [
        "div = 500\n",
        "ty = [history.accs[i*div] for i in range(0, len(history.accs)//div)]\n",
        "tx = [x for x in range(1*div, (len(ty)+1)*div, div)]\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(tx, ty, label=\"accs\", color='blue')\n",
        "plt.xticks(tx, rotation=90)\n",
        "plt.title(\"accs with epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accs\")\n",
        "plt.legend()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7efe4d651e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4UAAAFiCAYAAABBDn2zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCkkhBBCCCGEkAbz/wOIxEn3FoQc4AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOHm2K6nn-Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accs = []\n",
        "# tx = [x for x in range(100,2100,100)]\n",
        "# acc_max = [0,0]\n",
        "\n",
        "# x, y = dataset.test_set()\n",
        "\n",
        "# tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "# tmodel.compile(loss='categorical_crossentropy',\n",
        "#                          metrics=['accuracy'],\n",
        "#                          optimizer=Adam())\n",
        "\n",
        "# for e in tx:\n",
        "#   tmodel.load_weights(\"./models/discriminator_supervised-\"+ str(e) +\".h5\", by_name=False)\n",
        "#   _, acc = tmodel.evaluate(x, y)\n",
        "#   accs.append(acc)\n",
        "# print(max(accs))\n",
        "\n",
        "# plt.figure(figsize=(15, 5))\n",
        "# plt.plot(tx, accs, label=\"accs\", color='blue')\n",
        "# plt.xticks(tx, rotation=90)\n",
        "# plt.title(\"accs with epoch\")\n",
        "# plt.xlabel(\"epoch\")\n",
        "# plt.ylabel(\"accs\")\n",
        "# plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSbSVx1khsOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(iterations, batch_size, save_interval, iter_epochs, k):\n",
        "\n",
        "    x_test, y_test = dataset.test_set()\n",
        "\n",
        "    # Labels for real images: all ones\n",
        "    real = np.ones((batch_size, 1))\n",
        "\n",
        "    # Labels for fake images: all zeros\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        for _ in range(k):\n",
        "\n",
        "            # -------------------------\n",
        "            #  Train the Discriminator\n",
        "            # -------------------------\n",
        "\n",
        "            # Get labeled and unlabeled examples\n",
        "            imgs, labels = dataset.batch_labeled(batch_size)\n",
        "            imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
        "\n",
        "            # Generate a batch of fake images\n",
        "            z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "            fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "            fake_labels = to_categorical(fake_labels, num_classes=num_classes)\n",
        "            gen_imgs = generator.predict([z, fake_labels])\n",
        "\n",
        "            discriminator_supervised.trainable = True\n",
        "            discriminator_unsupervised.trainable = True\n",
        "\n",
        "            # Train on real labeled examples\n",
        "            datagen.fit(imgs)\n",
        "            discriminator_supervised.fit_generator(datagen.flow(imgs, labels, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=iter_epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "            loss_d_supervised, acc_d_supervised = history.losses[-1], history.accs[-1]\n",
        "\n",
        "            # Train on real unlabeled examples\n",
        "            # Error\n",
        "            # datagen.fit(imgs_unlabeled)\n",
        "            # discriminator_unsupervised.fit_generator(datagen.flow(imgs_unlabeled, real, batch_size=batch_size),\n",
        "            #             validation_data=(x_test, np.ones((len(x_test), 1))),\n",
        "            #             epochs=iter_epochs, verbose=1, workers=4,\n",
        "            #             callbacks=callbacks)\n",
        "            # loss_d_unsupervised_real, acc_d_unsupervised_real = history.losses[-1], history.accs[-1]\n",
        "            loss_d_unsupervised_real, acc_d_unsupervised_real = discriminator_unsupervised.train_on_batch(imgs_unlabeled, real)\n",
        "\n",
        "            # Train on fake examples\n",
        "            loss_d_unsupervised_fake, acc_d_unsupervised_fake = discriminator_unsupervised.train_on_batch(gen_imgs, fake)\n",
        "\n",
        "            # Calculate loss and acc\n",
        "            loss_d_unsupervised = 0.5 * np.add(loss_d_unsupervised_real, loss_d_unsupervised_fake)\n",
        "            loss_d = np.add(loss_d_supervised, loss_d_unsupervised)\n",
        "            acc_d_unsupervised = 0.5 * np.add(acc_d_unsupervised_real, acc_d_unsupervised_fake)\n",
        "            acc_d = np.add(acc_d_supervised, acc_d_unsupervised)\n",
        "        \n",
        "        # ---------------------\n",
        "        #  Train the Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Generate a batch of fake images\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "        fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "        fake_labels = to_categorical(fake_labels, num_classes=num_classes)\n",
        "        gen_imgs = generator.predict([z, fake_labels])\n",
        "\n",
        "        discriminator_supervised.trainable = False\n",
        "        discriminator_unsupervised.trainable = False\n",
        "\n",
        "        # Train Generator\n",
        "        loss_g_unsupervised, acc_g_unsupervised = gan.train_on_batch([z,labels], real)\n",
        "\n",
        "        # Calculate loss and acc\n",
        "        loss_g = loss_g_unsupervised\n",
        "        acc_g = acc_g_unsupervised\n",
        "\n",
        "        if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "            # Save losses to be plotted after training\n",
        "            losses_d_supervised.append(loss_d_supervised)\n",
        "            losses_d_unsupervised.append(loss_d_unsupervised)\n",
        "            losses_d_unsupervised_real.append(loss_d_unsupervised_real)\n",
        "            losses_d_unsupervised_fake.append(loss_d_unsupervised_fake)\n",
        "            losses_d.append(loss_d)\n",
        "            losses_g.append(loss_g)\n",
        "            \n",
        "            iteration_checkpoints.append(iteration + 1)\n",
        "\n",
        "            # Output training progress\n",
        "            print(\n",
        "                \"%d [D loss supervised: %.4f, acc.: %.2f%%] [D loss unsupervised: %.4f, acc.: %.2f%%] [G loss: %f, acc.: %.2f%%]\"\n",
        "                % (iteration + 1, \n",
        "                   loss_d_supervised, 100 * acc_d_supervised,\n",
        "                   loss_d_unsupervised, 100 * acc_d_unsupervised, \n",
        "                   loss_g, 100 * acc_g))\n",
        "            \n",
        "            discriminator_supervised.save(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-\" + str(iteration+1) + \".h5\")\n",
        "            discriminator_unsupervised.save(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_unsupervised-\" + str(iteration+1) + \".h5\")\n",
        "            generator.save(\"./models/models-label-\" + str(num_labeled) + \"/generator-\" + str(iteration+1) + \".h5\")\n",
        "            file1 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_d_supervised.json\"\n",
        "            file2 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_d_unsupervised.json\"\n",
        "            file3 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_g.json\"\n",
        "            with open(file1, 'w') as json_file:\n",
        "                  json.dump(str(losses_d_supervised), json_file)\n",
        "            with open(file2, 'w') as json_file:\n",
        "                  json.dump(str(losses_d_unsupervised), json_file)\n",
        "            with open(file3, 'w') as json_file:\n",
        "                  json.dump(str(losses_g), json_file)\n",
        "\n",
        "            # x,y = dataset.training_set()\n",
        "            # _, acc = discriminator_supervised.evaluate(x,y)\n",
        "            # print(str(100*acc)+\"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T__5V6FJn6xB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b2d7bb8-ca4e-4554-eeb6-123cf0dc4bf0"
      },
      "source": [
        "# Set hyperparameters\n",
        "iterations = 300 # 8000\n",
        "iter_epochs = 1 # 10\n",
        "batch_size = 32\n",
        "save_interval = 10\n",
        "k = 1 # iteration of Discriminator\n",
        "\n",
        "losses_d_supervised = []\n",
        "losses_d_unsupervised = []\n",
        "losses_d_unsupervised_real = []\n",
        "losses_d_unsupervised_fake = []\n",
        "losses_d = []\n",
        "losses_g = []\n",
        "\n",
        "iteration_checkpoints = []\n",
        "\n",
        "# discriminator_supervised = load_model(\"./models/discriminator_supervised-1200.h5\")\n",
        "discriminator_supervised = load_model(\"./useless_models/cifar10_model.019.h5\")\n",
        "starttime = time.clock()\n",
        "\n",
        "# Train the SCGAN-2D for the specified number of iterations\n",
        "train(iterations, batch_size, save_interval, iter_epochs, k)\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Training time: %.4fs\" % (endtime - starttime))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.5122 - acc: 0.8438 - val_loss: 0.6732 - val_acc: 0.8324\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.83500\n",
            "1 [D loss supervised: 0.5122, acc.: 84.38%] [D loss unsupervised: 0.2705, acc.: 100.00%] [G loss: 2.962576, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4464 - acc: 0.8750 - val_loss: 0.6423 - val_acc: 0.8387\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.83500 to 0.83870, saving model to /content/models/cifar10_model.001.h5\n",
            "2 [D loss supervised: 0.4464, acc.: 87.50%] [D loss unsupervised: 0.2706, acc.: 98.44%] [G loss: 3.046097, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5002 - acc: 0.8750 - val_loss: 0.6390 - val_acc: 0.8393\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.83870 to 0.83930, saving model to /content/models/cifar10_model.001.h5\n",
            "3 [D loss supervised: 0.5002, acc.: 87.50%] [D loss unsupervised: 0.2517, acc.: 98.44%] [G loss: 3.417806, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.7070 - acc: 0.7500 - val_loss: 0.6347 - val_acc: 0.8402\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.83930 to 0.84020, saving model to /content/models/cifar10_model.001.h5\n",
            "4 [D loss supervised: 0.7070, acc.: 75.00%] [D loss unsupervised: 0.2323, acc.: 100.00%] [G loss: 3.211754, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4532 - acc: 0.9375 - val_loss: 0.6202 - val_acc: 0.8451\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.84020 to 0.84510, saving model to /content/models/cifar10_model.001.h5\n",
            "5 [D loss supervised: 0.4532, acc.: 93.75%] [D loss unsupervised: 0.2693, acc.: 100.00%] [G loss: 3.331815, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6076 - acc: 0.8438 - val_loss: 0.6205 - val_acc: 0.8451\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84510\n",
            "6 [D loss supervised: 0.6076, acc.: 84.38%] [D loss unsupervised: 0.2580, acc.: 98.44%] [G loss: 3.034502, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5138 - acc: 0.8125 - val_loss: 0.6171 - val_acc: 0.8479\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.84510 to 0.84790, saving model to /content/models/cifar10_model.001.h5\n",
            "7 [D loss supervised: 0.5138, acc.: 81.25%] [D loss unsupervised: 0.3089, acc.: 98.44%] [G loss: 2.775570, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6660 - acc: 0.8125 - val_loss: 0.6215 - val_acc: 0.8467\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "8 [D loss supervised: 0.6660, acc.: 81.25%] [D loss unsupervised: 0.3049, acc.: 96.88%] [G loss: 1.878350, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5548 - acc: 0.8750 - val_loss: 0.6253 - val_acc: 0.8456\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "9 [D loss supervised: 0.5548, acc.: 87.50%] [D loss unsupervised: 0.3039, acc.: 98.44%] [G loss: 2.005913, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4002 - acc: 0.9375 - val_loss: 0.6323 - val_acc: 0.8425\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "10 [D loss supervised: 0.4002, acc.: 93.75%] [D loss unsupervised: 0.2748, acc.: 100.00%] [G loss: 2.399218, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6118 - acc: 0.7812 - val_loss: 0.6317 - val_acc: 0.8429\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "11 [D loss supervised: 0.6118, acc.: 78.12%] [D loss unsupervised: 0.2828, acc.: 96.88%] [G loss: 3.089212, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5628 - acc: 0.8750 - val_loss: 0.6319 - val_acc: 0.8440\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "12 [D loss supervised: 0.5628, acc.: 87.50%] [D loss unsupervised: 0.2197, acc.: 100.00%] [G loss: 3.238440, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4304 - acc: 0.9375 - val_loss: 0.6361 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "13 [D loss supervised: 0.4304, acc.: 93.75%] [D loss unsupervised: 0.2516, acc.: 96.88%] [G loss: 3.356405, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3316 - acc: 0.9688 - val_loss: 0.6417 - val_acc: 0.8413\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "14 [D loss supervised: 0.3316, acc.: 96.88%] [D loss unsupervised: 0.2455, acc.: 98.44%] [G loss: 2.931774, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6292 - acc: 0.7500 - val_loss: 0.6474 - val_acc: 0.8390\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "15 [D loss supervised: 0.6292, acc.: 75.00%] [D loss unsupervised: 0.2580, acc.: 100.00%] [G loss: 1.386154, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4959 - acc: 0.9375 - val_loss: 0.6552 - val_acc: 0.8344\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "16 [D loss supervised: 0.4959, acc.: 93.75%] [D loss unsupervised: 0.4160, acc.: 93.75%] [G loss: 1.233681, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3636 - acc: 0.9062 - val_loss: 0.6626 - val_acc: 0.8336\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "17 [D loss supervised: 0.3636, acc.: 90.62%] [D loss unsupervised: 0.2938, acc.: 96.88%] [G loss: 2.309983, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3913 - acc: 0.9375 - val_loss: 0.6678 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "18 [D loss supervised: 0.3913, acc.: 93.75%] [D loss unsupervised: 0.2665, acc.: 98.44%] [G loss: 2.740803, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4414 - acc: 0.9062 - val_loss: 0.6709 - val_acc: 0.8322\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "19 [D loss supervised: 0.4414, acc.: 90.62%] [D loss unsupervised: 0.3321, acc.: 95.31%] [G loss: 1.947205, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5215 - acc: 0.8750 - val_loss: 0.6667 - val_acc: 0.8327\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "20 [D loss supervised: 0.5215, acc.: 87.50%] [D loss unsupervised: 0.2952, acc.: 95.31%] [G loss: 1.575520, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5330 - acc: 0.9062 - val_loss: 0.6583 - val_acc: 0.8361\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "21 [D loss supervised: 0.5330, acc.: 90.62%] [D loss unsupervised: 0.2524, acc.: 100.00%] [G loss: 1.094013, acc.: 37.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.7200 - acc: 0.7812 - val_loss: 0.6548 - val_acc: 0.8380\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "22 [D loss supervised: 0.7200, acc.: 78.12%] [D loss unsupervised: 0.2338, acc.: 98.44%] [G loss: 0.737953, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3979 - acc: 0.9375 - val_loss: 0.6526 - val_acc: 0.8380\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "23 [D loss supervised: 0.3979, acc.: 93.75%] [D loss unsupervised: 0.2173, acc.: 100.00%] [G loss: 0.700754, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5260 - acc: 0.9062 - val_loss: 0.6517 - val_acc: 0.8389\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "24 [D loss supervised: 0.5260, acc.: 90.62%] [D loss unsupervised: 0.2380, acc.: 100.00%] [G loss: 0.993288, acc.: 50.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4677 - acc: 0.8750 - val_loss: 0.6527 - val_acc: 0.8391\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "25 [D loss supervised: 0.4677, acc.: 87.50%] [D loss unsupervised: 0.2276, acc.: 100.00%] [G loss: 1.224947, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5666 - acc: 0.8750 - val_loss: 0.6617 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "26 [D loss supervised: 0.5666, acc.: 87.50%] [D loss unsupervised: 0.2178, acc.: 100.00%] [G loss: 1.818767, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3968 - acc: 0.9688 - val_loss: 0.6706 - val_acc: 0.8344\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "27 [D loss supervised: 0.3968, acc.: 96.88%] [D loss unsupervised: 0.2876, acc.: 95.31%] [G loss: 1.933135, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5457 - acc: 0.8438 - val_loss: 0.6741 - val_acc: 0.8341\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "28 [D loss supervised: 0.5457, acc.: 84.38%] [D loss unsupervised: 0.2676, acc.: 98.44%] [G loss: 2.052097, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4100 - acc: 0.9375 - val_loss: 0.6784 - val_acc: 0.8315\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "29 [D loss supervised: 0.4100, acc.: 93.75%] [D loss unsupervised: 0.2510, acc.: 100.00%] [G loss: 2.358076, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4510 - acc: 0.9062 - val_loss: 0.6855 - val_acc: 0.8294\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "30 [D loss supervised: 0.4510, acc.: 90.62%] [D loss unsupervised: 0.2356, acc.: 100.00%] [G loss: 3.304409, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4931 - acc: 0.8750 - val_loss: 0.6965 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "31 [D loss supervised: 0.4931, acc.: 87.50%] [D loss unsupervised: 0.2049, acc.: 100.00%] [G loss: 3.840486, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5848 - acc: 0.8438 - val_loss: 0.7059 - val_acc: 0.8239\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "32 [D loss supervised: 0.5848, acc.: 84.38%] [D loss unsupervised: 0.2334, acc.: 100.00%] [G loss: 4.014298, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4135 - acc: 0.9062 - val_loss: 0.7168 - val_acc: 0.8211\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "33 [D loss supervised: 0.4135, acc.: 90.62%] [D loss unsupervised: 0.2202, acc.: 100.00%] [G loss: 4.183128, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4350 - acc: 0.9375 - val_loss: 0.7289 - val_acc: 0.8183\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "34 [D loss supervised: 0.4350, acc.: 93.75%] [D loss unsupervised: 0.2255, acc.: 100.00%] [G loss: 4.154865, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4496 - acc: 0.9375 - val_loss: 0.7403 - val_acc: 0.8151\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "35 [D loss supervised: 0.4496, acc.: 93.75%] [D loss unsupervised: 0.2010, acc.: 100.00%] [G loss: 4.013154, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4361 - acc: 0.8438 - val_loss: 0.7514 - val_acc: 0.8115\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "36 [D loss supervised: 0.4361, acc.: 84.38%] [D loss unsupervised: 0.2208, acc.: 98.44%] [G loss: 3.790524, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3807 - acc: 0.9375 - val_loss: 0.7678 - val_acc: 0.8067\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "37 [D loss supervised: 0.3807, acc.: 93.75%] [D loss unsupervised: 0.2111, acc.: 100.00%] [G loss: 3.627892, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4077 - acc: 0.9062 - val_loss: 0.7798 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "38 [D loss supervised: 0.4077, acc.: 90.62%] [D loss unsupervised: 0.2190, acc.: 100.00%] [G loss: 3.119236, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3849 - acc: 0.9688 - val_loss: 0.7945 - val_acc: 0.8017\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "39 [D loss supervised: 0.3849, acc.: 96.88%] [D loss unsupervised: 0.2208, acc.: 100.00%] [G loss: 2.537077, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5484 - acc: 0.8438 - val_loss: 0.8068 - val_acc: 0.7990\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "40 [D loss supervised: 0.5484, acc.: 84.38%] [D loss unsupervised: 0.2361, acc.: 98.44%] [G loss: 2.335386, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3834 - acc: 0.9062 - val_loss: 0.8215 - val_acc: 0.7976\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "41 [D loss supervised: 0.3834, acc.: 90.62%] [D loss unsupervised: 0.2366, acc.: 98.44%] [G loss: 1.869304, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5456 - acc: 0.8750 - val_loss: 0.8370 - val_acc: 0.7949\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "42 [D loss supervised: 0.5456, acc.: 87.50%] [D loss unsupervised: 0.2331, acc.: 100.00%] [G loss: 2.082068, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4766 - acc: 0.9062 - val_loss: 0.8415 - val_acc: 0.7950\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "43 [D loss supervised: 0.4766, acc.: 90.62%] [D loss unsupervised: 0.2291, acc.: 100.00%] [G loss: 2.222253, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6167 - acc: 0.8750 - val_loss: 0.8464 - val_acc: 0.7946\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "44 [D loss supervised: 0.6167, acc.: 87.50%] [D loss unsupervised: 0.3149, acc.: 93.75%] [G loss: 1.960812, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.7187 - acc: 0.7812 - val_loss: 0.8487 - val_acc: 0.7934\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "45 [D loss supervised: 0.7187, acc.: 78.12%] [D loss unsupervised: 0.2366, acc.: 100.00%] [G loss: 1.730756, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4296 - acc: 0.9062 - val_loss: 0.8523 - val_acc: 0.7930\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "46 [D loss supervised: 0.4296, acc.: 90.62%] [D loss unsupervised: 0.2170, acc.: 98.44%] [G loss: 1.257480, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4436 - acc: 0.8750 - val_loss: 0.8431 - val_acc: 0.7942\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "47 [D loss supervised: 0.4436, acc.: 87.50%] [D loss unsupervised: 0.2218, acc.: 100.00%] [G loss: 1.126503, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4407 - acc: 0.9375 - val_loss: 0.8257 - val_acc: 0.7977\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "48 [D loss supervised: 0.4407, acc.: 93.75%] [D loss unsupervised: 0.2358, acc.: 100.00%] [G loss: 1.308747, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4082 - acc: 0.9062 - val_loss: 0.8090 - val_acc: 0.8010\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "49 [D loss supervised: 0.4082, acc.: 90.62%] [D loss unsupervised: 0.2191, acc.: 100.00%] [G loss: 3.206339, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2628 - acc: 0.9688 - val_loss: 0.7923 - val_acc: 0.8052\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "50 [D loss supervised: 0.2628, acc.: 96.88%] [D loss unsupervised: 0.2134, acc.: 100.00%] [G loss: 3.530090, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3080 - acc: 0.9688 - val_loss: 0.7829 - val_acc: 0.8076\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "51 [D loss supervised: 0.3080, acc.: 96.88%] [D loss unsupervised: 0.2027, acc.: 100.00%] [G loss: 4.026888, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4940 - acc: 0.8438 - val_loss: 0.7738 - val_acc: 0.8088\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "52 [D loss supervised: 0.4940, acc.: 84.38%] [D loss unsupervised: 0.2079, acc.: 100.00%] [G loss: 4.259899, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3674 - acc: 0.9375 - val_loss: 0.7617 - val_acc: 0.8128\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "53 [D loss supervised: 0.3674, acc.: 93.75%] [D loss unsupervised: 0.2079, acc.: 100.00%] [G loss: 4.148007, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4146 - acc: 0.9375 - val_loss: 0.7569 - val_acc: 0.8138\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "54 [D loss supervised: 0.4146, acc.: 93.75%] [D loss unsupervised: 0.2266, acc.: 98.44%] [G loss: 3.649605, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4981 - acc: 0.8750 - val_loss: 0.7494 - val_acc: 0.8150\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "55 [D loss supervised: 0.4981, acc.: 87.50%] [D loss unsupervised: 0.1978, acc.: 100.00%] [G loss: 3.663976, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2953 - acc: 0.9688 - val_loss: 0.7452 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "56 [D loss supervised: 0.2953, acc.: 96.88%] [D loss unsupervised: 0.1956, acc.: 100.00%] [G loss: 3.113882, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4770 - acc: 0.9062 - val_loss: 0.7348 - val_acc: 0.8182\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "57 [D loss supervised: 0.4770, acc.: 90.62%] [D loss unsupervised: 0.2010, acc.: 100.00%] [G loss: 3.053675, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3356 - acc: 0.9375 - val_loss: 0.7273 - val_acc: 0.8169\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "58 [D loss supervised: 0.3356, acc.: 93.75%] [D loss unsupervised: 0.2060, acc.: 100.00%] [G loss: 2.598295, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5651 - acc: 0.8750 - val_loss: 0.7293 - val_acc: 0.8169\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "59 [D loss supervised: 0.5651, acc.: 87.50%] [D loss unsupervised: 0.2022, acc.: 100.00%] [G loss: 2.292420, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5768 - acc: 0.8750 - val_loss: 0.7420 - val_acc: 0.8117\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "60 [D loss supervised: 0.5768, acc.: 87.50%] [D loss unsupervised: 0.1910, acc.: 100.00%] [G loss: 1.772282, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5079 - acc: 0.8750 - val_loss: 0.7638 - val_acc: 0.8053\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "61 [D loss supervised: 0.5079, acc.: 87.50%] [D loss unsupervised: 0.2056, acc.: 100.00%] [G loss: 1.372975, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4098 - acc: 0.8750 - val_loss: 0.7803 - val_acc: 0.8005\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "62 [D loss supervised: 0.4098, acc.: 87.50%] [D loss unsupervised: 0.2042, acc.: 100.00%] [G loss: 1.527498, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4891 - acc: 0.9375 - val_loss: 0.7902 - val_acc: 0.7984\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "63 [D loss supervised: 0.4891, acc.: 93.75%] [D loss unsupervised: 0.2028, acc.: 100.00%] [G loss: 1.277170, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4629 - acc: 0.8750 - val_loss: 0.8015 - val_acc: 0.7955\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "64 [D loss supervised: 0.4629, acc.: 87.50%] [D loss unsupervised: 0.2065, acc.: 100.00%] [G loss: 1.300247, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4596 - acc: 0.9375 - val_loss: 0.8148 - val_acc: 0.7923\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "65 [D loss supervised: 0.4596, acc.: 93.75%] [D loss unsupervised: 0.1953, acc.: 100.00%] [G loss: 1.701754, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3600 - acc: 0.9688 - val_loss: 0.8297 - val_acc: 0.7900\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "66 [D loss supervised: 0.3600, acc.: 96.88%] [D loss unsupervised: 0.1928, acc.: 100.00%] [G loss: 1.430336, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4628 - acc: 0.8750 - val_loss: 0.8371 - val_acc: 0.7871\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "67 [D loss supervised: 0.4628, acc.: 87.50%] [D loss unsupervised: 0.1969, acc.: 100.00%] [G loss: 0.911204, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4118 - acc: 0.9375 - val_loss: 0.8396 - val_acc: 0.7865\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "68 [D loss supervised: 0.4118, acc.: 93.75%] [D loss unsupervised: 0.1995, acc.: 100.00%] [G loss: 1.199234, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4057 - acc: 0.9375 - val_loss: 0.8335 - val_acc: 0.7875\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "69 [D loss supervised: 0.4057, acc.: 93.75%] [D loss unsupervised: 0.1990, acc.: 100.00%] [G loss: 1.321495, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5095 - acc: 0.8125 - val_loss: 0.8278 - val_acc: 0.7901\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "70 [D loss supervised: 0.5095, acc.: 81.25%] [D loss unsupervised: 0.1915, acc.: 100.00%] [G loss: 1.113436, acc.: 37.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4858 - acc: 0.8750 - val_loss: 0.8170 - val_acc: 0.7923\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "71 [D loss supervised: 0.4858, acc.: 87.50%] [D loss unsupervised: 0.2019, acc.: 100.00%] [G loss: 1.004999, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4266 - acc: 0.9375 - val_loss: 0.8091 - val_acc: 0.7935\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "72 [D loss supervised: 0.4266, acc.: 93.75%] [D loss unsupervised: 0.1931, acc.: 100.00%] [G loss: 1.321540, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3559 - acc: 0.9375 - val_loss: 0.7999 - val_acc: 0.7966\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "73 [D loss supervised: 0.3559, acc.: 93.75%] [D loss unsupervised: 0.1989, acc.: 100.00%] [G loss: 1.777720, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3493 - acc: 0.9375 - val_loss: 0.7865 - val_acc: 0.7993\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "74 [D loss supervised: 0.3493, acc.: 93.75%] [D loss unsupervised: 0.2092, acc.: 100.00%] [G loss: 2.034553, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3438 - acc: 0.9688 - val_loss: 0.7743 - val_acc: 0.8034\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "75 [D loss supervised: 0.3438, acc.: 96.88%] [D loss unsupervised: 0.1892, acc.: 100.00%] [G loss: 2.077254, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4798 - acc: 0.9062 - val_loss: 0.7574 - val_acc: 0.8089\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "76 [D loss supervised: 0.4798, acc.: 90.62%] [D loss unsupervised: 0.1963, acc.: 100.00%] [G loss: 1.618526, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3447 - acc: 0.9375 - val_loss: 0.7417 - val_acc: 0.8132\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "77 [D loss supervised: 0.3447, acc.: 93.75%] [D loss unsupervised: 0.2093, acc.: 100.00%] [G loss: 1.296912, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4418 - acc: 0.8438 - val_loss: 0.7293 - val_acc: 0.8160\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "78 [D loss supervised: 0.4418, acc.: 84.38%] [D loss unsupervised: 0.1990, acc.: 100.00%] [G loss: 2.120513, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4379 - acc: 0.8750 - val_loss: 0.7143 - val_acc: 0.8180\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "79 [D loss supervised: 0.4379, acc.: 87.50%] [D loss unsupervised: 0.1997, acc.: 100.00%] [G loss: 2.842155, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5139 - acc: 0.8750 - val_loss: 0.6982 - val_acc: 0.8244\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "80 [D loss supervised: 0.5139, acc.: 87.50%] [D loss unsupervised: 0.2082, acc.: 100.00%] [G loss: 2.563019, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4841 - acc: 0.8438 - val_loss: 0.6898 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "81 [D loss supervised: 0.4841, acc.: 84.38%] [D loss unsupervised: 0.1959, acc.: 100.00%] [G loss: 1.446290, acc.: 40.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3832 - acc: 0.9062 - val_loss: 0.6883 - val_acc: 0.8277\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "82 [D loss supervised: 0.3832, acc.: 90.62%] [D loss unsupervised: 0.2074, acc.: 100.00%] [G loss: 1.253576, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4498 - acc: 0.9062 - val_loss: 0.6935 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "83 [D loss supervised: 0.4498, acc.: 90.62%] [D loss unsupervised: 0.2060, acc.: 100.00%] [G loss: 0.617578, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3882 - acc: 0.9375 - val_loss: 0.7042 - val_acc: 0.8238\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "84 [D loss supervised: 0.3882, acc.: 93.75%] [D loss unsupervised: 0.2130, acc.: 100.00%] [G loss: 1.248772, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3460 - acc: 0.9062 - val_loss: 0.7145 - val_acc: 0.8196\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "85 [D loss supervised: 0.3460, acc.: 90.62%] [D loss unsupervised: 0.2067, acc.: 100.00%] [G loss: 1.118393, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3996 - acc: 0.9375 - val_loss: 0.7281 - val_acc: 0.8174\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "86 [D loss supervised: 0.3996, acc.: 93.75%] [D loss unsupervised: 0.1930, acc.: 100.00%] [G loss: 2.045895, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3217 - acc: 0.9375 - val_loss: 0.7463 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "87 [D loss supervised: 0.3217, acc.: 93.75%] [D loss unsupervised: 0.1935, acc.: 100.00%] [G loss: 2.580127, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6033 - acc: 0.8125 - val_loss: 0.7700 - val_acc: 0.8054\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "88 [D loss supervised: 0.6033, acc.: 81.25%] [D loss unsupervised: 0.2015, acc.: 100.00%] [G loss: 2.435107, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3110 - acc: 1.0000 - val_loss: 0.7907 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "89 [D loss supervised: 0.3110, acc.: 100.00%] [D loss unsupervised: 0.1968, acc.: 100.00%] [G loss: 2.125349, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3655 - acc: 0.9688 - val_loss: 0.8085 - val_acc: 0.7971\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "90 [D loss supervised: 0.3655, acc.: 96.88%] [D loss unsupervised: 0.1883, acc.: 100.00%] [G loss: 1.638695, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3518 - acc: 0.9062 - val_loss: 0.8209 - val_acc: 0.7934\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "91 [D loss supervised: 0.3518, acc.: 90.62%] [D loss unsupervised: 0.2008, acc.: 100.00%] [G loss: 1.245601, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2916 - acc: 0.9688 - val_loss: 0.8236 - val_acc: 0.7930\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "92 [D loss supervised: 0.2916, acc.: 96.88%] [D loss unsupervised: 0.1902, acc.: 100.00%] [G loss: 0.949131, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3611 - acc: 0.9375 - val_loss: 0.8338 - val_acc: 0.7913\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "93 [D loss supervised: 0.3611, acc.: 93.75%] [D loss unsupervised: 0.1997, acc.: 100.00%] [G loss: 0.892627, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4110 - acc: 0.9375 - val_loss: 0.8211 - val_acc: 0.7938\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "94 [D loss supervised: 0.4110, acc.: 93.75%] [D loss unsupervised: 0.2012, acc.: 100.00%] [G loss: 0.978767, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4025 - acc: 0.8750 - val_loss: 0.8037 - val_acc: 0.7977\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "95 [D loss supervised: 0.4025, acc.: 87.50%] [D loss unsupervised: 0.1894, acc.: 100.00%] [G loss: 1.452087, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4280 - acc: 0.9375 - val_loss: 0.7863 - val_acc: 0.8013\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "96 [D loss supervised: 0.4280, acc.: 93.75%] [D loss unsupervised: 0.1852, acc.: 100.00%] [G loss: 2.114085, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4329 - acc: 0.8750 - val_loss: 0.7649 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "97 [D loss supervised: 0.4329, acc.: 87.50%] [D loss unsupervised: 0.1876, acc.: 100.00%] [G loss: 1.602327, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4584 - acc: 0.9062 - val_loss: 0.7371 - val_acc: 0.8142\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "98 [D loss supervised: 0.4584, acc.: 90.62%] [D loss unsupervised: 0.1926, acc.: 100.00%] [G loss: 1.832752, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3334 - acc: 0.9688 - val_loss: 0.7136 - val_acc: 0.8199\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "99 [D loss supervised: 0.3334, acc.: 96.88%] [D loss unsupervised: 0.1851, acc.: 100.00%] [G loss: 1.279231, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3751 - acc: 0.9375 - val_loss: 0.6983 - val_acc: 0.8221\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "100 [D loss supervised: 0.3751, acc.: 93.75%] [D loss unsupervised: 0.1855, acc.: 100.00%] [G loss: 1.079559, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3439 - acc: 0.9062 - val_loss: 0.6925 - val_acc: 0.8245\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "101 [D loss supervised: 0.3439, acc.: 90.62%] [D loss unsupervised: 0.1874, acc.: 100.00%] [G loss: 0.926581, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4186 - acc: 0.8750 - val_loss: 0.6928 - val_acc: 0.8254\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "102 [D loss supervised: 0.4186, acc.: 87.50%] [D loss unsupervised: 0.1933, acc.: 100.00%] [G loss: 1.134119, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3908 - acc: 0.9375 - val_loss: 0.6949 - val_acc: 0.8239\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "103 [D loss supervised: 0.3908, acc.: 93.75%] [D loss unsupervised: 0.1843, acc.: 100.00%] [G loss: 0.426428, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5679 - acc: 0.7812 - val_loss: 0.7004 - val_acc: 0.8207\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "104 [D loss supervised: 0.5679, acc.: 78.12%] [D loss unsupervised: 0.1888, acc.: 100.00%] [G loss: 0.717306, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3848 - acc: 0.9062 - val_loss: 0.7091 - val_acc: 0.8203\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "105 [D loss supervised: 0.3848, acc.: 90.62%] [D loss unsupervised: 0.1911, acc.: 100.00%] [G loss: 0.621005, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4374 - acc: 0.9062 - val_loss: 0.7145 - val_acc: 0.8190\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "106 [D loss supervised: 0.4374, acc.: 90.62%] [D loss unsupervised: 0.1874, acc.: 100.00%] [G loss: 0.671032, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4247 - acc: 0.8750 - val_loss: 0.7216 - val_acc: 0.8166\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "107 [D loss supervised: 0.4247, acc.: 87.50%] [D loss unsupervised: 0.1841, acc.: 100.00%] [G loss: 0.678727, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3573 - acc: 0.9688 - val_loss: 0.7317 - val_acc: 0.8155\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "108 [D loss supervised: 0.3573, acc.: 96.88%] [D loss unsupervised: 0.1847, acc.: 100.00%] [G loss: 0.860268, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4592 - acc: 0.9062 - val_loss: 0.7412 - val_acc: 0.8134\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "109 [D loss supervised: 0.4592, acc.: 90.62%] [D loss unsupervised: 0.1845, acc.: 100.00%] [G loss: 0.464023, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2512 - acc: 1.0000 - val_loss: 0.7509 - val_acc: 0.8107\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "110 [D loss supervised: 0.2512, acc.: 100.00%] [D loss unsupervised: 0.1836, acc.: 100.00%] [G loss: 0.560597, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3066 - acc: 0.9375 - val_loss: 0.7575 - val_acc: 0.8088\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "111 [D loss supervised: 0.3066, acc.: 93.75%] [D loss unsupervised: 0.1828, acc.: 100.00%] [G loss: 0.881793, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2409 - acc: 1.0000 - val_loss: 0.7629 - val_acc: 0.8066\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "112 [D loss supervised: 0.2409, acc.: 100.00%] [D loss unsupervised: 0.1930, acc.: 100.00%] [G loss: 0.569604, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3526 - acc: 0.9375 - val_loss: 0.7700 - val_acc: 0.8052\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "113 [D loss supervised: 0.3526, acc.: 93.75%] [D loss unsupervised: 0.1862, acc.: 100.00%] [G loss: 0.734249, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3591 - acc: 0.9688 - val_loss: 0.7726 - val_acc: 0.8056\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "114 [D loss supervised: 0.3591, acc.: 96.88%] [D loss unsupervised: 0.1834, acc.: 100.00%] [G loss: 0.937094, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3321 - acc: 0.9375 - val_loss: 0.7765 - val_acc: 0.8042\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "115 [D loss supervised: 0.3321, acc.: 93.75%] [D loss unsupervised: 0.1898, acc.: 100.00%] [G loss: 1.044278, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4243 - acc: 0.9062 - val_loss: 0.7771 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "116 [D loss supervised: 0.4243, acc.: 90.62%] [D loss unsupervised: 0.1944, acc.: 100.00%] [G loss: 0.885914, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6856 - acc: 0.7812 - val_loss: 0.7761 - val_acc: 0.8023\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "117 [D loss supervised: 0.6856, acc.: 78.12%] [D loss unsupervised: 0.1925, acc.: 100.00%] [G loss: 1.058509, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2936 - acc: 0.9688 - val_loss: 0.7800 - val_acc: 0.8011\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "118 [D loss supervised: 0.2936, acc.: 96.88%] [D loss unsupervised: 0.1894, acc.: 100.00%] [G loss: 0.887597, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2516 - acc: 1.0000 - val_loss: 0.7809 - val_acc: 0.8008\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "119 [D loss supervised: 0.2516, acc.: 100.00%] [D loss unsupervised: 0.1794, acc.: 100.00%] [G loss: 0.963417, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3022 - acc: 0.9375 - val_loss: 0.7796 - val_acc: 0.8000\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "120 [D loss supervised: 0.3022, acc.: 93.75%] [D loss unsupervised: 0.1950, acc.: 100.00%] [G loss: 0.606867, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3370 - acc: 0.9062 - val_loss: 0.7925 - val_acc: 0.7968\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "121 [D loss supervised: 0.3370, acc.: 90.62%] [D loss unsupervised: 0.1840, acc.: 100.00%] [G loss: 0.532771, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2590 - acc: 1.0000 - val_loss: 0.8044 - val_acc: 0.7947\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "122 [D loss supervised: 0.2590, acc.: 100.00%] [D loss unsupervised: 0.1855, acc.: 100.00%] [G loss: 0.434958, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3845 - acc: 0.9375 - val_loss: 0.8137 - val_acc: 0.7914\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "123 [D loss supervised: 0.3845, acc.: 93.75%] [D loss unsupervised: 0.1796, acc.: 100.00%] [G loss: 0.407870, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3407 - acc: 0.8750 - val_loss: 0.8158 - val_acc: 0.7920\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "124 [D loss supervised: 0.3407, acc.: 87.50%] [D loss unsupervised: 0.1830, acc.: 100.00%] [G loss: 0.616656, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2519 - acc: 1.0000 - val_loss: 0.8135 - val_acc: 0.7933\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "125 [D loss supervised: 0.2519, acc.: 100.00%] [D loss unsupervised: 0.1945, acc.: 100.00%] [G loss: 0.542559, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2857 - acc: 0.9688 - val_loss: 0.7979 - val_acc: 0.7970\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "126 [D loss supervised: 0.2857, acc.: 96.88%] [D loss unsupervised: 0.1907, acc.: 100.00%] [G loss: 0.544576, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3714 - acc: 0.9062 - val_loss: 0.7817 - val_acc: 0.8014\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "127 [D loss supervised: 0.3714, acc.: 90.62%] [D loss unsupervised: 0.1796, acc.: 100.00%] [G loss: 0.745494, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4475 - acc: 0.9062 - val_loss: 0.7659 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "128 [D loss supervised: 0.4475, acc.: 90.62%] [D loss unsupervised: 0.1801, acc.: 100.00%] [G loss: 0.618251, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3284 - acc: 0.9375 - val_loss: 0.7549 - val_acc: 0.8083\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "129 [D loss supervised: 0.3284, acc.: 93.75%] [D loss unsupervised: 0.1808, acc.: 100.00%] [G loss: 0.583209, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3768 - acc: 0.9062 - val_loss: 0.7355 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "130 [D loss supervised: 0.3768, acc.: 90.62%] [D loss unsupervised: 0.1839, acc.: 100.00%] [G loss: 0.859364, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2878 - acc: 1.0000 - val_loss: 0.7221 - val_acc: 0.8182\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "131 [D loss supervised: 0.2878, acc.: 100.00%] [D loss unsupervised: 0.1812, acc.: 100.00%] [G loss: 1.138456, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3306 - acc: 0.9375 - val_loss: 0.7107 - val_acc: 0.8214\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "132 [D loss supervised: 0.3306, acc.: 93.75%] [D loss unsupervised: 0.1782, acc.: 100.00%] [G loss: 1.107031, acc.: 40.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3388 - acc: 0.9062 - val_loss: 0.7033 - val_acc: 0.8248\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "133 [D loss supervised: 0.3388, acc.: 90.62%] [D loss unsupervised: 0.1779, acc.: 100.00%] [G loss: 1.317492, acc.: 37.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2757 - acc: 0.9688 - val_loss: 0.6975 - val_acc: 0.8261\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "134 [D loss supervised: 0.2757, acc.: 96.88%] [D loss unsupervised: 0.1841, acc.: 100.00%] [G loss: 1.063709, acc.: 40.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3443 - acc: 0.9688 - val_loss: 0.6945 - val_acc: 0.8280\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "135 [D loss supervised: 0.3443, acc.: 96.88%] [D loss unsupervised: 0.1831, acc.: 100.00%] [G loss: 0.913772, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2581 - acc: 1.0000 - val_loss: 0.6929 - val_acc: 0.8305\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "136 [D loss supervised: 0.2581, acc.: 100.00%] [D loss unsupervised: 0.1786, acc.: 100.00%] [G loss: 0.758999, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4068 - acc: 0.9688 - val_loss: 0.6924 - val_acc: 0.8304\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "137 [D loss supervised: 0.4068, acc.: 96.88%] [D loss unsupervised: 0.1798, acc.: 100.00%] [G loss: 0.536303, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2534 - acc: 0.9688 - val_loss: 0.6876 - val_acc: 0.8321\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "138 [D loss supervised: 0.2534, acc.: 96.88%] [D loss unsupervised: 0.1814, acc.: 100.00%] [G loss: 0.634963, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2802 - acc: 0.9688 - val_loss: 0.6809 - val_acc: 0.8346\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "139 [D loss supervised: 0.2802, acc.: 96.88%] [D loss unsupervised: 0.2203, acc.: 98.44%] [G loss: 0.642462, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4068 - acc: 0.8750 - val_loss: 0.6774 - val_acc: 0.8334\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "140 [D loss supervised: 0.4068, acc.: 87.50%] [D loss unsupervised: 0.1810, acc.: 100.00%] [G loss: 0.706732, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3570 - acc: 0.9062 - val_loss: 0.6768 - val_acc: 0.8328\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "141 [D loss supervised: 0.3570, acc.: 90.62%] [D loss unsupervised: 0.1814, acc.: 100.00%] [G loss: 0.693946, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2643 - acc: 0.9688 - val_loss: 0.6769 - val_acc: 0.8337\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "142 [D loss supervised: 0.2643, acc.: 96.88%] [D loss unsupervised: 0.1792, acc.: 100.00%] [G loss: 0.938449, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3263 - acc: 0.9375 - val_loss: 0.6737 - val_acc: 0.8363\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "143 [D loss supervised: 0.3263, acc.: 93.75%] [D loss unsupervised: 0.1803, acc.: 100.00%] [G loss: 0.924266, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2918 - acc: 0.9688 - val_loss: 0.6741 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "144 [D loss supervised: 0.2918, acc.: 96.88%] [D loss unsupervised: 0.1955, acc.: 100.00%] [G loss: 1.419905, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2819 - acc: 0.9688 - val_loss: 0.6768 - val_acc: 0.8371\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "145 [D loss supervised: 0.2819, acc.: 96.88%] [D loss unsupervised: 0.1931, acc.: 100.00%] [G loss: 0.860411, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4035 - acc: 0.9062 - val_loss: 0.6795 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "146 [D loss supervised: 0.4035, acc.: 90.62%] [D loss unsupervised: 0.1814, acc.: 100.00%] [G loss: 0.860156, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3377 - acc: 0.9062 - val_loss: 0.6847 - val_acc: 0.8319\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "147 [D loss supervised: 0.3377, acc.: 90.62%] [D loss unsupervised: 0.1893, acc.: 100.00%] [G loss: 0.667705, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4621 - acc: 0.9062 - val_loss: 0.6867 - val_acc: 0.8308\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "148 [D loss supervised: 0.4621, acc.: 90.62%] [D loss unsupervised: 0.1815, acc.: 100.00%] [G loss: 1.137516, acc.: 40.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3378 - acc: 0.9375 - val_loss: 0.6947 - val_acc: 0.8255\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "149 [D loss supervised: 0.3378, acc.: 93.75%] [D loss unsupervised: 0.1788, acc.: 100.00%] [G loss: 1.663708, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3715 - acc: 0.9688 - val_loss: 0.7033 - val_acc: 0.8219\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "150 [D loss supervised: 0.3715, acc.: 96.88%] [D loss unsupervised: 0.1808, acc.: 100.00%] [G loss: 1.175135, acc.: 40.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3307 - acc: 0.9375 - val_loss: 0.7073 - val_acc: 0.8205\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "151 [D loss supervised: 0.3307, acc.: 93.75%] [D loss unsupervised: 0.1832, acc.: 100.00%] [G loss: 1.522560, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2983 - acc: 0.9688 - val_loss: 0.7147 - val_acc: 0.8196\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "152 [D loss supervised: 0.2983, acc.: 96.88%] [D loss unsupervised: 0.1888, acc.: 100.00%] [G loss: 1.281752, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3427 - acc: 0.9375 - val_loss: 0.7210 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "153 [D loss supervised: 0.3427, acc.: 93.75%] [D loss unsupervised: 0.1832, acc.: 100.00%] [G loss: 1.001329, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2459 - acc: 1.0000 - val_loss: 0.7269 - val_acc: 0.8153\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "154 [D loss supervised: 0.2459, acc.: 100.00%] [D loss unsupervised: 0.1802, acc.: 100.00%] [G loss: 0.734672, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2503 - acc: 0.9688 - val_loss: 0.7370 - val_acc: 0.8131\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "155 [D loss supervised: 0.2503, acc.: 96.88%] [D loss unsupervised: 0.1850, acc.: 100.00%] [G loss: 0.547435, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3993 - acc: 0.8750 - val_loss: 0.7546 - val_acc: 0.8094\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "156 [D loss supervised: 0.3993, acc.: 87.50%] [D loss unsupervised: 0.1844, acc.: 100.00%] [G loss: 0.656891, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3247 - acc: 0.9375 - val_loss: 0.7595 - val_acc: 0.8080\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "157 [D loss supervised: 0.3247, acc.: 93.75%] [D loss unsupervised: 0.1816, acc.: 100.00%] [G loss: 0.527138, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2823 - acc: 1.0000 - val_loss: 0.7678 - val_acc: 0.8072\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "158 [D loss supervised: 0.2823, acc.: 100.00%] [D loss unsupervised: 0.1774, acc.: 100.00%] [G loss: 0.670057, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2967 - acc: 0.9688 - val_loss: 0.7726 - val_acc: 0.8054\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "159 [D loss supervised: 0.2967, acc.: 96.88%] [D loss unsupervised: 0.1828, acc.: 100.00%] [G loss: 0.809147, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3316 - acc: 0.9375 - val_loss: 0.7715 - val_acc: 0.8044\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "160 [D loss supervised: 0.3316, acc.: 93.75%] [D loss unsupervised: 0.1780, acc.: 100.00%] [G loss: 0.536883, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3149 - acc: 0.9375 - val_loss: 0.7657 - val_acc: 0.8045\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "161 [D loss supervised: 0.3149, acc.: 93.75%] [D loss unsupervised: 0.1775, acc.: 100.00%] [G loss: 0.521199, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2293 - acc: 1.0000 - val_loss: 0.7602 - val_acc: 0.8058\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "162 [D loss supervised: 0.2293, acc.: 100.00%] [D loss unsupervised: 0.1785, acc.: 100.00%] [G loss: 0.379391, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2448 - acc: 0.9688 - val_loss: 0.7538 - val_acc: 0.8079\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "163 [D loss supervised: 0.2448, acc.: 96.88%] [D loss unsupervised: 0.1864, acc.: 100.00%] [G loss: 0.580788, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3250 - acc: 0.9375 - val_loss: 0.7464 - val_acc: 0.8108\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "164 [D loss supervised: 0.3250, acc.: 93.75%] [D loss unsupervised: 0.1756, acc.: 100.00%] [G loss: 0.827010, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4454 - acc: 0.9375 - val_loss: 0.7441 - val_acc: 0.8113\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "165 [D loss supervised: 0.4454, acc.: 93.75%] [D loss unsupervised: 0.1844, acc.: 100.00%] [G loss: 0.673782, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2827 - acc: 0.9375 - val_loss: 0.7471 - val_acc: 0.8118\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "166 [D loss supervised: 0.2827, acc.: 93.75%] [D loss unsupervised: 0.1778, acc.: 100.00%] [G loss: 0.624333, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3764 - acc: 0.9062 - val_loss: 0.7516 - val_acc: 0.8108\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "167 [D loss supervised: 0.3764, acc.: 90.62%] [D loss unsupervised: 0.1760, acc.: 100.00%] [G loss: 0.544892, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3176 - acc: 0.9062 - val_loss: 0.7591 - val_acc: 0.8106\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "168 [D loss supervised: 0.3176, acc.: 90.62%] [D loss unsupervised: 0.1788, acc.: 100.00%] [G loss: 0.626657, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3634 - acc: 0.9062 - val_loss: 0.7623 - val_acc: 0.8077\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "169 [D loss supervised: 0.3634, acc.: 90.62%] [D loss unsupervised: 0.1756, acc.: 100.00%] [G loss: 1.718179, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3096 - acc: 0.9688 - val_loss: 0.7615 - val_acc: 0.8078\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "170 [D loss supervised: 0.3096, acc.: 96.88%] [D loss unsupervised: 0.1749, acc.: 100.00%] [G loss: 1.168220, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2700 - acc: 0.9688 - val_loss: 0.7631 - val_acc: 0.8085\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "171 [D loss supervised: 0.2700, acc.: 96.88%] [D loss unsupervised: 0.1766, acc.: 100.00%] [G loss: 1.105413, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4469 - acc: 0.9375 - val_loss: 0.7537 - val_acc: 0.8123\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "172 [D loss supervised: 0.4469, acc.: 93.75%] [D loss unsupervised: 0.1763, acc.: 100.00%] [G loss: 0.839928, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2858 - acc: 0.9375 - val_loss: 0.7440 - val_acc: 0.8139\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "173 [D loss supervised: 0.2858, acc.: 93.75%] [D loss unsupervised: 0.1783, acc.: 100.00%] [G loss: 0.913359, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3602 - acc: 0.9688 - val_loss: 0.7395 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "174 [D loss supervised: 0.3602, acc.: 96.88%] [D loss unsupervised: 0.1847, acc.: 100.00%] [G loss: 0.551977, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4603 - acc: 0.9062 - val_loss: 0.7375 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "175 [D loss supervised: 0.4603, acc.: 90.62%] [D loss unsupervised: 0.1760, acc.: 100.00%] [G loss: 0.919580, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3124 - acc: 0.9688 - val_loss: 0.7348 - val_acc: 0.8151\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "176 [D loss supervised: 0.3124, acc.: 96.88%] [D loss unsupervised: 0.1721, acc.: 100.00%] [G loss: 1.525538, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4314 - acc: 0.9062 - val_loss: 0.7336 - val_acc: 0.8160\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "177 [D loss supervised: 0.4314, acc.: 90.62%] [D loss unsupervised: 0.1719, acc.: 100.00%] [G loss: 2.041720, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2600 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 0.8176\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "178 [D loss supervised: 0.2600, acc.: 100.00%] [D loss unsupervised: 0.1734, acc.: 100.00%] [G loss: 2.016696, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2710 - acc: 0.9688 - val_loss: 0.7311 - val_acc: 0.8182\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "179 [D loss supervised: 0.2710, acc.: 96.88%] [D loss unsupervised: 0.1792, acc.: 100.00%] [G loss: 1.553405, acc.: 40.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4365 - acc: 0.8750 - val_loss: 0.7350 - val_acc: 0.8173\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "180 [D loss supervised: 0.4365, acc.: 87.50%] [D loss unsupervised: 0.1716, acc.: 100.00%] [G loss: 0.905003, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3363 - acc: 0.9375 - val_loss: 0.7388 - val_acc: 0.8162\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "181 [D loss supervised: 0.3363, acc.: 93.75%] [D loss unsupervised: 0.1726, acc.: 100.00%] [G loss: 0.817367, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3165 - acc: 0.9375 - val_loss: 0.7494 - val_acc: 0.8153\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "182 [D loss supervised: 0.3165, acc.: 93.75%] [D loss unsupervised: 0.1712, acc.: 100.00%] [G loss: 0.781390, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2657 - acc: 0.9688 - val_loss: 0.7621 - val_acc: 0.8113\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "183 [D loss supervised: 0.2657, acc.: 96.88%] [D loss unsupervised: 0.1716, acc.: 100.00%] [G loss: 0.760011, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3156 - acc: 0.9375 - val_loss: 0.7780 - val_acc: 0.8070\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "184 [D loss supervised: 0.3156, acc.: 93.75%] [D loss unsupervised: 0.1706, acc.: 100.00%] [G loss: 0.874116, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3696 - acc: 0.9688 - val_loss: 0.7956 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "185 [D loss supervised: 0.3696, acc.: 96.88%] [D loss unsupervised: 0.1771, acc.: 100.00%] [G loss: 1.150778, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4916 - acc: 0.8750 - val_loss: 0.8240 - val_acc: 0.7949\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "186 [D loss supervised: 0.4916, acc.: 87.50%] [D loss unsupervised: 0.1696, acc.: 100.00%] [G loss: 1.019350, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3048 - acc: 0.9375 - val_loss: 0.8542 - val_acc: 0.7888\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "187 [D loss supervised: 0.3048, acc.: 93.75%] [D loss unsupervised: 0.1705, acc.: 100.00%] [G loss: 1.055216, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3937 - acc: 0.9688 - val_loss: 0.8774 - val_acc: 0.7810\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "188 [D loss supervised: 0.3937, acc.: 96.88%] [D loss unsupervised: 0.1704, acc.: 100.00%] [G loss: 0.774622, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2900 - acc: 1.0000 - val_loss: 0.8923 - val_acc: 0.7782\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "189 [D loss supervised: 0.2900, acc.: 100.00%] [D loss unsupervised: 0.1749, acc.: 100.00%] [G loss: 0.656659, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2785 - acc: 0.9688 - val_loss: 0.8977 - val_acc: 0.7762\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "190 [D loss supervised: 0.2785, acc.: 96.88%] [D loss unsupervised: 0.1731, acc.: 100.00%] [G loss: 0.320684, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2449 - acc: 1.0000 - val_loss: 0.9018 - val_acc: 0.7754\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "191 [D loss supervised: 0.2449, acc.: 100.00%] [D loss unsupervised: 0.1700, acc.: 100.00%] [G loss: 0.707587, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3536 - acc: 0.9062 - val_loss: 0.8972 - val_acc: 0.7766\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "192 [D loss supervised: 0.3536, acc.: 90.62%] [D loss unsupervised: 0.1697, acc.: 100.00%] [G loss: 0.918111, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2848 - acc: 0.9688 - val_loss: 0.8980 - val_acc: 0.7780\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "193 [D loss supervised: 0.2848, acc.: 96.88%] [D loss unsupervised: 0.1696, acc.: 100.00%] [G loss: 0.829549, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3121 - acc: 0.9375 - val_loss: 0.8881 - val_acc: 0.7804\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "194 [D loss supervised: 0.3121, acc.: 93.75%] [D loss unsupervised: 0.1718, acc.: 100.00%] [G loss: 1.115487, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3170 - acc: 0.9688 - val_loss: 0.8761 - val_acc: 0.7821\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "195 [D loss supervised: 0.3170, acc.: 96.88%] [D loss unsupervised: 0.1711, acc.: 100.00%] [G loss: 0.414875, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2139 - acc: 1.0000 - val_loss: 0.8649 - val_acc: 0.7863\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "196 [D loss supervised: 0.2139, acc.: 100.00%] [D loss unsupervised: 0.1742, acc.: 100.00%] [G loss: 0.622547, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2957 - acc: 0.9375 - val_loss: 0.8454 - val_acc: 0.7921\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "197 [D loss supervised: 0.2957, acc.: 93.75%] [D loss unsupervised: 0.1686, acc.: 100.00%] [G loss: 0.814850, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3328 - acc: 0.9062 - val_loss: 0.8227 - val_acc: 0.7962\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "198 [D loss supervised: 0.3328, acc.: 90.62%] [D loss unsupervised: 0.1681, acc.: 100.00%] [G loss: 1.012279, acc.: 50.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2443 - acc: 0.9688 - val_loss: 0.8029 - val_acc: 0.8006\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "199 [D loss supervised: 0.2443, acc.: 96.88%] [D loss unsupervised: 0.1676, acc.: 100.00%] [G loss: 0.506509, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2422 - acc: 1.0000 - val_loss: 0.7862 - val_acc: 0.8030\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "200 [D loss supervised: 0.2422, acc.: 100.00%] [D loss unsupervised: 0.1734, acc.: 100.00%] [G loss: 0.485015, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2369 - acc: 1.0000 - val_loss: 0.7732 - val_acc: 0.8061\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "201 [D loss supervised: 0.2369, acc.: 100.00%] [D loss unsupervised: 0.1710, acc.: 100.00%] [G loss: 0.471460, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3566 - acc: 0.9375 - val_loss: 0.7600 - val_acc: 0.8103\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "202 [D loss supervised: 0.3566, acc.: 93.75%] [D loss unsupervised: 0.1708, acc.: 100.00%] [G loss: 0.462150, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3300 - acc: 0.9688 - val_loss: 0.7455 - val_acc: 0.8143\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "203 [D loss supervised: 0.3300, acc.: 96.88%] [D loss unsupervised: 0.1698, acc.: 100.00%] [G loss: 0.356749, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3384 - acc: 0.9375 - val_loss: 0.7348 - val_acc: 0.8180\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "204 [D loss supervised: 0.3384, acc.: 93.75%] [D loss unsupervised: 0.1738, acc.: 100.00%] [G loss: 0.631112, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3417 - acc: 0.9375 - val_loss: 0.7232 - val_acc: 0.8202\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "205 [D loss supervised: 0.3417, acc.: 93.75%] [D loss unsupervised: 0.1672, acc.: 100.00%] [G loss: 0.633173, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2364 - acc: 0.9688 - val_loss: 0.7157 - val_acc: 0.8220\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "206 [D loss supervised: 0.2364, acc.: 96.88%] [D loss unsupervised: 0.1667, acc.: 100.00%] [G loss: 0.522074, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2333 - acc: 1.0000 - val_loss: 0.7126 - val_acc: 0.8235\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "207 [D loss supervised: 0.2333, acc.: 100.00%] [D loss unsupervised: 0.1703, acc.: 100.00%] [G loss: 0.691296, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2795 - acc: 1.0000 - val_loss: 0.7085 - val_acc: 0.8250\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "208 [D loss supervised: 0.2795, acc.: 100.00%] [D loss unsupervised: 0.1677, acc.: 100.00%] [G loss: 0.949985, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2172 - acc: 1.0000 - val_loss: 0.7074 - val_acc: 0.8242\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "209 [D loss supervised: 0.2172, acc.: 100.00%] [D loss unsupervised: 0.1691, acc.: 100.00%] [G loss: 0.420123, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3663 - acc: 0.9062 - val_loss: 0.7065 - val_acc: 0.8250\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "210 [D loss supervised: 0.3663, acc.: 90.62%] [D loss unsupervised: 0.1749, acc.: 100.00%] [G loss: 0.729642, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1956 - acc: 1.0000 - val_loss: 0.7068 - val_acc: 0.8250\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "211 [D loss supervised: 0.1956, acc.: 100.00%] [D loss unsupervised: 0.1685, acc.: 100.00%] [G loss: 0.465370, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3006 - acc: 1.0000 - val_loss: 0.7095 - val_acc: 0.8236\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "212 [D loss supervised: 0.3006, acc.: 100.00%] [D loss unsupervised: 0.1667, acc.: 100.00%] [G loss: 0.446711, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2658 - acc: 1.0000 - val_loss: 0.7152 - val_acc: 0.8226\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "213 [D loss supervised: 0.2658, acc.: 100.00%] [D loss unsupervised: 0.1686, acc.: 100.00%] [G loss: 0.442487, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4555 - acc: 0.9062 - val_loss: 0.7186 - val_acc: 0.8223\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "214 [D loss supervised: 0.4555, acc.: 90.62%] [D loss unsupervised: 0.1667, acc.: 100.00%] [G loss: 0.292809, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2667 - acc: 0.9375 - val_loss: 0.7173 - val_acc: 0.8236\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "215 [D loss supervised: 0.2667, acc.: 93.75%] [D loss unsupervised: 0.1688, acc.: 100.00%] [G loss: 0.532791, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3174 - acc: 0.9375 - val_loss: 0.7174 - val_acc: 0.8233\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "216 [D loss supervised: 0.3174, acc.: 93.75%] [D loss unsupervised: 0.1664, acc.: 100.00%] [G loss: 0.930709, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3015 - acc: 0.9375 - val_loss: 0.7235 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "217 [D loss supervised: 0.3015, acc.: 93.75%] [D loss unsupervised: 0.1648, acc.: 100.00%] [G loss: 0.913649, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2682 - acc: 0.9688 - val_loss: 0.7344 - val_acc: 0.8180\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "218 [D loss supervised: 0.2682, acc.: 96.88%] [D loss unsupervised: 0.1650, acc.: 100.00%] [G loss: 1.103546, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2846 - acc: 0.9688 - val_loss: 0.7434 - val_acc: 0.8163\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "219 [D loss supervised: 0.2846, acc.: 96.88%] [D loss unsupervised: 0.1647, acc.: 100.00%] [G loss: 0.881550, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2591 - acc: 0.9688 - val_loss: 0.7467 - val_acc: 0.8150\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "220 [D loss supervised: 0.2591, acc.: 96.88%] [D loss unsupervised: 0.1649, acc.: 100.00%] [G loss: 1.411882, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3133 - acc: 0.9375 - val_loss: 0.7510 - val_acc: 0.8153\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "221 [D loss supervised: 0.3133, acc.: 93.75%] [D loss unsupervised: 0.1658, acc.: 100.00%] [G loss: 0.845170, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2281 - acc: 0.9688 - val_loss: 0.7545 - val_acc: 0.8148\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "222 [D loss supervised: 0.2281, acc.: 96.88%] [D loss unsupervised: 0.1652, acc.: 100.00%] [G loss: 0.926159, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2232 - acc: 0.9688 - val_loss: 0.7565 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "223 [D loss supervised: 0.2232, acc.: 96.88%] [D loss unsupervised: 0.1644, acc.: 100.00%] [G loss: 2.249823, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3220 - acc: 0.9375 - val_loss: 0.7645 - val_acc: 0.8116\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "224 [D loss supervised: 0.3220, acc.: 93.75%] [D loss unsupervised: 0.1645, acc.: 100.00%] [G loss: 1.935474, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4034 - acc: 0.9375 - val_loss: 0.7763 - val_acc: 0.8070\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "225 [D loss supervised: 0.4034, acc.: 93.75%] [D loss unsupervised: 0.1648, acc.: 100.00%] [G loss: 1.555964, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2237 - acc: 1.0000 - val_loss: 0.7890 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "226 [D loss supervised: 0.2237, acc.: 100.00%] [D loss unsupervised: 0.1639, acc.: 100.00%] [G loss: 1.136408, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3266 - acc: 0.9375 - val_loss: 0.7907 - val_acc: 0.8027\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "227 [D loss supervised: 0.3266, acc.: 93.75%] [D loss unsupervised: 0.1693, acc.: 100.00%] [G loss: 0.852863, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3549 - acc: 0.9062 - val_loss: 0.7888 - val_acc: 0.8037\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "228 [D loss supervised: 0.3549, acc.: 90.62%] [D loss unsupervised: 0.1636, acc.: 100.00%] [G loss: 1.065823, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2531 - acc: 0.9688 - val_loss: 0.7917 - val_acc: 0.8036\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "229 [D loss supervised: 0.2531, acc.: 96.88%] [D loss unsupervised: 0.1655, acc.: 100.00%] [G loss: 0.875978, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4112 - acc: 0.9375 - val_loss: 0.7914 - val_acc: 0.8046\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "230 [D loss supervised: 0.4112, acc.: 93.75%] [D loss unsupervised: 0.1645, acc.: 100.00%] [G loss: 1.149959, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2617 - acc: 0.9688 - val_loss: 0.7958 - val_acc: 0.8028\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "231 [D loss supervised: 0.2617, acc.: 96.88%] [D loss unsupervised: 0.1649, acc.: 100.00%] [G loss: 0.604720, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3502 - acc: 0.9062 - val_loss: 0.7858 - val_acc: 0.8057\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "232 [D loss supervised: 0.3502, acc.: 90.62%] [D loss unsupervised: 0.1633, acc.: 100.00%] [G loss: 1.534730, acc.: 50.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2073 - acc: 1.0000 - val_loss: 0.7749 - val_acc: 0.8085\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "233 [D loss supervised: 0.2073, acc.: 100.00%] [D loss unsupervised: 0.1638, acc.: 100.00%] [G loss: 1.393650, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2215 - acc: 1.0000 - val_loss: 0.7637 - val_acc: 0.8110\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "234 [D loss supervised: 0.2215, acc.: 100.00%] [D loss unsupervised: 0.1654, acc.: 100.00%] [G loss: 0.963685, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4123 - acc: 0.9375 - val_loss: 0.7485 - val_acc: 0.8143\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "235 [D loss supervised: 0.4123, acc.: 93.75%] [D loss unsupervised: 0.1631, acc.: 100.00%] [G loss: 0.631813, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3458 - acc: 0.9688 - val_loss: 0.7390 - val_acc: 0.8185\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "236 [D loss supervised: 0.3458, acc.: 96.88%] [D loss unsupervised: 0.1627, acc.: 100.00%] [G loss: 0.841634, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3468 - acc: 0.9375 - val_loss: 0.7311 - val_acc: 0.8201\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "237 [D loss supervised: 0.3468, acc.: 93.75%] [D loss unsupervised: 0.1624, acc.: 100.00%] [G loss: 0.959138, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1904 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 0.8185\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "238 [D loss supervised: 0.1904, acc.: 100.00%] [D loss unsupervised: 0.1643, acc.: 100.00%] [G loss: 0.735548, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2101 - acc: 1.0000 - val_loss: 0.7252 - val_acc: 0.8175\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "239 [D loss supervised: 0.2101, acc.: 100.00%] [D loss unsupervised: 0.1624, acc.: 100.00%] [G loss: 0.939298, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2751 - acc: 0.9688 - val_loss: 0.7308 - val_acc: 0.8163\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "240 [D loss supervised: 0.2751, acc.: 96.88%] [D loss unsupervised: 0.1642, acc.: 100.00%] [G loss: 0.553844, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2541 - acc: 0.9688 - val_loss: 0.7365 - val_acc: 0.8149\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "241 [D loss supervised: 0.2541, acc.: 96.88%] [D loss unsupervised: 0.1638, acc.: 100.00%] [G loss: 0.466552, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2694 - acc: 0.9688 - val_loss: 0.7452 - val_acc: 0.8121\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "242 [D loss supervised: 0.2694, acc.: 96.88%] [D loss unsupervised: 0.1664, acc.: 100.00%] [G loss: 0.704896, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2048 - acc: 1.0000 - val_loss: 0.7529 - val_acc: 0.8112\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "243 [D loss supervised: 0.2048, acc.: 100.00%] [D loss unsupervised: 0.1627, acc.: 100.00%] [G loss: 0.685761, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3746 - acc: 0.9375 - val_loss: 0.7585 - val_acc: 0.8088\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "244 [D loss supervised: 0.3746, acc.: 93.75%] [D loss unsupervised: 0.1626, acc.: 100.00%] [G loss: 0.629869, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3539 - acc: 0.9375 - val_loss: 0.7543 - val_acc: 0.8103\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "245 [D loss supervised: 0.3539, acc.: 93.75%] [D loss unsupervised: 0.1607, acc.: 100.00%] [G loss: 0.706157, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2302 - acc: 1.0000 - val_loss: 0.7507 - val_acc: 0.8110\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "246 [D loss supervised: 0.2302, acc.: 100.00%] [D loss unsupervised: 0.1708, acc.: 100.00%] [G loss: 0.891870, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2775 - acc: 0.9375 - val_loss: 0.7505 - val_acc: 0.8112\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "247 [D loss supervised: 0.2775, acc.: 93.75%] [D loss unsupervised: 0.1612, acc.: 100.00%] [G loss: 1.044902, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2747 - acc: 0.9375 - val_loss: 0.7453 - val_acc: 0.8131\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "248 [D loss supervised: 0.2747, acc.: 93.75%] [D loss unsupervised: 0.1613, acc.: 100.00%] [G loss: 0.935235, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2883 - acc: 0.9688 - val_loss: 0.7374 - val_acc: 0.8145\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "249 [D loss supervised: 0.2883, acc.: 96.88%] [D loss unsupervised: 0.1612, acc.: 100.00%] [G loss: 0.654087, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4148 - acc: 0.9062 - val_loss: 0.7285 - val_acc: 0.8167\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "250 [D loss supervised: 0.4148, acc.: 90.62%] [D loss unsupervised: 0.1631, acc.: 100.00%] [G loss: 0.634800, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3467 - acc: 0.9375 - val_loss: 0.7226 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "251 [D loss supervised: 0.3467, acc.: 93.75%] [D loss unsupervised: 0.1605, acc.: 100.00%] [G loss: 0.872235, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2048 - acc: 1.0000 - val_loss: 0.7194 - val_acc: 0.8196\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "252 [D loss supervised: 0.2048, acc.: 100.00%] [D loss unsupervised: 0.1610, acc.: 100.00%] [G loss: 1.224985, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3731 - acc: 0.9375 - val_loss: 0.7237 - val_acc: 0.8185\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "253 [D loss supervised: 0.3731, acc.: 93.75%] [D loss unsupervised: 0.1632, acc.: 100.00%] [G loss: 0.459081, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2336 - acc: 1.0000 - val_loss: 0.7282 - val_acc: 0.8188\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "254 [D loss supervised: 0.2336, acc.: 100.00%] [D loss unsupervised: 0.1614, acc.: 100.00%] [G loss: 0.907497, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2305 - acc: 1.0000 - val_loss: 0.7347 - val_acc: 0.8178\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "255 [D loss supervised: 0.2305, acc.: 100.00%] [D loss unsupervised: 0.1606, acc.: 100.00%] [G loss: 0.675659, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1937 - acc: 1.0000 - val_loss: 0.7406 - val_acc: 0.8171\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "256 [D loss supervised: 0.1937, acc.: 100.00%] [D loss unsupervised: 0.1610, acc.: 100.00%] [G loss: 0.850139, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4366 - acc: 0.9375 - val_loss: 0.7442 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "257 [D loss supervised: 0.4366, acc.: 93.75%] [D loss unsupervised: 0.1612, acc.: 100.00%] [G loss: 0.529339, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2004 - acc: 1.0000 - val_loss: 0.7504 - val_acc: 0.8156\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "258 [D loss supervised: 0.2004, acc.: 100.00%] [D loss unsupervised: 0.1611, acc.: 100.00%] [G loss: 0.766105, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2540 - acc: 1.0000 - val_loss: 0.7505 - val_acc: 0.8150\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "259 [D loss supervised: 0.2540, acc.: 100.00%] [D loss unsupervised: 0.1780, acc.: 98.44%] [G loss: 0.254707, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2297 - acc: 1.0000 - val_loss: 0.7492 - val_acc: 0.8162\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "260 [D loss supervised: 0.2297, acc.: 100.00%] [D loss unsupervised: 0.1613, acc.: 100.00%] [G loss: 0.180443, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2361 - acc: 0.9688 - val_loss: 0.7343 - val_acc: 0.8200\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "261 [D loss supervised: 0.2361, acc.: 96.88%] [D loss unsupervised: 0.1657, acc.: 100.00%] [G loss: 0.379833, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2571 - acc: 0.9688 - val_loss: 0.7217 - val_acc: 0.8226\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "262 [D loss supervised: 0.2571, acc.: 96.88%] [D loss unsupervised: 0.1598, acc.: 100.00%] [G loss: 1.646220, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4568 - acc: 0.8438 - val_loss: 0.7111 - val_acc: 0.8246\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "263 [D loss supervised: 0.4568, acc.: 84.38%] [D loss unsupervised: 0.1591, acc.: 100.00%] [G loss: 3.665997, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2357 - acc: 1.0000 - val_loss: 0.7038 - val_acc: 0.8252\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "264 [D loss supervised: 0.2357, acc.: 100.00%] [D loss unsupervised: 0.1579, acc.: 100.00%] [G loss: 3.923737, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2394 - acc: 0.9688 - val_loss: 0.7017 - val_acc: 0.8262\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "265 [D loss supervised: 0.2394, acc.: 96.88%] [D loss unsupervised: 0.1601, acc.: 100.00%] [G loss: 4.213125, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5383 - acc: 0.9062 - val_loss: 0.7096 - val_acc: 0.8244\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "266 [D loss supervised: 0.5383, acc.: 90.62%] [D loss unsupervised: 0.1587, acc.: 100.00%] [G loss: 3.924668, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3391 - acc: 0.9375 - val_loss: 0.7181 - val_acc: 0.8232\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "267 [D loss supervised: 0.3391, acc.: 93.75%] [D loss unsupervised: 0.1606, acc.: 100.00%] [G loss: 3.554521, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3092 - acc: 0.9688 - val_loss: 0.7261 - val_acc: 0.8215\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "268 [D loss supervised: 0.3092, acc.: 96.88%] [D loss unsupervised: 0.1579, acc.: 100.00%] [G loss: 4.506756, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2150 - acc: 1.0000 - val_loss: 0.7349 - val_acc: 0.8193\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "269 [D loss supervised: 0.2150, acc.: 100.00%] [D loss unsupervised: 0.1580, acc.: 100.00%] [G loss: 2.555573, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2105 - acc: 1.0000 - val_loss: 0.7426 - val_acc: 0.8157\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "270 [D loss supervised: 0.2105, acc.: 100.00%] [D loss unsupervised: 0.1580, acc.: 100.00%] [G loss: 1.446114, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3050 - acc: 0.9688 - val_loss: 0.7471 - val_acc: 0.8152\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "271 [D loss supervised: 0.3050, acc.: 96.88%] [D loss unsupervised: 0.1587, acc.: 100.00%] [G loss: 1.067310, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2124 - acc: 1.0000 - val_loss: 0.7510 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "272 [D loss supervised: 0.2124, acc.: 100.00%] [D loss unsupervised: 0.1588, acc.: 100.00%] [G loss: 0.656670, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2607 - acc: 0.9688 - val_loss: 0.7508 - val_acc: 0.8142\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "273 [D loss supervised: 0.2607, acc.: 96.88%] [D loss unsupervised: 0.1598, acc.: 100.00%] [G loss: 1.178219, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2540 - acc: 0.9688 - val_loss: 0.7493 - val_acc: 0.8135\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "274 [D loss supervised: 0.2540, acc.: 96.88%] [D loss unsupervised: 0.1590, acc.: 100.00%] [G loss: 0.736979, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2534 - acc: 0.9688 - val_loss: 0.7493 - val_acc: 0.8145\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "275 [D loss supervised: 0.2534, acc.: 96.88%] [D loss unsupervised: 0.1576, acc.: 100.00%] [G loss: 0.954533, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2561 - acc: 1.0000 - val_loss: 0.7449 - val_acc: 0.8158\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "276 [D loss supervised: 0.2561, acc.: 100.00%] [D loss unsupervised: 0.1691, acc.: 100.00%] [G loss: 0.310560, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2363 - acc: 1.0000 - val_loss: 0.7374 - val_acc: 0.8170\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "277 [D loss supervised: 0.2363, acc.: 100.00%] [D loss unsupervised: 0.1580, acc.: 100.00%] [G loss: 0.219060, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3174 - acc: 0.9375 - val_loss: 0.7264 - val_acc: 0.8229\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "278 [D loss supervised: 0.3174, acc.: 93.75%] [D loss unsupervised: 0.1581, acc.: 100.00%] [G loss: 0.263907, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3303 - acc: 0.9375 - val_loss: 0.7232 - val_acc: 0.8235\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "279 [D loss supervised: 0.3303, acc.: 93.75%] [D loss unsupervised: 0.1577, acc.: 100.00%] [G loss: 0.299360, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2248 - acc: 0.9688 - val_loss: 0.7219 - val_acc: 0.8240\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "280 [D loss supervised: 0.2248, acc.: 96.88%] [D loss unsupervised: 0.1576, acc.: 100.00%] [G loss: 0.308231, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2805 - acc: 0.9688 - val_loss: 0.7231 - val_acc: 0.8245\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "281 [D loss supervised: 0.2805, acc.: 96.88%] [D loss unsupervised: 0.1567, acc.: 100.00%] [G loss: 0.295135, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2888 - acc: 0.9375 - val_loss: 0.7268 - val_acc: 0.8253\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "282 [D loss supervised: 0.2888, acc.: 93.75%] [D loss unsupervised: 0.1561, acc.: 100.00%] [G loss: 0.475218, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2394 - acc: 1.0000 - val_loss: 0.7312 - val_acc: 0.8246\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "283 [D loss supervised: 0.2394, acc.: 100.00%] [D loss unsupervised: 0.1561, acc.: 100.00%] [G loss: 1.385925, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2190 - acc: 1.0000 - val_loss: 0.7374 - val_acc: 0.8217\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "284 [D loss supervised: 0.2190, acc.: 100.00%] [D loss unsupervised: 0.1560, acc.: 100.00%] [G loss: 0.539374, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2638 - acc: 0.9688 - val_loss: 0.7414 - val_acc: 0.8220\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "285 [D loss supervised: 0.2638, acc.: 96.88%] [D loss unsupervised: 0.1556, acc.: 100.00%] [G loss: 0.428945, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2503 - acc: 1.0000 - val_loss: 0.7455 - val_acc: 0.8214\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "286 [D loss supervised: 0.2503, acc.: 100.00%] [D loss unsupervised: 0.1555, acc.: 100.00%] [G loss: 0.382199, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3385 - acc: 0.9688 - val_loss: 0.7504 - val_acc: 0.8187\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "287 [D loss supervised: 0.3385, acc.: 96.88%] [D loss unsupervised: 0.1565, acc.: 100.00%] [G loss: 0.606466, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2440 - acc: 0.9688 - val_loss: 0.7557 - val_acc: 0.8175\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "288 [D loss supervised: 0.2440, acc.: 96.88%] [D loss unsupervised: 0.1564, acc.: 100.00%] [G loss: 0.414641, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3776 - acc: 0.9375 - val_loss: 0.7534 - val_acc: 0.8186\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "289 [D loss supervised: 0.3776, acc.: 93.75%] [D loss unsupervised: 0.1561, acc.: 100.00%] [G loss: 0.352731, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3309 - acc: 0.9375 - val_loss: 0.7450 - val_acc: 0.8214\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "290 [D loss supervised: 0.3309, acc.: 93.75%] [D loss unsupervised: 0.1549, acc.: 100.00%] [G loss: 0.612685, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2318 - acc: 1.0000 - val_loss: 0.7402 - val_acc: 0.8220\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "291 [D loss supervised: 0.2318, acc.: 100.00%] [D loss unsupervised: 0.1547, acc.: 100.00%] [G loss: 0.266468, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2941 - acc: 0.9688 - val_loss: 0.7327 - val_acc: 0.8240\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "292 [D loss supervised: 0.2941, acc.: 96.88%] [D loss unsupervised: 0.1546, acc.: 100.00%] [G loss: 0.253580, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2313 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.8237\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "293 [D loss supervised: 0.2313, acc.: 100.00%] [D loss unsupervised: 0.1543, acc.: 100.00%] [G loss: 0.259703, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3230 - acc: 0.9062 - val_loss: 0.7251 - val_acc: 0.8251\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "294 [D loss supervised: 0.3230, acc.: 90.62%] [D loss unsupervised: 0.1573, acc.: 100.00%] [G loss: 0.306037, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2763 - acc: 0.9688 - val_loss: 0.7221 - val_acc: 0.8258\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "295 [D loss supervised: 0.2763, acc.: 96.88%] [D loss unsupervised: 0.1565, acc.: 100.00%] [G loss: 0.257794, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2371 - acc: 0.9688 - val_loss: 0.7192 - val_acc: 0.8266\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "296 [D loss supervised: 0.2371, acc.: 96.88%] [D loss unsupervised: 0.1539, acc.: 100.00%] [G loss: 0.213428, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3578 - acc: 0.9688 - val_loss: 0.7115 - val_acc: 0.8299\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "297 [D loss supervised: 0.3578, acc.: 96.88%] [D loss unsupervised: 0.1538, acc.: 100.00%] [G loss: 0.198397, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3623 - acc: 0.9062 - val_loss: 0.7010 - val_acc: 0.8318\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "298 [D loss supervised: 0.3623, acc.: 90.62%] [D loss unsupervised: 0.1542, acc.: 100.00%] [G loss: 0.213941, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2195 - acc: 1.0000 - val_loss: 0.6947 - val_acc: 0.8335\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "299 [D loss supervised: 0.2195, acc.: 100.00%] [D loss unsupervised: 0.1544, acc.: 100.00%] [G loss: 0.259715, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2428 - acc: 0.9688 - val_loss: 0.6942 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.84790\n",
            "300 [D loss supervised: 0.2428, acc.: 96.88%] [D loss unsupervised: 0.1537, acc.: 100.00%] [G loss: 0.180611, acc.: 100.00%]\n",
            "Training time: 1315.0732s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfUFnOB4qLYj",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rt3ZhdCn6mk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "396e6132-f050-4b19-f433-a050fdcc3990"
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "tmodel.compile(loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'],\n",
        "                         optimizer=Adam())\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-300.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 33s 665us/step\n",
            "Training Accuracy: 86.13%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO7jfk1Pa-J8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2b8cd7af-c070-4215-e64d-e25ea5ed14e5"
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-300.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the test set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 516us/step\n",
            "Test Accuracy: 83.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk87Xx_Aa-Bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c099a813-23cc-4252-ade1-e9b2a659f5ec"
      },
      "source": [
        "div = 10\n",
        "accs = []\n",
        "tx = [x for x in range(1*div, (len(iteration_checkpoints)+1) * div, div)]\n",
        "acc_max = [0,0]\n",
        "\n",
        "for e in tx:\n",
        "  tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-\"+ str(e) +\".h5\", by_name=False)\n",
        "  _, acc = tmodel.evaluate(x, y)\n",
        "  accs.append(acc)\n",
        "print(max(accs))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(tx, accs, label=\"accs\", color='blue')\n",
        "plt.xticks(tx, rotation=90)\n",
        "plt.title(\"SCGAN-2D's accs with epoch, num_labeled=%d\" % num_labeled)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accs\")\n",
        "plt.legend()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 516us/step\n",
            "10000/10000 [==============================] - 5s 518us/step\n",
            "10000/10000 [==============================] - 5s 515us/step\n",
            "10000/10000 [==============================] - 5s 511us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 514us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 513us/step\n",
            "10000/10000 [==============================] - 5s 510us/step\n",
            "10000/10000 [==============================] - 5s 510us/step\n",
            "10000/10000 [==============================] - 5s 509us/step\n",
            "10000/10000 [==============================] - 5s 524us/step\n",
            "10000/10000 [==============================] - 5s 514us/step\n",
            "10000/10000 [==============================] - 5s 535us/step\n",
            "10000/10000 [==============================] - 5s 534us/step\n",
            "10000/10000 [==============================] - 5s 514us/step\n",
            "10000/10000 [==============================] - 5s 515us/step\n",
            "10000/10000 [==============================] - 5s 521us/step\n",
            "10000/10000 [==============================] - 5s 525us/step\n",
            "10000/10000 [==============================] - 5s 513us/step\n",
            "10000/10000 [==============================] - 5s 511us/step\n",
            "10000/10000 [==============================] - 5s 512us/step\n",
            "10000/10000 [==============================] - 5s 519us/step\n",
            "10000/10000 [==============================] - 5s 513us/step\n",
            "10000/10000 [==============================] - 5s 510us/step\n",
            "10000/10000 [==============================] - 5s 504us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 516us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 510us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 509us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 512us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 504us/step\n",
            "10000/10000 [==============================] - 5s 518us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 508us/step\n",
            "10000/10000 [==============================] - 5s 508us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 508us/step\n",
            "10000/10000 [==============================] - 5s 510us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 509us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 496us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 515us/step\n",
            "10000/10000 [==============================] - 5s 529us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 509us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 510us/step\n",
            "10000/10000 [==============================] - 5s 509us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 495us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 510us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 509us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 516us/step\n",
            "10000/10000 [==============================] - 5s 510us/step\n",
            "10000/10000 [==============================] - 5s 492us/step\n",
            "10000/10000 [==============================] - 5s 537us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 531us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 495us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 490us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 494us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 495us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 494us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 493us/step\n",
            "10000/10000 [==============================] - 5s 495us/step\n",
            "10000/10000 [==============================] - 5s 495us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 496us/step\n",
            "10000/10000 [==============================] - 5s 510us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 496us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 494us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 513us/step\n",
            "10000/10000 [==============================] - 5s 508us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 504us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 504us/step\n",
            "10000/10000 [==============================] - 5s 508us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 495us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 511us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 496us/step\n",
            "10000/10000 [==============================] - 5s 496us/step\n",
            "10000/10000 [==============================] - 5s 515us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 496us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 494us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 492us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 508us/step\n",
            "10000/10000 [==============================] - 5s 508us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 511us/step\n",
            "10000/10000 [==============================] - 5s 509us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 504us/step\n",
            "10000/10000 [==============================] - 5s 504us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 512us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 512us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 508us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 504us/step\n",
            "10000/10000 [==============================] - 5s 504us/step\n",
            "10000/10000 [==============================] - 5s 514us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 494us/step\n",
            "10000/10000 [==============================] - 5s 508us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 503us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 495us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 493us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 495us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 507us/step\n",
            "10000/10000 [==============================] - 5s 514us/step\n",
            "10000/10000 [==============================] - 5s 509us/step\n",
            "10000/10000 [==============================] - 5s 504us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 504us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "10000/10000 [==============================] - 5s 502us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 495us/step\n",
            "10000/10000 [==============================] - 5s 493us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 493us/step\n",
            "10000/10000 [==============================] - 5s 496us/step\n",
            "10000/10000 [==============================] - 5s 493us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 496us/step\n",
            "10000/10000 [==============================] - 5s 489us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 499us/step\n",
            "10000/10000 [==============================] - 5s 497us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 500us/step\n",
            "10000/10000 [==============================] - 5s 506us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 505us/step\n",
            "10000/10000 [==============================] - 5s 508us/step\n",
            "10000/10000 [==============================] - 5s 496us/step\n",
            "10000/10000 [==============================] - 5s 496us/step\n",
            "10000/10000 [==============================] - 5s 493us/step\n",
            "10000/10000 [==============================] - 5s 498us/step\n",
            "10000/10000 [==============================] - 5s 501us/step\n",
            "0.8479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7efe38a92748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFWCAYAAAA2SU9mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXfwxMiWbBLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "aa97e694-a55e-4865-808d-145a23a90997"
      },
      "source": [
        "d_supervised_loss = np.array(losses_d_supervised)\n",
        "d_unsupervised_loss = np.array(losses_d_unsupervised)\n",
        "d_unsupervised_real_loss = np.array(losses_d_unsupervised_real)\n",
        "d_unsupervised_fake_loss = np.array(losses_d_unsupervised_fake)\n",
        "d_loss = np.array(losses_d)\n",
        "g_loss = np.array(losses_g)  # Generator unsupervised loss\n",
        "all_loss = np.add(d_loss, g_loss)\n",
        "\n",
        "# Plot Discriminator supervised loss\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(iteration_checkpoints, d_supervised_loss, label=\"Discriminator supervised loss\", color='blue', linestyle='dashed')\n",
        "plt.plot(iteration_checkpoints, d_unsupervised_loss, label=\"Discriminator unsupervised loss\", color='green', linestyle='dashed')\n",
        "# plt.plot(iteration_checkpoints, d_unsupervised_real_loss, label=\"Discriminator unsupervised real loss\", color='yellow')\n",
        "# plt.plot(iteration_checkpoints, d_unsupervised_fake_loss, label=\"Discriminator unsupervised fake loss\", color='yellow')\n",
        "plt.plot(iteration_checkpoints, g_loss, label=\"Generator unsupervised loss\", color='tab:red', linestyle='dashed')\n",
        "plt.plot(iteration_checkpoints, all_loss, label=\"All losses\", color='black')\n",
        "\n",
        "plt.xticks(iteration_checkpoints, rotation=90)\n",
        "\n",
        "plt.title(\"SCGAN-2D's Discriminator Loss + Generator Loss, num_labeled=%d\" % num_labeled)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7efe384c2e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAAFWCAYAAAAR586OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwWAwGDo4zHAzGAwGg8FgMBgMhg6O/w+9Pm50cnoougAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq-YzbJRqOMH",
        "colab_type": "text"
      },
      "source": [
        "# Generate Pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgIT1giiqQU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZNbvo9zqSZB",
        "colab_type": "text"
      },
      "source": [
        "# Pseudo Label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9jhBOIcqT-h",
        "colab_type": "text"
      },
      "source": [
        "# Mean Teacher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UrCrrObhruT",
        "colab_type": "text"
      },
      "source": [
        "# To be deleted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N7bCb6u7h7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-eb3VpX7mRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'useless_models')\n",
        "model_name = 'cifar10_model.{epoch:03d}.h5'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.accs = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.accs.append(logs.get('acc'))\n",
        "\n",
        "history = LossHistory()\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler, history]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0bnB6CI_zts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik5uq5X3Rbi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(iterations, batch_size, iter_epochs, save_interval):\n",
        "\n",
        "    x_test, y_test = dataset.test_set()\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        imgs, labels = dataset.batch_labeled(batch_size)\n",
        "\n",
        "        # Compute quantities required for featurewise normalization (std, mean, and principal components if ZCA whitening is applied).\n",
        "        datagen.fit(imgs)\n",
        "        model.fit_generator(datagen.flow(imgs, labels, batch_size=batch_size),\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=iter_epochs, verbose=1, workers=4,\n",
        "                    callbacks=callbacks)\n",
        "        \n",
        "        if (iteration + 1) % save_interval == 0:\n",
        "            losses.append(history.losses[-1])\n",
        "            accs.append(history.accs[-1])\n",
        "            iteration_checkpoints.append(iteration + 1)\n",
        "            discriminator_supervised.save(\"./models/model-\" + str(iteration+1) + \".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr0Q7EaWOar9",
        "colab_type": "code",
        "outputId": "db7014bf-2598-4046-ab57-4e80f44640dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "iterations = 5\n",
        "iter_epochs = 10\n",
        "save_interval = 10\n",
        "batch_size = 32\n",
        "num_labeled = 100\n",
        "losses = []\n",
        "accs = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "dataset = Dataset_CIFAR10(num_labeled)\n",
        "\n",
        "starttime = time.clock()\n",
        "\n",
        "train(iterations, batch_size, iter_epochs, save_interval)\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Use time:\" + str(endtime-starttime) + \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2716 - acc: 1.0000 - val_loss: 1.5633 - val_acc: 0.7275\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.73420\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2799 - acc: 1.0000 - val_loss: 1.5599 - val_acc: 0.7273\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.73420\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2757 - acc: 1.0000 - val_loss: 1.5565 - val_acc: 0.7272\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.73420\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2784 - acc: 1.0000 - val_loss: 1.5532 - val_acc: 0.7272\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.73420\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2789 - acc: 1.0000 - val_loss: 1.5482 - val_acc: 0.7278\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.73420\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2742 - acc: 1.0000 - val_loss: 1.5430 - val_acc: 0.7291\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.73420\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2996 - acc: 1.0000 - val_loss: 1.5316 - val_acc: 0.7308\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.73420\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2808 - acc: 1.0000 - val_loss: 1.5165 - val_acc: 0.7327\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.73420\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2705 - acc: 1.0000 - val_loss: 1.5049 - val_acc: 0.7339\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.73420\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2722 - acc: 1.0000 - val_loss: 1.4943 - val_acc: 0.7351\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.73420 to 0.73510, saving model to /content/saved_models/cifar10_ResNet20v1_model.010.h5\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3956 - acc: 0.9688 - val_loss: 1.4862 - val_acc: 0.7348\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.73510\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3032 - acc: 1.0000 - val_loss: 1.4795 - val_acc: 0.7346\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.73510\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3062 - acc: 1.0000 - val_loss: 1.4726 - val_acc: 0.7359\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.73510 to 0.73590, saving model to /content/saved_models/cifar10_ResNet20v1_model.003.h5\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2877 - acc: 1.0000 - val_loss: 1.4676 - val_acc: 0.7361\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.73590 to 0.73610, saving model to /content/saved_models/cifar10_ResNet20v1_model.004.h5\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3063 - acc: 0.9688 - val_loss: 1.4657 - val_acc: 0.7368\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.73610 to 0.73680, saving model to /content/saved_models/cifar10_ResNet20v1_model.005.h5\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3436 - acc: 0.9688 - val_loss: 1.4577 - val_acc: 0.7382\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.73680 to 0.73820, saving model to /content/saved_models/cifar10_ResNet20v1_model.006.h5\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2751 - acc: 1.0000 - val_loss: 1.4565 - val_acc: 0.7365\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.73820\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3166 - acc: 0.9688 - val_loss: 1.4655 - val_acc: 0.7338\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.73820\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2734 - acc: 1.0000 - val_loss: 1.4773 - val_acc: 0.7321\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.73820\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3418 - acc: 0.9688 - val_loss: 1.4931 - val_acc: 0.7280\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.73820\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2748 - acc: 1.0000 - val_loss: 1.5108 - val_acc: 0.7239\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.73820\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2711 - acc: 1.0000 - val_loss: 1.5287 - val_acc: 0.7225\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.73820\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2710 - acc: 1.0000 - val_loss: 1.5459 - val_acc: 0.7203\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.73820\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2706 - acc: 1.0000 - val_loss: 1.5630 - val_acc: 0.7188\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.73820\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2713 - acc: 1.0000 - val_loss: 1.5802 - val_acc: 0.7174\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.73820\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2733 - acc: 1.0000 - val_loss: 1.5959 - val_acc: 0.7148\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.73820\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2782 - acc: 1.0000 - val_loss: 1.6087 - val_acc: 0.7132\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.73820\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2755 - acc: 1.0000 - val_loss: 1.6190 - val_acc: 0.7111\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.73820\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2965 - acc: 1.0000 - val_loss: 1.6283 - val_acc: 0.7096\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.73820\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2710 - acc: 1.0000 - val_loss: 1.6368 - val_acc: 0.7080\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.73820\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2950 - acc: 0.9688 - val_loss: 1.6413 - val_acc: 0.7072\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.73820\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2727 - acc: 1.0000 - val_loss: 1.6451 - val_acc: 0.7056\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.73820\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2873 - acc: 1.0000 - val_loss: 1.6464 - val_acc: 0.7052\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.73820\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2858 - acc: 1.0000 - val_loss: 1.6465 - val_acc: 0.7047\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.73820\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2697 - acc: 1.0000 - val_loss: 1.6467 - val_acc: 0.7043\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.73820\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2707 - acc: 1.0000 - val_loss: 1.6466 - val_acc: 0.7038\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.73820\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4211 - acc: 0.9688 - val_loss: 1.6265 - val_acc: 0.7052\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.73820\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2730 - acc: 1.0000 - val_loss: 1.6096 - val_acc: 0.7068\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.73820\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2732 - acc: 1.0000 - val_loss: 1.5967 - val_acc: 0.7071\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.73820\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2811 - acc: 1.0000 - val_loss: 1.5849 - val_acc: 0.7078\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.73820\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2735 - acc: 1.0000 - val_loss: 1.5728 - val_acc: 0.7091\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.73820\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2724 - acc: 1.0000 - val_loss: 1.5632 - val_acc: 0.7099\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.73820\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2710 - acc: 1.0000 - val_loss: 1.5545 - val_acc: 0.7106\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.73820\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2763 - acc: 1.0000 - val_loss: 1.5466 - val_acc: 0.7116\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.73820\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2727 - acc: 1.0000 - val_loss: 1.5397 - val_acc: 0.7119\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.73820\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2865 - acc: 1.0000 - val_loss: 1.5371 - val_acc: 0.7122\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.73820\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2705 - acc: 1.0000 - val_loss: 1.5350 - val_acc: 0.7128\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.73820\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2737 - acc: 1.0000 - val_loss: 1.5334 - val_acc: 0.7139\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.73820\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2711 - acc: 1.0000 - val_loss: 1.5314 - val_acc: 0.7140\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.73820\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2711 - acc: 1.0000 - val_loss: 1.5306 - val_acc: 0.7148\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.73820\n",
            "[0.27351266, 0.27242652, 0.27099964, 0.27627712, 0.27269456, 0.286533, 0.2704616, 0.27368137, 0.27110267, 0.27113327]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAIJ9nrnaNjk",
        "colab_type": "code",
        "outputId": "a194db45-69be-467c-8e6c-d8c1e1fef82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Score trained model.\n",
        "x_test, y_test = dataset.test_set()\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 315us/step\n",
            "Test loss: 1.5306017761230468\n",
            "Test accuracy: 0.7148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-sKr5pbY390",
        "colab_type": "code",
        "outputId": "1af8d53b-fb53-4776-c5d6-6da612570555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(losses)\n",
        "print(accs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6Y7noknSmXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}