{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_xDiTP_67MV",
        "colab_type": "code",
        "outputId": "cc526568-83b2-4ce2-b1ad-747de3760b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import (Dense, Conv2D, BatchNormalization, Activation, \n",
        "                          AveragePooling2D, Input, Flatten, \n",
        "                          Concatenate, Dropout, Lambda, \n",
        "                          Reshape, Embedding, Multiply)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, Callback\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from __future__ import print_function\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSaEOfjG6ztu",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_hPw_jy8jea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset_CIFAR10:\n",
        "    def __init__(self, num_labeled):\n",
        "\n",
        "        def preprocess_imgs(x):\n",
        "            # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "            x = (x.astype(np.float32) - 127.5) / 127.5\n",
        "            return x\n",
        "\n",
        "        def preprocess_labels(y):\n",
        "            y = y.reshape(-1, 1)\n",
        "            y = to_categorical(y, num_classes = 10)\n",
        "            return y\n",
        "\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        x_train = preprocess_imgs(x_train)\n",
        "        y_train = preprocess_labels(y_train)\n",
        "        x_test = preprocess_imgs(x_test)\n",
        "        y_test = preprocess_labels(y_test)\n",
        "\n",
        "        # Number labeled examples to use for training\n",
        "        self.num_labeled = num_labeled\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "        del x_train, y_train, x_test, y_test\n",
        "\n",
        "    def batch_labeled(self, batch_size):\n",
        "        # Get a random batch of labeled images and their labels\n",
        "        idx = np.random.randint(0, self.num_labeled, batch_size)\n",
        "        imgs = self.x_train[idx]\n",
        "        labels = self.y_train[idx]\n",
        "        return imgs, labels\n",
        "\n",
        "    def batch_unlabeled(self, batch_size):\n",
        "        # Get a random batch of unlabeled images\n",
        "        idx = np.random.randint(self.num_labeled, self.x_train.shape[0], batch_size)\n",
        "        imgs = self.x_train[idx]\n",
        "        return imgs\n",
        "\n",
        "    def training_set(self):\n",
        "        return self.x_train, self.y_train\n",
        "\n",
        "    def test_set(self):\n",
        "        return self.x_test, self.y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5nWXxcZdgQb",
        "colab_type": "text"
      },
      "source": [
        "## Check the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf5jJexNdigk",
        "colab_type": "code",
        "outputId": "80c9c905-369a-40b7-e388-6b7a3d1d67c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# CIFAR-10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Training set\n",
        "d_ytrain = {}\n",
        "for i in range(10):\n",
        "  d_ytrain[i] = 0\n",
        "for i in range(len(y_train)):\n",
        "  d_ytrain[y_train[i][0]] = d_ytrain.get(y_train[i][0]) + 1\n",
        "print(\"CIFAR-10 training set:\")\n",
        "print(d_ytrain)\n",
        "\n",
        "# Test set\n",
        "d_ytest = {}\n",
        "for i in range(10):\n",
        "  d_ytest[i] = 0\n",
        "for i in range(len(y_test)):\n",
        "  d_ytest[y_test[i][0]] = d_ytest.get(y_test[i][0]) + 1\n",
        "print(\"CIFAR-10 test set:\")\n",
        "print(d_ytest)\n",
        "\n",
        "del x_train, y_train, x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "CIFAR-10 training set:\n",
            "{0: 5000, 1: 5000, 2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000, 8: 5000, 9: 5000}\n",
            "CIFAR-10 test set:\n",
            "{0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRSrTM11pJtd",
        "colab_type": "code",
        "outputId": "73b65b08-f8cb-4eed-96c1-278990dfa0f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "d_imgs = {}\n",
        "num_imgs = 0\n",
        "for i in range(1000):\n",
        "  if y_train[i][0] not in d_imgs:\n",
        "    d_imgs[y_train[i][0]] = x_train[i]\n",
        "    num_imgs += 1\n",
        "  if num_imgs == 10: break\n",
        "\n",
        "d_name = {0:\"airplane\", 1:\"automobile\", 2:\"bird\", 3:\"cat\", 4:\"deer\", 5:\"dog\", 6:\"frog\", 7:\"horse\", 8:\"ship\", 9:\"truck\"}\t\n",
        "\n",
        "# Set image grid\n",
        "fig, axs = plt.subplots(2,\n",
        "                        5,\n",
        "                        figsize=(10, 4),\n",
        "                        sharey=True,\n",
        "                        sharex=True)\n",
        "\n",
        "cnt = 0\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        # Output a grid of images\n",
        "        axs[i, j].imshow(d_imgs[cnt])\n",
        "        axs[i, j].axis('off')\n",
        "        axs[i, j].set_title(\"Class: \" + str(d_name[cnt]))\n",
        "        cnt += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAD1CAYAAABUdy/PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwrpoGSKdmrp",
        "colab_type": "text"
      },
      "source": [
        "# Number of labeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvYSG5vKdoSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labeled = 1500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjhxJulqdyFs",
        "colab_type": "text"
      },
      "source": [
        "# SCGAN-2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipcTHBiShR9m",
        "colab_type": "text"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA0DtW_2d14g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "input_shape = img_shape = (32, 32, 3)\n",
        "num_classes = 10\n",
        "z_dim = 100   # Size of the noise vector, used as input to the Generator\n",
        "n = 3\n",
        "depth = n * 6 + 2   # Depth of ResNet model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgzlORUA7eUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eZ2B42_7fiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abhpWtyBfaxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CIFAR-10\n",
        "\n",
        "def build_generator(z_dim):\n",
        "  \n",
        "    z = Input(shape=(z_dim, ))\n",
        "    label = Input(shape=(num_classes, ), dtype='float32')\n",
        "    label_embedding = Dense(z_dim, input_dim=num_classes)(label)\n",
        "    joined_representation = Multiply()([z, label_embedding])\n",
        "    \n",
        "#     model = Sequential()\n",
        "\n",
        "    # Reshape input into 8x8x256 tensor via a fully connected layer\n",
        "    model = Dense(256 * 8 * 8, input_dim=z_dim)(joined_representation)\n",
        "    model = Reshape((8, 8, 256))(model)\n",
        "\n",
        "    # Transposed convolution layer, from 8x8x256 into 16x16x128 tensor\n",
        "    model = Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(model)\n",
        "\n",
        "    # Batch normalization\n",
        "    model = BatchNormalization()(model)\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model = LeakyReLU(alpha=0.01)(model)\n",
        "\n",
        "    # Transposed convolution layer, from 16x16x128 to 16x16x64 tensor\n",
        "    model = Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')(model)\n",
        "\n",
        "    # Batch normalization\n",
        "    model = BatchNormalization()(model)\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model = LeakyReLU(alpha=0.01)(model)\n",
        "\n",
        "    # Transposed convolution layer, from 16x16x64 to 32x32x3 tensor\n",
        "    model = Conv2DTranspose(3, kernel_size=3, strides=2, padding='same')(model)\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "    conditioned_img = Activation('tanh')(model)\n",
        "    \n",
        "#     conditioned_img = model(joined_representation)\n",
        "\n",
        "    model = Model([z, label], conditioned_img)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ09_xGfffbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_net(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes, kernel_initializer='he_normal')(y)\n",
        "    # outputs = Dense(num_classes,\n",
        "    #                 activation='softmax',\n",
        "    #                 kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx6rxPK2hiqj",
        "colab_type": "code",
        "outputId": "84f14265-b68c-48cd-a4f8-9c437e806a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "build_discriminator_net(img_shape, depth).summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOTS0nBXhMhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_supervised(discriminator_net):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(discriminator_net)\n",
        "\n",
        "    # Softmax activation, giving predicted probability distribution over the real classes\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuxULq-IhOlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_unsupervised(discriminator_net):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(discriminator_net)\n",
        "\n",
        "    def predict(x):\n",
        "        # Transform distribution over real classes into a binary real-vs-fake probability\n",
        "        prediction = 1.0 - (1.0 / (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.0))\n",
        "        return prediction\n",
        "\n",
        "    # 'Real-vs-fake' output neuron defined above\n",
        "    model.add(Lambda(predict))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3LcMzjZhQFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gan(generator, discriminator):\n",
        "    \n",
        "    z = Input(shape=(z_dim, ))\n",
        "    label = Input(shape=(num_classes, ))\n",
        "    img = generator([z, label])\n",
        "    output = discriminator(img)\n",
        "    model = Model([z, label], output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X4FZirFhWA7",
        "colab_type": "code",
        "outputId": "615148a9-6cc5-4eb2-856e-f7b56a76d131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "# Core Discriminator network:\n",
        "# These layers are shared during supervised and unsupervised training\n",
        "\n",
        "discriminator_net = build_discriminator_net(input_shape=img_shape, depth=depth)\n",
        "\n",
        "discriminator_supervised = build_discriminator_supervised(discriminator_net)\n",
        "discriminator_supervised.compile(loss='categorical_crossentropy',\n",
        "                                 metrics=['accuracy'],\n",
        "                                 optimizer=Adam())\n",
        "# discriminator_supervised.compile(loss='categorical_crossentropy',\n",
        "#                                  metrics=['accuracy'],\n",
        "#                                  optimizer=Adam(lr=lr_schedule(0)))\n",
        "\n",
        "discriminator_unsupervised = build_discriminator_unsupervised(discriminator_net)\n",
        "discriminator_unsupervised.compile(loss='binary_crossentropy',\n",
        "                                metrics=['accuracy'],\n",
        "                                optimizer=Adam())\n",
        "# discriminator_unsupervised.compile(loss='binary_crossentropy',\n",
        "#                                 metrics=['accuracy'],\n",
        "#                                 optimizer=Adam(lr=lr_schedule(0)))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1nVA_1egKoX",
        "colab_type": "code",
        "outputId": "e0e1d0ca-2aab-47c1-f2e7-0c807fc4c058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "discriminator_unsupervised.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 10)                274442    \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpsqRccThV02",
        "colab_type": "code",
        "outputId": "9708cb90-1f99-451e-db7e-84a9717a3297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Build the Generator\n",
        "generator = build_generator(z_dim)\n",
        "\n",
        "discriminator_supervised.trainable = False\n",
        "discriminator_unsupervised.trainable = False\n",
        "gan = build_gan(generator, discriminator_unsupervised)\n",
        "gan.compile(loss='binary_crossentropy', \n",
        "            metrics=['accuracy'], \n",
        "            optimizer=Adam())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yrZyUchhhER",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW25Txjghf7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir models\n",
        "%mkdir losses\n",
        "%mkdir models/models-label-1500\n",
        "%mkdir losses/losses-label-1500\n",
        "\n",
        "# if not os.path.isdir(save_dir):\n",
        "#     os.makedirs(save_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNb1Q6IQkL-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'models')\n",
        "model_name = 'cifar10_model.{epoch:03d}.h5'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.accs = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.accs.append(logs.get('acc'))\n",
        "\n",
        "history = LossHistory()\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler, history]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF3q3OrbkUGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR2Hun3ChbSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretrain(iterations_pre, batch_size, save_interval, iter_epochs):\n",
        "  for iteration in range(iterations_pre):\n",
        "      imgs, labels = dataset.training_set()\n",
        "      # imgs, labels = dataset.batch_labeled(batch_size)\n",
        "      x_test, y_test = dataset.test_set()\n",
        "\n",
        "      # Compute quantities required for featurewise normalization (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(imgs)\n",
        "      discriminator_supervised.fit_generator(datagen.flow(imgs, labels, batch_size=batch_size),\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  epochs=iter_epochs, verbose=1, workers=4,\n",
        "                  callbacks=callbacks)\n",
        "      \n",
        "      if (iteration + 1) % save_interval == 0:\n",
        "          \n",
        "          # Output training progress\n",
        "          print(\n",
        "              \"%d [D loss class: %.4f, acc: %.2f%%]\"\n",
        "              % (iteration + 1, history.losses[-1], 100 * history.accs[-1]))\n",
        "          iteration_checkpoints.append(iteration + 1)\n",
        "          losses.append(history.losses[-1])\n",
        "          accs.append(history.accs[-1])\n",
        "          discriminator_supervised.save_weights(\"./models/discriminator_supervised-\" + str(iteration+1) + \".h5\")\n",
        "          \n",
        "          # x, y = dataset.training_set()\n",
        "          # _, accuracy = discriminator_supervised.evaluate(x, y)\n",
        "          # print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGIfXoRgW-0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def pretrain(iterations_pre, batch_size, save_interval):\n",
        "#   for iteration in range(iterations_pre):\n",
        "#       # imgs, labels = dataset.training_set()\n",
        "#       imgs, labels = dataset.batch_labeled(1000)\n",
        "      \n",
        "#       loss, acc = discriminator_supervised.train_on_batch(imgs, labels)\n",
        "      \n",
        "#       if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "#           losses.append(loss)\n",
        "#           accs.append(acc)\n",
        "#           iteration_checkpoints.append(iteration + 1)\n",
        "          \n",
        "#           # Output training progress\n",
        "#           print(\n",
        "#               \"%d [D loss class: %.4f, acc: %.2f%%]\"\n",
        "#               % (iteration + 1, loss, 100 * acc))\n",
        "#           discriminator_supervised.save(\"./models/discriminator_supervised-\" + str(iteration+1) + \".h5\")\n",
        "          \n",
        "#           # x, y = dataset.training_set()\n",
        "#           # _, accuracy = discriminator_supervised.evaluate(x, y)\n",
        "#           # print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nIEI7nOhsUa",
        "colab_type": "code",
        "outputId": "ca48b2a9-0e1f-4d94-c6e1-6cf0280e559f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Pretrain\n",
        "\n",
        "# Set hyperparameters\n",
        "iterations_pre = 1\n",
        "iter_epochs = 40    # 20\n",
        "batch_size = 32\n",
        "save_interval = 1\n",
        "losses = []\n",
        "accs = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "dataset = Dataset_CIFAR10(num_labeled)\n",
        "\n",
        "discriminator_supervised.trainable = True\n",
        "\n",
        "starttime = time.clock()\n",
        "\n",
        "pretrain(iterations_pre, batch_size, save_interval\n",
        "         , iter_epochs\n",
        "         )\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Use time:\" + str(endtime-starttime) + \"s\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 103s 66ms/step - loss: 1.5808 - acc: 0.4826 - val_loss: 1.8150 - val_acc: 0.4500\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.45000, saving model to /content/models/cifar10_model.001.h5\n",
            "Epoch 2/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 1.1992 - acc: 0.6297 - val_loss: 1.0872 - val_acc: 0.6709\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.45000 to 0.67090, saving model to /content/models/cifar10_model.002.h5\n",
            "Epoch 3/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 57ms/step - loss: 1.0207 - acc: 0.7006 - val_loss: 1.2265 - val_acc: 0.6507\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.67090\n",
            "Epoch 4/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 0.9298 - acc: 0.7329 - val_loss: 1.2809 - val_acc: 0.6587\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.67090\n",
            "Epoch 5/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 0.8577 - acc: 0.7603 - val_loss: 1.0542 - val_acc: 0.7087\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.67090 to 0.70870, saving model to /content/models/cifar10_model.005.h5\n",
            "Epoch 6/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 0.8189 - acc: 0.7766 - val_loss: 1.0047 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.70870 to 0.71930, saving model to /content/models/cifar10_model.006.h5\n",
            "Epoch 7/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 0.7821 - acc: 0.7890 - val_loss: 0.8666 - val_acc: 0.7683\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.71930 to 0.76830, saving model to /content/models/cifar10_model.007.h5\n",
            "Epoch 8/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 57ms/step - loss: 0.7518 - acc: 0.8014 - val_loss: 0.8860 - val_acc: 0.7659\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.76830\n",
            "Epoch 9/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.7288 - acc: 0.8092 - val_loss: 0.7375 - val_acc: 0.8129\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.76830 to 0.81290, saving model to /content/models/cifar10_model.009.h5\n",
            "Epoch 10/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.7015 - acc: 0.8188 - val_loss: 0.9818 - val_acc: 0.7465\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.81290\n",
            "Epoch 11/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.6936 - acc: 0.8230 - val_loss: 0.9713 - val_acc: 0.7414\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.81290\n",
            "Epoch 12/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6778 - acc: 0.8303 - val_loss: 0.8673 - val_acc: 0.7682\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.81290\n",
            "Epoch 13/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.6644 - acc: 0.8354 - val_loss: 0.7908 - val_acc: 0.8004\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.81290\n",
            "Epoch 14/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.6521 - acc: 0.8389 - val_loss: 0.8083 - val_acc: 0.7946\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.81290\n",
            "Epoch 15/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6439 - acc: 0.8427 - val_loss: 0.7838 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.81290\n",
            "Epoch 16/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 89s 57ms/step - loss: 0.6332 - acc: 0.8470 - val_loss: 1.1694 - val_acc: 0.7222\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.81290\n",
            "Epoch 17/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6233 - acc: 0.8512 - val_loss: 1.0825 - val_acc: 0.7278\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.81290\n",
            "Epoch 18/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6197 - acc: 0.8527 - val_loss: 0.7515 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.81290 to 0.81460, saving model to /content/models/cifar10_model.018.h5\n",
            "Epoch 19/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.6082 - acc: 0.8566 - val_loss: 0.7396 - val_acc: 0.8215\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.81460 to 0.82150, saving model to /content/models/cifar10_model.019.h5\n",
            "Epoch 20/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.6055 - acc: 0.8597 - val_loss: 0.9240 - val_acc: 0.7650\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.82150\n",
            "Epoch 21/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5980 - acc: 0.8601 - val_loss: 0.7379 - val_acc: 0.8264\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.82150 to 0.82640, saving model to /content/models/cifar10_model.021.h5\n",
            "Epoch 22/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.5940 - acc: 0.8651 - val_loss: 0.7044 - val_acc: 0.8275\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.82640 to 0.82750, saving model to /content/models/cifar10_model.022.h5\n",
            "Epoch 23/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 59ms/step - loss: 0.5865 - acc: 0.8659 - val_loss: 0.8063 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.82750\n",
            "Epoch 24/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 0.5812 - acc: 0.8689 - val_loss: 0.8172 - val_acc: 0.8031\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.82750\n",
            "Epoch 25/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5747 - acc: 0.8701 - val_loss: 1.0520 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.82750\n",
            "Epoch 26/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5741 - acc: 0.8705 - val_loss: 0.8520 - val_acc: 0.7920\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.82750\n",
            "Epoch 27/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5712 - acc: 0.8721 - val_loss: 0.7520 - val_acc: 0.8223\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.82750\n",
            "Epoch 28/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 59ms/step - loss: 0.5697 - acc: 0.8739 - val_loss: 0.8162 - val_acc: 0.8101\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.82750\n",
            "Epoch 29/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.5658 - acc: 0.8758 - val_loss: 0.7576 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.82750\n",
            "Epoch 30/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5635 - acc: 0.8748 - val_loss: 0.6934 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.82750 to 0.83810, saving model to /content/models/cifar10_model.030.h5\n",
            "Epoch 31/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.5554 - acc: 0.8798 - val_loss: 0.8414 - val_acc: 0.8054\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.83810\n",
            "Epoch 32/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.5618 - acc: 0.8757 - val_loss: 0.7020 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.83810\n",
            "Epoch 33/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.5493 - acc: 0.8821 - val_loss: 0.7654 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.83810\n",
            "Epoch 34/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5496 - acc: 0.8815 - val_loss: 0.7557 - val_acc: 0.8285\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.83810\n",
            "Epoch 35/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5474 - acc: 0.8817 - val_loss: 0.6423 - val_acc: 0.8568\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.83810 to 0.85680, saving model to /content/models/cifar10_model.035.h5\n",
            "Epoch 36/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 0.5437 - acc: 0.8820 - val_loss: 0.6972 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.85680\n",
            "Epoch 37/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.5420 - acc: 0.8823 - val_loss: 0.8670 - val_acc: 0.8009\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.85680\n",
            "Epoch 38/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5417 - acc: 0.8846 - val_loss: 0.7269 - val_acc: 0.8360\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.85680\n",
            "Epoch 39/40\n",
            "Learning rate:  0.001\n",
            "1462/1563 [===========================>..] - ETA: 5s - loss: 0.5345 - acc: 0.8864Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlf871AuWzWb",
        "colab_type": "code",
        "outputId": "ab7a7c08-a839-40b9-ceac-d447bfe1881f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "%ls models"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar10_model.001.h5  cifar10_model.009.h5  cifar10_model.030.h5\n",
            "cifar10_model.002.h5  cifar10_model.018.h5  cifar10_model.035.h5\n",
            "cifar10_model.005.h5  cifar10_model.019.h5  discriminator_supervised-1.h5\n",
            "cifar10_model.006.h5  cifar10_model.021.h5  \u001b[0m\u001b[01;34mmodels-label-1500\u001b[0m/\n",
            "cifar10_model.007.h5  cifar10_model.022.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lzo6IL5z9wE",
        "colab_type": "code",
        "outputId": "83039db5-41a9-4613-c9e6-be3ac5283c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "tmodel.compile(loss='categorical_crossentropy',\n",
        "                                 metrics=['accuracy'],\n",
        "                                 optimizer=Adam())\n",
        "# tmodel.load_weights(\"./models/discriminator_supervised-2000.h5\", by_name=False)\n",
        "tmodel.load_weights(\"./models/cifar10_model.035.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 360us/step\n",
            "Training Accuracy: 88.54%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etkdmP6Ez7Jy",
        "colab_type": "code",
        "outputId": "8cbe8134-1e7f-40a1-cbaf-036b02f1048d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "tmodel.load_weights(\"./models/cifar10_model.035.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the test set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 352us/step\n",
            "Test Accuracy: 85.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xEVpUqmWb90",
        "colab_type": "code",
        "outputId": "50301db8-a35f-45bf-c533-43efb143ce38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "div = 1000\n",
        "ty = [history.accs[i*div] for i in range(0, len(history.accs)//div)]\n",
        "tx = [x for x in range(1*div, (len(ty)+1)*div, div)]\n",
        "print(max(ty))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(tx, ty, label=\"accs\", color='blue')\n",
        "plt.xticks(tx, rotation=90)\n",
        "plt.title(\"accs with epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accs\")\n",
        "plt.legend()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.96875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29d93d3cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFiCAYAAACkvHqaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTwghhBBCCCFmCP8f1huuQNEQc/sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOHm2K6nn-Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accs = []\n",
        "# tx = [x for x in range(100,2100,100)]\n",
        "# acc_max = [0,0]\n",
        "\n",
        "# x, y = dataset.test_set()\n",
        "\n",
        "# tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "# tmodel.compile(loss='categorical_crossentropy',\n",
        "#                          metrics=['accuracy'],\n",
        "#                          optimizer=Adam())\n",
        "\n",
        "# for e in tx:\n",
        "#   tmodel.load_weights(\"./models/discriminator_supervised-\"+ str(e) +\".h5\", by_name=False)\n",
        "#   _, acc = tmodel.evaluate(x, y)\n",
        "#   accs.append(acc)\n",
        "# print(max(accs))\n",
        "\n",
        "# plt.figure(figsize=(15, 5))\n",
        "# plt.plot(tx, accs, label=\"accs\", color='blue')\n",
        "# plt.xticks(tx, rotation=90)\n",
        "# plt.title(\"accs with epoch\")\n",
        "# plt.xlabel(\"epoch\")\n",
        "# plt.ylabel(\"accs\")\n",
        "# plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSbSVx1khsOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(iterations, batch_size, save_interval, iter_epochs, k):\n",
        "\n",
        "    x_test, y_test = dataset.test_set()\n",
        "\n",
        "    # Labels for real images: all ones\n",
        "    real = np.ones((batch_size, 1))\n",
        "\n",
        "    # Labels for fake images: all zeros\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        for _ in range(k):\n",
        "\n",
        "            # -------------------------\n",
        "            #  Train the Discriminator\n",
        "            # -------------------------\n",
        "\n",
        "            # Get labeled and unlabeled examples\n",
        "            imgs, labels = dataset.batch_labeled(batch_size)\n",
        "            imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
        "\n",
        "            # Generate a batch of fake images\n",
        "            z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "            fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "            fake_labels = to_categorical(fake_labels, num_classes=num_classes)\n",
        "            gen_imgs = generator.predict([z, fake_labels])\n",
        "\n",
        "            discriminator_supervised.trainable = True\n",
        "            discriminator_unsupervised.trainable = True\n",
        "\n",
        "            # Train on real labeled examples\n",
        "            datagen.fit(imgs)\n",
        "            discriminator_supervised.fit_generator(datagen.flow(imgs, labels, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=iter_epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "            loss_d_supervised, acc_d_supervised = history.losses[-1], history.accs[-1]\n",
        "\n",
        "            # Train on real unlabeled examples\n",
        "            # Error\n",
        "            # datagen.fit(imgs_unlabeled)\n",
        "            # discriminator_unsupervised.fit_generator(datagen.flow(imgs_unlabeled, real, batch_size=batch_size),\n",
        "            #             validation_data=(x_test, np.ones((len(x_test), 1))),\n",
        "            #             epochs=iter_epochs, verbose=1, workers=4,\n",
        "            #             callbacks=callbacks)\n",
        "            # loss_d_unsupervised_real, acc_d_unsupervised_real = history.losses[-1], history.accs[-1]\n",
        "            loss_d_unsupervised_real, acc_d_unsupervised_real = discriminator_unsupervised.train_on_batch(imgs_unlabeled, real)\n",
        "\n",
        "            # Train on fake examples\n",
        "            loss_d_unsupervised_fake, acc_d_unsupervised_fake = discriminator_unsupervised.train_on_batch(gen_imgs, fake)\n",
        "\n",
        "            # Calculate loss and acc\n",
        "            loss_d_unsupervised = 0.5 * np.add(loss_d_unsupervised_real, loss_d_unsupervised_fake)\n",
        "            loss_d = np.add(loss_d_supervised, loss_d_unsupervised)\n",
        "            acc_d_unsupervised = 0.5 * np.add(acc_d_unsupervised_real, acc_d_unsupervised_fake)\n",
        "            acc_d = np.add(acc_d_supervised, acc_d_unsupervised)\n",
        "        \n",
        "        # ---------------------\n",
        "        #  Train the Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Generate a batch of fake images\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "        fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "        fake_labels = to_categorical(fake_labels, num_classes=num_classes)\n",
        "        gen_imgs = generator.predict([z, fake_labels])\n",
        "\n",
        "        discriminator_supervised.trainable = False\n",
        "        discriminator_unsupervised.trainable = False\n",
        "\n",
        "        # Train Generator\n",
        "        loss_g_unsupervised, acc_g_unsupervised = gan.train_on_batch([z,labels], real)\n",
        "\n",
        "        # Calculate loss and acc\n",
        "        loss_g = loss_g_unsupervised\n",
        "        acc_g = acc_g_unsupervised\n",
        "\n",
        "        if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "            # Save losses to be plotted after training\n",
        "            losses_d_supervised.append(loss_d_supervised)\n",
        "            losses_d_unsupervised.append(loss_d_unsupervised)\n",
        "            losses_d_unsupervised_real.append(loss_d_unsupervised_real)\n",
        "            losses_d_unsupervised_fake.append(loss_d_unsupervised_fake)\n",
        "            losses_d.append(loss_d)\n",
        "            losses_g.append(loss_g)\n",
        "            \n",
        "            iteration_checkpoints.append(iteration + 1)\n",
        "\n",
        "            # Output training progress\n",
        "            print(\n",
        "                \"%d [D loss supervised: %.4f, acc.: %.2f%%] [D loss unsupervised: %.4f, acc.: %.2f%%] [G loss: %f, acc.: %.2f%%]\"\n",
        "                % (iteration + 1, \n",
        "                   loss_d_supervised, 100 * acc_d_supervised,\n",
        "                   loss_d_unsupervised, 100 * acc_d_unsupervised, \n",
        "                   loss_g, 100 * acc_g))\n",
        "            \n",
        "            discriminator_supervised.save(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-\" + str(iteration+1) + \".h5\")\n",
        "            discriminator_unsupervised.save(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_unsupervised-\" + str(iteration+1) + \".h5\")\n",
        "            generator.save(\"./models/models-label-\" + str(num_labeled) + \"/generator-\" + str(iteration+1) + \".h5\")\n",
        "            file1 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_d_supervised.json\"\n",
        "            file2 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_d_unsupervised.json\"\n",
        "            file3 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_g.json\"\n",
        "            with open(file1, 'w') as json_file:\n",
        "                  json.dump(str(losses_d_supervised), json_file)\n",
        "            with open(file2, 'w') as json_file:\n",
        "                  json.dump(str(losses_d_unsupervised), json_file)\n",
        "            with open(file3, 'w') as json_file:\n",
        "                  json.dump(str(losses_g), json_file)\n",
        "\n",
        "            # x,y = dataset.training_set()\n",
        "            # _, acc = discriminator_supervised.evaluate(x,y)\n",
        "            # print(str(100*acc)+\"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T__5V6FJn6xB",
        "colab_type": "code",
        "outputId": "563d3ac9-16bf-4e27-8542-2d9ea17d6d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set hyperparameters\n",
        "iterations = 500 # 500\n",
        "iter_epochs = 1 # 1\n",
        "batch_size = 32 # 10\n",
        "save_interval = 10\n",
        "k = 1 # iteration of Discriminator\n",
        "\n",
        "losses_d_supervised = []\n",
        "losses_d_unsupervised = []\n",
        "losses_d_unsupervised_real = []\n",
        "losses_d_unsupervised_fake = []\n",
        "losses_d = []\n",
        "losses_g = []\n",
        "\n",
        "iteration_checkpoints = []\n",
        "\n",
        "# discriminator_supervised = load_model(\"./models/discriminator_supervised-1200.h5\")\n",
        "discriminator_supervised = load_model(\"./models/cifar10_model.035.h5\")\n",
        "starttime = time.clock()\n",
        "\n",
        "# Train the SCGAN-2D for the specified number of iterations\n",
        "train(iterations, batch_size, save_interval, iter_epochs, k)\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Training time: %.4fs\" % (endtime - starttime))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 13s 13s/step - loss: 0.5412 - acc: 0.8438 - val_loss: 0.5922 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.86680 to 0.87100, saving model to /content/models/cifar10_model.001.h5\n",
            "1 [D loss supervised: 0.5412, acc.: 84.38%] [D loss unsupervised: 0.2966, acc.: 100.00%] [G loss: 1.467857, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4403 - acc: 0.8750 - val_loss: 0.6075 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87100\n",
            "2 [D loss supervised: 0.4403, acc.: 87.50%] [D loss unsupervised: 0.3055, acc.: 95.31%] [G loss: 1.847920, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4125 - acc: 0.9375 - val_loss: 0.5997 - val_acc: 0.8712\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.87100 to 0.87120, saving model to /content/models/cifar10_model.001.h5\n",
            "3 [D loss supervised: 0.4125, acc.: 93.75%] [D loss unsupervised: 0.2800, acc.: 98.44%] [G loss: 1.937941, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6461 - acc: 0.8438 - val_loss: 0.6016 - val_acc: 0.8712\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87120\n",
            "4 [D loss supervised: 0.6461, acc.: 84.38%] [D loss unsupervised: 0.2759, acc.: 98.44%] [G loss: 1.776596, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3852 - acc: 0.9375 - val_loss: 0.5820 - val_acc: 0.8762\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.87120 to 0.87620, saving model to /content/models/cifar10_model.001.h5\n",
            "5 [D loss supervised: 0.3852, acc.: 93.75%] [D loss unsupervised: 0.2778, acc.: 100.00%] [G loss: 2.074960, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5386 - acc: 0.9062 - val_loss: 0.5823 - val_acc: 0.8759\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87620\n",
            "6 [D loss supervised: 0.5386, acc.: 90.62%] [D loss unsupervised: 0.2885, acc.: 100.00%] [G loss: 2.313745, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8502 - acc: 0.7500 - val_loss: 0.5816 - val_acc: 0.8768\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.87620 to 0.87680, saving model to /content/models/cifar10_model.001.h5\n",
            "7 [D loss supervised: 0.8502, acc.: 75.00%] [D loss unsupervised: 0.2650, acc.: 100.00%] [G loss: 2.742483, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4040 - acc: 0.9062 - val_loss: 0.5818 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "8 [D loss supervised: 0.4040, acc.: 90.62%] [D loss unsupervised: 0.3039, acc.: 95.31%] [G loss: 2.885997, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4880 - acc: 0.9062 - val_loss: 0.5840 - val_acc: 0.8763\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "9 [D loss supervised: 0.4880, acc.: 90.62%] [D loss unsupervised: 0.2845, acc.: 96.88%] [G loss: 3.023329, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5519 - acc: 0.8438 - val_loss: 0.5919 - val_acc: 0.8740\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "10 [D loss supervised: 0.5519, acc.: 84.38%] [D loss unsupervised: 0.2924, acc.: 96.88%] [G loss: 3.060005, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6786 - acc: 0.8750 - val_loss: 0.5933 - val_acc: 0.8738\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "11 [D loss supervised: 0.6786, acc.: 87.50%] [D loss unsupervised: 0.2811, acc.: 98.44%] [G loss: 3.202062, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4929 - acc: 0.9062 - val_loss: 0.5975 - val_acc: 0.8723\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "12 [D loss supervised: 0.4929, acc.: 90.62%] [D loss unsupervised: 0.2750, acc.: 98.44%] [G loss: 3.214714, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4662 - acc: 0.9062 - val_loss: 0.6052 - val_acc: 0.8699\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "13 [D loss supervised: 0.4662, acc.: 90.62%] [D loss unsupervised: 0.2734, acc.: 98.44%] [G loss: 2.979795, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4919 - acc: 0.9062 - val_loss: 0.6125 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "14 [D loss supervised: 0.4919, acc.: 90.62%] [D loss unsupervised: 0.2585, acc.: 98.44%] [G loss: 2.809040, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6754 - acc: 0.8438 - val_loss: 0.6155 - val_acc: 0.8649\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "15 [D loss supervised: 0.6754, acc.: 84.38%] [D loss unsupervised: 0.2473, acc.: 100.00%] [G loss: 2.770586, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3444 - acc: 0.9688 - val_loss: 0.6214 - val_acc: 0.8642\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "16 [D loss supervised: 0.3444, acc.: 96.88%] [D loss unsupervised: 0.2558, acc.: 100.00%] [G loss: 2.677388, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3676 - acc: 0.9375 - val_loss: 0.6306 - val_acc: 0.8618\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "17 [D loss supervised: 0.3676, acc.: 93.75%] [D loss unsupervised: 0.2545, acc.: 98.44%] [G loss: 2.710370, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4790 - acc: 0.8438 - val_loss: 0.6401 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "18 [D loss supervised: 0.4790, acc.: 84.38%] [D loss unsupervised: 0.2457, acc.: 100.00%] [G loss: 2.829528, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4061 - acc: 0.9375 - val_loss: 0.6502 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "19 [D loss supervised: 0.4061, acc.: 93.75%] [D loss unsupervised: 0.2506, acc.: 100.00%] [G loss: 2.792872, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3459 - acc: 0.9688 - val_loss: 0.6618 - val_acc: 0.8570\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "20 [D loss supervised: 0.3459, acc.: 96.88%] [D loss unsupervised: 0.2503, acc.: 100.00%] [G loss: 2.652853, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5463 - acc: 0.8750 - val_loss: 0.6679 - val_acc: 0.8540\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "21 [D loss supervised: 0.5463, acc.: 87.50%] [D loss unsupervised: 0.2639, acc.: 100.00%] [G loss: 2.879297, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3067 - acc: 0.9688 - val_loss: 0.6730 - val_acc: 0.8506\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "22 [D loss supervised: 0.3067, acc.: 96.88%] [D loss unsupervised: 0.2404, acc.: 100.00%] [G loss: 3.007036, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5239 - acc: 0.9375 - val_loss: 0.6751 - val_acc: 0.8501\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "23 [D loss supervised: 0.5239, acc.: 93.75%] [D loss unsupervised: 0.2663, acc.: 98.44%] [G loss: 2.940410, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3966 - acc: 0.9062 - val_loss: 0.6819 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "24 [D loss supervised: 0.3966, acc.: 90.62%] [D loss unsupervised: 0.2643, acc.: 100.00%] [G loss: 3.038638, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4977 - acc: 0.9375 - val_loss: 0.6807 - val_acc: 0.8477\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "25 [D loss supervised: 0.4977, acc.: 93.75%] [D loss unsupervised: 0.3124, acc.: 98.44%] [G loss: 2.881484, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4359 - acc: 0.9375 - val_loss: 0.6841 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "26 [D loss supervised: 0.4359, acc.: 93.75%] [D loss unsupervised: 0.2380, acc.: 100.00%] [G loss: 2.972910, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5997 - acc: 0.8438 - val_loss: 0.6922 - val_acc: 0.8449\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "27 [D loss supervised: 0.5997, acc.: 84.38%] [D loss unsupervised: 0.2348, acc.: 100.00%] [G loss: 3.014970, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4799 - acc: 0.9062 - val_loss: 0.6998 - val_acc: 0.8435\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "28 [D loss supervised: 0.4799, acc.: 90.62%] [D loss unsupervised: 0.2618, acc.: 96.88%] [G loss: 3.371656, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5829 - acc: 0.8750 - val_loss: 0.7101 - val_acc: 0.8398\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "29 [D loss supervised: 0.5829, acc.: 87.50%] [D loss unsupervised: 0.2311, acc.: 100.00%] [G loss: 3.457724, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2912 - acc: 1.0000 - val_loss: 0.7214 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "30 [D loss supervised: 0.2912, acc.: 100.00%] [D loss unsupervised: 0.2491, acc.: 100.00%] [G loss: 3.547090, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3684 - acc: 0.9375 - val_loss: 0.7339 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "31 [D loss supervised: 0.3684, acc.: 93.75%] [D loss unsupervised: 0.2562, acc.: 100.00%] [G loss: 3.359709, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3665 - acc: 0.9375 - val_loss: 0.7434 - val_acc: 0.8307\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "32 [D loss supervised: 0.3665, acc.: 93.75%] [D loss unsupervised: 0.2385, acc.: 100.00%] [G loss: 3.563681, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4998 - acc: 0.8438 - val_loss: 0.7488 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "33 [D loss supervised: 0.4998, acc.: 84.38%] [D loss unsupervised: 0.2882, acc.: 100.00%] [G loss: 3.271981, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5267 - acc: 0.8438 - val_loss: 0.7553 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "34 [D loss supervised: 0.5267, acc.: 84.38%] [D loss unsupervised: 0.2389, acc.: 100.00%] [G loss: 3.354815, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3029 - acc: 0.9688 - val_loss: 0.7611 - val_acc: 0.8249\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "35 [D loss supervised: 0.3029, acc.: 96.88%] [D loss unsupervised: 0.2297, acc.: 100.00%] [G loss: 3.283721, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3589 - acc: 0.9375 - val_loss: 0.7666 - val_acc: 0.8235\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "36 [D loss supervised: 0.3589, acc.: 93.75%] [D loss unsupervised: 0.2291, acc.: 100.00%] [G loss: 3.184906, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5882 - acc: 0.9062 - val_loss: 0.7770 - val_acc: 0.8210\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "37 [D loss supervised: 0.5882, acc.: 90.62%] [D loss unsupervised: 0.2596, acc.: 98.44%] [G loss: 2.819465, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4233 - acc: 0.9062 - val_loss: 0.7897 - val_acc: 0.8200\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "38 [D loss supervised: 0.4233, acc.: 90.62%] [D loss unsupervised: 0.2502, acc.: 98.44%] [G loss: 2.412357, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5395 - acc: 0.8750 - val_loss: 0.8009 - val_acc: 0.8187\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "39 [D loss supervised: 0.5395, acc.: 87.50%] [D loss unsupervised: 0.2354, acc.: 100.00%] [G loss: 1.752187, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3043 - acc: 0.9688 - val_loss: 0.8028 - val_acc: 0.8190\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "40 [D loss supervised: 0.3043, acc.: 96.88%] [D loss unsupervised: 0.2488, acc.: 100.00%] [G loss: 1.460318, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4471 - acc: 0.9062 - val_loss: 0.8039 - val_acc: 0.8193\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "41 [D loss supervised: 0.4471, acc.: 90.62%] [D loss unsupervised: 0.2656, acc.: 100.00%] [G loss: 1.768502, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3295 - acc: 0.9375 - val_loss: 0.8081 - val_acc: 0.8185\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "42 [D loss supervised: 0.3295, acc.: 93.75%] [D loss unsupervised: 0.2483, acc.: 100.00%] [G loss: 2.395546, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3427 - acc: 0.9688 - val_loss: 0.8156 - val_acc: 0.8170\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "43 [D loss supervised: 0.3427, acc.: 96.88%] [D loss unsupervised: 0.2479, acc.: 100.00%] [G loss: 2.637100, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5414 - acc: 0.9375 - val_loss: 0.8191 - val_acc: 0.8169\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "44 [D loss supervised: 0.5414, acc.: 93.75%] [D loss unsupervised: 0.2302, acc.: 100.00%] [G loss: 2.848704, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7280 - acc: 0.7812 - val_loss: 0.8291 - val_acc: 0.8140\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "45 [D loss supervised: 0.7280, acc.: 78.12%] [D loss unsupervised: 0.2346, acc.: 100.00%] [G loss: 2.688225, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3684 - acc: 0.9375 - val_loss: 0.8321 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "46 [D loss supervised: 0.3684, acc.: 93.75%] [D loss unsupervised: 0.2313, acc.: 100.00%] [G loss: 1.767336, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5553 - acc: 0.8750 - val_loss: 0.8340 - val_acc: 0.8115\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "47 [D loss supervised: 0.5553, acc.: 87.50%] [D loss unsupervised: 0.2451, acc.: 100.00%] [G loss: 1.347567, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5679 - acc: 0.9062 - val_loss: 0.8328 - val_acc: 0.8122\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "48 [D loss supervised: 0.5679, acc.: 90.62%] [D loss unsupervised: 0.2346, acc.: 100.00%] [G loss: 1.783210, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3857 - acc: 0.9062 - val_loss: 0.8291 - val_acc: 0.8134\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "49 [D loss supervised: 0.3857, acc.: 90.62%] [D loss unsupervised: 0.2338, acc.: 100.00%] [G loss: 2.011524, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3763 - acc: 0.9062 - val_loss: 0.8255 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "50 [D loss supervised: 0.3763, acc.: 90.62%] [D loss unsupervised: 0.2659, acc.: 98.44%] [G loss: 1.967727, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4267 - acc: 0.9375 - val_loss: 0.8222 - val_acc: 0.8151\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "51 [D loss supervised: 0.4267, acc.: 93.75%] [D loss unsupervised: 0.2539, acc.: 98.44%] [G loss: 2.368564, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5994 - acc: 0.8750 - val_loss: 0.8252 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "52 [D loss supervised: 0.5994, acc.: 87.50%] [D loss unsupervised: 0.2496, acc.: 98.44%] [G loss: 1.481684, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6179 - acc: 0.8125 - val_loss: 0.8336 - val_acc: 0.8141\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "53 [D loss supervised: 0.6179, acc.: 81.25%] [D loss unsupervised: 0.2510, acc.: 98.44%] [G loss: 1.813754, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3986 - acc: 0.9375 - val_loss: 0.8414 - val_acc: 0.8108\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "54 [D loss supervised: 0.3986, acc.: 93.75%] [D loss unsupervised: 0.2216, acc.: 100.00%] [G loss: 1.867898, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6275 - acc: 0.8438 - val_loss: 0.8298 - val_acc: 0.8129\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "55 [D loss supervised: 0.6275, acc.: 84.38%] [D loss unsupervised: 0.2331, acc.: 100.00%] [G loss: 2.000415, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5955 - acc: 0.9062 - val_loss: 0.8167 - val_acc: 0.8159\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "56 [D loss supervised: 0.5955, acc.: 90.62%] [D loss unsupervised: 0.2173, acc.: 100.00%] [G loss: 2.109390, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5838 - acc: 0.8438 - val_loss: 0.7960 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "57 [D loss supervised: 0.5838, acc.: 84.38%] [D loss unsupervised: 0.2125, acc.: 100.00%] [G loss: 1.754953, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3791 - acc: 0.9375 - val_loss: 0.7748 - val_acc: 0.8266\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "58 [D loss supervised: 0.3791, acc.: 93.75%] [D loss unsupervised: 0.2260, acc.: 100.00%] [G loss: 2.019485, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5186 - acc: 0.9062 - val_loss: 0.7554 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "59 [D loss supervised: 0.5186, acc.: 90.62%] [D loss unsupervised: 0.2299, acc.: 100.00%] [G loss: 1.532098, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4511 - acc: 0.9062 - val_loss: 0.7400 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "60 [D loss supervised: 0.4511, acc.: 90.62%] [D loss unsupervised: 0.2149, acc.: 100.00%] [G loss: 1.648492, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6258 - acc: 0.8750 - val_loss: 0.7235 - val_acc: 0.8367\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "61 [D loss supervised: 0.6258, acc.: 87.50%] [D loss unsupervised: 0.2139, acc.: 100.00%] [G loss: 1.084772, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5786 - acc: 0.8438 - val_loss: 0.7057 - val_acc: 0.8422\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "62 [D loss supervised: 0.5786, acc.: 84.38%] [D loss unsupervised: 0.2248, acc.: 100.00%] [G loss: 1.194712, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3326 - acc: 0.9375 - val_loss: 0.6933 - val_acc: 0.8440\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "63 [D loss supervised: 0.3326, acc.: 93.75%] [D loss unsupervised: 0.2162, acc.: 100.00%] [G loss: 0.987396, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3790 - acc: 0.9688 - val_loss: 0.6866 - val_acc: 0.8466\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "64 [D loss supervised: 0.3790, acc.: 96.88%] [D loss unsupervised: 0.2172, acc.: 100.00%] [G loss: 0.705806, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3564 - acc: 0.9375 - val_loss: 0.6830 - val_acc: 0.8469\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "65 [D loss supervised: 0.3564, acc.: 93.75%] [D loss unsupervised: 0.2164, acc.: 100.00%] [G loss: 0.822104, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3314 - acc: 0.9688 - val_loss: 0.6808 - val_acc: 0.8478\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "66 [D loss supervised: 0.3314, acc.: 96.88%] [D loss unsupervised: 0.2164, acc.: 100.00%] [G loss: 1.514272, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4638 - acc: 0.9062 - val_loss: 0.6797 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "67 [D loss supervised: 0.4638, acc.: 90.62%] [D loss unsupervised: 0.2141, acc.: 100.00%] [G loss: 0.785259, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3973 - acc: 0.9062 - val_loss: 0.6814 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "68 [D loss supervised: 0.3973, acc.: 90.62%] [D loss unsupervised: 0.2100, acc.: 100.00%] [G loss: 0.999223, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4036 - acc: 0.9062 - val_loss: 0.6835 - val_acc: 0.8463\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "69 [D loss supervised: 0.4036, acc.: 90.62%] [D loss unsupervised: 0.2098, acc.: 100.00%] [G loss: 1.022411, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4470 - acc: 0.9375 - val_loss: 0.6895 - val_acc: 0.8455\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "70 [D loss supervised: 0.4470, acc.: 93.75%] [D loss unsupervised: 0.2084, acc.: 100.00%] [G loss: 0.963734, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3788 - acc: 0.9062 - val_loss: 0.6963 - val_acc: 0.8437\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "71 [D loss supervised: 0.3788, acc.: 90.62%] [D loss unsupervised: 0.2054, acc.: 100.00%] [G loss: 0.731563, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4456 - acc: 0.9062 - val_loss: 0.7073 - val_acc: 0.8408\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "72 [D loss supervised: 0.4456, acc.: 90.62%] [D loss unsupervised: 0.2125, acc.: 100.00%] [G loss: 0.673303, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3289 - acc: 0.9688 - val_loss: 0.7165 - val_acc: 0.8384\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "73 [D loss supervised: 0.3289, acc.: 96.88%] [D loss unsupervised: 0.2225, acc.: 98.44%] [G loss: 0.834085, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3970 - acc: 0.9062 - val_loss: 0.7239 - val_acc: 0.8370\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "74 [D loss supervised: 0.3970, acc.: 90.62%] [D loss unsupervised: 0.2053, acc.: 100.00%] [G loss: 0.649260, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3872 - acc: 0.9375 - val_loss: 0.7356 - val_acc: 0.8357\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "75 [D loss supervised: 0.3872, acc.: 93.75%] [D loss unsupervised: 0.2126, acc.: 100.00%] [G loss: 0.595431, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3982 - acc: 0.9062 - val_loss: 0.7419 - val_acc: 0.8350\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "76 [D loss supervised: 0.3982, acc.: 90.62%] [D loss unsupervised: 0.2113, acc.: 100.00%] [G loss: 0.582028, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4159 - acc: 0.9062 - val_loss: 0.7338 - val_acc: 0.8371\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "77 [D loss supervised: 0.4159, acc.: 90.62%] [D loss unsupervised: 0.2141, acc.: 100.00%] [G loss: 0.450163, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2562 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 0.8378\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "78 [D loss supervised: 0.2562, acc.: 100.00%] [D loss unsupervised: 0.2133, acc.: 100.00%] [G loss: 0.482822, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4406 - acc: 0.9062 - val_loss: 0.7235 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "79 [D loss supervised: 0.4406, acc.: 90.62%] [D loss unsupervised: 0.2100, acc.: 100.00%] [G loss: 0.348407, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4112 - acc: 0.9375 - val_loss: 0.7143 - val_acc: 0.8389\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "80 [D loss supervised: 0.4112, acc.: 93.75%] [D loss unsupervised: 0.2127, acc.: 100.00%] [G loss: 0.534153, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4056 - acc: 0.9375 - val_loss: 0.7027 - val_acc: 0.8412\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "81 [D loss supervised: 0.4056, acc.: 93.75%] [D loss unsupervised: 0.2076, acc.: 100.00%] [G loss: 0.334237, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4704 - acc: 0.9375 - val_loss: 0.6908 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "82 [D loss supervised: 0.4704, acc.: 93.75%] [D loss unsupervised: 0.2107, acc.: 100.00%] [G loss: 0.417596, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5775 - acc: 0.8125 - val_loss: 0.6759 - val_acc: 0.8492\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "83 [D loss supervised: 0.5775, acc.: 81.25%] [D loss unsupervised: 0.2404, acc.: 98.44%] [G loss: 0.255151, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3191 - acc: 0.9688 - val_loss: 0.6671 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "84 [D loss supervised: 0.3191, acc.: 96.88%] [D loss unsupervised: 0.2054, acc.: 100.00%] [G loss: 0.304271, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6767 - acc: 0.8438 - val_loss: 0.6640 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "85 [D loss supervised: 0.6767, acc.: 84.38%] [D loss unsupervised: 0.2104, acc.: 100.00%] [G loss: 0.313980, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4829 - acc: 0.8750 - val_loss: 0.6652 - val_acc: 0.8519\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "86 [D loss supervised: 0.4829, acc.: 87.50%] [D loss unsupervised: 0.2065, acc.: 100.00%] [G loss: 0.272075, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4375 - acc: 0.8750 - val_loss: 0.6667 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "87 [D loss supervised: 0.4375, acc.: 87.50%] [D loss unsupervised: 0.2078, acc.: 100.00%] [G loss: 0.303854, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3365 - acc: 0.9688 - val_loss: 0.6694 - val_acc: 0.8512\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "88 [D loss supervised: 0.3365, acc.: 96.88%] [D loss unsupervised: 0.2033, acc.: 100.00%] [G loss: 0.249633, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4010 - acc: 0.9375 - val_loss: 0.6717 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "89 [D loss supervised: 0.4010, acc.: 93.75%] [D loss unsupervised: 0.2057, acc.: 100.00%] [G loss: 0.279845, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4654 - acc: 0.9375 - val_loss: 0.6753 - val_acc: 0.8506\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "90 [D loss supervised: 0.4654, acc.: 93.75%] [D loss unsupervised: 0.2090, acc.: 100.00%] [G loss: 0.368382, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4061 - acc: 0.9375 - val_loss: 0.6834 - val_acc: 0.8476\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "91 [D loss supervised: 0.4061, acc.: 93.75%] [D loss unsupervised: 0.2010, acc.: 100.00%] [G loss: 0.308264, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4945 - acc: 0.9062 - val_loss: 0.6874 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "92 [D loss supervised: 0.4945, acc.: 90.62%] [D loss unsupervised: 0.2029, acc.: 100.00%] [G loss: 0.359028, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4439 - acc: 0.8750 - val_loss: 0.6924 - val_acc: 0.8446\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "93 [D loss supervised: 0.4439, acc.: 87.50%] [D loss unsupervised: 0.2046, acc.: 100.00%] [G loss: 0.330778, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3566 - acc: 0.9375 - val_loss: 0.6983 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "94 [D loss supervised: 0.3566, acc.: 93.75%] [D loss unsupervised: 0.2034, acc.: 100.00%] [G loss: 0.279690, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3906 - acc: 0.9062 - val_loss: 0.7040 - val_acc: 0.8428\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "95 [D loss supervised: 0.3906, acc.: 90.62%] [D loss unsupervised: 0.2004, acc.: 100.00%] [G loss: 0.295281, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3406 - acc: 0.9375 - val_loss: 0.7121 - val_acc: 0.8404\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "96 [D loss supervised: 0.3406, acc.: 93.75%] [D loss unsupervised: 0.2026, acc.: 100.00%] [G loss: 0.275100, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3651 - acc: 0.9688 - val_loss: 0.7189 - val_acc: 0.8391\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "97 [D loss supervised: 0.3651, acc.: 96.88%] [D loss unsupervised: 0.2045, acc.: 100.00%] [G loss: 0.299148, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3962 - acc: 0.9375 - val_loss: 0.7234 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "98 [D loss supervised: 0.3962, acc.: 93.75%] [D loss unsupervised: 0.2045, acc.: 100.00%] [G loss: 0.255254, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4212 - acc: 0.9375 - val_loss: 0.7246 - val_acc: 0.8376\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "99 [D loss supervised: 0.4212, acc.: 93.75%] [D loss unsupervised: 0.1991, acc.: 100.00%] [G loss: 0.302656, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7373 - acc: 0.8438 - val_loss: 0.7324 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "100 [D loss supervised: 0.7373, acc.: 84.38%] [D loss unsupervised: 0.1997, acc.: 100.00%] [G loss: 0.319725, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3458 - acc: 0.9688 - val_loss: 0.7409 - val_acc: 0.8325\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "101 [D loss supervised: 0.3458, acc.: 96.88%] [D loss unsupervised: 0.2005, acc.: 100.00%] [G loss: 0.248603, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5539 - acc: 0.8438 - val_loss: 0.7441 - val_acc: 0.8309\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "102 [D loss supervised: 0.5539, acc.: 84.38%] [D loss unsupervised: 0.1996, acc.: 100.00%] [G loss: 0.245983, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4667 - acc: 0.9062 - val_loss: 0.7504 - val_acc: 0.8285\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "103 [D loss supervised: 0.4667, acc.: 90.62%] [D loss unsupervised: 0.1998, acc.: 100.00%] [G loss: 0.271288, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4336 - acc: 0.9062 - val_loss: 0.7511 - val_acc: 0.8287\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "104 [D loss supervised: 0.4336, acc.: 90.62%] [D loss unsupervised: 0.2053, acc.: 100.00%] [G loss: 0.353889, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5071 - acc: 0.8750 - val_loss: 0.7443 - val_acc: 0.8283\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "105 [D loss supervised: 0.5071, acc.: 87.50%] [D loss unsupervised: 0.2021, acc.: 100.00%] [G loss: 0.250616, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3556 - acc: 0.9375 - val_loss: 0.7393 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "106 [D loss supervised: 0.3556, acc.: 93.75%] [D loss unsupervised: 0.2128, acc.: 100.00%] [G loss: 0.296752, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4795 - acc: 0.8438 - val_loss: 0.7337 - val_acc: 0.8285\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "107 [D loss supervised: 0.4795, acc.: 84.38%] [D loss unsupervised: 0.2065, acc.: 100.00%] [G loss: 0.243734, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5070 - acc: 0.8750 - val_loss: 0.7206 - val_acc: 0.8344\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "108 [D loss supervised: 0.5070, acc.: 87.50%] [D loss unsupervised: 0.2069, acc.: 100.00%] [G loss: 0.275559, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4149 - acc: 0.9688 - val_loss: 0.7086 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "109 [D loss supervised: 0.4149, acc.: 96.88%] [D loss unsupervised: 0.1985, acc.: 100.00%] [G loss: 0.335974, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4551 - acc: 0.8438 - val_loss: 0.6990 - val_acc: 0.8398\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "110 [D loss supervised: 0.4551, acc.: 84.38%] [D loss unsupervised: 0.1997, acc.: 100.00%] [G loss: 0.244767, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3797 - acc: 0.9688 - val_loss: 0.6902 - val_acc: 0.8436\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "111 [D loss supervised: 0.3797, acc.: 96.88%] [D loss unsupervised: 0.1982, acc.: 100.00%] [G loss: 0.255556, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3635 - acc: 0.9688 - val_loss: 0.6843 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "112 [D loss supervised: 0.3635, acc.: 96.88%] [D loss unsupervised: 0.2004, acc.: 100.00%] [G loss: 0.308300, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3744 - acc: 0.9375 - val_loss: 0.6802 - val_acc: 0.8478\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "113 [D loss supervised: 0.3744, acc.: 93.75%] [D loss unsupervised: 0.2015, acc.: 100.00%] [G loss: 0.276462, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3383 - acc: 0.9375 - val_loss: 0.6789 - val_acc: 0.8483\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "114 [D loss supervised: 0.3383, acc.: 93.75%] [D loss unsupervised: 0.1971, acc.: 100.00%] [G loss: 0.339244, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4243 - acc: 0.9062 - val_loss: 0.6795 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "115 [D loss supervised: 0.4243, acc.: 90.62%] [D loss unsupervised: 0.2055, acc.: 100.00%] [G loss: 0.396164, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3675 - acc: 0.9375 - val_loss: 0.6790 - val_acc: 0.8464\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "116 [D loss supervised: 0.3675, acc.: 93.75%] [D loss unsupervised: 0.2091, acc.: 100.00%] [G loss: 0.481619, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6154 - acc: 0.8438 - val_loss: 0.6726 - val_acc: 0.8480\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "117 [D loss supervised: 0.6154, acc.: 84.38%] [D loss unsupervised: 0.1942, acc.: 100.00%] [G loss: 0.584723, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2889 - acc: 0.9688 - val_loss: 0.6695 - val_acc: 0.8480\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "118 [D loss supervised: 0.2889, acc.: 96.88%] [D loss unsupervised: 0.2108, acc.: 100.00%] [G loss: 0.359756, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4314 - acc: 0.9688 - val_loss: 0.6659 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "119 [D loss supervised: 0.4314, acc.: 96.88%] [D loss unsupervised: 0.2001, acc.: 100.00%] [G loss: 0.458572, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3221 - acc: 0.9688 - val_loss: 0.6623 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "120 [D loss supervised: 0.3221, acc.: 96.88%] [D loss unsupervised: 0.1990, acc.: 100.00%] [G loss: 0.314739, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3814 - acc: 0.9062 - val_loss: 0.6567 - val_acc: 0.8492\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "121 [D loss supervised: 0.3814, acc.: 90.62%] [D loss unsupervised: 0.2017, acc.: 100.00%] [G loss: 0.328498, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3891 - acc: 0.8438 - val_loss: 0.6481 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "122 [D loss supervised: 0.3891, acc.: 84.38%] [D loss unsupervised: 0.1959, acc.: 100.00%] [G loss: 0.286401, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3348 - acc: 1.0000 - val_loss: 0.6405 - val_acc: 0.8534\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "123 [D loss supervised: 0.3348, acc.: 100.00%] [D loss unsupervised: 0.2152, acc.: 98.44%] [G loss: 0.279672, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3805 - acc: 0.9375 - val_loss: 0.6331 - val_acc: 0.8562\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "124 [D loss supervised: 0.3805, acc.: 93.75%] [D loss unsupervised: 0.1967, acc.: 100.00%] [G loss: 0.228480, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2982 - acc: 1.0000 - val_loss: 0.6264 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "125 [D loss supervised: 0.2982, acc.: 100.00%] [D loss unsupervised: 0.1993, acc.: 100.00%] [G loss: 0.258581, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4054 - acc: 0.9375 - val_loss: 0.6216 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "126 [D loss supervised: 0.4054, acc.: 93.75%] [D loss unsupervised: 0.2000, acc.: 100.00%] [G loss: 0.259475, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3528 - acc: 0.9375 - val_loss: 0.6178 - val_acc: 0.8588\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "127 [D loss supervised: 0.3528, acc.: 93.75%] [D loss unsupervised: 0.1982, acc.: 100.00%] [G loss: 0.231461, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3789 - acc: 0.9688 - val_loss: 0.6159 - val_acc: 0.8592\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "128 [D loss supervised: 0.3789, acc.: 96.88%] [D loss unsupervised: 0.1940, acc.: 100.00%] [G loss: 0.255032, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3868 - acc: 0.9375 - val_loss: 0.6151 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "129 [D loss supervised: 0.3868, acc.: 93.75%] [D loss unsupervised: 0.1964, acc.: 100.00%] [G loss: 0.242829, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3896 - acc: 0.9688 - val_loss: 0.6153 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "130 [D loss supervised: 0.3896, acc.: 96.88%] [D loss unsupervised: 0.1929, acc.: 100.00%] [G loss: 0.265448, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2778 - acc: 1.0000 - val_loss: 0.6169 - val_acc: 0.8616\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "131 [D loss supervised: 0.2778, acc.: 100.00%] [D loss unsupervised: 0.1965, acc.: 100.00%] [G loss: 0.325961, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3183 - acc: 0.9375 - val_loss: 0.6181 - val_acc: 0.8619\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "132 [D loss supervised: 0.3183, acc.: 93.75%] [D loss unsupervised: 0.1971, acc.: 100.00%] [G loss: 0.237766, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2879 - acc: 1.0000 - val_loss: 0.6203 - val_acc: 0.8617\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "133 [D loss supervised: 0.2879, acc.: 100.00%] [D loss unsupervised: 0.2004, acc.: 100.00%] [G loss: 0.336588, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2837 - acc: 1.0000 - val_loss: 0.6231 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "134 [D loss supervised: 0.2837, acc.: 100.00%] [D loss unsupervised: 0.1935, acc.: 100.00%] [G loss: 0.383740, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3477 - acc: 0.9375 - val_loss: 0.6249 - val_acc: 0.8618\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "135 [D loss supervised: 0.3477, acc.: 93.75%] [D loss unsupervised: 0.1920, acc.: 100.00%] [G loss: 0.435940, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2544 - acc: 1.0000 - val_loss: 0.6257 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "136 [D loss supervised: 0.2544, acc.: 100.00%] [D loss unsupervised: 0.1953, acc.: 100.00%] [G loss: 0.382984, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4684 - acc: 0.8750 - val_loss: 0.6282 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "137 [D loss supervised: 0.4684, acc.: 87.50%] [D loss unsupervised: 0.1976, acc.: 100.00%] [G loss: 0.427846, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3080 - acc: 0.9688 - val_loss: 0.6307 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "138 [D loss supervised: 0.3080, acc.: 96.88%] [D loss unsupervised: 0.1958, acc.: 100.00%] [G loss: 0.397323, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3093 - acc: 0.9688 - val_loss: 0.6342 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "139 [D loss supervised: 0.3093, acc.: 96.88%] [D loss unsupervised: 0.2162, acc.: 100.00%] [G loss: 0.252274, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3567 - acc: 0.9375 - val_loss: 0.6381 - val_acc: 0.8597\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "140 [D loss supervised: 0.3567, acc.: 93.75%] [D loss unsupervised: 0.2023, acc.: 100.00%] [G loss: 0.322514, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3004 - acc: 1.0000 - val_loss: 0.6415 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "141 [D loss supervised: 0.3004, acc.: 100.00%] [D loss unsupervised: 0.1968, acc.: 100.00%] [G loss: 0.612753, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3711 - acc: 0.9062 - val_loss: 0.6432 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "142 [D loss supervised: 0.3711, acc.: 90.62%] [D loss unsupervised: 0.1919, acc.: 100.00%] [G loss: 1.292829, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4939 - acc: 0.9062 - val_loss: 0.6379 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "143 [D loss supervised: 0.4939, acc.: 90.62%] [D loss unsupervised: 0.1931, acc.: 100.00%] [G loss: 0.810477, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2656 - acc: 0.9688 - val_loss: 0.6348 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "144 [D loss supervised: 0.2656, acc.: 96.88%] [D loss unsupervised: 0.2036, acc.: 100.00%] [G loss: 0.453584, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4490 - acc: 0.9375 - val_loss: 0.6342 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "145 [D loss supervised: 0.4490, acc.: 93.75%] [D loss unsupervised: 0.1991, acc.: 100.00%] [G loss: 0.728045, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4761 - acc: 0.9375 - val_loss: 0.6360 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "146 [D loss supervised: 0.4761, acc.: 93.75%] [D loss unsupervised: 0.1939, acc.: 100.00%] [G loss: 1.080369, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2963 - acc: 0.9688 - val_loss: 0.6402 - val_acc: 0.8566\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "147 [D loss supervised: 0.2963, acc.: 96.88%] [D loss unsupervised: 0.1921, acc.: 100.00%] [G loss: 1.166160, acc.: 40.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3404 - acc: 0.9688 - val_loss: 0.6440 - val_acc: 0.8545\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "148 [D loss supervised: 0.3404, acc.: 96.88%] [D loss unsupervised: 0.2031, acc.: 100.00%] [G loss: 1.266680, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2512 - acc: 1.0000 - val_loss: 0.6466 - val_acc: 0.8547\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "149 [D loss supervised: 0.2512, acc.: 100.00%] [D loss unsupervised: 0.1971, acc.: 100.00%] [G loss: 0.771612, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3129 - acc: 0.9688 - val_loss: 0.6453 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "150 [D loss supervised: 0.3129, acc.: 96.88%] [D loss unsupervised: 0.2248, acc.: 98.44%] [G loss: 0.381371, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3201 - acc: 0.9375 - val_loss: 0.6444 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "151 [D loss supervised: 0.3201, acc.: 93.75%] [D loss unsupervised: 0.2045, acc.: 100.00%] [G loss: 0.567256, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2804 - acc: 1.0000 - val_loss: 0.6427 - val_acc: 0.8549\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "152 [D loss supervised: 0.2804, acc.: 100.00%] [D loss unsupervised: 0.1970, acc.: 100.00%] [G loss: 0.470065, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3649 - acc: 0.9375 - val_loss: 0.6434 - val_acc: 0.8541\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "153 [D loss supervised: 0.3649, acc.: 93.75%] [D loss unsupervised: 0.1944, acc.: 100.00%] [G loss: 1.304121, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2614 - acc: 1.0000 - val_loss: 0.6443 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "154 [D loss supervised: 0.2614, acc.: 100.00%] [D loss unsupervised: 0.1964, acc.: 100.00%] [G loss: 0.802815, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3192 - acc: 0.9688 - val_loss: 0.6419 - val_acc: 0.8565\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "155 [D loss supervised: 0.3192, acc.: 96.88%] [D loss unsupervised: 0.1960, acc.: 100.00%] [G loss: 0.777039, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2705 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "156 [D loss supervised: 0.2705, acc.: 100.00%] [D loss unsupervised: 0.1953, acc.: 100.00%] [G loss: 0.677087, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4270 - acc: 0.9375 - val_loss: 0.6281 - val_acc: 0.8617\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "157 [D loss supervised: 0.4270, acc.: 93.75%] [D loss unsupervised: 0.1960, acc.: 100.00%] [G loss: 0.591675, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3459 - acc: 0.9688 - val_loss: 0.6209 - val_acc: 0.8633\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "158 [D loss supervised: 0.3459, acc.: 96.88%] [D loss unsupervised: 0.1981, acc.: 100.00%] [G loss: 0.474534, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3588 - acc: 0.9375 - val_loss: 0.6187 - val_acc: 0.8644\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "159 [D loss supervised: 0.3588, acc.: 93.75%] [D loss unsupervised: 0.1914, acc.: 100.00%] [G loss: 0.322312, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3359 - acc: 0.9688 - val_loss: 0.6191 - val_acc: 0.8637\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "160 [D loss supervised: 0.3359, acc.: 96.88%] [D loss unsupervised: 0.2046, acc.: 100.00%] [G loss: 0.302545, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3394 - acc: 1.0000 - val_loss: 0.6172 - val_acc: 0.8644\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "161 [D loss supervised: 0.3394, acc.: 100.00%] [D loss unsupervised: 0.1927, acc.: 100.00%] [G loss: 0.451356, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3114 - acc: 0.9688 - val_loss: 0.6161 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "162 [D loss supervised: 0.3114, acc.: 96.88%] [D loss unsupervised: 0.1953, acc.: 100.00%] [G loss: 0.305910, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3899 - acc: 0.9375 - val_loss: 0.6193 - val_acc: 0.8623\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "163 [D loss supervised: 0.3899, acc.: 93.75%] [D loss unsupervised: 0.1900, acc.: 100.00%] [G loss: 0.238989, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5221 - acc: 0.8750 - val_loss: 0.6237 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "164 [D loss supervised: 0.5221, acc.: 87.50%] [D loss unsupervised: 0.1895, acc.: 100.00%] [G loss: 0.245507, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2577 - acc: 1.0000 - val_loss: 0.6282 - val_acc: 0.8588\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "165 [D loss supervised: 0.2577, acc.: 100.00%] [D loss unsupervised: 0.1977, acc.: 100.00%] [G loss: 0.251860, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3587 - acc: 0.9375 - val_loss: 0.6336 - val_acc: 0.8569\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "166 [D loss supervised: 0.3587, acc.: 93.75%] [D loss unsupervised: 0.1876, acc.: 100.00%] [G loss: 0.382869, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3111 - acc: 0.9688 - val_loss: 0.6396 - val_acc: 0.8562\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "167 [D loss supervised: 0.3111, acc.: 96.88%] [D loss unsupervised: 0.1875, acc.: 100.00%] [G loss: 0.278977, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4912 - acc: 0.9062 - val_loss: 0.6441 - val_acc: 0.8558\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "168 [D loss supervised: 0.4912, acc.: 90.62%] [D loss unsupervised: 0.1900, acc.: 100.00%] [G loss: 0.306897, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3906 - acc: 0.9688 - val_loss: 0.6441 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "169 [D loss supervised: 0.3906, acc.: 96.88%] [D loss unsupervised: 0.1888, acc.: 100.00%] [G loss: 0.262318, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3572 - acc: 0.9688 - val_loss: 0.6440 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "170 [D loss supervised: 0.3572, acc.: 96.88%] [D loss unsupervised: 0.2052, acc.: 100.00%] [G loss: 0.212178, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3802 - acc: 0.9375 - val_loss: 0.6423 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "171 [D loss supervised: 0.3802, acc.: 93.75%] [D loss unsupervised: 0.1890, acc.: 100.00%] [G loss: 0.191064, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2732 - acc: 0.9688 - val_loss: 0.6420 - val_acc: 0.8590\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "172 [D loss supervised: 0.2732, acc.: 96.88%] [D loss unsupervised: 0.2011, acc.: 100.00%] [G loss: 0.195483, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3600 - acc: 0.9375 - val_loss: 0.6437 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "173 [D loss supervised: 0.3600, acc.: 93.75%] [D loss unsupervised: 0.1900, acc.: 100.00%] [G loss: 0.219801, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2297 - acc: 1.0000 - val_loss: 0.6453 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "174 [D loss supervised: 0.2297, acc.: 100.00%] [D loss unsupervised: 0.1866, acc.: 100.00%] [G loss: 0.215623, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4170 - acc: 0.9688 - val_loss: 0.6451 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "175 [D loss supervised: 0.4170, acc.: 96.88%] [D loss unsupervised: 0.1860, acc.: 100.00%] [G loss: 0.314583, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6127 - acc: 0.8750 - val_loss: 0.6407 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "176 [D loss supervised: 0.6127, acc.: 87.50%] [D loss unsupervised: 0.1856, acc.: 100.00%] [G loss: 0.212004, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2965 - acc: 1.0000 - val_loss: 0.6404 - val_acc: 0.8620\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "177 [D loss supervised: 0.2965, acc.: 100.00%] [D loss unsupervised: 0.1863, acc.: 100.00%] [G loss: 0.423897, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3234 - acc: 0.9688 - val_loss: 0.6428 - val_acc: 0.8613\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "178 [D loss supervised: 0.3234, acc.: 96.88%] [D loss unsupervised: 0.1870, acc.: 100.00%] [G loss: 0.274281, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4329 - acc: 0.9375 - val_loss: 0.6436 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "179 [D loss supervised: 0.4329, acc.: 93.75%] [D loss unsupervised: 0.1866, acc.: 100.00%] [G loss: 0.253876, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3052 - acc: 0.9688 - val_loss: 0.6450 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "180 [D loss supervised: 0.3052, acc.: 96.88%] [D loss unsupervised: 0.1953, acc.: 100.00%] [G loss: 0.255276, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4774 - acc: 0.8438 - val_loss: 0.6527 - val_acc: 0.8584\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "181 [D loss supervised: 0.4774, acc.: 84.38%] [D loss unsupervised: 0.1852, acc.: 100.00%] [G loss: 0.245138, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4514 - acc: 0.9062 - val_loss: 0.6596 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "182 [D loss supervised: 0.4514, acc.: 90.62%] [D loss unsupervised: 0.1856, acc.: 100.00%] [G loss: 0.212038, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3280 - acc: 1.0000 - val_loss: 0.6663 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "183 [D loss supervised: 0.3280, acc.: 100.00%] [D loss unsupervised: 0.1847, acc.: 100.00%] [G loss: 0.245240, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3456 - acc: 0.9688 - val_loss: 0.6704 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "184 [D loss supervised: 0.3456, acc.: 96.88%] [D loss unsupervised: 0.1846, acc.: 100.00%] [G loss: 0.202802, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2775 - acc: 0.9688 - val_loss: 0.6731 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "185 [D loss supervised: 0.2775, acc.: 96.88%] [D loss unsupervised: 0.1889, acc.: 100.00%] [G loss: 0.233355, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3526 - acc: 0.9375 - val_loss: 0.6738 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "186 [D loss supervised: 0.3526, acc.: 93.75%] [D loss unsupervised: 0.1827, acc.: 100.00%] [G loss: 0.228480, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2884 - acc: 0.9375 - val_loss: 0.6728 - val_acc: 0.8528\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "187 [D loss supervised: 0.2884, acc.: 93.75%] [D loss unsupervised: 0.1893, acc.: 100.00%] [G loss: 0.196910, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3746 - acc: 0.9375 - val_loss: 0.6699 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "188 [D loss supervised: 0.3746, acc.: 93.75%] [D loss unsupervised: 0.1942, acc.: 100.00%] [G loss: 0.199235, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3055 - acc: 0.9688 - val_loss: 0.6694 - val_acc: 0.8525\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "189 [D loss supervised: 0.3055, acc.: 96.88%] [D loss unsupervised: 0.1842, acc.: 100.00%] [G loss: 0.208844, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3911 - acc: 0.9375 - val_loss: 0.6681 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "190 [D loss supervised: 0.3911, acc.: 93.75%] [D loss unsupervised: 0.1828, acc.: 100.00%] [G loss: 0.210852, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3731 - acc: 0.9375 - val_loss: 0.6577 - val_acc: 0.8560\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "191 [D loss supervised: 0.3731, acc.: 93.75%] [D loss unsupervised: 0.1825, acc.: 100.00%] [G loss: 0.253171, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3317 - acc: 0.9375 - val_loss: 0.6473 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "192 [D loss supervised: 0.3317, acc.: 93.75%] [D loss unsupervised: 0.1831, acc.: 100.00%] [G loss: 0.294286, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3568 - acc: 0.9688 - val_loss: 0.6407 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "193 [D loss supervised: 0.3568, acc.: 96.88%] [D loss unsupervised: 0.1823, acc.: 100.00%] [G loss: 0.239953, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4631 - acc: 0.9062 - val_loss: 0.6380 - val_acc: 0.8616\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "194 [D loss supervised: 0.4631, acc.: 90.62%] [D loss unsupervised: 0.1816, acc.: 100.00%] [G loss: 0.243206, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3706 - acc: 0.9375 - val_loss: 0.6385 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "195 [D loss supervised: 0.3706, acc.: 93.75%] [D loss unsupervised: 0.1827, acc.: 100.00%] [G loss: 0.246963, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3047 - acc: 0.9375 - val_loss: 0.6383 - val_acc: 0.8584\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "196 [D loss supervised: 0.3047, acc.: 93.75%] [D loss unsupervised: 0.1808, acc.: 100.00%] [G loss: 0.249767, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2442 - acc: 1.0000 - val_loss: 0.6415 - val_acc: 0.8559\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "197 [D loss supervised: 0.2442, acc.: 100.00%] [D loss unsupervised: 0.1808, acc.: 100.00%] [G loss: 0.226455, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4332 - acc: 0.9375 - val_loss: 0.6450 - val_acc: 0.8543\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "198 [D loss supervised: 0.4332, acc.: 93.75%] [D loss unsupervised: 0.1814, acc.: 100.00%] [G loss: 0.303439, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4836 - acc: 0.9375 - val_loss: 0.6493 - val_acc: 0.8530\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "199 [D loss supervised: 0.4836, acc.: 93.75%] [D loss unsupervised: 0.1803, acc.: 100.00%] [G loss: 0.221888, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2867 - acc: 0.9688 - val_loss: 0.6537 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "200 [D loss supervised: 0.2867, acc.: 96.88%] [D loss unsupervised: 0.1813, acc.: 100.00%] [G loss: 0.210411, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2726 - acc: 1.0000 - val_loss: 0.6582 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "201 [D loss supervised: 0.2726, acc.: 100.00%] [D loss unsupervised: 0.1830, acc.: 100.00%] [G loss: 0.254184, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4526 - acc: 0.8750 - val_loss: 0.6611 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "202 [D loss supervised: 0.4526, acc.: 87.50%] [D loss unsupervised: 0.1848, acc.: 100.00%] [G loss: 0.201694, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3353 - acc: 1.0000 - val_loss: 0.6597 - val_acc: 0.8498\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "203 [D loss supervised: 0.3353, acc.: 100.00%] [D loss unsupervised: 0.1802, acc.: 100.00%] [G loss: 0.205894, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2964 - acc: 0.9688 - val_loss: 0.6554 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "204 [D loss supervised: 0.2964, acc.: 96.88%] [D loss unsupervised: 0.1821, acc.: 100.00%] [G loss: 0.208413, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3589 - acc: 0.9375 - val_loss: 0.6510 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "205 [D loss supervised: 0.3589, acc.: 93.75%] [D loss unsupervised: 0.1860, acc.: 100.00%] [G loss: 0.210445, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3753 - acc: 0.9062 - val_loss: 0.6455 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "206 [D loss supervised: 0.3753, acc.: 90.62%] [D loss unsupervised: 0.1799, acc.: 100.00%] [G loss: 0.194537, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2679 - acc: 1.0000 - val_loss: 0.6411 - val_acc: 0.8549\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "207 [D loss supervised: 0.2679, acc.: 100.00%] [D loss unsupervised: 0.1807, acc.: 100.00%] [G loss: 0.194039, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2348 - acc: 1.0000 - val_loss: 0.6373 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "208 [D loss supervised: 0.2348, acc.: 100.00%] [D loss unsupervised: 0.1833, acc.: 100.00%] [G loss: 0.214562, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3968 - acc: 0.9375 - val_loss: 0.6329 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "209 [D loss supervised: 0.3968, acc.: 93.75%] [D loss unsupervised: 0.1789, acc.: 100.00%] [G loss: 0.259103, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3537 - acc: 0.9688 - val_loss: 0.6310 - val_acc: 0.8583\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "210 [D loss supervised: 0.3537, acc.: 96.88%] [D loss unsupervised: 0.1797, acc.: 100.00%] [G loss: 0.279172, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3816 - acc: 0.9688 - val_loss: 0.6293 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "211 [D loss supervised: 0.3816, acc.: 96.88%] [D loss unsupervised: 0.1815, acc.: 100.00%] [G loss: 0.204386, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2637 - acc: 1.0000 - val_loss: 0.6297 - val_acc: 0.8596\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "212 [D loss supervised: 0.2637, acc.: 100.00%] [D loss unsupervised: 0.1807, acc.: 100.00%] [G loss: 0.245599, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3912 - acc: 0.9375 - val_loss: 0.6306 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "213 [D loss supervised: 0.3912, acc.: 93.75%] [D loss unsupervised: 0.1782, acc.: 100.00%] [G loss: 0.389351, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2547 - acc: 1.0000 - val_loss: 0.6331 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "214 [D loss supervised: 0.2547, acc.: 100.00%] [D loss unsupervised: 0.1779, acc.: 100.00%] [G loss: 0.230548, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3575 - acc: 0.9062 - val_loss: 0.6369 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "215 [D loss supervised: 0.3575, acc.: 90.62%] [D loss unsupervised: 0.1808, acc.: 100.00%] [G loss: 0.224265, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3692 - acc: 0.9688 - val_loss: 0.6424 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "216 [D loss supervised: 0.3692, acc.: 96.88%] [D loss unsupervised: 0.1779, acc.: 100.00%] [G loss: 0.376576, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2907 - acc: 0.9688 - val_loss: 0.6501 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "217 [D loss supervised: 0.2907, acc.: 96.88%] [D loss unsupervised: 0.1780, acc.: 100.00%] [G loss: 0.213649, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4467 - acc: 0.9062 - val_loss: 0.6580 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "218 [D loss supervised: 0.4467, acc.: 90.62%] [D loss unsupervised: 0.1809, acc.: 100.00%] [G loss: 0.212965, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2963 - acc: 0.9688 - val_loss: 0.6670 - val_acc: 0.8531\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "219 [D loss supervised: 0.2963, acc.: 96.88%] [D loss unsupervised: 0.1810, acc.: 100.00%] [G loss: 0.397975, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2310 - acc: 1.0000 - val_loss: 0.6755 - val_acc: 0.8493\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "220 [D loss supervised: 0.2310, acc.: 100.00%] [D loss unsupervised: 0.1773, acc.: 100.00%] [G loss: 0.224362, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2809 - acc: 0.9688 - val_loss: 0.6814 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "221 [D loss supervised: 0.2809, acc.: 96.88%] [D loss unsupervised: 0.1776, acc.: 100.00%] [G loss: 0.282925, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3885 - acc: 0.9375 - val_loss: 0.6834 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "222 [D loss supervised: 0.3885, acc.: 93.75%] [D loss unsupervised: 0.1770, acc.: 100.00%] [G loss: 0.260175, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4146 - acc: 0.9062 - val_loss: 0.6789 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "223 [D loss supervised: 0.4146, acc.: 90.62%] [D loss unsupervised: 0.1778, acc.: 100.00%] [G loss: 0.296069, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3304 - acc: 0.9688 - val_loss: 0.6741 - val_acc: 0.8513\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "224 [D loss supervised: 0.3304, acc.: 96.88%] [D loss unsupervised: 0.1791, acc.: 100.00%] [G loss: 0.406790, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3849 - acc: 0.9375 - val_loss: 0.6707 - val_acc: 0.8510\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "225 [D loss supervised: 0.3849, acc.: 93.75%] [D loss unsupervised: 0.1795, acc.: 100.00%] [G loss: 0.268861, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2390 - acc: 1.0000 - val_loss: 0.6685 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "226 [D loss supervised: 0.2390, acc.: 100.00%] [D loss unsupervised: 0.1828, acc.: 100.00%] [G loss: 0.433112, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3501 - acc: 0.9688 - val_loss: 0.6675 - val_acc: 0.8516\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "227 [D loss supervised: 0.3501, acc.: 96.88%] [D loss unsupervised: 0.1804, acc.: 100.00%] [G loss: 0.469741, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2605 - acc: 1.0000 - val_loss: 0.6685 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "228 [D loss supervised: 0.2605, acc.: 100.00%] [D loss unsupervised: 0.1784, acc.: 100.00%] [G loss: 1.918772, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4677 - acc: 0.8125 - val_loss: 0.6673 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "229 [D loss supervised: 0.4677, acc.: 81.25%] [D loss unsupervised: 0.1773, acc.: 100.00%] [G loss: 1.407270, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2935 - acc: 1.0000 - val_loss: 0.6668 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "230 [D loss supervised: 0.2935, acc.: 100.00%] [D loss unsupervised: 0.1835, acc.: 100.00%] [G loss: 1.111043, acc.: 50.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3796 - acc: 0.9375 - val_loss: 0.6677 - val_acc: 0.8531\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "231 [D loss supervised: 0.3796, acc.: 93.75%] [D loss unsupervised: 0.1782, acc.: 100.00%] [G loss: 0.504281, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3619 - acc: 0.9375 - val_loss: 0.6654 - val_acc: 0.8513\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "232 [D loss supervised: 0.3619, acc.: 93.75%] [D loss unsupervised: 0.1822, acc.: 100.00%] [G loss: 0.696184, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2880 - acc: 1.0000 - val_loss: 0.6627 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "233 [D loss supervised: 0.2880, acc.: 100.00%] [D loss unsupervised: 0.1799, acc.: 100.00%] [G loss: 0.876953, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4407 - acc: 0.9062 - val_loss: 0.6582 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "234 [D loss supervised: 0.4407, acc.: 90.62%] [D loss unsupervised: 0.2005, acc.: 98.44%] [G loss: 0.672852, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3146 - acc: 1.0000 - val_loss: 0.6539 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "235 [D loss supervised: 0.3146, acc.: 100.00%] [D loss unsupervised: 0.1774, acc.: 100.00%] [G loss: 0.404501, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2451 - acc: 1.0000 - val_loss: 0.6501 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "236 [D loss supervised: 0.2451, acc.: 100.00%] [D loss unsupervised: 0.1759, acc.: 100.00%] [G loss: 0.520752, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2824 - acc: 1.0000 - val_loss: 0.6484 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "237 [D loss supervised: 0.2824, acc.: 100.00%] [D loss unsupervised: 0.1769, acc.: 100.00%] [G loss: 0.668116, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2763 - acc: 1.0000 - val_loss: 0.6496 - val_acc: 0.8565\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "238 [D loss supervised: 0.2763, acc.: 100.00%] [D loss unsupervised: 0.1801, acc.: 100.00%] [G loss: 0.805557, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3715 - acc: 0.9062 - val_loss: 0.6530 - val_acc: 0.8569\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "239 [D loss supervised: 0.3715, acc.: 90.62%] [D loss unsupervised: 0.1761, acc.: 100.00%] [G loss: 2.572074, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2527 - acc: 1.0000 - val_loss: 0.6589 - val_acc: 0.8554\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "240 [D loss supervised: 0.2527, acc.: 100.00%] [D loss unsupervised: 0.1830, acc.: 100.00%] [G loss: 2.996155, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3641 - acc: 0.9688 - val_loss: 0.6675 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "241 [D loss supervised: 0.3641, acc.: 96.88%] [D loss unsupervised: 0.1767, acc.: 100.00%] [G loss: 1.944279, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3168 - acc: 0.9688 - val_loss: 0.6786 - val_acc: 0.8501\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "242 [D loss supervised: 0.3168, acc.: 96.88%] [D loss unsupervised: 0.1751, acc.: 100.00%] [G loss: 2.000528, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2790 - acc: 1.0000 - val_loss: 0.6902 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "243 [D loss supervised: 0.2790, acc.: 100.00%] [D loss unsupervised: 0.1742, acc.: 100.00%] [G loss: 1.099450, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3209 - acc: 0.9688 - val_loss: 0.7017 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "244 [D loss supervised: 0.3209, acc.: 96.88%] [D loss unsupervised: 0.1741, acc.: 100.00%] [G loss: 1.344966, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2402 - acc: 1.0000 - val_loss: 0.7147 - val_acc: 0.8405\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "245 [D loss supervised: 0.2402, acc.: 100.00%] [D loss unsupervised: 0.1741, acc.: 100.00%] [G loss: 1.168115, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2250 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "246 [D loss supervised: 0.2250, acc.: 100.00%] [D loss unsupervised: 0.1906, acc.: 100.00%] [G loss: 0.800429, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3079 - acc: 0.9375 - val_loss: 0.7400 - val_acc: 0.8358\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "247 [D loss supervised: 0.3079, acc.: 93.75%] [D loss unsupervised: 0.1733, acc.: 100.00%] [G loss: 1.048049, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4442 - acc: 0.9062 - val_loss: 0.7469 - val_acc: 0.8350\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "248 [D loss supervised: 0.4442, acc.: 90.62%] [D loss unsupervised: 0.1764, acc.: 100.00%] [G loss: 0.605763, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2853 - acc: 0.9688 - val_loss: 0.7581 - val_acc: 0.8329\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "249 [D loss supervised: 0.2853, acc.: 96.88%] [D loss unsupervised: 0.1755, acc.: 100.00%] [G loss: 0.566263, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3852 - acc: 0.9375 - val_loss: 0.7653 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "250 [D loss supervised: 0.3852, acc.: 93.75%] [D loss unsupervised: 0.1734, acc.: 100.00%] [G loss: 0.293063, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2978 - acc: 1.0000 - val_loss: 0.7737 - val_acc: 0.8300\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "251 [D loss supervised: 0.2978, acc.: 100.00%] [D loss unsupervised: 0.1732, acc.: 100.00%] [G loss: 0.632126, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3617 - acc: 0.9688 - val_loss: 0.7845 - val_acc: 0.8264\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "252 [D loss supervised: 0.3617, acc.: 96.88%] [D loss unsupervised: 0.1844, acc.: 100.00%] [G loss: 0.612837, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3852 - acc: 0.9062 - val_loss: 0.7860 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "253 [D loss supervised: 0.3852, acc.: 90.62%] [D loss unsupervised: 0.1734, acc.: 100.00%] [G loss: 0.706996, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4115 - acc: 0.9375 - val_loss: 0.7805 - val_acc: 0.8259\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "254 [D loss supervised: 0.4115, acc.: 93.75%] [D loss unsupervised: 0.1756, acc.: 100.00%] [G loss: 0.559516, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3644 - acc: 0.9688 - val_loss: 0.7792 - val_acc: 0.8263\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "255 [D loss supervised: 0.3644, acc.: 96.88%] [D loss unsupervised: 0.1733, acc.: 100.00%] [G loss: 0.376396, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3950 - acc: 0.9375 - val_loss: 0.7738 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "256 [D loss supervised: 0.3950, acc.: 93.75%] [D loss unsupervised: 0.1724, acc.: 100.00%] [G loss: 0.699161, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4330 - acc: 0.8750 - val_loss: 0.7595 - val_acc: 0.8314\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "257 [D loss supervised: 0.4330, acc.: 87.50%] [D loss unsupervised: 0.1712, acc.: 100.00%] [G loss: 0.593054, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3780 - acc: 0.9375 - val_loss: 0.7296 - val_acc: 0.8380\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "258 [D loss supervised: 0.3780, acc.: 93.75%] [D loss unsupervised: 0.1713, acc.: 100.00%] [G loss: 0.331796, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4104 - acc: 0.9062 - val_loss: 0.7060 - val_acc: 0.8434\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "259 [D loss supervised: 0.4104, acc.: 90.62%] [D loss unsupervised: 0.1711, acc.: 100.00%] [G loss: 0.534459, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3210 - acc: 0.9375 - val_loss: 0.6853 - val_acc: 0.8483\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "260 [D loss supervised: 0.3210, acc.: 93.75%] [D loss unsupervised: 0.1707, acc.: 100.00%] [G loss: 0.612633, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2868 - acc: 0.9688 - val_loss: 0.6664 - val_acc: 0.8521\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "261 [D loss supervised: 0.2868, acc.: 96.88%] [D loss unsupervised: 0.1709, acc.: 100.00%] [G loss: 0.363803, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2913 - acc: 0.9688 - val_loss: 0.6558 - val_acc: 0.8538\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "262 [D loss supervised: 0.2913, acc.: 96.88%] [D loss unsupervised: 0.1712, acc.: 100.00%] [G loss: 0.458299, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2892 - acc: 0.9688 - val_loss: 0.6503 - val_acc: 0.8555\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "263 [D loss supervised: 0.2892, acc.: 96.88%] [D loss unsupervised: 0.1709, acc.: 100.00%] [G loss: 0.449144, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2428 - acc: 1.0000 - val_loss: 0.6485 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "264 [D loss supervised: 0.2428, acc.: 100.00%] [D loss unsupervised: 0.1705, acc.: 100.00%] [G loss: 0.302191, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4171 - acc: 0.9062 - val_loss: 0.6505 - val_acc: 0.8549\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "265 [D loss supervised: 0.4171, acc.: 90.62%] [D loss unsupervised: 0.1758, acc.: 100.00%] [G loss: 0.264099, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2615 - acc: 1.0000 - val_loss: 0.6544 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "266 [D loss supervised: 0.2615, acc.: 100.00%] [D loss unsupervised: 0.1694, acc.: 100.00%] [G loss: 0.257174, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2358 - acc: 1.0000 - val_loss: 0.6604 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "267 [D loss supervised: 0.2358, acc.: 100.00%] [D loss unsupervised: 0.1779, acc.: 100.00%] [G loss: 0.464080, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3693 - acc: 0.9375 - val_loss: 0.6652 - val_acc: 0.8516\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "268 [D loss supervised: 0.3693, acc.: 93.75%] [D loss unsupervised: 0.1704, acc.: 100.00%] [G loss: 0.383687, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4360 - acc: 0.9375 - val_loss: 0.6690 - val_acc: 0.8493\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "269 [D loss supervised: 0.4360, acc.: 93.75%] [D loss unsupervised: 0.1707, acc.: 100.00%] [G loss: 0.273488, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2974 - acc: 0.9688 - val_loss: 0.6717 - val_acc: 0.8497\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "270 [D loss supervised: 0.2974, acc.: 96.88%] [D loss unsupervised: 0.1693, acc.: 100.00%] [G loss: 0.278982, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2995 - acc: 0.9688 - val_loss: 0.6770 - val_acc: 0.8486\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "271 [D loss supervised: 0.2995, acc.: 96.88%] [D loss unsupervised: 0.1696, acc.: 100.00%] [G loss: 0.269656, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2542 - acc: 1.0000 - val_loss: 0.6823 - val_acc: 0.8477\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "272 [D loss supervised: 0.2542, acc.: 100.00%] [D loss unsupervised: 0.1685, acc.: 100.00%] [G loss: 0.324545, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4098 - acc: 0.9375 - val_loss: 0.6852 - val_acc: 0.8469\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "273 [D loss supervised: 0.4098, acc.: 93.75%] [D loss unsupervised: 0.1696, acc.: 100.00%] [G loss: 0.256478, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2421 - acc: 1.0000 - val_loss: 0.6879 - val_acc: 0.8464\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "274 [D loss supervised: 0.2421, acc.: 100.00%] [D loss unsupervised: 0.1680, acc.: 100.00%] [G loss: 0.352953, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4109 - acc: 0.9062 - val_loss: 0.6902 - val_acc: 0.8454\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "275 [D loss supervised: 0.4109, acc.: 90.62%] [D loss unsupervised: 0.1681, acc.: 100.00%] [G loss: 0.266654, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2221 - acc: 1.0000 - val_loss: 0.6939 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "276 [D loss supervised: 0.2221, acc.: 100.00%] [D loss unsupervised: 0.1676, acc.: 100.00%] [G loss: 0.359775, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4414 - acc: 0.9062 - val_loss: 0.6985 - val_acc: 0.8417\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "277 [D loss supervised: 0.4414, acc.: 90.62%] [D loss unsupervised: 0.1691, acc.: 100.00%] [G loss: 0.287203, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2655 - acc: 1.0000 - val_loss: 0.7050 - val_acc: 0.8403\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "278 [D loss supervised: 0.2655, acc.: 100.00%] [D loss unsupervised: 0.1672, acc.: 100.00%] [G loss: 0.542694, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3244 - acc: 0.9375 - val_loss: 0.7088 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "279 [D loss supervised: 0.3244, acc.: 93.75%] [D loss unsupervised: 0.1691, acc.: 100.00%] [G loss: 0.613879, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3546 - acc: 0.9375 - val_loss: 0.7108 - val_acc: 0.8378\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "280 [D loss supervised: 0.3546, acc.: 93.75%] [D loss unsupervised: 0.1669, acc.: 100.00%] [G loss: 0.254461, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2518 - acc: 1.0000 - val_loss: 0.7140 - val_acc: 0.8364\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "281 [D loss supervised: 0.2518, acc.: 100.00%] [D loss unsupervised: 0.1680, acc.: 100.00%] [G loss: 0.350174, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3814 - acc: 0.9375 - val_loss: 0.7138 - val_acc: 0.8367\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "282 [D loss supervised: 0.3814, acc.: 93.75%] [D loss unsupervised: 0.1667, acc.: 100.00%] [G loss: 0.359523, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3081 - acc: 0.9688 - val_loss: 0.7097 - val_acc: 0.8384\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "283 [D loss supervised: 0.3081, acc.: 96.88%] [D loss unsupervised: 0.1670, acc.: 100.00%] [G loss: 0.540897, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3098 - acc: 0.9688 - val_loss: 0.7114 - val_acc: 0.8378\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "284 [D loss supervised: 0.3098, acc.: 96.88%] [D loss unsupervised: 0.1668, acc.: 100.00%] [G loss: 0.664151, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2807 - acc: 0.9688 - val_loss: 0.7135 - val_acc: 0.8376\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "285 [D loss supervised: 0.2807, acc.: 96.88%] [D loss unsupervised: 0.1669, acc.: 100.00%] [G loss: 0.800738, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4104 - acc: 0.9688 - val_loss: 0.7122 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "286 [D loss supervised: 0.4104, acc.: 96.88%] [D loss unsupervised: 0.1661, acc.: 100.00%] [G loss: 0.537691, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2670 - acc: 1.0000 - val_loss: 0.7083 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "287 [D loss supervised: 0.2670, acc.: 100.00%] [D loss unsupervised: 0.1668, acc.: 100.00%] [G loss: 0.747716, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2753 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.8396\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "288 [D loss supervised: 0.2753, acc.: 100.00%] [D loss unsupervised: 0.1659, acc.: 100.00%] [G loss: 1.402482, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3673 - acc: 0.9375 - val_loss: 0.6962 - val_acc: 0.8414\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "289 [D loss supervised: 0.3673, acc.: 93.75%] [D loss unsupervised: 0.1668, acc.: 100.00%] [G loss: 0.643325, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3570 - acc: 0.9688 - val_loss: 0.6942 - val_acc: 0.8407\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "290 [D loss supervised: 0.3570, acc.: 96.88%] [D loss unsupervised: 0.1671, acc.: 100.00%] [G loss: 1.278895, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2709 - acc: 1.0000 - val_loss: 0.6920 - val_acc: 0.8434\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "291 [D loss supervised: 0.2709, acc.: 100.00%] [D loss unsupervised: 0.1664, acc.: 100.00%] [G loss: 1.427744, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2531 - acc: 1.0000 - val_loss: 0.6936 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "292 [D loss supervised: 0.2531, acc.: 100.00%] [D loss unsupervised: 0.1670, acc.: 100.00%] [G loss: 0.821489, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2633 - acc: 1.0000 - val_loss: 0.6960 - val_acc: 0.8442\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "293 [D loss supervised: 0.2633, acc.: 100.00%] [D loss unsupervised: 0.1658, acc.: 100.00%] [G loss: 1.776463, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2473 - acc: 1.0000 - val_loss: 0.6977 - val_acc: 0.8448\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "294 [D loss supervised: 0.2473, acc.: 100.00%] [D loss unsupervised: 0.1653, acc.: 100.00%] [G loss: 2.199261, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3225 - acc: 0.9688 - val_loss: 0.7006 - val_acc: 0.8428\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "295 [D loss supervised: 0.3225, acc.: 96.88%] [D loss unsupervised: 0.1668, acc.: 100.00%] [G loss: 1.099059, acc.: 50.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2757 - acc: 1.0000 - val_loss: 0.7024 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "296 [D loss supervised: 0.2757, acc.: 100.00%] [D loss unsupervised: 0.1657, acc.: 100.00%] [G loss: 1.987286, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2377 - acc: 1.0000 - val_loss: 0.7049 - val_acc: 0.8414\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "297 [D loss supervised: 0.2377, acc.: 100.00%] [D loss unsupervised: 0.1697, acc.: 100.00%] [G loss: 1.735085, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3714 - acc: 0.9688 - val_loss: 0.7038 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "298 [D loss supervised: 0.3714, acc.: 96.88%] [D loss unsupervised: 0.1660, acc.: 100.00%] [G loss: 1.375732, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5475 - acc: 0.7812 - val_loss: 0.6933 - val_acc: 0.8442\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "299 [D loss supervised: 0.5475, acc.: 78.12%] [D loss unsupervised: 0.1703, acc.: 100.00%] [G loss: 2.571230, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3273 - acc: 0.9688 - val_loss: 0.6886 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "300 [D loss supervised: 0.3273, acc.: 96.88%] [D loss unsupervised: 0.1656, acc.: 100.00%] [G loss: 3.750202, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2623 - acc: 1.0000 - val_loss: 0.6851 - val_acc: 0.8456\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "301 [D loss supervised: 0.2623, acc.: 100.00%] [D loss unsupervised: 0.1661, acc.: 100.00%] [G loss: 4.190045, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2852 - acc: 1.0000 - val_loss: 0.6803 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "302 [D loss supervised: 0.2852, acc.: 100.00%] [D loss unsupervised: 0.1670, acc.: 100.00%] [G loss: 3.624425, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2527 - acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.8452\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "303 [D loss supervised: 0.2527, acc.: 100.00%] [D loss unsupervised: 0.1692, acc.: 100.00%] [G loss: 2.806790, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3425 - acc: 0.9375 - val_loss: 0.6767 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "304 [D loss supervised: 0.3425, acc.: 93.75%] [D loss unsupervised: 0.1761, acc.: 100.00%] [G loss: 2.003493, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3110 - acc: 0.9688 - val_loss: 0.6725 - val_acc: 0.8475\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "305 [D loss supervised: 0.3110, acc.: 96.88%] [D loss unsupervised: 0.1713, acc.: 100.00%] [G loss: 2.283381, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2510 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 0.8476\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "306 [D loss supervised: 0.2510, acc.: 100.00%] [D loss unsupervised: 0.1782, acc.: 100.00%] [G loss: 1.937716, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3729 - acc: 0.9688 - val_loss: 0.6673 - val_acc: 0.8478\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "307 [D loss supervised: 0.3729, acc.: 96.88%] [D loss unsupervised: 0.1662, acc.: 100.00%] [G loss: 2.071823, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2813 - acc: 1.0000 - val_loss: 0.6670 - val_acc: 0.8485\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "308 [D loss supervised: 0.2813, acc.: 100.00%] [D loss unsupervised: 0.1652, acc.: 100.00%] [G loss: 2.144446, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3043 - acc: 0.9688 - val_loss: 0.6717 - val_acc: 0.8477\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "309 [D loss supervised: 0.3043, acc.: 96.88%] [D loss unsupervised: 0.1663, acc.: 100.00%] [G loss: 1.929560, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3117 - acc: 0.9688 - val_loss: 0.6767 - val_acc: 0.8457\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "310 [D loss supervised: 0.3117, acc.: 96.88%] [D loss unsupervised: 0.1677, acc.: 100.00%] [G loss: 2.389674, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4195 - acc: 0.9688 - val_loss: 0.6835 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "311 [D loss supervised: 0.4195, acc.: 96.88%] [D loss unsupervised: 0.1637, acc.: 100.00%] [G loss: 1.888204, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2226 - acc: 1.0000 - val_loss: 0.6903 - val_acc: 0.8440\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "312 [D loss supervised: 0.2226, acc.: 100.00%] [D loss unsupervised: 0.1643, acc.: 100.00%] [G loss: 2.098484, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2653 - acc: 1.0000 - val_loss: 0.6953 - val_acc: 0.8432\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "313 [D loss supervised: 0.2653, acc.: 100.00%] [D loss unsupervised: 0.1637, acc.: 100.00%] [G loss: 2.415478, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2692 - acc: 0.9688 - val_loss: 0.6984 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "314 [D loss supervised: 0.2692, acc.: 96.88%] [D loss unsupervised: 0.1645, acc.: 100.00%] [G loss: 2.503240, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2510 - acc: 1.0000 - val_loss: 0.7019 - val_acc: 0.8436\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "315 [D loss supervised: 0.2510, acc.: 100.00%] [D loss unsupervised: 0.1733, acc.: 100.00%] [G loss: 2.712358, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2582 - acc: 1.0000 - val_loss: 0.7056 - val_acc: 0.8429\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "316 [D loss supervised: 0.2582, acc.: 100.00%] [D loss unsupervised: 0.1643, acc.: 100.00%] [G loss: 3.908401, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3157 - acc: 1.0000 - val_loss: 0.7083 - val_acc: 0.8421\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "317 [D loss supervised: 0.3157, acc.: 100.00%] [D loss unsupervised: 0.1624, acc.: 100.00%] [G loss: 4.493382, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3376 - acc: 0.9375 - val_loss: 0.7080 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "318 [D loss supervised: 0.3376, acc.: 93.75%] [D loss unsupervised: 0.1621, acc.: 100.00%] [G loss: 3.596434, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3272 - acc: 0.9375 - val_loss: 0.7052 - val_acc: 0.8446\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "319 [D loss supervised: 0.3272, acc.: 93.75%] [D loss unsupervised: 0.1620, acc.: 100.00%] [G loss: 3.337653, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2935 - acc: 1.0000 - val_loss: 0.7033 - val_acc: 0.8455\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "320 [D loss supervised: 0.2935, acc.: 100.00%] [D loss unsupervised: 0.1742, acc.: 98.44%] [G loss: 2.666442, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3687 - acc: 0.9375 - val_loss: 0.6994 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "321 [D loss supervised: 0.3687, acc.: 93.75%] [D loss unsupervised: 0.1680, acc.: 100.00%] [G loss: 2.819689, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3197 - acc: 0.9688 - val_loss: 0.6969 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "322 [D loss supervised: 0.3197, acc.: 96.88%] [D loss unsupervised: 0.1624, acc.: 100.00%] [G loss: 3.654212, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3249 - acc: 0.9688 - val_loss: 0.6916 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "323 [D loss supervised: 0.3249, acc.: 96.88%] [D loss unsupervised: 0.1623, acc.: 100.00%] [G loss: 2.816136, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3208 - acc: 0.9688 - val_loss: 0.6876 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "324 [D loss supervised: 0.3208, acc.: 96.88%] [D loss unsupervised: 0.1639, acc.: 100.00%] [G loss: 2.760268, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2679 - acc: 0.9688 - val_loss: 0.6852 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "325 [D loss supervised: 0.2679, acc.: 96.88%] [D loss unsupervised: 0.1630, acc.: 100.00%] [G loss: 3.443612, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2374 - acc: 1.0000 - val_loss: 0.6839 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "326 [D loss supervised: 0.2374, acc.: 100.00%] [D loss unsupervised: 0.1616, acc.: 100.00%] [G loss: 3.249836, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2559 - acc: 1.0000 - val_loss: 0.6830 - val_acc: 0.8533\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "327 [D loss supervised: 0.2559, acc.: 100.00%] [D loss unsupervised: 0.1622, acc.: 100.00%] [G loss: 3.019246, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2799 - acc: 0.9688 - val_loss: 0.6799 - val_acc: 0.8533\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "328 [D loss supervised: 0.2799, acc.: 96.88%] [D loss unsupervised: 0.1642, acc.: 100.00%] [G loss: 3.172407, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2690 - acc: 1.0000 - val_loss: 0.6771 - val_acc: 0.8545\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "329 [D loss supervised: 0.2690, acc.: 100.00%] [D loss unsupervised: 0.1620, acc.: 100.00%] [G loss: 3.282761, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2694 - acc: 0.9688 - val_loss: 0.6754 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "330 [D loss supervised: 0.2694, acc.: 96.88%] [D loss unsupervised: 0.1607, acc.: 100.00%] [G loss: 2.836027, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2751 - acc: 0.9688 - val_loss: 0.6755 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "331 [D loss supervised: 0.2751, acc.: 96.88%] [D loss unsupervised: 0.1631, acc.: 100.00%] [G loss: 2.609496, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2111 - acc: 1.0000 - val_loss: 0.6768 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "332 [D loss supervised: 0.2111, acc.: 100.00%] [D loss unsupervised: 0.1610, acc.: 100.00%] [G loss: 2.534936, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2426 - acc: 1.0000 - val_loss: 0.6786 - val_acc: 0.8499\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "333 [D loss supervised: 0.2426, acc.: 100.00%] [D loss unsupervised: 0.1618, acc.: 100.00%] [G loss: 2.855857, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2514 - acc: 1.0000 - val_loss: 0.6815 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "334 [D loss supervised: 0.2514, acc.: 100.00%] [D loss unsupervised: 0.1624, acc.: 100.00%] [G loss: 2.753378, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2579 - acc: 1.0000 - val_loss: 0.6857 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "335 [D loss supervised: 0.2579, acc.: 100.00%] [D loss unsupervised: 0.1614, acc.: 100.00%] [G loss: 3.662387, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2480 - acc: 1.0000 - val_loss: 0.6904 - val_acc: 0.8453\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "336 [D loss supervised: 0.2480, acc.: 100.00%] [D loss unsupervised: 0.1660, acc.: 100.00%] [G loss: 3.041087, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3409 - acc: 0.9688 - val_loss: 0.6908 - val_acc: 0.8453\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "337 [D loss supervised: 0.3409, acc.: 96.88%] [D loss unsupervised: 0.1629, acc.: 100.00%] [G loss: 2.672217, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2280 - acc: 1.0000 - val_loss: 0.6918 - val_acc: 0.8449\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "338 [D loss supervised: 0.2280, acc.: 100.00%] [D loss unsupervised: 0.1613, acc.: 100.00%] [G loss: 2.524186, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2965 - acc: 0.9688 - val_loss: 0.6906 - val_acc: 0.8458\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "339 [D loss supervised: 0.2965, acc.: 96.88%] [D loss unsupervised: 0.1623, acc.: 100.00%] [G loss: 2.624174, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2452 - acc: 1.0000 - val_loss: 0.6893 - val_acc: 0.8465\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "340 [D loss supervised: 0.2452, acc.: 100.00%] [D loss unsupervised: 0.1610, acc.: 100.00%] [G loss: 2.698624, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3019 - acc: 0.9375 - val_loss: 0.6830 - val_acc: 0.8496\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "341 [D loss supervised: 0.3019, acc.: 93.75%] [D loss unsupervised: 0.1612, acc.: 100.00%] [G loss: 1.669277, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2693 - acc: 1.0000 - val_loss: 0.6751 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "342 [D loss supervised: 0.2693, acc.: 100.00%] [D loss unsupervised: 0.1704, acc.: 100.00%] [G loss: 4.340105, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2313 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.8526\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "343 [D loss supervised: 0.2313, acc.: 100.00%] [D loss unsupervised: 0.1663, acc.: 100.00%] [G loss: 5.235507, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2628 - acc: 0.9688 - val_loss: 0.6631 - val_acc: 0.8532\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "344 [D loss supervised: 0.2628, acc.: 96.88%] [D loss unsupervised: 0.1854, acc.: 98.44%] [G loss: 5.492744, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3989 - acc: 0.9688 - val_loss: 0.6598 - val_acc: 0.8557\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "345 [D loss supervised: 0.3989, acc.: 96.88%] [D loss unsupervised: 0.1618, acc.: 100.00%] [G loss: 5.442096, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2877 - acc: 0.9688 - val_loss: 0.6575 - val_acc: 0.8560\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "346 [D loss supervised: 0.2877, acc.: 96.88%] [D loss unsupervised: 0.1628, acc.: 100.00%] [G loss: 5.697756, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3193 - acc: 0.9375 - val_loss: 0.6568 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "347 [D loss supervised: 0.3193, acc.: 93.75%] [D loss unsupervised: 0.1581, acc.: 100.00%] [G loss: 5.394989, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2997 - acc: 0.9688 - val_loss: 0.6588 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "348 [D loss supervised: 0.2997, acc.: 96.88%] [D loss unsupervised: 0.1576, acc.: 100.00%] [G loss: 5.322198, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4745 - acc: 0.9062 - val_loss: 0.6619 - val_acc: 0.8540\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "349 [D loss supervised: 0.4745, acc.: 90.62%] [D loss unsupervised: 0.1678, acc.: 100.00%] [G loss: 5.165796, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3399 - acc: 0.9688 - val_loss: 0.6642 - val_acc: 0.8523\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "350 [D loss supervised: 0.3399, acc.: 96.88%] [D loss unsupervised: 0.1576, acc.: 100.00%] [G loss: 4.754653, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2516 - acc: 1.0000 - val_loss: 0.6690 - val_acc: 0.8524\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "351 [D loss supervised: 0.2516, acc.: 100.00%] [D loss unsupervised: 0.1610, acc.: 100.00%] [G loss: 4.092860, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2894 - acc: 0.9688 - val_loss: 0.6740 - val_acc: 0.8508\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "352 [D loss supervised: 0.2894, acc.: 96.88%] [D loss unsupervised: 0.1585, acc.: 100.00%] [G loss: 4.107539, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3900 - acc: 0.9375 - val_loss: 0.6781 - val_acc: 0.8505\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "353 [D loss supervised: 0.3900, acc.: 93.75%] [D loss unsupervised: 0.1587, acc.: 100.00%] [G loss: 3.533521, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2504 - acc: 1.0000 - val_loss: 0.6827 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "354 [D loss supervised: 0.2504, acc.: 100.00%] [D loss unsupervised: 0.1712, acc.: 100.00%] [G loss: 3.594002, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2948 - acc: 0.9688 - val_loss: 0.6846 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "355 [D loss supervised: 0.2948, acc.: 96.88%] [D loss unsupervised: 0.1569, acc.: 100.00%] [G loss: 3.686290, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3592 - acc: 0.9375 - val_loss: 0.6896 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "356 [D loss supervised: 0.3592, acc.: 93.75%] [D loss unsupervised: 0.1572, acc.: 100.00%] [G loss: 3.348302, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3714 - acc: 0.9375 - val_loss: 0.6947 - val_acc: 0.8488\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "357 [D loss supervised: 0.3714, acc.: 93.75%] [D loss unsupervised: 0.1570, acc.: 100.00%] [G loss: 3.466629, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2335 - acc: 1.0000 - val_loss: 0.6998 - val_acc: 0.8481\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "358 [D loss supervised: 0.2335, acc.: 100.00%] [D loss unsupervised: 0.1597, acc.: 100.00%] [G loss: 3.709291, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2647 - acc: 0.9688 - val_loss: 0.7051 - val_acc: 0.8484\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "359 [D loss supervised: 0.2647, acc.: 96.88%] [D loss unsupervised: 0.1556, acc.: 100.00%] [G loss: 3.690846, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2297 - acc: 1.0000 - val_loss: 0.7142 - val_acc: 0.8453\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "360 [D loss supervised: 0.2297, acc.: 100.00%] [D loss unsupervised: 0.1552, acc.: 100.00%] [G loss: 3.862269, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2388 - acc: 1.0000 - val_loss: 0.7254 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "361 [D loss supervised: 0.2388, acc.: 100.00%] [D loss unsupervised: 0.1552, acc.: 100.00%] [G loss: 3.894103, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3270 - acc: 0.9688 - val_loss: 0.7363 - val_acc: 0.8399\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "362 [D loss supervised: 0.3270, acc.: 96.88%] [D loss unsupervised: 0.1544, acc.: 100.00%] [G loss: 4.062887, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2900 - acc: 0.9688 - val_loss: 0.7478 - val_acc: 0.8365\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "363 [D loss supervised: 0.2900, acc.: 96.88%] [D loss unsupervised: 0.1555, acc.: 100.00%] [G loss: 3.587575, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3414 - acc: 0.9375 - val_loss: 0.7592 - val_acc: 0.8342\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "364 [D loss supervised: 0.3414, acc.: 93.75%] [D loss unsupervised: 0.1552, acc.: 100.00%] [G loss: 3.461124, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3266 - acc: 0.9375 - val_loss: 0.7711 - val_acc: 0.8313\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "365 [D loss supervised: 0.3266, acc.: 93.75%] [D loss unsupervised: 0.1541, acc.: 100.00%] [G loss: 3.225020, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2462 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.8280\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "366 [D loss supervised: 0.2462, acc.: 100.00%] [D loss unsupervised: 0.1540, acc.: 100.00%] [G loss: 3.540123, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2575 - acc: 0.9688 - val_loss: 0.7971 - val_acc: 0.8261\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "367 [D loss supervised: 0.2575, acc.: 96.88%] [D loss unsupervised: 0.1539, acc.: 100.00%] [G loss: 3.476610, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2360 - acc: 1.0000 - val_loss: 0.8096 - val_acc: 0.8232\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "368 [D loss supervised: 0.2360, acc.: 100.00%] [D loss unsupervised: 0.1546, acc.: 100.00%] [G loss: 2.924460, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5089 - acc: 0.9062 - val_loss: 0.8248 - val_acc: 0.8182\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "369 [D loss supervised: 0.5089, acc.: 90.62%] [D loss unsupervised: 0.1538, acc.: 100.00%] [G loss: 2.785222, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2117 - acc: 1.0000 - val_loss: 0.8364 - val_acc: 0.8166\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "370 [D loss supervised: 0.2117, acc.: 100.00%] [D loss unsupervised: 0.1529, acc.: 100.00%] [G loss: 2.634441, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2440 - acc: 1.0000 - val_loss: 0.8455 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "371 [D loss supervised: 0.2440, acc.: 100.00%] [D loss unsupervised: 0.1630, acc.: 100.00%] [G loss: 3.149295, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3517 - acc: 0.9688 - val_loss: 0.8510 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "372 [D loss supervised: 0.3517, acc.: 96.88%] [D loss unsupervised: 0.1526, acc.: 100.00%] [G loss: 2.881303, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2790 - acc: 0.9688 - val_loss: 0.8533 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "373 [D loss supervised: 0.2790, acc.: 96.88%] [D loss unsupervised: 0.1521, acc.: 100.00%] [G loss: 3.009426, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2218 - acc: 1.0000 - val_loss: 0.8541 - val_acc: 0.8129\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "374 [D loss supervised: 0.2218, acc.: 100.00%] [D loss unsupervised: 0.1520, acc.: 100.00%] [G loss: 2.955455, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2817 - acc: 0.9688 - val_loss: 0.8612 - val_acc: 0.8121\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "375 [D loss supervised: 0.2817, acc.: 96.88%] [D loss unsupervised: 0.1525, acc.: 100.00%] [G loss: 2.211748, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2761 - acc: 1.0000 - val_loss: 0.8651 - val_acc: 0.8113\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "376 [D loss supervised: 0.2761, acc.: 100.00%] [D loss unsupervised: 0.1516, acc.: 100.00%] [G loss: 2.608203, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3885 - acc: 0.9062 - val_loss: 0.8589 - val_acc: 0.8131\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "377 [D loss supervised: 0.3885, acc.: 90.62%] [D loss unsupervised: 0.1515, acc.: 100.00%] [G loss: 2.669611, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3561 - acc: 0.9375 - val_loss: 0.8499 - val_acc: 0.8159\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "378 [D loss supervised: 0.3561, acc.: 93.75%] [D loss unsupervised: 0.1520, acc.: 100.00%] [G loss: 2.696965, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3964 - acc: 0.9375 - val_loss: 0.8337 - val_acc: 0.8183\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "379 [D loss supervised: 0.3964, acc.: 93.75%] [D loss unsupervised: 0.1513, acc.: 100.00%] [G loss: 2.621931, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2520 - acc: 1.0000 - val_loss: 0.8161 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "380 [D loss supervised: 0.2520, acc.: 100.00%] [D loss unsupervised: 0.1512, acc.: 100.00%] [G loss: 2.034041, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2262 - acc: 1.0000 - val_loss: 0.8011 - val_acc: 0.8275\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "381 [D loss supervised: 0.2262, acc.: 100.00%] [D loss unsupervised: 0.1512, acc.: 100.00%] [G loss: 1.971328, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2903 - acc: 0.9688 - val_loss: 0.7817 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "382 [D loss supervised: 0.2903, acc.: 96.88%] [D loss unsupervised: 0.1510, acc.: 100.00%] [G loss: 2.264974, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2553 - acc: 1.0000 - val_loss: 0.7655 - val_acc: 0.8332\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "383 [D loss supervised: 0.2553, acc.: 100.00%] [D loss unsupervised: 0.1507, acc.: 100.00%] [G loss: 1.910738, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4048 - acc: 0.8750 - val_loss: 0.7520 - val_acc: 0.8362\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "384 [D loss supervised: 0.4048, acc.: 87.50%] [D loss unsupervised: 0.1505, acc.: 100.00%] [G loss: 2.457308, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2358 - acc: 0.9688 - val_loss: 0.7394 - val_acc: 0.8406\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "385 [D loss supervised: 0.2358, acc.: 96.88%] [D loss unsupervised: 0.1508, acc.: 100.00%] [G loss: 2.360926, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3001 - acc: 0.9688 - val_loss: 0.7283 - val_acc: 0.8429\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "386 [D loss supervised: 0.3001, acc.: 96.88%] [D loss unsupervised: 0.1506, acc.: 100.00%] [G loss: 1.781089, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2780 - acc: 1.0000 - val_loss: 0.7191 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "387 [D loss supervised: 0.2780, acc.: 100.00%] [D loss unsupervised: 0.1498, acc.: 100.00%] [G loss: 2.109504, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4583 - acc: 0.9375 - val_loss: 0.7092 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "388 [D loss supervised: 0.4583, acc.: 93.75%] [D loss unsupervised: 0.1500, acc.: 100.00%] [G loss: 1.565225, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3631 - acc: 0.9062 - val_loss: 0.6987 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "389 [D loss supervised: 0.3631, acc.: 90.62%] [D loss unsupervised: 0.1582, acc.: 100.00%] [G loss: 3.389671, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3211 - acc: 0.9375 - val_loss: 0.6892 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "390 [D loss supervised: 0.3211, acc.: 93.75%] [D loss unsupervised: 0.1500, acc.: 100.00%] [G loss: 4.000185, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2868 - acc: 0.9688 - val_loss: 0.6852 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "391 [D loss supervised: 0.2868, acc.: 96.88%] [D loss unsupervised: 0.1496, acc.: 100.00%] [G loss: 4.762583, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2279 - acc: 1.0000 - val_loss: 0.6826 - val_acc: 0.8511\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "392 [D loss supervised: 0.2279, acc.: 100.00%] [D loss unsupervised: 0.1491, acc.: 100.00%] [G loss: 4.836833, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2172 - acc: 1.0000 - val_loss: 0.6806 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "393 [D loss supervised: 0.2172, acc.: 100.00%] [D loss unsupervised: 0.1500, acc.: 100.00%] [G loss: 4.562516, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2716 - acc: 0.9688 - val_loss: 0.6795 - val_acc: 0.8510\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "394 [D loss supervised: 0.2716, acc.: 96.88%] [D loss unsupervised: 0.1513, acc.: 100.00%] [G loss: 4.759452, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2521 - acc: 1.0000 - val_loss: 0.6786 - val_acc: 0.8511\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "395 [D loss supervised: 0.2521, acc.: 100.00%] [D loss unsupervised: 0.1497, acc.: 100.00%] [G loss: 4.162257, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2705 - acc: 0.9688 - val_loss: 0.6784 - val_acc: 0.8518\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "396 [D loss supervised: 0.2705, acc.: 96.88%] [D loss unsupervised: 0.1506, acc.: 100.00%] [G loss: 4.086682, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2272 - acc: 1.0000 - val_loss: 0.6780 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "397 [D loss supervised: 0.2272, acc.: 100.00%] [D loss unsupervised: 0.1504, acc.: 100.00%] [G loss: 4.116241, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2939 - acc: 0.9375 - val_loss: 0.6778 - val_acc: 0.8526\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "398 [D loss supervised: 0.2939, acc.: 93.75%] [D loss unsupervised: 0.1494, acc.: 100.00%] [G loss: 4.009306, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2475 - acc: 1.0000 - val_loss: 0.6777 - val_acc: 0.8533\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "399 [D loss supervised: 0.2475, acc.: 100.00%] [D loss unsupervised: 0.1492, acc.: 100.00%] [G loss: 4.119387, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3682 - acc: 0.9062 - val_loss: 0.6766 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "400 [D loss supervised: 0.3682, acc.: 90.62%] [D loss unsupervised: 0.1487, acc.: 100.00%] [G loss: 3.901102, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2599 - acc: 0.9688 - val_loss: 0.6770 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "401 [D loss supervised: 0.2599, acc.: 96.88%] [D loss unsupervised: 0.1500, acc.: 100.00%] [G loss: 4.127256, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2282 - acc: 1.0000 - val_loss: 0.6788 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "402 [D loss supervised: 0.2282, acc.: 100.00%] [D loss unsupervised: 0.1480, acc.: 100.00%] [G loss: 3.826200, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3044 - acc: 0.9688 - val_loss: 0.6799 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "403 [D loss supervised: 0.3044, acc.: 96.88%] [D loss unsupervised: 0.1475, acc.: 100.00%] [G loss: 3.884667, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3233 - acc: 0.9062 - val_loss: 0.6797 - val_acc: 0.8555\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "404 [D loss supervised: 0.3233, acc.: 90.62%] [D loss unsupervised: 0.1501, acc.: 100.00%] [G loss: 3.970012, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2668 - acc: 0.9688 - val_loss: 0.6753 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "405 [D loss supervised: 0.2668, acc.: 96.88%] [D loss unsupervised: 0.1478, acc.: 100.00%] [G loss: 3.942588, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3937 - acc: 0.9375 - val_loss: 0.6726 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "406 [D loss supervised: 0.3937, acc.: 93.75%] [D loss unsupervised: 0.1477, acc.: 100.00%] [G loss: 3.656971, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2757 - acc: 1.0000 - val_loss: 0.6700 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "407 [D loss supervised: 0.2757, acc.: 100.00%] [D loss unsupervised: 0.1475, acc.: 100.00%] [G loss: 4.533122, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3523 - acc: 0.9688 - val_loss: 0.6668 - val_acc: 0.8577\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "408 [D loss supervised: 0.3523, acc.: 96.88%] [D loss unsupervised: 0.1472, acc.: 100.00%] [G loss: 3.887986, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2160 - acc: 1.0000 - val_loss: 0.6653 - val_acc: 0.8588\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "409 [D loss supervised: 0.2160, acc.: 100.00%] [D loss unsupervised: 0.1469, acc.: 100.00%] [G loss: 3.734803, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2278 - acc: 1.0000 - val_loss: 0.6656 - val_acc: 0.8597\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "410 [D loss supervised: 0.2278, acc.: 100.00%] [D loss unsupervised: 0.1467, acc.: 100.00%] [G loss: 4.272110, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2921 - acc: 0.9688 - val_loss: 0.6658 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "411 [D loss supervised: 0.2921, acc.: 96.88%] [D loss unsupervised: 0.1464, acc.: 100.00%] [G loss: 4.293713, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2982 - acc: 0.9375 - val_loss: 0.6672 - val_acc: 0.8608\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "412 [D loss supervised: 0.2982, acc.: 93.75%] [D loss unsupervised: 0.1463, acc.: 100.00%] [G loss: 4.482901, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2454 - acc: 0.9688 - val_loss: 0.6678 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "413 [D loss supervised: 0.2454, acc.: 96.88%] [D loss unsupervised: 0.1459, acc.: 100.00%] [G loss: 4.349250, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3288 - acc: 0.9688 - val_loss: 0.6667 - val_acc: 0.8622\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "414 [D loss supervised: 0.3288, acc.: 96.88%] [D loss unsupervised: 0.1466, acc.: 100.00%] [G loss: 4.232227, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2871 - acc: 0.9688 - val_loss: 0.6673 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "415 [D loss supervised: 0.2871, acc.: 96.88%] [D loss unsupervised: 0.1473, acc.: 100.00%] [G loss: 4.339596, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2526 - acc: 1.0000 - val_loss: 0.6677 - val_acc: 0.8607\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "416 [D loss supervised: 0.2526, acc.: 100.00%] [D loss unsupervised: 0.1460, acc.: 100.00%] [G loss: 4.687909, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2214 - acc: 1.0000 - val_loss: 0.6674 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "417 [D loss supervised: 0.2214, acc.: 100.00%] [D loss unsupervised: 0.1454, acc.: 100.00%] [G loss: 4.723396, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3188 - acc: 0.9688 - val_loss: 0.6661 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "418 [D loss supervised: 0.3188, acc.: 96.88%] [D loss unsupervised: 0.1451, acc.: 100.00%] [G loss: 4.592272, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2721 - acc: 0.9688 - val_loss: 0.6643 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "419 [D loss supervised: 0.2721, acc.: 96.88%] [D loss unsupervised: 0.1450, acc.: 100.00%] [G loss: 4.607597, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2456 - acc: 1.0000 - val_loss: 0.6640 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "420 [D loss supervised: 0.2456, acc.: 100.00%] [D loss unsupervised: 0.1447, acc.: 100.00%] [G loss: 5.015951, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3323 - acc: 0.9688 - val_loss: 0.6645 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "421 [D loss supervised: 0.3323, acc.: 96.88%] [D loss unsupervised: 0.1452, acc.: 100.00%] [G loss: 4.512965, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2333 - acc: 1.0000 - val_loss: 0.6656 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "422 [D loss supervised: 0.2333, acc.: 100.00%] [D loss unsupervised: 0.1445, acc.: 100.00%] [G loss: 4.577627, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2474 - acc: 1.0000 - val_loss: 0.6664 - val_acc: 0.8586\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "423 [D loss supervised: 0.2474, acc.: 100.00%] [D loss unsupervised: 0.1444, acc.: 100.00%] [G loss: 4.749954, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2469 - acc: 1.0000 - val_loss: 0.6666 - val_acc: 0.8583\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "424 [D loss supervised: 0.2469, acc.: 100.00%] [D loss unsupervised: 0.1443, acc.: 100.00%] [G loss: 4.740180, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2741 - acc: 0.9688 - val_loss: 0.6679 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "425 [D loss supervised: 0.2741, acc.: 96.88%] [D loss unsupervised: 0.1444, acc.: 100.00%] [G loss: 4.534158, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2265 - acc: 1.0000 - val_loss: 0.6693 - val_acc: 0.8579\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "426 [D loss supervised: 0.2265, acc.: 100.00%] [D loss unsupervised: 0.1438, acc.: 100.00%] [G loss: 4.683218, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2266 - acc: 1.0000 - val_loss: 0.6704 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "427 [D loss supervised: 0.2266, acc.: 100.00%] [D loss unsupervised: 0.1438, acc.: 100.00%] [G loss: 4.597580, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2689 - acc: 0.9688 - val_loss: 0.6712 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "428 [D loss supervised: 0.2689, acc.: 96.88%] [D loss unsupervised: 0.1437, acc.: 100.00%] [G loss: 4.690327, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2805 - acc: 1.0000 - val_loss: 0.6714 - val_acc: 0.8592\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "429 [D loss supervised: 0.2805, acc.: 100.00%] [D loss unsupervised: 0.1433, acc.: 100.00%] [G loss: 4.519864, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3387 - acc: 0.9688 - val_loss: 0.6693 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "430 [D loss supervised: 0.3387, acc.: 96.88%] [D loss unsupervised: 0.1430, acc.: 100.00%] [G loss: 4.560594, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2282 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "431 [D loss supervised: 0.2282, acc.: 100.00%] [D loss unsupervised: 0.1430, acc.: 100.00%] [G loss: 4.746303, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2812 - acc: 0.9688 - val_loss: 0.6681 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "432 [D loss supervised: 0.2812, acc.: 96.88%] [D loss unsupervised: 0.1434, acc.: 100.00%] [G loss: 4.752958, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2283 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "433 [D loss supervised: 0.2283, acc.: 100.00%] [D loss unsupervised: 0.1426, acc.: 100.00%] [G loss: 5.075414, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3194 - acc: 0.9688 - val_loss: 0.6681 - val_acc: 0.8612\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "434 [D loss supervised: 0.3194, acc.: 96.88%] [D loss unsupervised: 0.1423, acc.: 100.00%] [G loss: 5.178544, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2634 - acc: 1.0000 - val_loss: 0.6681 - val_acc: 0.8617\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "435 [D loss supervised: 0.2634, acc.: 100.00%] [D loss unsupervised: 0.1429, acc.: 100.00%] [G loss: 4.946586, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2843 - acc: 1.0000 - val_loss: 0.6679 - val_acc: 0.8615\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "436 [D loss supervised: 0.2843, acc.: 100.00%] [D loss unsupervised: 0.1430, acc.: 100.00%] [G loss: 4.856692, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3601 - acc: 0.9688 - val_loss: 0.6684 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "437 [D loss supervised: 0.3601, acc.: 96.88%] [D loss unsupervised: 0.1420, acc.: 100.00%] [G loss: 4.918026, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2458 - acc: 1.0000 - val_loss: 0.6698 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "438 [D loss supervised: 0.2458, acc.: 100.00%] [D loss unsupervised: 0.1440, acc.: 100.00%] [G loss: 4.955874, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2460 - acc: 1.0000 - val_loss: 0.6733 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "439 [D loss supervised: 0.2460, acc.: 100.00%] [D loss unsupervised: 0.1419, acc.: 100.00%] [G loss: 4.845293, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2816 - acc: 0.9688 - val_loss: 0.6719 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "440 [D loss supervised: 0.2816, acc.: 96.88%] [D loss unsupervised: 0.1422, acc.: 100.00%] [G loss: 4.851287, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2269 - acc: 1.0000 - val_loss: 0.6700 - val_acc: 0.8598\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "441 [D loss supervised: 0.2269, acc.: 100.00%] [D loss unsupervised: 0.1415, acc.: 100.00%] [G loss: 4.664833, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3090 - acc: 0.9375 - val_loss: 0.6749 - val_acc: 0.8597\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "442 [D loss supervised: 0.3090, acc.: 93.75%] [D loss unsupervised: 0.1414, acc.: 100.00%] [G loss: 4.568464, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2410 - acc: 1.0000 - val_loss: 0.6804 - val_acc: 0.8577\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "443 [D loss supervised: 0.2410, acc.: 100.00%] [D loss unsupervised: 0.1412, acc.: 100.00%] [G loss: 4.806532, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2992 - acc: 0.9688 - val_loss: 0.6862 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "444 [D loss supervised: 0.2992, acc.: 96.88%] [D loss unsupervised: 0.1408, acc.: 100.00%] [G loss: 4.464635, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2389 - acc: 1.0000 - val_loss: 0.6944 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "445 [D loss supervised: 0.2389, acc.: 100.00%] [D loss unsupervised: 0.1417, acc.: 100.00%] [G loss: 4.717868, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2453 - acc: 1.0000 - val_loss: 0.7032 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "446 [D loss supervised: 0.2453, acc.: 100.00%] [D loss unsupervised: 0.1408, acc.: 100.00%] [G loss: 4.764218, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2472 - acc: 1.0000 - val_loss: 0.7082 - val_acc: 0.8501\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "447 [D loss supervised: 0.2472, acc.: 100.00%] [D loss unsupervised: 0.1402, acc.: 100.00%] [G loss: 4.537995, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2629 - acc: 1.0000 - val_loss: 0.7075 - val_acc: 0.8505\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "448 [D loss supervised: 0.2629, acc.: 100.00%] [D loss unsupervised: 0.1404, acc.: 100.00%] [G loss: 4.905994, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2276 - acc: 1.0000 - val_loss: 0.7048 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "449 [D loss supervised: 0.2276, acc.: 100.00%] [D loss unsupervised: 0.1400, acc.: 100.00%] [G loss: 4.760175, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2231 - acc: 1.0000 - val_loss: 0.7020 - val_acc: 0.8511\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "450 [D loss supervised: 0.2231, acc.: 100.00%] [D loss unsupervised: 0.1400, acc.: 100.00%] [G loss: 4.980199, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4558 - acc: 0.9062 - val_loss: 0.6979 - val_acc: 0.8518\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "451 [D loss supervised: 0.4558, acc.: 90.62%] [D loss unsupervised: 0.1397, acc.: 100.00%] [G loss: 4.940465, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2989 - acc: 0.9688 - val_loss: 0.6918 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "452 [D loss supervised: 0.2989, acc.: 96.88%] [D loss unsupervised: 0.1395, acc.: 100.00%] [G loss: 4.937975, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2465 - acc: 1.0000 - val_loss: 0.6839 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "453 [D loss supervised: 0.2465, acc.: 100.00%] [D loss unsupervised: 0.1394, acc.: 100.00%] [G loss: 5.102133, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2733 - acc: 1.0000 - val_loss: 0.6758 - val_acc: 0.8570\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "454 [D loss supervised: 0.2733, acc.: 100.00%] [D loss unsupervised: 0.1391, acc.: 100.00%] [G loss: 5.016792, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2287 - acc: 1.0000 - val_loss: 0.6693 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "455 [D loss supervised: 0.2287, acc.: 100.00%] [D loss unsupervised: 0.1388, acc.: 100.00%] [G loss: 5.239878, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2935 - acc: 0.9688 - val_loss: 0.6635 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "456 [D loss supervised: 0.2935, acc.: 96.88%] [D loss unsupervised: 0.1397, acc.: 100.00%] [G loss: 5.558189, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2238 - acc: 1.0000 - val_loss: 0.6602 - val_acc: 0.8596\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "457 [D loss supervised: 0.2238, acc.: 100.00%] [D loss unsupervised: 0.1387, acc.: 100.00%] [G loss: 5.147485, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2268 - acc: 1.0000 - val_loss: 0.6585 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "458 [D loss supervised: 0.2268, acc.: 100.00%] [D loss unsupervised: 0.1388, acc.: 100.00%] [G loss: 4.853664, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2229 - acc: 1.0000 - val_loss: 0.6584 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "459 [D loss supervised: 0.2229, acc.: 100.00%] [D loss unsupervised: 0.1391, acc.: 100.00%] [G loss: 4.322186, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2737 - acc: 1.0000 - val_loss: 0.6594 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "460 [D loss supervised: 0.2737, acc.: 100.00%] [D loss unsupervised: 0.1388, acc.: 100.00%] [G loss: 4.049326, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3187 - acc: 0.9688 - val_loss: 0.6646 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "461 [D loss supervised: 0.3187, acc.: 96.88%] [D loss unsupervised: 0.1400, acc.: 100.00%] [G loss: 2.220240, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2505 - acc: 0.9688 - val_loss: 0.6718 - val_acc: 0.8565\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "462 [D loss supervised: 0.2505, acc.: 96.88%] [D loss unsupervised: 0.1393, acc.: 100.00%] [G loss: 2.249941, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4185 - acc: 0.9375 - val_loss: 0.6780 - val_acc: 0.8551\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "463 [D loss supervised: 0.4185, acc.: 93.75%] [D loss unsupervised: 0.1389, acc.: 100.00%] [G loss: 2.582822, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2693 - acc: 0.9688 - val_loss: 0.6839 - val_acc: 0.8540\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "464 [D loss supervised: 0.2693, acc.: 96.88%] [D loss unsupervised: 0.1390, acc.: 100.00%] [G loss: 2.103788, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2342 - acc: 1.0000 - val_loss: 0.6910 - val_acc: 0.8532\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "465 [D loss supervised: 0.2342, acc.: 100.00%] [D loss unsupervised: 0.1385, acc.: 100.00%] [G loss: 2.594411, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4510 - acc: 0.9688 - val_loss: 0.6953 - val_acc: 0.8516\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "466 [D loss supervised: 0.4510, acc.: 96.88%] [D loss unsupervised: 0.4548, acc.: 89.06%] [G loss: 7.661736, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2573 - acc: 1.0000 - val_loss: 0.6991 - val_acc: 0.8516\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "467 [D loss supervised: 0.2573, acc.: 100.00%] [D loss unsupervised: 3.5930, acc.: 50.00%] [G loss: 6.902751, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2884 - acc: 1.0000 - val_loss: 0.7025 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "468 [D loss supervised: 0.2884, acc.: 100.00%] [D loss unsupervised: 2.7185, acc.: 51.56%] [G loss: 4.337932, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2478 - acc: 0.9688 - val_loss: 0.7066 - val_acc: 0.8511\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "469 [D loss supervised: 0.2478, acc.: 96.88%] [D loss unsupervised: 1.3844, acc.: 56.25%] [G loss: 2.658898, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2339 - acc: 1.0000 - val_loss: 0.7106 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "470 [D loss supervised: 0.2339, acc.: 100.00%] [D loss unsupervised: 0.6416, acc.: 70.31%] [G loss: 1.650034, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2526 - acc: 1.0000 - val_loss: 0.7117 - val_acc: 0.8493\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "471 [D loss supervised: 0.2526, acc.: 100.00%] [D loss unsupervised: 0.4064, acc.: 90.62%] [G loss: 1.551754, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2684 - acc: 0.9688 - val_loss: 0.7068 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "472 [D loss supervised: 0.2684, acc.: 96.88%] [D loss unsupervised: 0.3367, acc.: 95.31%] [G loss: 1.214458, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2897 - acc: 0.9688 - val_loss: 0.7001 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "473 [D loss supervised: 0.2897, acc.: 96.88%] [D loss unsupervised: 0.3922, acc.: 90.62%] [G loss: 1.595357, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2964 - acc: 0.9688 - val_loss: 0.6926 - val_acc: 0.8536\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "474 [D loss supervised: 0.2964, acc.: 96.88%] [D loss unsupervised: 0.2680, acc.: 100.00%] [G loss: 2.101987, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2453 - acc: 1.0000 - val_loss: 0.6851 - val_acc: 0.8552\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "475 [D loss supervised: 0.2453, acc.: 100.00%] [D loss unsupervised: 0.2171, acc.: 100.00%] [G loss: 2.277400, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2537 - acc: 1.0000 - val_loss: 0.6764 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "476 [D loss supervised: 0.2537, acc.: 100.00%] [D loss unsupervised: 0.2274, acc.: 98.44%] [G loss: 2.517119, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2535 - acc: 1.0000 - val_loss: 0.6680 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "477 [D loss supervised: 0.2535, acc.: 100.00%] [D loss unsupervised: 0.2394, acc.: 98.44%] [G loss: 2.303618, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2715 - acc: 0.9688 - val_loss: 0.6632 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "478 [D loss supervised: 0.2715, acc.: 96.88%] [D loss unsupervised: 0.2022, acc.: 100.00%] [G loss: 2.013140, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3229 - acc: 0.9688 - val_loss: 0.6580 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "479 [D loss supervised: 0.3229, acc.: 96.88%] [D loss unsupervised: 0.2472, acc.: 98.44%] [G loss: 2.174323, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3364 - acc: 0.9688 - val_loss: 0.6546 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "480 [D loss supervised: 0.3364, acc.: 96.88%] [D loss unsupervised: 0.2114, acc.: 98.44%] [G loss: 2.309388, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2189 - acc: 1.0000 - val_loss: 0.6541 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "481 [D loss supervised: 0.2189, acc.: 100.00%] [D loss unsupervised: 0.2291, acc.: 96.88%] [G loss: 2.534171, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3876 - acc: 0.9688 - val_loss: 0.6546 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "482 [D loss supervised: 0.3876, acc.: 96.88%] [D loss unsupervised: 0.2166, acc.: 98.44%] [G loss: 2.278991, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2825 - acc: 1.0000 - val_loss: 0.6555 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "483 [D loss supervised: 0.2825, acc.: 100.00%] [D loss unsupervised: 0.1847, acc.: 100.00%] [G loss: 1.896575, acc.: 37.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3679 - acc: 0.9062 - val_loss: 0.6558 - val_acc: 0.8592\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "484 [D loss supervised: 0.3679, acc.: 90.62%] [D loss unsupervised: 0.1920, acc.: 100.00%] [G loss: 2.221781, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4336 - acc: 0.9688 - val_loss: 0.6550 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "485 [D loss supervised: 0.4336, acc.: 96.88%] [D loss unsupervised: 0.1979, acc.: 100.00%] [G loss: 2.156103, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2294 - acc: 1.0000 - val_loss: 0.6544 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "486 [D loss supervised: 0.2294, acc.: 100.00%] [D loss unsupervised: 0.2054, acc.: 100.00%] [G loss: 1.599647, acc.: 40.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2300 - acc: 1.0000 - val_loss: 0.6536 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "487 [D loss supervised: 0.2300, acc.: 100.00%] [D loss unsupervised: 0.1835, acc.: 100.00%] [G loss: 1.822977, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2535 - acc: 0.9688 - val_loss: 0.6542 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "488 [D loss supervised: 0.2535, acc.: 96.88%] [D loss unsupervised: 0.2088, acc.: 98.44%] [G loss: 1.552279, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2216 - acc: 1.0000 - val_loss: 0.6549 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "489 [D loss supervised: 0.2216, acc.: 100.00%] [D loss unsupervised: 0.1720, acc.: 100.00%] [G loss: 1.513780, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3555 - acc: 0.9375 - val_loss: 0.6532 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "490 [D loss supervised: 0.3555, acc.: 93.75%] [D loss unsupervised: 0.1954, acc.: 98.44%] [G loss: 1.531944, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2147 - acc: 1.0000 - val_loss: 0.6524 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "491 [D loss supervised: 0.2147, acc.: 100.00%] [D loss unsupervised: 0.1861, acc.: 100.00%] [G loss: 1.661533, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2522 - acc: 1.0000 - val_loss: 0.6522 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "492 [D loss supervised: 0.2522, acc.: 100.00%] [D loss unsupervised: 0.1844, acc.: 100.00%] [G loss: 1.850374, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2721 - acc: 0.9688 - val_loss: 0.6514 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "493 [D loss supervised: 0.2721, acc.: 96.88%] [D loss unsupervised: 0.2019, acc.: 98.44%] [G loss: 1.870528, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2437 - acc: 1.0000 - val_loss: 0.6499 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "494 [D loss supervised: 0.2437, acc.: 100.00%] [D loss unsupervised: 0.1927, acc.: 98.44%] [G loss: 1.664862, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2408 - acc: 1.0000 - val_loss: 0.6483 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "495 [D loss supervised: 0.2408, acc.: 100.00%] [D loss unsupervised: 0.1980, acc.: 100.00%] [G loss: 1.210494, acc.: 50.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2748 - acc: 0.9688 - val_loss: 0.6473 - val_acc: 0.8612\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "496 [D loss supervised: 0.2748, acc.: 96.88%] [D loss unsupervised: 0.1951, acc.: 98.44%] [G loss: 1.759200, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2233 - acc: 1.0000 - val_loss: 0.6463 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "497 [D loss supervised: 0.2233, acc.: 100.00%] [D loss unsupervised: 0.1917, acc.: 98.44%] [G loss: 1.907724, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2499 - acc: 0.9688 - val_loss: 0.6461 - val_acc: 0.8599\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "498 [D loss supervised: 0.2499, acc.: 96.88%] [D loss unsupervised: 0.1834, acc.: 98.44%] [G loss: 1.604475, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2468 - acc: 1.0000 - val_loss: 0.6474 - val_acc: 0.8598\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "499 [D loss supervised: 0.2468, acc.: 100.00%] [D loss unsupervised: 0.1774, acc.: 98.44%] [G loss: 1.538978, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4775 - acc: 0.9062 - val_loss: 0.6483 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "500 [D loss supervised: 0.4775, acc.: 90.62%] [D loss unsupervised: 0.1845, acc.: 98.44%] [G loss: 1.581404, acc.: 21.88%]\n",
            "Training time: 1852.0433s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfUFnOB4qLYj",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rt3ZhdCn6mk",
        "colab_type": "code",
        "outputId": "e0a9b039-a46b-4686-c3a5-a2b4fcfd723c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "tmodel.compile(loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'],\n",
        "                         optimizer=Adam())\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-300.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 22s 448us/step\n",
            "Training Accuracy: 88.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO7jfk1Pa-J8",
        "colab_type": "code",
        "outputId": "e8ae5ac1-25da-4a46-8b40-88cac26b3f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-300.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the test set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 385us/step\n",
            "Test Accuracy: 85.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk87Xx_Aa-Bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82c3a30e-e34a-4bb6-d980-fe13456033da"
      },
      "source": [
        "div = 1   # 1\n",
        "accs = []\n",
        "tx = [x for x in range(1*div, len(iteration_checkpoints)+1, div)]\n",
        "acc_max = [0,0]\n",
        "\n",
        "for e in tx:\n",
        "  tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-\"+ str(e) +\".h5\", by_name=False)\n",
        "  _, acc = tmodel.evaluate(x, y)\n",
        "  accs.append(acc)\n",
        "print(max(accs))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(tx, accs, label=\"accs\", color='blue')\n",
        "plt.xticks(tx, rotation=90)\n",
        "plt.title(\"SCGAN-2D's accs with epoch, num_labeled=%d\" % num_labeled)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accs\")\n",
        "plt.legend()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 431us/step\n",
            "10000/10000 [==============================] - 4s 411us/step\n",
            "10000/10000 [==============================] - 4s 408us/step\n",
            "10000/10000 [==============================] - 4s 402us/step\n",
            "10000/10000 [==============================] - 4s 404us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 399us/step\n",
            "10000/10000 [==============================] - 4s 392us/step\n",
            "10000/10000 [==============================] - 4s 393us/step\n",
            "10000/10000 [==============================] - 4s 412us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 399us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 405us/step\n",
            "10000/10000 [==============================] - 4s 411us/step\n",
            "10000/10000 [==============================] - 4s 402us/step\n",
            "10000/10000 [==============================] - 4s 397us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 393us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 397us/step\n",
            "10000/10000 [==============================] - 4s 397us/step\n",
            "10000/10000 [==============================] - 4s 397us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 403us/step\n",
            "10000/10000 [==============================] - 4s 415us/step\n",
            "10000/10000 [==============================] - 4s 402us/step\n",
            "10000/10000 [==============================] - 4s 400us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 401us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 399us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 399us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 397us/step\n",
            "0.874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29ce5bd710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFWCAYAAAA2SU9mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXfwxMiWbBLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "7ea93829-d5ca-4b9c-d4a4-f1ce6f32b5f5"
      },
      "source": [
        "d_supervised_loss = np.array(losses_d_supervised)\n",
        "d_unsupervised_loss = np.array(losses_d_unsupervised)\n",
        "d_unsupervised_real_loss = np.array(losses_d_unsupervised_real)\n",
        "d_unsupervised_fake_loss = np.array(losses_d_unsupervised_fake)\n",
        "d_loss = np.array(losses_d)\n",
        "g_loss = np.array(losses_g)  # Generator unsupervised loss\n",
        "all_loss = np.add(d_loss, g_loss)\n",
        "\n",
        "# Plot Discriminator supervised loss\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(iteration_checkpoints, d_supervised_loss, label=\"Discriminator supervised loss\", color='blue', linestyle='dashed')\n",
        "plt.plot(iteration_checkpoints, d_unsupervised_loss, label=\"Discriminator unsupervised loss\", color='green', linestyle='dashed')\n",
        "# plt.plot(iteration_checkpoints, d_unsupervised_real_loss, label=\"Discriminator unsupervised real loss\", color='yellow')\n",
        "# plt.plot(iteration_checkpoints, d_unsupervised_fake_loss, label=\"Discriminator unsupervised fake loss\", color='yellow')\n",
        "plt.plot(iteration_checkpoints, g_loss, label=\"Generator unsupervised loss\", color='tab:red', linestyle='dashed')\n",
        "plt.plot(iteration_checkpoints, all_loss, label=\"All losses\", color='black')\n",
        "\n",
        "plt.xticks(iteration_checkpoints, rotation=90)\n",
        "\n",
        "plt.title(\"SCGAN-2D's Discriminator Loss + Generator Loss, num_labeled=%d\" % num_labeled)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29ce2026a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAAFWCAYAAAAR586OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq-YzbJRqOMH",
        "colab_type": "text"
      },
      "source": [
        "## Generate Pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB2PSr3uEFw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMF87KVVEFuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "# fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "# fake_labels = to_categorical(fake_labels, num_classes=num_classes)\n",
        "# gen_imgs = generator.predict([z, fake_labels])\n",
        "\n",
        "d_name = {0:\"airplane\", 1:\"automobile\", 2:\"bird\", 3:\"cat\", 4:\"deer\", 5:\"dog\", 6:\"frog\", 7:\"horse\", 8:\"ship\", 9:\"truck\"}\t\n",
        "\n",
        "def sample_images(image_grid_rows=2, image_grid_columns=5):\n",
        "\n",
        "    # Sample random noise\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "\n",
        "    # Get image labels 0-9\n",
        "    fake_labels = [0,1,2,3,4,5,6,7,8,9]\n",
        "    fake_labels_category = to_categorical(fake_labels, num_classes=num_classes)\n",
        "\n",
        "    # Generate images from random noise\n",
        "    gen_imgs = generator.predict([z, fake_labels_category])\n",
        "\n",
        "    # Rescale image pixel values to [0, 1]\n",
        "    # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    # gen_imgs = (gen_imgs+1) * 255/2\n",
        "\n",
        "    # Set image grid\n",
        "    fig, axs = plt.subplots(image_grid_rows,\n",
        "                            image_grid_columns,\n",
        "                            figsize=(10, 4),\n",
        "                            sharey=True,\n",
        "                            sharex=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            # Output a grid of images\n",
        "            axs[i, j].imshow(gen_imgs[cnt])\n",
        "            axs[i, j].axis('off')\n",
        "            axs[i, j].set_title(\"Class: \" + str(d_name[fake_labels[cnt]]))\n",
        "            cnt += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx4Ocr7DLE0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "3e79b096-9a7a-4c86-b2b6-0c1909a0b395"
      },
      "source": [
        "sample_images()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAD1CAYAAABUdy/PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAD1CAYAAABUdy/PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYpjIMLIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQdwFLMvBd-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_images_specific(image_grid_rows=2, image_grid_columns=5, label=0):\n",
        "\n",
        "    # Sample random noise\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "\n",
        "    # Get image labels 0-9\n",
        "    fake_labels = [label] * 10\n",
        "    fake_labels_category = to_categorical(fake_labels, num_classes=num_classes)\n",
        "\n",
        "    # Generate images from random noise\n",
        "    gen_imgs = generator.predict([z, fake_labels_category])\n",
        "\n",
        "    # Rescale image pixel values to [0, 1]\n",
        "    # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    # gen_imgs = (gen_imgs+1) * 255/2\n",
        "\n",
        "    # Set image grid\n",
        "    fig, axs = plt.subplots(image_grid_rows,\n",
        "                            image_grid_columns,\n",
        "                            figsize=(10, 4),\n",
        "                            sharey=True,\n",
        "                            sharex=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            # Output a grid of images\n",
        "            axs[i, j].imshow(gen_imgs[cnt])\n",
        "            axs[i, j].axis('off')\n",
        "            axs[i, j].set_title(\"Class: \" + str(d_name[fake_labels[cnt]]))\n",
        "            cnt += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Qw77TpBvcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "21bd40f1-7ffb-49d7-90e9-07a203fb9663"
      },
      "source": [
        "sample_images_specific(2,5,0)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAD1CAYAAABUdy/PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgIT1giiqQU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def plot_images_labels_prediction(images,labels,prediction,idx,num=10):\n",
        "#     fig=plt.gcf()\n",
        "#     fig.set_size_inches(12,14)\n",
        "#     if num>25: num=25\n",
        "#     for i in range(0,num):\n",
        "#         ax = plt.subplot(5,5,i+1)\n",
        "#         ax.imshow(images[idx],cmap='binary') \n",
        "#         title= str(i)+' '+label_dict[labels[i][0]]   #\n",
        "#         if len(prediction)>0:\n",
        "#             title+= '=>'+label_dict[prediction[i]]   #\n",
        "#         ax.set_title(title,fontsize=10)\n",
        "#         ax.set_xticks([])\n",
        "#         ax.set_yticks([])\n",
        "#         idx+=1\n",
        "#     plt.show()\n",
        "\n",
        "# plot_images_labels_prediction(x_train,y_train,[],0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZNbvo9zqSZB",
        "colab_type": "text"
      },
      "source": [
        "# Pseudo Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYa-jKsACxRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pseudo_model = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "pseudo_model.compile(loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'],\n",
        "                         optimizer=Adam())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjVlrccQCxOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pseudo_train(iterations, batch_size, save_interval, alpha_f, t1, t2, iter_epochs):\n",
        "\n",
        "    x_test, y_test = dataset.test_set()\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        # Get unlabeled examples and pseudo labels\n",
        "        imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
        "        pseudo_label = pseudo_model.predict(imgs_unlabeled)\n",
        "\n",
        "        # -------------------------\n",
        "        #  Supervised Training\n",
        "        # -------------------------\n",
        "\n",
        "        # Get labeled examples\n",
        "        imgs_labeled, labels = dataset.batch_labeled(batch_size)\n",
        "\n",
        "        # Train on labeled examples\n",
        "        alpha = 1\n",
        "        # loss_labeled, acc_labeled = pseudo_model.train_on_batch(imgs_labeled, labels)\n",
        "        datagen.fit(imgs_labeled)\n",
        "        pseudo_model.fit_generator(datagen.flow(imgs_labeled, labels, batch_size=batch_size),\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=iter_epochs, verbose=1, workers=4,\n",
        "                    callbacks=callbacks)\n",
        "        loss_labeled, acc_labeled = history.losses[-1], history.accs[-1]\n",
        "\n",
        "\n",
        "        loss_unlabeled = -1\n",
        "        acc_unlabeled = -1\n",
        "\n",
        "        # -------------------------\n",
        "        #  Supervised Training\n",
        "        # -------------------------\n",
        "\n",
        "        # Set alpha\n",
        "        if iteration < t1: alpha = 0\n",
        "        else:\n",
        "            if t1 <= iteration < t2: alpha = (iteration - t1)/(t2 - t1) * alpha_f\n",
        "            else: alpha = alpha_f\n",
        "\n",
        "            # Train on unlabeled examples\n",
        "            loss_unlabeled, acc_unlabeled = pseudo_model.train_on_batch(imgs_unlabeled, pseudo_label)\n",
        "\n",
        "        if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "          # Save losses\n",
        "          losses_pseudo_labeled.append(loss_labeled)\n",
        "          losses_pseudo_unlabeled.append(loss_unlabeled)\n",
        "          losses_pseudo.append(loss_labeled + alpha * loss_unlabeled)\n",
        "          accs_pseudo_labeled.append(acc_labeled)\n",
        "          accs_pseudo_unlabeled.append(acc_unlabeled)\n",
        "          accs_pseudo.append((acc_labeled + alpha*acc_unlabeled)/(1 + alpha))\n",
        "          iteration_checkpoints.append(iteration + 1)\n",
        "\n",
        "          # Output training progress\n",
        "          print(\n",
        "              \"%d [supervised loss: %.4f, acc: %.2f%%] [unsupervised loss: %.4f, acc: %.2f%%]\"\n",
        "              % (iteration + 1, loss_labeled, 100 * acc_labeled, \n",
        "                  loss_unlabeled, 100 * acc_unlabeled))\n",
        "          \n",
        "          pseudo_model.save(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-\" + str(iteration+1) + \".h5\")\n",
        "          file1 = \"./losses/losses-label-\" + str(num_labeled) + \"/p_supervised_losses.json\"\n",
        "          file2 = \"./losses/losses-label-\" + str(num_labeled) + \"/p_unsupervised_losses.json\"\n",
        "          file3 = \"./losses/losses-label-\" + str(num_labeled) + \"/p_losses.json\"\n",
        "          with open(file1, 'w') as json_file:\n",
        "                json.dump(str(losses_pseudo_labeled), json_file)\n",
        "          with open(file2, 'w') as json_file:\n",
        "                json.dump(str(losses_pseudo_unlabeled), json_file)\n",
        "          with open(file3, 'w') as json_file:\n",
        "                json.dump(str(losses_pseudo), json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GnU0n4JCxMB",
        "colab_type": "code",
        "outputId": "70b8912e-33ef-4402-f870-379a5994b8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set hyperparameters\n",
        "iterations = 50 # 30\n",
        "batch_size = 32\n",
        "save_interval = 1\n",
        "alpha_f = 3\n",
        "t1 = 2 # 500\n",
        "t2 = 4 # 1000\n",
        "iter_epochs = 10\n",
        "\n",
        "losses_pseudo_labeled = []\n",
        "losses_pseudo_unlabeled = []\n",
        "losses_pseudo = []\n",
        "accs_pseudo_labeled = []\n",
        "accs_pseudo_unlabeled = []\n",
        "accs_pseudo = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "discriminator_supervised.trainable = True\n",
        "pseudo_model = load_model(\"./models/cifar10_model.035.h5\")\n",
        "\n",
        "starttime = time.clock()\n",
        "\n",
        "# Train the SGGAN for the specified number of iterations\n",
        "pseudo_train(iterations, batch_size, save_interval, alpha_f, t1, t2, iter_epochs)\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Training time: %.4fs\" % (endtime - starttime))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 15s 15s/step - loss: 0.5187 - acc: 0.8438 - val_loss: 0.6246 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4502 - acc: 0.8750 - val_loss: 0.6295 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4992 - acc: 0.8750 - val_loss: 0.6264 - val_acc: 0.8596\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3824 - acc: 0.9062 - val_loss: 0.6310 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3377 - acc: 0.9375 - val_loss: 0.6443 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2767 - acc: 1.0000 - val_loss: 0.6573 - val_acc: 0.8505\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2750 - acc: 1.0000 - val_loss: 0.6726 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2612 - acc: 1.0000 - val_loss: 0.6912 - val_acc: 0.8393\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2600 - acc: 1.0000 - val_loss: 0.7119 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2472 - acc: 1.0000 - val_loss: 0.7324 - val_acc: 0.8273\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "1 [supervised loss: 0.2472, acc: 100.00%] [unsupervised loss: -1.0000, acc: -100.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7185 - acc: 0.7812 - val_loss: 0.7439 - val_acc: 0.8237\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7609 - acc: 0.8438 - val_loss: 0.7525 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5938 - acc: 0.8438 - val_loss: 0.7622 - val_acc: 0.8166\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4963 - acc: 0.8438 - val_loss: 0.7738 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3935 - acc: 0.9688 - val_loss: 0.7816 - val_acc: 0.8130\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3495 - acc: 0.9688 - val_loss: 0.7909 - val_acc: 0.8095\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3013 - acc: 0.9688 - val_loss: 0.7963 - val_acc: 0.8065\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2611 - acc: 1.0000 - val_loss: 0.8001 - val_acc: 0.8050\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2802 - acc: 1.0000 - val_loss: 0.8044 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2478 - acc: 1.0000 - val_loss: 0.8090 - val_acc: 0.8029\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "2 [supervised loss: 0.2478, acc: 100.00%] [unsupervised loss: -1.0000, acc: -100.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7037 - acc: 0.8750 - val_loss: 0.7997 - val_acc: 0.8053\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5812 - acc: 0.9062 - val_loss: 0.7883 - val_acc: 0.8101\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5407 - acc: 0.9062 - val_loss: 0.7737 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4879 - acc: 0.9375 - val_loss: 0.7600 - val_acc: 0.8174\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4591 - acc: 0.9062 - val_loss: 0.7526 - val_acc: 0.8184\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3662 - acc: 0.9688 - val_loss: 0.7494 - val_acc: 0.8223\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3193 - acc: 0.9688 - val_loss: 0.7395 - val_acc: 0.8241\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2533 - acc: 1.0000 - val_loss: 0.7334 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2616 - acc: 1.0000 - val_loss: 0.7296 - val_acc: 0.8267\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2465 - acc: 1.0000 - val_loss: 0.7273 - val_acc: 0.8262\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "3 [supervised loss: 0.2465, acc: 100.00%] [unsupervised loss: 1.0317, acc: 75.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4629 - acc: 0.9062 - val_loss: 0.7357 - val_acc: 0.8232\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4436 - acc: 0.9062 - val_loss: 0.7432 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4260 - acc: 0.9062 - val_loss: 0.7543 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2789 - acc: 1.0000 - val_loss: 0.7671 - val_acc: 0.8140\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3172 - acc: 0.9688 - val_loss: 0.7793 - val_acc: 0.8098\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2691 - acc: 1.0000 - val_loss: 0.7918 - val_acc: 0.8076\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2652 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 0.8052\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2488 - acc: 1.0000 - val_loss: 0.8168 - val_acc: 0.8020\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2639 - acc: 1.0000 - val_loss: 0.8292 - val_acc: 0.7989\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2353 - acc: 1.0000 - val_loss: 0.8408 - val_acc: 0.7947\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "4 [supervised loss: 0.2353, acc: 100.00%] [unsupervised loss: 0.6375, acc: 96.88%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4921 - acc: 0.9062 - val_loss: 0.8606 - val_acc: 0.7905\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4898 - acc: 0.8750 - val_loss: 0.8694 - val_acc: 0.7881\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3901 - acc: 0.9375 - val_loss: 0.8764 - val_acc: 0.7874\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3687 - acc: 0.9375 - val_loss: 0.8807 - val_acc: 0.7865\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3743 - acc: 0.9688 - val_loss: 0.8854 - val_acc: 0.7842\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3083 - acc: 0.9688 - val_loss: 0.8906 - val_acc: 0.7828\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3799 - acc: 0.9375 - val_loss: 0.8944 - val_acc: 0.7839\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3279 - acc: 0.9688 - val_loss: 0.8988 - val_acc: 0.7839\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2737 - acc: 1.0000 - val_loss: 0.9044 - val_acc: 0.7831\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2769 - acc: 0.9688 - val_loss: 0.9096 - val_acc: 0.7830\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "5 [supervised loss: 0.2769, acc: 96.88%] [unsupervised loss: 0.7566, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6808 - acc: 0.8750 - val_loss: 0.9036 - val_acc: 0.7853\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7193 - acc: 0.8125 - val_loss: 0.8800 - val_acc: 0.7887\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5221 - acc: 0.9062 - val_loss: 0.8555 - val_acc: 0.7964\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5153 - acc: 0.9062 - val_loss: 0.8301 - val_acc: 0.8036\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3917 - acc: 0.9375 - val_loss: 0.8131 - val_acc: 0.8085\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4908 - acc: 0.9688 - val_loss: 0.7988 - val_acc: 0.8120\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3810 - acc: 0.9375 - val_loss: 0.7891 - val_acc: 0.8120\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2739 - acc: 1.0000 - val_loss: 0.7859 - val_acc: 0.8116\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3639 - acc: 0.9688 - val_loss: 0.7851 - val_acc: 0.8117\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2716 - acc: 1.0000 - val_loss: 0.7876 - val_acc: 0.8121\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "6 [supervised loss: 0.2716, acc: 100.00%] [unsupervised loss: 0.9091, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7527 - acc: 0.8125 - val_loss: 0.8065 - val_acc: 0.8060\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7241 - acc: 0.9062 - val_loss: 0.8046 - val_acc: 0.8065\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4780 - acc: 0.8750 - val_loss: 0.8022 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7295 - acc: 0.8438 - val_loss: 0.7975 - val_acc: 0.8072\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3980 - acc: 0.9375 - val_loss: 0.7962 - val_acc: 0.8093\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4474 - acc: 0.9375 - val_loss: 0.7972 - val_acc: 0.8078\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3447 - acc: 0.9688 - val_loss: 0.8002 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2867 - acc: 1.0000 - val_loss: 0.8070 - val_acc: 0.8050\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2804 - acc: 1.0000 - val_loss: 0.8172 - val_acc: 0.8019\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2396 - acc: 1.0000 - val_loss: 0.8265 - val_acc: 0.8002\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "7 [supervised loss: 0.2396, acc: 100.00%] [unsupervised loss: 0.6325, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6480 - acc: 0.8438 - val_loss: 0.8336 - val_acc: 0.7977\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6685 - acc: 0.8125 - val_loss: 0.8241 - val_acc: 0.7984\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5017 - acc: 0.9062 - val_loss: 0.8126 - val_acc: 0.7999\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4281 - acc: 0.9375 - val_loss: 0.8007 - val_acc: 0.8014\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4488 - acc: 0.8750 - val_loss: 0.7935 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3246 - acc: 0.9375 - val_loss: 0.7937 - val_acc: 0.8063\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3096 - acc: 0.9688 - val_loss: 0.8002 - val_acc: 0.8059\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2957 - acc: 0.9688 - val_loss: 0.8132 - val_acc: 0.8029\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2878 - acc: 0.9688 - val_loss: 0.8316 - val_acc: 0.7989\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2322 - acc: 1.0000 - val_loss: 0.8542 - val_acc: 0.7929\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "8 [supervised loss: 0.2322, acc: 100.00%] [unsupervised loss: 0.7895, acc: 87.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7514 - acc: 0.8750 - val_loss: 0.8655 - val_acc: 0.7905\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7200 - acc: 0.8438 - val_loss: 0.8687 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6679 - acc: 0.8438 - val_loss: 0.8759 - val_acc: 0.7873\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4953 - acc: 0.8750 - val_loss: 0.8817 - val_acc: 0.7864\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5462 - acc: 0.9062 - val_loss: 0.8847 - val_acc: 0.7843\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3288 - acc: 0.9688 - val_loss: 0.8941 - val_acc: 0.7794\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2838 - acc: 1.0000 - val_loss: 0.9075 - val_acc: 0.7772\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2790 - acc: 1.0000 - val_loss: 0.9223 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2455 - acc: 1.0000 - val_loss: 0.9396 - val_acc: 0.7686\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2442 - acc: 1.0000 - val_loss: 0.9593 - val_acc: 0.7628\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "9 [supervised loss: 0.2442, acc: 100.00%] [unsupervised loss: 0.8021, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6101 - acc: 0.8438 - val_loss: 0.9846 - val_acc: 0.7583\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4511 - acc: 0.9062 - val_loss: 0.9857 - val_acc: 0.7576\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6921 - acc: 0.8438 - val_loss: 0.9702 - val_acc: 0.7616\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4361 - acc: 0.8750 - val_loss: 0.9482 - val_acc: 0.7676\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3500 - acc: 0.9062 - val_loss: 0.9270 - val_acc: 0.7736\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3253 - acc: 0.9688 - val_loss: 0.9124 - val_acc: 0.7791\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2867 - acc: 0.9688 - val_loss: 0.9032 - val_acc: 0.7841\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2718 - acc: 0.9688 - val_loss: 0.8990 - val_acc: 0.7879\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2650 - acc: 0.9688 - val_loss: 0.8971 - val_acc: 0.7878\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2357 - acc: 1.0000 - val_loss: 0.8993 - val_acc: 0.7879\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "10 [supervised loss: 0.2357, acc: 100.00%] [unsupervised loss: 0.8588, acc: 87.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8206 - acc: 0.8438 - val_loss: 0.9156 - val_acc: 0.7860\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7687 - acc: 0.7812 - val_loss: 0.9406 - val_acc: 0.7824\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7149 - acc: 0.7812 - val_loss: 0.9890 - val_acc: 0.7735\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4073 - acc: 0.9375 - val_loss: 1.0640 - val_acc: 0.7616\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3399 - acc: 0.9688 - val_loss: 1.1736 - val_acc: 0.7421\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3403 - acc: 0.9375 - val_loss: 1.3096 - val_acc: 0.7163\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2960 - acc: 0.9688 - val_loss: 1.4745 - val_acc: 0.6921\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2509 - acc: 1.0000 - val_loss: 1.6522 - val_acc: 0.6692\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2911 - acc: 0.9688 - val_loss: 1.8452 - val_acc: 0.6474\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2384 - acc: 1.0000 - val_loss: 2.0318 - val_acc: 0.6299\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "11 [supervised loss: 0.2384, acc: 100.00%] [unsupervised loss: 1.1306, acc: 68.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbIxExOyCxJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_pseudo_supervised_losses = np.array(losses_pseudo_labeled)\n",
        "plot_pseudo_unsupervised_losses = np.array(losses_pseudo_unlabeled)\n",
        "plot_pseudo_all_losses = np.array(losses_pseudo)\n",
        "\n",
        "# Plot losses\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(iteration_checkpoints, plot_pseudo_all_losses, label=\"All loss\", color='black')\n",
        "plt.plot(iteration_checkpoints, plot_pseudo_supervised_losses, label=\"Supervised loss\", color='tab:blue', linestyle='dashed')\n",
        "plt.plot(iteration_checkpoints, plot_pseudo_unsupervised_losses, label=\"Unsupervised loss\", color='tab:green', linestyle='dashed')\n",
        "\n",
        "plt.xticks(iteration_checkpoints, rotation=90)\n",
        "\n",
        "plt.title(\"Pseudo Label's Supervised and Unsupervised Loss, num_labeled=%d\" % num_labeled)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-4ZGValCxGj",
        "colab_type": "code",
        "outputId": "475a1cbb-8a96-4869-9d7e-fb4a3a5dd660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "# tmodel = load_model(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-8000.h5\")\n",
        "tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "tmodel.compile(loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'],\n",
        "                         optimizer=Adam())\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-30.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 25s 505us/step\n",
            "Training Accuracy: 75.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-jD1xtbCw7H",
        "colab_type": "code",
        "outputId": "a5fcf47f-880b-47d5-b261-abad697b5333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "# tmodel = load_model(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-6000.h5\")\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-30.h5\", by_name=False)\n",
        "\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 459us/step\n",
            "Test Accuracy: 74.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeX3mD5qC5TQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "05de55e8-3f3e-4acb-cd37-0bb331f3727b"
      },
      "source": [
        "accs = []\n",
        "# tx = [x for x in range(1,31,1)]\n",
        "tx = [x for x in range(1, len(iteration_checkpoints)+1, 1)]\n",
        "acc_max = [0,0]\n",
        "\n",
        "for e in tx:\n",
        "  # tmodel = load_model(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-\"+ str(e) +\".h5\")\n",
        "  tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-\"+ str(e) +\".h5\", by_name=False)\n",
        "  _, acc = tmodel.evaluate(x, y)\n",
        "  accs.append(acc)\n",
        "print(max(accs))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(tx, accs, label=\"accs\", color='blue')\n",
        "plt.xticks(tx, rotation=90)\n",
        "plt.title(\"Pseudo Label's accs with epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accs\")\n",
        "plt.legend()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-0eebca0c63c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR4PM4STC5Q3",
        "colab_type": "code",
        "outputId": "6abae66c-7903-4dca-96ed-d7222c50b24d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print(max(accs[15:]))\n",
        "# for acc in accs:\n",
        "#   print(acc)\n",
        "pseudo_accs = accs\n",
        "print(pseudo_accs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8112\n",
            "[0.8634, 0.8549, 0.8464, 0.8475, 0.8423, 0.8309, 0.8178, 0.7995, 0.7981, 0.8066, 0.7921, 0.7936, 0.7801, 0.7829, 0.793, 0.8068, 0.8112, 0.81, 0.8002, 0.7746, 0.7616, 0.7478, 0.7321, 0.6938, 0.7257, 0.7305, 0.7414, 0.75, 0.7388, 0.692, 0.6977, 0.6248, 0.6487, 0.4684, 0.4003, 0.441, 0.6315, 0.5675, 0.6554, 0.5682, 0.4988, 0.4995, 0.4328, 0.3352, 0.241, 0.4082, 0.4646, 0.4485, 0.4369, 0.443]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9jhBOIcqT-h",
        "colab_type": "text"
      },
      "source": [
        "# Mean Teacher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxPsJI6lMwsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "student = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "teacher = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "student.compile(loss='categorical_crossentropy', \n",
        "                metrics=['accuracy'], \n",
        "                optimizer=Adam())\n",
        "teacher.compile(loss='categorical_crossentropy', \n",
        "                metrics=['accuracy'], \n",
        "                optimizer=Adam())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anKFkigJMwpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_teacher_train(iterations, batch_size, save_interval, alpha, iter_epochs):\n",
        "\n",
        "    x_test, y_test = dataset.test_set()\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        # -------------------------\n",
        "        #  Train the model\n",
        "        # -------------------------\n",
        "\n",
        "        # Get labeled examples\n",
        "        imgs_labeled, labels = dataset.batch_labeled(batch_size)\n",
        "\n",
        "        # Get unlabeled examples\n",
        "        imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
        "\n",
        "        # Train on labeled examples\n",
        "        # loss_labeled_classification, acc_labeled_classification = student.train_on_batch(imgs_labeled, labels)\n",
        "        datagen.fit(imgs_labeled)\n",
        "        student.fit_generator(datagen.flow(imgs_labeled, labels, batch_size=batch_size),\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=iter_epochs, verbose=1, workers=4,\n",
        "                    callbacks=callbacks)\n",
        "        loss_labeled_classification, acc_labeled_classification = history.losses[-1], history.accs[-1]\n",
        "        pred_teacher_labeled = teacher.predict(imgs_labeled)\n",
        "        loss_labeled_consistency, acc_labeled_consistency = student.train_on_batch(imgs_labeled, pred_teacher_labeled)\n",
        "\n",
        "        # Train on unlabeled examples\n",
        "        pred_teacher_unlabeled = teacher.predict(imgs_unlabeled)\n",
        "        loss_unlabeled_consistency, acc_unlabeled_consistency = student.train_on_batch(imgs_unlabeled, pred_teacher_unlabeled)\n",
        "\n",
        "        # Update teacher model\n",
        "        teacher_weights_this = teacher.get_weights()\n",
        "        student_weights_this = student.get_weights()\n",
        "        for i in range(len(teacher_weights_this)):\n",
        "          teacher_weights_this[i] = alpha * teacher_weights_this[i] + (1-alpha) * student_weights_this[i]\n",
        "        # teacher_weights_this = alpha * teacher_weights_this + (1-alpha) * student_weights_this\n",
        "        teacher_weights_last = teacher_weights_this\n",
        "        teacher.set_weights(teacher_weights_this)\n",
        "\n",
        "        if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "          # Save losses\n",
        "          supervised_losses.append(loss_labeled_classification)\n",
        "          unsupervised_losses.append(loss_labeled_consistency + loss_unlabeled_consistency)\n",
        "          labeled_consistency_costs.append(loss_labeled_consistency)\n",
        "          unlabeled_consistency_costs.append(loss_unlabeled_consistency)\n",
        "          accs_supervised.append(acc_labeled_classification)\n",
        "          accs_unsupervised.append((acc_labeled_consistency + acc_unlabeled_consistency)/2.0)\n",
        "          accs_labeled_consistency.append(acc_labeled_consistency)\n",
        "          accs_unlabeled_consistency.append(acc_unlabeled_consistency)\n",
        "\n",
        "          iteration_checkpoints.append(iteration + 1)\n",
        "\n",
        "          # Output training progress\n",
        "          print(\n",
        "              \"%d [supervised loss: %.4f, acc: %.2f%%] [unsupervised loss: %.4f, acc: %.2f%%] [labeled consistency loss: %.4f, acc:acc: %.2f%%] [unlabeled consistency loss: %.4f, acc: %.2f%%]\"\n",
        "              % (iteration + 1, loss_labeled_classification, 100 * acc_labeled_classification, \n",
        "                 loss_labeled_consistency + loss_unlabeled_consistency, 100 * ((acc_labeled_consistency + acc_unlabeled_consistency)/2.0), \n",
        "                 loss_labeled_consistency, 100 * acc_labeled_consistency, \n",
        "                  loss_unlabeled_consistency, 100 * acc_unlabeled_consistency))\n",
        "          \n",
        "          student.save(\"./models/models-label-\" + str(num_labeled) + \"/student-\" + str(iteration+1) + \".h5\")\n",
        "          teacher.save(\"./models/models-label-\" + str(num_labeled) + \"/teacher-\" + str(iteration+1) + \".h5\")\n",
        "          file1 = \"./losses/losses-label-\" + str(num_labeled) + \"/mt_supervised_losses.json\"\n",
        "          file2 = \"./losses/losses-label-\" + str(num_labeled) + \"/mt_unsupervised_losses.json\"\n",
        "          file3 = \"./losses/losses-label-\" + str(num_labeled) + \"/mt_labeled_consistency_costs.json\"\n",
        "          file4 = \"./losses/losses-label-\" + str(num_labeled) + \"/mt_unlabeled_consistency_costs.json\"\n",
        "          with open(file1, 'w') as json_file:\n",
        "                json.dump(str(supervised_losses), json_file)\n",
        "          with open(file2, 'w') as json_file:\n",
        "                json.dump(str(unsupervised_losses), json_file)\n",
        "          with open(file3, 'w') as json_file:\n",
        "                json.dump(str(labeled_consistency_costs), json_file)\n",
        "          with open(file4, 'w') as json_file:\n",
        "                json.dump(str(unlabeled_consistency_costs), json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS6N6-dRMwnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set hyperparameters\n",
        "iterations = 50 # 30\n",
        "batch_size = 32\n",
        "save_interval = 1\n",
        "alpha = 0.5\n",
        "iter_epochs = 10\n",
        "\n",
        "supervised_losses = [] # classification cost\n",
        "unsupervised_losses = [] # consistency cost\n",
        "labeled_consistency_costs = []\n",
        "unlabeled_consistency_costs = []\n",
        "accs_supervised = []\n",
        "accs_unsupervised = []\n",
        "accs_labeled_consistency = []\n",
        "accs_unlabeled_consistency = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "discriminator_supervised.trainable = True\n",
        "student = load_model(\"./models/cifar10_model.035.h5\")\n",
        "\n",
        "starttime = time.clock()\n",
        "\n",
        "# Train the mean teacher for the specified number of iterations\n",
        "mean_teacher_train(iterations, batch_size, save_interval, alpha, iter_epochs)\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Training time: %.4fs\" % (endtime - starttime))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ndAup4NMwkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_supervised_losses = np.array(supervised_losses)\n",
        "plot_unsupervised_losses = np.array(unsupervised_losses)\n",
        "plot_labeled_consistency_costs = np.array(labeled_consistency_costs)\n",
        "plot_unlabeled_consistency_costs = np.array(unlabeled_consistency_costs)\n",
        "plot_all_losses = np.array(supervised_losses)+np.array(unsupervised_losses)\n",
        "\n",
        "# Plot losses\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(iteration_checkpoints, plot_all_losses, label=\"All loss\", color='black')\n",
        "plt.plot(iteration_checkpoints, plot_supervised_losses, label=\"Supervised loss\", color='tab:blue')\n",
        "plt.plot(iteration_checkpoints, plot_unsupervised_losses, label=\"Unsupervised loss\", color='tab:green')\n",
        "plt.plot(iteration_checkpoints, plot_labeled_consistency_costs, label=\"Labeled consistency loss\", color='tab:red', linestyle='dashed')\n",
        "plt.plot(iteration_checkpoints, plot_unlabeled_consistency_costs, label=\"Unlabeled consistency loss\", color='tab:orange', linestyle='dashed')\n",
        "\n",
        "plt.xticks(iteration_checkpoints, rotation=90)\n",
        "\n",
        "plt.title(\"Mean Teacher's Supervised and Unsupervised Loss, num_labeled=%d\" % num_labeled)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4omcpkiBMwiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "tmodel.compile(loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'],\n",
        "                         optimizer=Adam())\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/teacher-50.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftgecc1jMwfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/teacher-50.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the test set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aDJmNbdMwce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accs = []\n",
        "# tx = [x for x in range(1,51,1)]\n",
        "tx = [x for x in range(1, len(iteration_checkpoints)+1, 1)]\n",
        "acc_max = [0,0]\n",
        "\n",
        "for e in tx:\n",
        "  tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/teacher-\"+ str(e) +\".h5\", by_name=False)\n",
        "  _, acc = tmodel.evaluate(x, y)\n",
        "  accs.append(acc)\n",
        "print(max(accs))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(tx, accs, label=\"accs\", color='blue')\n",
        "plt.xticks(tx, rotation=90)\n",
        "plt.title(\"Mean Teacher's accs with epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accs\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2feQLXtMwY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(max(accs[2:]))\n",
        "# for acc in accs:\n",
        "#   print(acc)\n",
        "mt_accs = accs\n",
        "print(mt_accs)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}