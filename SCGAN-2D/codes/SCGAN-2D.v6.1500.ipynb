{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_xDiTP_67MV",
        "colab_type": "code",
        "outputId": "cc526568-83b2-4ce2-b1ad-747de3760b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import (Dense, Conv2D, BatchNormalization, Activation, \n",
        "                          AveragePooling2D, Input, Flatten, \n",
        "                          Concatenate, Dropout, Lambda, \n",
        "                          Reshape, Embedding, Multiply)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, Callback\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from __future__ import print_function\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSaEOfjG6ztu",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_hPw_jy8jea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset_CIFAR10:\n",
        "    def __init__(self, num_labeled):\n",
        "\n",
        "        def preprocess_imgs(x):\n",
        "            # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
        "            x = (x.astype(np.float32) - 127.5) / 127.5\n",
        "            return x\n",
        "\n",
        "        def preprocess_labels(y):\n",
        "            y = y.reshape(-1, 1)\n",
        "            y = to_categorical(y, num_classes = 10)\n",
        "            return y\n",
        "\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        x_train = preprocess_imgs(x_train)\n",
        "        y_train = preprocess_labels(y_train)\n",
        "        x_test = preprocess_imgs(x_test)\n",
        "        y_test = preprocess_labels(y_test)\n",
        "\n",
        "        # Number labeled examples to use for training\n",
        "        self.num_labeled = num_labeled\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "        del x_train, y_train, x_test, y_test\n",
        "\n",
        "    def batch_labeled(self, batch_size):\n",
        "        # Get a random batch of labeled images and their labels\n",
        "        idx = np.random.randint(0, self.num_labeled, batch_size)\n",
        "        imgs = self.x_train[idx]\n",
        "        labels = self.y_train[idx]\n",
        "        return imgs, labels\n",
        "\n",
        "    def batch_unlabeled(self, batch_size):\n",
        "        # Get a random batch of unlabeled images\n",
        "        idx = np.random.randint(self.num_labeled, self.x_train.shape[0], batch_size)\n",
        "        imgs = self.x_train[idx]\n",
        "        return imgs\n",
        "\n",
        "    def training_set(self):\n",
        "        return self.x_train, self.y_train\n",
        "\n",
        "    def test_set(self):\n",
        "        return self.x_test, self.y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5nWXxcZdgQb",
        "colab_type": "text"
      },
      "source": [
        "## Check the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf5jJexNdigk",
        "colab_type": "code",
        "outputId": "80c9c905-369a-40b7-e388-6b7a3d1d67c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# CIFAR-10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Training set\n",
        "d_ytrain = {}\n",
        "for i in range(10):\n",
        "  d_ytrain[i] = 0\n",
        "for i in range(len(y_train)):\n",
        "  d_ytrain[y_train[i][0]] = d_ytrain.get(y_train[i][0]) + 1\n",
        "print(\"CIFAR-10 training set:\")\n",
        "print(d_ytrain)\n",
        "\n",
        "# Test set\n",
        "d_ytest = {}\n",
        "for i in range(10):\n",
        "  d_ytest[i] = 0\n",
        "for i in range(len(y_test)):\n",
        "  d_ytest[y_test[i][0]] = d_ytest.get(y_test[i][0]) + 1\n",
        "print(\"CIFAR-10 test set:\")\n",
        "print(d_ytest)\n",
        "\n",
        "del x_train, y_train, x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "CIFAR-10 training set:\n",
            "{0: 5000, 1: 5000, 2: 5000, 3: 5000, 4: 5000, 5: 5000, 6: 5000, 7: 5000, 8: 5000, 9: 5000}\n",
            "CIFAR-10 test set:\n",
            "{0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRSrTM11pJtd",
        "colab_type": "code",
        "outputId": "73b65b08-f8cb-4eed-96c1-278990dfa0f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "d_imgs = {}\n",
        "num_imgs = 0\n",
        "for i in range(1000):\n",
        "  if y_train[i][0] not in d_imgs:\n",
        "    d_imgs[y_train[i][0]] = x_train[i]\n",
        "    num_imgs += 1\n",
        "  if num_imgs == 10: break\n",
        "\n",
        "d_name = {0:\"airplane\", 1:\"automobile\", 2:\"bird\", 3:\"cat\", 4:\"deer\", 5:\"dog\", 6:\"frog\", 7:\"horse\", 8:\"ship\", 9:\"truck\"}\t\n",
        "\n",
        "# Set image grid\n",
        "fig, axs = plt.subplots(2,\n",
        "                        5,\n",
        "                        figsize=(10, 4),\n",
        "                        sharey=True,\n",
        "                        sharex=True)\n",
        "\n",
        "cnt = 0\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        # Output a grid of images\n",
        "        axs[i, j].imshow(d_imgs[cnt])\n",
        "        axs[i, j].axis('off')\n",
        "        axs[i, j].set_title(\"Class: \" + str(d_name[cnt]))\n",
        "        cnt += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAD1CAYAAABUdy/PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwrpoGSKdmrp",
        "colab_type": "text"
      },
      "source": [
        "# Number of labeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvYSG5vKdoSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labeled = 1500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjhxJulqdyFs",
        "colab_type": "text"
      },
      "source": [
        "# SCGAN-2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipcTHBiShR9m",
        "colab_type": "text"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA0DtW_2d14g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "input_shape = img_shape = (32, 32, 3)\n",
        "num_classes = 10\n",
        "z_dim = 100   # Size of the noise vector, used as input to the Generator\n",
        "n = 3\n",
        "depth = n * 6 + 2   # Depth of ResNet model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgzlORUA7eUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eZ2B42_7fiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abhpWtyBfaxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CIFAR-10\n",
        "\n",
        "def build_generator(z_dim):\n",
        "  \n",
        "    z = Input(shape=(z_dim, ))\n",
        "    label = Input(shape=(num_classes, ), dtype='float32')\n",
        "    label_embedding = Dense(z_dim, input_dim=num_classes)(label)\n",
        "    joined_representation = Multiply()([z, label_embedding])\n",
        "    \n",
        "#     model = Sequential()\n",
        "\n",
        "    # Reshape input into 8x8x256 tensor via a fully connected layer\n",
        "    model = Dense(256 * 8 * 8, input_dim=z_dim)(joined_representation)\n",
        "    model = Reshape((8, 8, 256))(model)\n",
        "\n",
        "    # Transposed convolution layer, from 8x8x256 into 16x16x128 tensor\n",
        "    model = Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(model)\n",
        "\n",
        "    # Batch normalization\n",
        "    model = BatchNormalization()(model)\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model = LeakyReLU(alpha=0.01)(model)\n",
        "\n",
        "    # Transposed convolution layer, from 16x16x128 to 16x16x64 tensor\n",
        "    model = Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')(model)\n",
        "\n",
        "    # Batch normalization\n",
        "    model = BatchNormalization()(model)\n",
        "\n",
        "    # Leaky ReLU activation\n",
        "    model = LeakyReLU(alpha=0.01)(model)\n",
        "\n",
        "    # Transposed convolution layer, from 16x16x64 to 32x32x3 tensor\n",
        "    model = Conv2DTranspose(3, kernel_size=3, strides=2, padding='same')(model)\n",
        "\n",
        "    # Output layer with tanh activation\n",
        "    conditioned_img = Activation('tanh')(model)\n",
        "    \n",
        "#     conditioned_img = model(joined_representation)\n",
        "\n",
        "    model = Model([z, label], conditioned_img)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ09_xGfffbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_net(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes, kernel_initializer='he_normal')(y)\n",
        "    # outputs = Dense(num_classes,\n",
        "    #                 activation='softmax',\n",
        "    #                 kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx6rxPK2hiqj",
        "colab_type": "code",
        "outputId": "84f14265-b68c-48cd-a4f8-9c437e806a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "build_discriminator_net(img_shape, depth).summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOTS0nBXhMhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_supervised(discriminator_net):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(discriminator_net)\n",
        "\n",
        "    # Softmax activation, giving predicted probability distribution over the real classes\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuxULq-IhOlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_unsupervised(discriminator_net):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(discriminator_net)\n",
        "\n",
        "    def predict(x):\n",
        "        # Transform distribution over real classes into a binary real-vs-fake probability\n",
        "        prediction = 1.0 - (1.0 / (K.sum(K.exp(x), axis=-1, keepdims=True) + 1.0))\n",
        "        return prediction\n",
        "\n",
        "    # 'Real-vs-fake' output neuron defined above\n",
        "    model.add(Lambda(predict))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3LcMzjZhQFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gan(generator, discriminator):\n",
        "    \n",
        "    z = Input(shape=(z_dim, ))\n",
        "    label = Input(shape=(num_classes, ))\n",
        "    img = generator([z, label])\n",
        "    output = discriminator(img)\n",
        "    model = Model([z, label], output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X4FZirFhWA7",
        "colab_type": "code",
        "outputId": "615148a9-6cc5-4eb2-856e-f7b56a76d131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "# Core Discriminator network:\n",
        "# These layers are shared during supervised and unsupervised training\n",
        "\n",
        "discriminator_net = build_discriminator_net(input_shape=img_shape, depth=depth)\n",
        "\n",
        "discriminator_supervised = build_discriminator_supervised(discriminator_net)\n",
        "discriminator_supervised.compile(loss='categorical_crossentropy',\n",
        "                                 metrics=['accuracy'],\n",
        "                                 optimizer=Adam())\n",
        "# discriminator_supervised.compile(loss='categorical_crossentropy',\n",
        "#                                  metrics=['accuracy'],\n",
        "#                                  optimizer=Adam(lr=lr_schedule(0)))\n",
        "\n",
        "discriminator_unsupervised = build_discriminator_unsupervised(discriminator_net)\n",
        "discriminator_unsupervised.compile(loss='binary_crossentropy',\n",
        "                                metrics=['accuracy'],\n",
        "                                optimizer=Adam())\n",
        "# discriminator_unsupervised.compile(loss='binary_crossentropy',\n",
        "#                                 metrics=['accuracy'],\n",
        "#                                 optimizer=Adam(lr=lr_schedule(0)))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1nVA_1egKoX",
        "colab_type": "code",
        "outputId": "e0e1d0ca-2aab-47c1-f2e7-0c807fc4c058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "discriminator_unsupervised.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_2 (Model)              (None, 10)                274442    \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpsqRccThV02",
        "colab_type": "code",
        "outputId": "9708cb90-1f99-451e-db7e-84a9717a3297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Build the Generator\n",
        "generator = build_generator(z_dim)\n",
        "\n",
        "discriminator_supervised.trainable = False\n",
        "discriminator_unsupervised.trainable = False\n",
        "gan = build_gan(generator, discriminator_unsupervised)\n",
        "gan.compile(loss='binary_crossentropy', \n",
        "            metrics=['accuracy'], \n",
        "            optimizer=Adam())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yrZyUchhhER",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW25Txjghf7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir models\n",
        "%mkdir losses\n",
        "%mkdir models/models-label-1500\n",
        "%mkdir losses/losses-label-1500\n",
        "\n",
        "# if not os.path.isdir(save_dir):\n",
        "#     os.makedirs(save_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNb1Q6IQkL-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'models')\n",
        "model_name = 'cifar10_model.{epoch:03d}.h5'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.accs = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.accs.append(logs.get('acc'))\n",
        "\n",
        "history = LossHistory()\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler, history]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF3q3OrbkUGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR2Hun3ChbSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretrain(iterations_pre, batch_size, save_interval, iter_epochs):\n",
        "  for iteration in range(iterations_pre):\n",
        "      imgs, labels = dataset.training_set()\n",
        "      # imgs, labels = dataset.batch_labeled(batch_size)\n",
        "      x_test, y_test = dataset.test_set()\n",
        "\n",
        "      # Compute quantities required for featurewise normalization (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(imgs)\n",
        "      discriminator_supervised.fit_generator(datagen.flow(imgs, labels, batch_size=batch_size),\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  epochs=iter_epochs, verbose=1, workers=4,\n",
        "                  callbacks=callbacks)\n",
        "      \n",
        "      if (iteration + 1) % save_interval == 0:\n",
        "          \n",
        "          # Output training progress\n",
        "          print(\n",
        "              \"%d [D loss class: %.4f, acc: %.2f%%]\"\n",
        "              % (iteration + 1, history.losses[-1], 100 * history.accs[-1]))\n",
        "          iteration_checkpoints.append(iteration + 1)\n",
        "          losses.append(history.losses[-1])\n",
        "          accs.append(history.accs[-1])\n",
        "          discriminator_supervised.save_weights(\"./models/discriminator_supervised-\" + str(iteration+1) + \".h5\")\n",
        "          \n",
        "          # x, y = dataset.training_set()\n",
        "          # _, accuracy = discriminator_supervised.evaluate(x, y)\n",
        "          # print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGIfXoRgW-0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def pretrain(iterations_pre, batch_size, save_interval):\n",
        "#   for iteration in range(iterations_pre):\n",
        "#       # imgs, labels = dataset.training_set()\n",
        "#       imgs, labels = dataset.batch_labeled(1000)\n",
        "      \n",
        "#       loss, acc = discriminator_supervised.train_on_batch(imgs, labels)\n",
        "      \n",
        "#       if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "#           losses.append(loss)\n",
        "#           accs.append(acc)\n",
        "#           iteration_checkpoints.append(iteration + 1)\n",
        "          \n",
        "#           # Output training progress\n",
        "#           print(\n",
        "#               \"%d [D loss class: %.4f, acc: %.2f%%]\"\n",
        "#               % (iteration + 1, loss, 100 * acc))\n",
        "#           discriminator_supervised.save(\"./models/discriminator_supervised-\" + str(iteration+1) + \".h5\")\n",
        "          \n",
        "#           # x, y = dataset.training_set()\n",
        "#           # _, accuracy = discriminator_supervised.evaluate(x, y)\n",
        "#           # print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nIEI7nOhsUa",
        "colab_type": "code",
        "outputId": "ca48b2a9-0e1f-4d94-c6e1-6cf0280e559f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Pretrain\n",
        "\n",
        "# Set hyperparameters\n",
        "iterations_pre = 1\n",
        "iter_epochs = 40    # 20\n",
        "batch_size = 32\n",
        "save_interval = 1\n",
        "losses = []\n",
        "accs = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "dataset = Dataset_CIFAR10(num_labeled)\n",
        "\n",
        "discriminator_supervised.trainable = True\n",
        "\n",
        "starttime = time.clock()\n",
        "\n",
        "pretrain(iterations_pre, batch_size, save_interval\n",
        "         , iter_epochs\n",
        "         )\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Use time:\" + str(endtime-starttime) + \"s\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 103s 66ms/step - loss: 1.5808 - acc: 0.4826 - val_loss: 1.8150 - val_acc: 0.4500\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.45000, saving model to /content/models/cifar10_model.001.h5\n",
            "Epoch 2/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 1.1992 - acc: 0.6297 - val_loss: 1.0872 - val_acc: 0.6709\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.45000 to 0.67090, saving model to /content/models/cifar10_model.002.h5\n",
            "Epoch 3/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 57ms/step - loss: 1.0207 - acc: 0.7006 - val_loss: 1.2265 - val_acc: 0.6507\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.67090\n",
            "Epoch 4/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 0.9298 - acc: 0.7329 - val_loss: 1.2809 - val_acc: 0.6587\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.67090\n",
            "Epoch 5/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 0.8577 - acc: 0.7603 - val_loss: 1.0542 - val_acc: 0.7087\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.67090 to 0.70870, saving model to /content/models/cifar10_model.005.h5\n",
            "Epoch 6/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 0.8189 - acc: 0.7766 - val_loss: 1.0047 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.70870 to 0.71930, saving model to /content/models/cifar10_model.006.h5\n",
            "Epoch 7/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 0.7821 - acc: 0.7890 - val_loss: 0.8666 - val_acc: 0.7683\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.71930 to 0.76830, saving model to /content/models/cifar10_model.007.h5\n",
            "Epoch 8/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 57ms/step - loss: 0.7518 - acc: 0.8014 - val_loss: 0.8860 - val_acc: 0.7659\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.76830\n",
            "Epoch 9/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.7288 - acc: 0.8092 - val_loss: 0.7375 - val_acc: 0.8129\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.76830 to 0.81290, saving model to /content/models/cifar10_model.009.h5\n",
            "Epoch 10/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.7015 - acc: 0.8188 - val_loss: 0.9818 - val_acc: 0.7465\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.81290\n",
            "Epoch 11/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.6936 - acc: 0.8230 - val_loss: 0.9713 - val_acc: 0.7414\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.81290\n",
            "Epoch 12/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6778 - acc: 0.8303 - val_loss: 0.8673 - val_acc: 0.7682\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.81290\n",
            "Epoch 13/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.6644 - acc: 0.8354 - val_loss: 0.7908 - val_acc: 0.8004\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.81290\n",
            "Epoch 14/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.6521 - acc: 0.8389 - val_loss: 0.8083 - val_acc: 0.7946\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.81290\n",
            "Epoch 15/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6439 - acc: 0.8427 - val_loss: 0.7838 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.81290\n",
            "Epoch 16/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 89s 57ms/step - loss: 0.6332 - acc: 0.8470 - val_loss: 1.1694 - val_acc: 0.7222\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.81290\n",
            "Epoch 17/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6233 - acc: 0.8512 - val_loss: 1.0825 - val_acc: 0.7278\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.81290\n",
            "Epoch 18/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.6197 - acc: 0.8527 - val_loss: 0.7515 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.81290 to 0.81460, saving model to /content/models/cifar10_model.018.h5\n",
            "Epoch 19/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.6082 - acc: 0.8566 - val_loss: 0.7396 - val_acc: 0.8215\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.81460 to 0.82150, saving model to /content/models/cifar10_model.019.h5\n",
            "Epoch 20/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 95s 61ms/step - loss: 0.6055 - acc: 0.8597 - val_loss: 0.9240 - val_acc: 0.7650\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.82150\n",
            "Epoch 21/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5980 - acc: 0.8601 - val_loss: 0.7379 - val_acc: 0.8264\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.82150 to 0.82640, saving model to /content/models/cifar10_model.021.h5\n",
            "Epoch 22/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.5940 - acc: 0.8651 - val_loss: 0.7044 - val_acc: 0.8275\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.82640 to 0.82750, saving model to /content/models/cifar10_model.022.h5\n",
            "Epoch 23/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 59ms/step - loss: 0.5865 - acc: 0.8659 - val_loss: 0.8063 - val_acc: 0.8033\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.82750\n",
            "Epoch 24/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 90s 58ms/step - loss: 0.5812 - acc: 0.8689 - val_loss: 0.8172 - val_acc: 0.8031\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.82750\n",
            "Epoch 25/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5747 - acc: 0.8701 - val_loss: 1.0520 - val_acc: 0.7609\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.82750\n",
            "Epoch 26/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5741 - acc: 0.8705 - val_loss: 0.8520 - val_acc: 0.7920\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.82750\n",
            "Epoch 27/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5712 - acc: 0.8721 - val_loss: 0.7520 - val_acc: 0.8223\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.82750\n",
            "Epoch 28/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 59ms/step - loss: 0.5697 - acc: 0.8739 - val_loss: 0.8162 - val_acc: 0.8101\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.82750\n",
            "Epoch 29/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.5658 - acc: 0.8758 - val_loss: 0.7576 - val_acc: 0.8133\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.82750\n",
            "Epoch 30/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5635 - acc: 0.8748 - val_loss: 0.6934 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.82750 to 0.83810, saving model to /content/models/cifar10_model.030.h5\n",
            "Epoch 31/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 91s 58ms/step - loss: 0.5554 - acc: 0.8798 - val_loss: 0.8414 - val_acc: 0.8054\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.83810\n",
            "Epoch 32/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.5618 - acc: 0.8757 - val_loss: 0.7020 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.83810\n",
            "Epoch 33/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.5493 - acc: 0.8821 - val_loss: 0.7654 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.83810\n",
            "Epoch 34/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5496 - acc: 0.8815 - val_loss: 0.7557 - val_acc: 0.8285\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.83810\n",
            "Epoch 35/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5474 - acc: 0.8817 - val_loss: 0.6423 - val_acc: 0.8568\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.83810 to 0.85680, saving model to /content/models/cifar10_model.035.h5\n",
            "Epoch 36/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 94s 60ms/step - loss: 0.5437 - acc: 0.8820 - val_loss: 0.6972 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.85680\n",
            "Epoch 37/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 93s 59ms/step - loss: 0.5420 - acc: 0.8823 - val_loss: 0.8670 - val_acc: 0.8009\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.85680\n",
            "Epoch 38/40\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5417 - acc: 0.8846 - val_loss: 0.7269 - val_acc: 0.8360\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.85680\n",
            "Epoch 39/40\n",
            "Learning rate:  0.001\n",
            "1462/1563 [===========================>..] - ETA: 5s - loss: 0.5345 - acc: 0.8864Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlf871AuWzWb",
        "colab_type": "code",
        "outputId": "ab7a7c08-a839-40b9-ceac-d447bfe1881f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "%ls models"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar10_model.001.h5  cifar10_model.009.h5  cifar10_model.030.h5\n",
            "cifar10_model.002.h5  cifar10_model.018.h5  cifar10_model.035.h5\n",
            "cifar10_model.005.h5  cifar10_model.019.h5  discriminator_supervised-1.h5\n",
            "cifar10_model.006.h5  cifar10_model.021.h5  \u001b[0m\u001b[01;34mmodels-label-1500\u001b[0m/\n",
            "cifar10_model.007.h5  cifar10_model.022.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lzo6IL5z9wE",
        "colab_type": "code",
        "outputId": "83039db5-41a9-4613-c9e6-be3ac5283c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "tmodel.compile(loss='categorical_crossentropy',\n",
        "                                 metrics=['accuracy'],\n",
        "                                 optimizer=Adam())\n",
        "# tmodel.load_weights(\"./models/discriminator_supervised-2000.h5\", by_name=False)\n",
        "tmodel.load_weights(\"./models/cifar10_model.035.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 18s 360us/step\n",
            "Training Accuracy: 88.54%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etkdmP6Ez7Jy",
        "colab_type": "code",
        "outputId": "8cbe8134-1e7f-40a1-cbaf-036b02f1048d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "tmodel.load_weights(\"./models/cifar10_model.035.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the test set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 352us/step\n",
            "Test Accuracy: 85.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xEVpUqmWb90",
        "colab_type": "code",
        "outputId": "50301db8-a35f-45bf-c533-43efb143ce38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "div = 1000\n",
        "ty = [history.accs[i*div] for i in range(0, len(history.accs)//div)]\n",
        "tx = [x for x in range(1*div, (len(ty)+1)*div, div)]\n",
        "print(max(ty))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(tx, ty, label=\"accs\", color='blue')\n",
        "plt.xticks(tx, rotation=90)\n",
        "plt.title(\"accs with epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accs\")\n",
        "plt.legend()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.96875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29d93d3cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFiCAYAAACkvHqaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3hU1dYG8HfTQXoRpAkIKh0CIiog\nEAWUFkQFPkEBI1e/T8RybYDl2sXu1atiQMUC2BhRkBaaSEBjBARFKSKS0JvSAknW98fKuRnCJJly\nzpyZyft7njzJzJzZZyeZM3PW2WuvbUQEREREREREFP1KuN0BIiIiIiIisgcDPCIiIiIiohjBAI+I\niIiIiChGMMAjIiIiIiKKEQzwiIiIiIiIYgQDPCIiIiIiohjBAI+IiCgfY0xXY8yvhTzeyBgjxphS\n4exXIIwx24wxV7jdDyIiCi8GeERERPmIyDcicoF1m8ESERFFCwZ4REREREREMYIBHhERhZ0x5gFj\nzBZjzN/GmJ+NMYPyPX6LMeYXr8fjcu9vYIz53Biz1xiz3xjzWu79TY0xy4wxh40x+4wxMwvY73vG\nmHtyf66Xm2b5f7m3zzPGHDDGlDDGdDfG7Mi9/30ADQF8aYw5Yoy5z6vJG4wx23P3OaGQ37esMeb5\n3G13G2PeNMaUz32suzFmhzFmfG4724wxN3g9t4oxZlru7/yHMWaiMaaE1+M+/1a52hlj1uX+XWYa\nY8r58/8hIqLoxQCPiIjcsAVAVwBVAPwLwAfGmHMAwBhzHYBHAdwIoDKAAQD2G2NKAvgKwB8AGgGo\nB2BGbnuPA1gAoBqA+gD+XcB+lwHonvvz5QC2AujmdfsbEcnxfoKIjACwHUB/EakoIpO8Hu4C4AIA\n8QAeNsY0L2C/zwA4H0A7AE1z+/6w1+N1ANTMvf8mAJONMVaK6L+hf6cmuX28EcAooOC/lVe71wPo\nA6AxgDYARhbQPyIiihEM8IiIKOxE5BMRyRCRHBGZCWATgE65DycCmCQi34vaLCJ/5D5eF8C9InJU\nRE6IyIrc55wCcC6Auvnuz28ZgC65I2DdAEwCcFnuY5fnPh6If4nIcRFZC2AtgLb5NzDGGABjANwl\nIgdE5G8ATwEYmm/Th0QkU0SWAZgD4PrcoHYogAdF5G8R2QbgBQAjcp9T0N/K8mru3/kAgC+hASYR\nEcUwBnhERBR2xpgbjTFrjDGHjDGHALSCjmABQAPoCF9+DQD8ISJZPh67D4AB8J0xZoMxZrSv/YrI\nFgBHoYFOV+iIYEbuaFkwAd4ur5+PAajoY5taACoA+MHr952Xe7/loIgc9br9BzSYrQmgdO5t78fq\n5f5c0N8qkP4REVEMidjyzkREFJuMMecCeBua1pgiItnGmDXQAA0A/gRwno+n/gmgoTGmVP4gT0R2\nAbglt/0uABYZY5aLyGYf7SwDcC2AMiKSboxZBk2LrAZgTQHdloB+ydPtA3AcQEsRSS9gm2rGmLO8\ngryGANbnPtcanfzZ6zGrnYL+VkREVExxBI+IiMLtLGjAtBcAjDGjoCN4liQA/zTGdDCqaW5Q+B2A\nnQCeMcacZYwpZ4y5LLeN64wx9XOffzC3/dPm0nlZBuB2AMtzby/Nvb1CRLILeM5u6By4gOXO6Xsb\nwEvGmLNz+1vPGNM736b/MsaUMcZ0BdAPwCe5/fkYwJPGmEq5f4e7AXyQ+5yC/lZERFRMMcAjIqKw\nEpGfofPIUqCBU2sA33o9/gmAJwF8BOBvAB4A1XODnf7QIiXbAewAMCT3aRcBWG2MOQJgNoBxIrK1\ngC4sA1AJeQHeCmgK5fICtgeApwFMzE2x/GdAv7C6H8BmAKuMMX8BWAQtzmLZBQ1MMwB8COBWEdmY\n+9hYaFrp1ty+fgRgKlDw3yqI/hERUYwwIqFknRAREVEojDHdAXwgIvWL2paIiKgoHMEjIiIiIiKK\nEQzwiIiIiIiIYgRTNImIiIiIiGIER/CIiIiIiIhiRNQFeMaYeW73gYiIiIiIyC2FxURRt9B55cqV\ne3fs2JF5pUREREREVFz9VdADjgV4xpip0IVa94hIKx+PGwCvALgawDEAI0Ukrah2mzVrhtTUVLu7\nS0REREREFBWMMZsKeszJFM13AfQp5PGrADTL/RoD4A0H+0JERERERBTzHAvwRGQ5gAOFbDIQwDRR\nqwBUNcac41R/iIiIiIiIYp2bRVbqAfjT6/aO3PvOYIwZY4xJNcak7t27NyydIyIiIiIiijZRUWRF\nRCYDmAwALLBCRERERESnTp3Cjh07cOLECbe74phy5cqhfv36KF26tN/PcTPASwfQwOt2/dz7iIiI\niIiICrVjxw5UqlQJjRo1gtZvjC0igv3792PHjh1o3Lix389zM0VzNoAbjeoM4LCI7HSxP0RERERE\nFCVOnDiBGjVqxGRwBwDGGNSoUSPgEUonl0mYDqA7gJrGmB0AHgFQGgBE5E0Ac6FLJGyGLpMwyqm+\nEBERERFR7InV4M4SzO/nWIAnIsOKeFwA/J9T+yciIiIiIipu3EzRJCIiIiIiIhsxwCMiItts2ABc\nfDGwa5fbPaFw+eADYMAA4OhRt3tC5Kx584CePYHMTOf28fHHQIMGQL16/n81aAB89plzfaLCJSQk\noEOHDmjZsiUmT54MAJg3bx7i4uLQtm1bxMfHAwCOHDmCUaNGoXXr1mjTpg0+++wzZGdnY+TIkWjV\nqhVat26Nl156yZY+RcUyCUREFB3eeQf47jvgk0+AsWPd7g05LScHeOghYNs2YMwYDfZifDoMFWOv\nvw4sWQIsXQr07u3MPv7zHz2urr7a/+csWQLccw/Qrx9Qtqwz/YoGd94JrFljb5vt2gEvv1z4NlOn\nTkX16tVx/PhxXHTRRRg4cCBuueUWLF++HI0bN8aBAwcAAI8//jiqVKmCn376CQBw8OBBrFmzBunp\n6Vi/fj0A4NChQ7b0mwEeERHZQgTwePRnj4cBXnGQnKzBXdeuwEcfAZdcAtx+u9u9IrLfkSPAwoX6\ns8fjTIC3bx/wzTfAhAnAY4/5/7z584E+fYCkJOD/WN0i7F599VXMmjULAPDnn39i8uTJ6Nat23+X\nNahevToAYNGiRZgxY8Z/n1etWjU0adIEW7duxdixY9G3b1/06tXLlj4xwCMiIlusXw9s2QI0bAgs\nWwbs3w/UqOF2r8hJSUlA9ep6gjlkCHDXXUBcHHDppW73jMhe8+ZpambDhsAXX+hoXgmbJzp9+aWO\n3iUkBPa8Xr30IssTTwCjRgEVKtjbr2hR1EibE5YuXYpFixYhJSUFFSpUQPfu3dGuXTts3LjRr+dX\nq1YNa9euxfz58/Hmm2/i448/xtSpU0PuF+fgERGRLTweTc977TUgOxuYM8ftHpGT9u0DZs0CbrwR\nKF8emDYNOPdc4NprOQeTYo/Hoxes/vUvYOdOTUV3Yh8NGgDt2wf2PGOAJ5/U4+611+zvFxXs8OHD\nqFatGipUqICNGzdi1apVOHHiBJYvX47ff/8dAP6bonnllVfi9ddf/+9zDx48iH379iEnJweDBw/G\nE088gbS0NFv6xQCPiIhs4fEAnTsDffvqxH8rXZNi0/vvA6dOATffrLerVgU+/xw4dEhH806dcrd/\nRHY5dQr46iugf39g4ECgZEn739+OHgUWLNDRu2DmsXbtqmmazz4LHD5sb9+oYH369EFWVhaaN2+O\nBx54AJ07d0atWrUwefJkXHPNNWjbti2GDBkCAJg4cSIOHjyIVq1aoW3btliyZAnS09P/O+o3fPhw\nPP3007b0iymaREQUsu3bgbQ0PbkoUUJPgt55Bzh2rPimC8UyEU3P7NwZaNUq7/42bYDJk4ERI4AH\nHgBeeMG9PhLZZdkyDZoSEoBq1YDu3TXAe+YZ+/axYAFw4gQwaFDwbTzxBNCxI/DiizrSSM4rW7Ys\nvv76a5+PXXXVVafdrlixIt57770ztrNr1M4bR/CIiChkX3yh362Tk0GDgOPHgUWL3OsTOSclBfj5\nZyAx8czHhg/XQisvvgjMnBn+vhHZzePRC1VW/YtBg4BffwX8nGbl9z6qVdORuGB16AAMHqzH3r59\n9vWNog8DPKIYMWcOcPnlQFaW2z2h4sjjAVq0AJo109uXXw5UqcI0zcLMmaMnc06uqeWUpCSgYkVN\nxfTlhRe00MrNN+vaiLFoyxYdvfz+e7d7Qk6yqgP37q1zTQFd9xGw7/0tK0sLrPTvD5QKMbfuscc0\nc8LO0UWKPgzwiGLE9OnA8uXAL7+43RMqbg4c0BQm78pvpUvrmkyzZ/OiQ0FmzABWrNA1rKLJX3/p\nyNzQoRrk+VKmjK6FWLEicM01+pxY89BDGrzee68GARSbfvgBSE8//f2tQQNNhbQrwPvmG+DgwcCr\nZ/rSooWOor/+uvabiicGeEQxIiVFvzuQyk1UqDlztGpm/pOThARdKuHbb93pV6SzjtloG+WcMUNH\nCG65pfDt6tbVQHDLFmDkyNgKgtat04tqF16oFzeYihy7PB4tqtK37+n3JyQAq1cDGRn27KNcubwU\n0FA9+qi+Jz/xhD3tRTqJpTcXH4L5/RjgEcWA3buBrVv1ZwZ4FG6zZmnVzA4dTr+/d2+gbNnoC2DC\nYc8eDXxKldL5izk5bvfIf0lJQOvWwEUXFb3t5ZcDkybpa2TSJOf7Fi4PPaQpyEuX6rpo48fHVgBL\neWbNArp1O3NNT+uCljX/OFhWCmivXsBZZ4XWlqVxY50fm5SUd24Qq8qVK4f9+/fHbJAnIti/fz/K\nlSsX0PNYRZMoBlgjAZUqMcCj8Dp2TBcAHjXqzEV/K1UCrrhCT15efDG40t+xyjpmx4wB/vMfXVOr\nc2d3++SPtWt1ztkrr/j//7zrLh3pGD9e09ri453to9NWrdLU4yefBGrX1tGS0aP1RN+OFDuKHL/9\npsWE/vGPMx9r0QJo2lTf3267Lfh9/PijViF+9NHg2/Bl4kStZPzoo7pGZayqX78+duzYgb1797rd\nFceUK1cO9evXD+g5DPCIYkBKis55GjYM+PBDHQ3If7JN5IRFi7RaZkEntgkJmsK5bh3Qtm14+xbJ\nrGP2oYd0WQFrDcFIl5Sko7LDh/v/HGOAKVOAn37SeXtpaTqHKVpNmACcfTZwxx16e8QIXR5k4kQt\nklGypLv9I/tYo3MDB575mDH6/vbyy7r2Y9Wqwe3D49HP6379gu+nL3XrAmPHAs8/D9x/P9Cypb3t\nR4rSpUujcePGbncj4vAUkCgGpKQAcXFate7oUWDTJrd7RMWFx6Opapdf7vvx/v31RIhpmqdLSQHa\ntwfq1AF69IiOv8/x48AHH2jRlOrVA3tuxYqa6paZCVx7bXRWDgWA5GRg8WIdjbQKzJQqpZULN2zQ\n+YkUOzwePU7PPdf34wkJWkSqgGXQ/N5H165ArVrBt1GQ++/X1+nDD9vfNkU2BnhEUe7UKU2ZuuQS\nDfIApmlSeGRlaapav35aNdGX2rWByy6LjgAmXLyPWUBPEu1eU8sJn3+uIxW+1r7zxwUXAO+9p+mo\n48bZ27dwENHRu/r1z0zZu/ZaHaF++GH9/1L027VLL8QUtvB45876Hhfs+9uWLTqy7VRqb40awD33\n6LGbmurMPigyMcAjCoPkZL0KeOSI/W2vWQOcOKEni82bayUupwK8Dz7QK43Z2c60Hy7PPQdcfHHe\nPCgKzsqVWiWzqJOThAR9nW7bZs9+k5N1vb0pU6KzsMXatToadumlettaU2vWLPv39eGH+t5gx6LH\nSUnAeecB3bsH38agQTqq8NZb0Rf0f/WVziV85BF9n/VWooTOydu6Vec92eWbb3Su1zff2NdmqFJT\n9TV1663Refz568sv9fcr7P2tZEk9fufODW5UurAUULvcdZcGehMnBvd8EX0fOfdcHQ108qtaNWDh\nQnt//+LKRFvVmY4dO0oqL0NQlLnjDuDf/9YThPyllkP16qt6NXz7dp3XcvHF+kaZnGzvfgAdqZkz\nR082unSxv/1wENEPqj//1NTB//1f4KmngMqV3e5Z9Ln7bi0QsnevFlQpyObNGpC9/HLoIzc5OUC7\ndlr4IDtb0xvfeitvgfVo8O9/63uCdcwCQKdO+npcvdq+/YhoGf/fftNiN/PmBT8/bNMm4Pzz9Vh5\n8MHQ+pWVpf+v886LnuUFcnL0It2xY/raK136zG1EdLR6+3Z9zQdY9O4MGRmalbF7t44SpaXpvCq3\nHD2qI5Qvv6wLfh89qp8/Y8e61ycn9e2ro+qbNxdeUGjuXN127lzgqqsC20e3brpG5Jo1ofW1KM8/\nr+s1Llum+/TXtm1aQGbePH2P6trVsS4C0LUzq1bVwjOsI1A0Y8wPItLR54MiElVfHTp0EKJoc9ll\nIoDI3Xfb3/bQoSL16+fdvvVWkapVRXJy7N1PTo5IjRr6e9xzj71th9MPP+jv8OqrInfcIWKM/v1m\nz3a7Z9ElJ0ekcWORvn39275VK5HLLw99vx99pP+/Dz8UmTxZpEoVkXLlRJ5+WuTkydDbD4dhw0Tq\n1Tv9vief1N9rxw779rNsmbZ59dX6ffz44Nu6/36RkiVF0tPt6dtjj2mfNm+2pz2nTZ+u/f3oo8K3\nW7JEt3vxxdD2l5kpcumlImedJfLxxyIVKujtzMzQ2g3WvHkijRrp7/aPf4gcOCDSv79IqVIiK1a4\n0ycn/fWXSJky/n1mHz8uUrGiyJgxge1j926REiVEHnkkqC4G5NgxkXPOEenSxb9zg6wsfQ1XqKC/\n26uv6n1O+/BDfY1Nn+78vmIBgFQpIF5yPWAL9IsBHkWbrCz9kAZE2ra1v/1zzxW57rq825Mn6762\nbLF3P7/+qu2WLi1y3nn2B5Dh8tBD+qG6d6/eTknR4AMQuf56kZ073e1ftFizRv9mb7/t3/YTJ57+\ndw/GyZMiTZuKtGkjkp2t92VkiAwenHd8ffdd8O2HS6NGItdee/p9P/+sv8N//mPffkaMEKlcWeTI\nEZHERG3f4wm8nZMnRWrXFhkwwL6+/fmnvh5CCTrD5dQpkWbNRFq3znvdFeaKK0Rq1tQgIVhjx+r/\na+ZMvT1jht6+447g2wzG3r0iw4frvi+4QGT58rzHDh7Uz4Jzzom9982ZM/V39v59C3PddXqMBBIE\nJSXpPn78Mbg+Buo//9H9zZ1b+HZr14pcdFHexaE//ghP/0T0+GrVSo+3U6fCt99oxQCPyEW//JL3\n4QiI7NljX9vp6WdeLU5N1fs++cS+/YiIvPuutmudePz0k73th0vr1meOJGVmijz+uF6xrVpVZMqU\n6A1gw+XRR3X0c9cu/7a3XpfvvBP8Pt9+W9vwNdo6a5ZI3boaNNx1lwY1kSgjQ3+HF144/f6cHJHz\nzxfp1cue/Rw8qCObt96qt48fF+nYUQO+X38NrK1Zswr+u4eib18NDiL9RM46Ef/iC/+2X71at3/8\n8eD29/774jPj46675L+j107LyRH54AMNVEuV0gs0x4+fud3atSLly4t06xY9I+j+GDZMf3d/AzZr\n5Onbb/3fR79+eoE2XJ81mZl6cal9e98XKo4dE3nwQf1/16qlo2hufA56PPq3TEoK/76jDQM8IhdZ\nb/zWyJp1RdYOn36qbaak5N134oS+QT/4oH37EdG0nMqVNag0RlOsos3mzfr3eukl349v3KgnKoBI\nz54imzaFt3/RpF07TT32V06OpsIOHBjc/o4fF2nQQOTiiws+6Th0SAMaQE9k5s0Lbl9O+uyzM49Z\ny3336bF78GDo+3n9dd3PDz/k3bdtm6ZZt2wZWADct68Gz3YHYk4FjnY6cUJfd506BXayO3Cgvl/u\n3x/Y/goLmE6eFOnaVR9fuzawdgPx++8ivXvr/+bii0XWrSt8+w8+0G3vusu5PoVTZqb+70aP9v85\nBw/qsXvvvf5t//ffImXLiowbF1wfg/Xee74vAC9dqqNmgMjIkSL79oW3X95ycvR4a9BAjz8qGAM8\nIhfdc49eST9+XD80/vEPe9suW/bMN8F27fQD2k6tW+eNLlxyiUhcnL3th8Pzz+u73u+/F7xNdrbI\nW2/p/yra5naFy++/69/xuecCe97tt+vJ6dGjge/z5Zd1n8nJRW+7fLnIhRfq9sOHh5YWard//lNH\nin2duKxcad8ITfv2+pXfggV6gWbYMP8CFiuVcsKE0PuUnxOpn3Z75RX9nyxaFNjz1q3Tv/P99/v/\nHCvlsW7dglMed+7UUc+mTe25EODNe97VWWcFNu/KyuyYMcPePrlh/vzgLjxceaX+X/w5rqyLs0uX\nBtfHYGVliTRvru+PWVk6l9JK327SRGThwvD2pyALF2qfXnnF7Z5ENgZ4RC7q3l2vRonopPSmTe1r\n+9JL9Su/0aM1xcKu9IrDh/VkxZoMPmmSvnuEMzffDl26aPDrj/R0kWuukf/O7fr+e2f7Fk2sYCvQ\nEc7kZH3erFmBPe/vv0XOPltHVf11/LjOtyxdWket3n8/MtJuL7tML5D4kp2tAY/3nNpgWIWEXn/d\n9+NWQZeXXy66rccfF0fm9FrsLt5ipyNH9HXXo0dwz/+f/9ELGv7MT8vOzitaUlSa34oVul3//v7N\nCfTHmjWhzbvyLgqzfr09fXLLbbfp73HsWGDPs+a4bdhQ9LbDh+v7khvpyVZwOWaMSJ06evzde29w\nF96ckpOj505nnx256faRgAEekUuys3UkyJoH89JL9gVGJ07oSICvipavvab7+fPP0Pcjknc1zUp5\n++03+W8lymixe7cGqY8+GtjzPv9cr5gD+kEYyNcVV/ietxLtunfXifCBOnlSpFo1kZtuCux5VkDi\nK62xKD/9JNK5sz6/Vy+RrVsDb8MumZk64l5YZb4xY7RqXSivm9tu09HngkZ4srM1hbBUqcKLSGRn\na6prfHzwfSmK9V7y1FPO7SNYTz2lfVu5Mrjnb9qk7wO33170tlYg/e9/+9f2q6/q9k88EVzfLHbO\nu0pP1wsU55+vFwWjUXa2jqAOHhz4c3fs0P/Jk08Wvt3JkzrXe+TI4PoYqpwczcABdJTfO407knz7\nbeS+N0QKBnhELrHmfFmVBtet09tTp4bedkqKtvXpp2c+ZqV6+VsUoCiPPabBkfcJY4sWgY2ouM0q\nlLBmTeDPPXhQRy0nTPD/y0pZCrR0dqTbt09T9iZODO75I0aIVK/u/5XrAwd0KYT+/YPbn4imIr36\nqgZOFSpoGlo4Sn7nt2pVwcesZe5c3WbOnOD2ceSIXlQaMaLw7Q4d0myCOnW08IsvCxZIWEqWd++u\nqYl2jUbZ4eBBPQnv1y+0dm65RUeRt20reJt58/T99YYb/A+ucnJ0hNAYTSkMxpIlefOubrrJnnlX\ny5ZpUDtoUGSMmAfKKpDz/vvBPb9TJx0JLcyiRRJ0RVu7bNyohdMivcBRv356HNqdjhwrGOARueTj\nj+W0Qgc5OZpycMMNobf94ovatq/UpqNH7V1fp08fLczgbfx4/SAPtIiAW/r109GIcJ50PPig/o+m\nTAnfPp1mVVNNTQ3u+VaRkcWL/dt+/Hjd3o6iEtu3a8EQQCtKBhPsh8IawS8sHfHECZFKlTQwCIb1\n/1m2rOhtf/pJA94uXXzPM73+eg3GnR6Ftop0+DO/MlwmTAj+gpC37dt11HbUKN+P//67/o3btAk8\nRe7IEZ0bXb164fOK83N63pX12fTMM/a2Gw4PPqifawcOBPd8a9S3sOyZUOYiFzc//qh/TyfmAMcC\nBnhELnngAb16611QYehQTfkLNdC47jotsVyQli1DG/WwZGfrFbTExNPv/+47fQeZNi30fTjNqlh2\n553h3W9WlqZpli0bfEAUaRIStBpmsK/fI0c0fdCf9bx27dIAZOjQ4PblS06OFoI4+2w9kXvwwcDn\n2gTr+utFGjYsershQ7R/wYwydumiKXL+/n+shePzV/Pbu1ffu8JR5e/YMX2PGTbM+X35Y9cunYM1\nZIg97d15p15w27jx9PuPHdNUuSpVgq/Yu2mTPr9Dh6ID8ZwcrZ5Yu7az865ycvRvV6JE4MVp3Na8\neWgpydZ6lq+95vtxq5pwQkLw+yhuhgzR43H3brd7EnkY4BG5pFevMyvZWWt5/fxzaG3Xq1f4ie+I\nEbpNqKwPrPyjUNnZ2v6gQaHvw2mffCKuVCwT0XUPGzTQYNzN0tN2OHpUrzz7M6eoMP37a6BTVBAy\nbpyeiAa6bps/9u/XURVAUxX9HVEMRYMG/gUN06dLwGtqieStuTlpUmDPGzdOn/fRR3n3WaMw4Vrv\n8vbbdU5xJBwjdr/udu/WE9Trr8+7Lycn7/UX6jIRX3yh7dx8c8Hb7Nih8y7DNe/q7781jb9mTR3F\njAYbN0pA8yB9sdazvOIK349//73u4913g99HcbNxo14sCPcF2mhQWIBXAkTkCBEgLQ2Iizv9/p49\n9XtycvBt//knkJ4OXHJJwdvExek2u3cHvx8ASEnR75deevr9JUoAAwcC8+YBx46Ftg+neTxAjRrA\nZZeFf9+1agGffQbs3AnccAOQnR3+PthlwQLg+HEgISG0dhISgO3bgTVrCt5m+3bgjTeAkSOB888P\nbX++VK8OTJ0KLFwI5OTocXnLLcDBg/bvCwB27NDjNv9x5MtVVwGlSwOzZgW2jylTgFKlgBtvDOx5\nzz0HdOkCJCYC69fre1dSEtC5M9CqVWBtBSsxETh5Evjww/DsryDW6+6mm+x73Z19NnDnncDHH+e9\n5pOSgHfeASZOBPr3D639AQOACRP0/5+UdPpjOTn6+zRvrsfvpEnAd9+d+blkt4oVgc8/BzIzgWuv\n1e+RzuPR7wMHBt+GMfr+tnSp7/cSj0c/O/v1C34fxc0FF+jnwBtv6Hso+amgyC9SvziCR9Fi+3Yp\nsFR5o0ahpWjMnKltF1a6f9ky3ebrr4Pfj4imZlar5rsAglWEwa5iLk44eVJTmAqaAxMu1kL3wRYn\niQQ33aSvhVDXBdyzR6/IPvxwwdskJuqITjiW4jh6VBcZL1lS09c++cT+uZrWfNzvvvNv+969tfCI\nv/3IzNQqiNdcE1z/MjK04EqzZnmFXpKSgmsrWB07anVWN4tzWK+7woqiBMMq2tK3rxbyKFNG/8d2\nFfvJytKMkTJl8l5jP/+sy48J/G0AACAASURBVHIAOqK0ebM9+wrE55/r/u1c/9UpnTtrqmuorCJn\nH3xw5mMtW2pRIQrMtm2aMh7s3ORYBaZoEoWfxyMFlna/+Wb9sA/2w/3OOzVVrrAT7cOHxZYy2i1a\niFx1le/HMjMjI3gqjLXEg9tBaE6Ork9oR0qWG06d0mIORVVn9Fe3blpYwpffftNgKxzzv7ylpeWV\nDx8wwL5lRkRE7rpL5x5mZvq3/RtvaD/8XVPMSkOeOzf4Pn7zjZbLL1tWK47+/XfwbQXjzTf1d1i9\nOrz7tVivO3/mhwbj6af196tZ05mU7X37tN0GDfRCUpkyekHm3XfdDZofeEBsqx7tlIwMez4vRfRi\naJ06Itdee/r91pIgXLw7OGPH6vEZ7HzVWFRYgMcUTSKHpKVpKkabNmc+Fh8PHDoE/PhjcG2vXAl0\n7KhpXAWpXBlo1kz7EaxDh4Cffy44FbRMGaBvX2D2bCArK/j9OMnjASpUAK680t1+GAO89pqmRo0Y\nAWze7G5/ArViBXDgQOjpmZaEBGDdOmDr1jMfe+QRoGxZ4MEH7dmXv9q3B1av1pTFhQuBtm2Bffvs\naTslRY/ZMmX8237AAP1upY0VJSkJaNAA6NUruP4Bmqb5/POaTjd0qKbZhdOwYXqs5k8zDIecHOCu\nu/R1N368M/sYOxaoXRv4+29NX6xRw972a9TQdPA9e4AnngAGDwY2btR0U2Ps3VcgHn9cP/Nuuw14\n8cXI/KyYPVu/2/H+Zk1f+Ppr4MSJvPu/+EK/h5ICWpyNH6/H5yOPuN2T6MAAj8ghaWk676FChTMf\n69FDvwczD+/ECQ0MC5t/Z4mLCy3AW71avxe2r0GDgP37NeiMNCJ6gty7N1C+vNu90T589hlQsiRw\nzTWRP3fRm8cDlCunf0s7WCc5+QOYtWuB6dN1zlLt2vbsKxClSgH//CewfLkGtB98EHqbJ07ocejP\n/DtL3brAxRf7F+D98YfOrxo9Wl9bobjjDuCTT4Bnnw2tnWBUrgwMGaL//yNHwrvvZ58F5swBnn7a\nudfdWWcBc+cCS5Y4NweuQwdg/nxg0SLgo490/p/bSpUCZs7Ui2z33KNzOwubf+sGjwdo2hRo0cKe\n9hISgKNHT/+M93j0ItK559qzj+KmTh19f5o+HfjpJ7d7E/kY4BE5xFeBFUudOkDLlsEFeD/8AJw6\n5d/JYlwcsG2bnqgGIyVFr0Z26lTwNr1761U1f0cawumHH7TQjF2jTnZo1EhPvNavB8aM0SA00lmB\n8pVX6kmqHZo00dHt/K+bhx4CqlTRIMtNHTvqiWhSUuj/o7Q0LSDiz0UZbwkJQGpq0YUF3nlHv48a\nFVz/vBmjRTGqVw+9rWAkJmpwN3Nm+Pa5cKEWOxk2TEfZnBQXF/jrIFCXX64jZpGkRg0dJZs5U1/P\nHTvqCP3x4273DPjrL/0sTkiwb6SzRw+gUqW897fdu/UiaCR9FkWje+/VC0EPPeR2TyIfAzwiB+za\nBWRkFH6VNj5e094CrS5mVbX0dwQPCC0VtFUrfUMtSKVKwBVX6AdZpAUrHo+OaPTt63ZPTte7N/DY\nY1ox8PXX3e5N0dau1VEiu09OEhKAb7/VlDIAWLUK+PJL4L77gGrV7N1XMBITgQ0btF+hCOSY9TZo\nkH630sd8yc7WaqC9esXGyMAll2jmQ7jSNP/4QwO7Fi2At992N5Ux1hkDXH898Msvmjb6zDN6kWfx\nYnf79fXXetHUzve3smWBq6/WtMzsbD2GRRjghap6db3498UXeRlG5BsDPCIHWGmRRQV4x48HfvK4\ncqWOfviTetO+/en9CUROjr6B+nNSmpAA/P67zqmKJLNmAd262T/XxQ7jx2t59Lvuisz0Vm+zZulI\nbqjl3PNLSNDX2Vdf6e0JE/R1fccd9u4nWEOG6Dy0UIONlBSgcePAU/8uuAC48MLCl0tYuFBHRBIT\nQ+tjpDBGf5dVq3SU20knTuho5alTOifOrtFpKlz16rqkQ3KyBj3x8cDNNwefaRKqWbP0fadzZ3vb\nTUgA9u7V49/j0feA1q3t3UdxNG6cLj80caLbPYlsDPCIHGAFVFaA5cvll+tJcyBpmiL6YeHvSECN\nGnpVP5gA7+efNXXFn331768nZpGUpvnbb/o7ROoV0xIlgGnT9P9z7bU66hupPB5dQ7BWLXvbbdcO\naNhQ209O1iv548eHv7hHQSpW1GIjM2bosRCMQI/Z/ApbUwvQ4LNmzbyiLLFgxAgtIDVlirP7GTtW\nU2CnTdOCVBRePXvqXKoHHgDee09Hbj/+OLyZIJmZOi9ywIDQ56/mZ61n+f77OifSzhTQ4qxSJU3v\nXbRI57OSbwzwiByQlqaL5FaqVPA2VaroPIRAArw//tBAIJBiDcEWWilogXNfatfW7SIpwLMqlkVq\ngAcAVavqyMGhQzpadOqU2z0609atOjLrxN/RWhR4wQJNy6xfH/jHP+zfTygSE7UYTrBzwrZv13Tt\nQI5ZbwkJmuI1Z86Zj+3era/zm27yvzpnNKhVS9NTp01zboHspCT9Gj+eVQ3dVL68FrZJTdUqsEOG\n6P8jXAtaL1miVU2deH+rUkWD2KQknYMbyZ9F0ea22/TzYsKEyJsaEikY4FHEi8aDt7ACK97i44Hv\nvtMPGH8EM5cnLk5HswIdgUhJ0ZGBpk392z4hQSujbdsW2H6c4vHo796wods9KVybNjr3Z/lyvZLt\ntMxMre7m79enn+rznDo5GTRI+5SWpuWvy5VzZj/B6tRJ56EGm6YZ7Pw7y0UXAeec4/viybRpWnI+\nVtIzvSUmasqeExeNUlOB22/XokGPPWZ/+xS4du00LfeFF/SiZ4sWuqzMkSOBvV8F+vXZZzpS71RR\nmkGDNA29Zk3NgiB7lCsHPPxwXvqrk6+Ro0cjoxhQwApaIC9Sv7jQefEyf75I7doiS5e63RP/7dun\ni5lOmlT0tosW6bZz5vjX9u23i5x1li467a85c3Qfy5f7/xwRkQsuEOnXz//trUVcX345sP04YedO\nEWNEHnvM7Z74b+xY/fvNmOHcPmbPFilfXvcTyFfr1s716dQpkRo1RJo2FTl50rn9hOKVV/TvsHZt\n4M+94w6RChUCO2bzu/VWPe6PHcu7LydH5PzzRbp0Cb7dSJadrYt2x8fb2+7evSING+rX3r32tk32\n2LpVpFevwN+ngv3KvyC5nTIy9LNo1Cjn9lFcnTwpct554XmNXHyx27+tbyhkofNSTgaPxpg+AF4B\nUBJAkog8k+/xhgDeA1A1d5sHRGSuk32i6JGTo9WSdu/WyltpaUC9em73qmhWxUp/RvAuvVSrbSUn\na8WtoqSk6BX9UgEcuR066Pe0NKBrV/+ec+AA8OuvwI03+r+fZs106QePRydBu+nLL6OvYtnzz+uy\nDjffrCNGLVva2/6mTcDw4Vq443/+J7DnXnGFvX3xVqqUVpirUkXnq0Si4cM1hTQpCXj11cCeG8wx\nm19CAvDmm/o+0a+f3rdihY7MO7Uot9tKlNBj4eGHNU24SZPQ28zO1tf+rl1avbVmzdDbJPs1bgzM\nm6fpx5s2ObsvY3RBeKecc47O8Wvb1rl9FFelS+sUh/nznd/XOec4vw/bFRT5hfoFDdi2AGgCoAyA\ntQBa5NtmMoDbcn9uAWBbUe1yBK/4+OgjvXLy8MMiFSuKXHqpSGam270q2rPPar/37/dv+x49RNq2\nLXq7o0dFSpUSefDBwPtUt67IiBH+b2+N+i1ZEth+Jk4UKVFCRzHddPXVIk2a6ChHNElP1xHr888X\nOXzYvnaPHBFp1UpHyrZts6/d4mTYMJGqVU8fRSvKsWPBH7PeMjNFKlcWGT06774bb9T7jhwJre1I\ntn27vp9MmGBPexMm6Pva22/b0x4RkZtQyAiek3PwOgHYLCJbReQkgBkA8k9lFgDWCltVAGQ42B+K\nIqdO6ZXb1q11Xs7UqVpK/p573O5Z0dLSdDFrfxcKjo/Xdcb27i18u9RUnW8TTLGGQAutpKRoRbGL\nLgpsP1bZ+y+/DOx5dvrrr+itWFa3rlaR27IFGDnSnvmnIrqg+oYNwPTpsbFWmhsSE7UYTmFLFuRn\nHbOhLmxdpoyu5Th7to5CHToEfPKJjkbFcmn/Bg2APn10IfesrNDamj0bePJJ/T/G4pxFIiJvTgZ4\n9QB410HakXuft0cBDDfG7AAwF8BYXw0ZY8YYY1KNMal7izoLppjw3nvA5s3AE09oqs5112lw99pr\nwAcfuN27wvlbYMViTe5eurTw7ay10oJZqycuTheXPXbMv+1XrtTiH4GePMbFaWUrN6tpzpsX3RXL\nunUDnntOA4lJk0Jv79//Bj76SI+lK68Mvb3iqnt3TRMMpNiKVWDFjvW1EhKAffv02Jw+XSf9F4dA\nJTFRq5DOmxd8G5s26dILHTro8UBEFOvcrqI5DMC7IlIfwNUA3jfGnNEnEZksIh1FpGMtuxdioohz\n4oRWNuvU6fSFlZ95RteOGzMm8hbUtvz1l55MBBLgdewIVK5c9HIJKSk6zy2YeSNxcTqy5s/fLTtb\nK3sGM+rgXfbe32DSbh6PllkPtix9JLjzTi0XPn58YMto5LdihV4YGTAgPBU6Y5k1J2zJEr345I+U\nFK1Ca8fHVp8+OpLn8WjV1fbt8+bXxrJ+/XQZlmCrmB49Clxzjc6B/OyzyKvSSkTkBCcDvHQADbxu\n18+9z9vNAD4GABFJAVAOAKc9F3NvvaVr4Dz11OkpdqVK6VpU1arpB/ahQ+71sSCBFFixlCqlgWth\nJ/IS4mLJVn/8SdNcv15LU4eyMPPx4xrkhdvJk7pemBOL1oaTMXpCe+GFutB2MGtC7dypI9+NGumI\neAm3L+fFgJEj9XXlzwLc1jFr14WGypV1tD8pSd9nisPoHaCFFEaOBL76Sl/TgWB6MhEVV05+5H8P\noJkxprExpgyAoQBm59tmO4B4ADDGNIcGeMzBjCKhzovI78gRDex69PC9Lk3t2jr3ZPt2TbnJybFn\nv3a1YwVQgQR4gC6Gunmz/l6+bN2qc/SCPVmsX19H/vwJ8AJZ4NyXbt10AW830jSXLtVR1GhNz/RW\nsaJWCMvMBK69NrAFn0+d0hHAv/7SNqpWda6fxUndujoX7t13i16U/vfftQJwqPPvvCUk6P+0XLnA\nK6FGs5tv1syCyZO1wq+/Xy+/nJee3KuX278FEVH4OBbgiUgWgNsBzAfwC4CPRWSDMeYxY8yA3M3u\nAXCLMWYtgOkARuZWhaEo8P33QKVKWsrYLq++CuzZo5PhC3LppcBLL+kV3aeeCm1/e/boiVL16vYs\n0J2WpieBtWsH9jwrmF282PfjoS6WbIz/hVZWrgTOPltLVQejdGlNq/ryS/svABTF49F5g04tWhtu\nF1ygo2/ffRfY0hP33Qd8842O9rRu7Vz/iqPERC2zP7eIBX1CPWZ9GTBAj+XrriteQXuzZprl8Oij\nQI0a/n/dfTfTk4moeHJ0HTzRNe3m5rvvYa+ffwZwmZN9IOdMn67z5W68UYO9888Prb2DB7W4RL9+\nRZ8U/e//AqtWaaXNjh11fkogRIBp0/QE4MgRvRo/ZQrw+OPB9x/QACqYeTGtWmlQlZys6Uj5rVyp\nwXQoa6PFxQEvvKAjQWXLFrydlQoaSgXKhAQthrNihRanCIecHL3Y0KcPUL58ePYZDoMGAfffDzz7\nLHDxxcCoUYVvP2OGjlzccQcwbFh4+licXHWVromUlAQMzF8X2ktKio7Ctmpl377r1AEWLiyeQfuU\nKZp+HYjy5fUYYHoyERU3jgZ4FLtEtMpfp05a0v2aa4DVq0Mr2f388zqv7oknit7WGJ2rt26djsD9\n8IP/I05btgC33qql9C+7TAsW3HOPluJ+5JHgFyQ+ehTYuFGvrgfKGE3TTE7Wv23+4ColRf/Wocwr\ni4vTQHbDhoJTSPfu1VTRUOf39O6tQaTHE74ALzVVq+3FQnpmfk88ob/fbbfpgrkF/f82bNB0tssu\n0+OJ7FeqlAbZzzwD7Nih6c++pKRoQG73XNBYGZ0O1Hnn6UULIiIqGq9rUVDWrdOUxsREHTH45Rfg\nlluCX7dr924ddRg6VE9g/VGhglZFy8kBBg/Wwh6FycrSEcLWrTUY/c9/gOXLgebNte/p6cD8+cH1\nH9C/SU5O4PPvLD17ahGBjRtPv//IEW071GIN/hRaWbVKv4e6r4oVtST/rFn2rOXmj1mz9GS6b9/w\n7C+cSpXSEfNatfS1vn//mdscPqyjfZUr6zzV0qXD38/iYvRoPdbffdf340eP6tqWdqZnEhER+YsB\nHgXF49FRpgEDgCuu0BGG6dN1Dl0wnn5aUwf/9a/Ante0qaYC/vijpm0WFEykpekI2H336WT7n3/W\n0RArdadfP02RDLYUt7UPIPgAr6B5eN9/ryeToZ4sNmkCVKlSeICXkqLBRMeOoe0L0GBj+3ZgzZrQ\n2/KHNVpYrVp49hdutWrpBY2MDOCGG7TohCUnB7jpJi3s8fHHmkJIzjnvPL0gM2WK7wJN33+v/x8G\neERE5AYGeBQUj0dHeaxiIvffr/NR/vlPLe4QiO3bgTfe0Llnwczj69cPeOghvZr+9tunP3bsmAZ1\nnTrp6Ninn+pIT/60KqsU95dfBl6K25KWpifh9eoF9/wmTbSkff7lEkJZ4NybMbp21g8/FLzNypVA\nu3b2zGHr318D6HBU09y4Ub8GDXJ+X27q1EkXap4/X9eKtEyapPMPn38e6NrVvf4VJ4mJmsXgqzCS\nnQucExERBYoBHgVs2zYdlfGe61SihFb7a9wYuP76wIIkq7DJww8Xvl1hHnlE532NHasVBwGdY9e6\ntaZljhqlo3aDBxdcPMQqxf3ee8H1IS1NR+9CKU4SH68LKXuPzqSk6HpodoxMxcVp6pivEu9ZWTry\nYNeoQ61aOhcsHAGeVcl1wIDCt4sFt9yir+fHHtNKsosWARMmaHoz5yiFz6BBWn3X16h/SopWQK1e\nPfz9IiIiYoBHAbNOpvNXkKtSRdfc+usvDfKKWicKADZt0uImt94KNGwYfJ9KlgQ+/FCXKBg8WNPV\nrrxS71+yREf2igqQzj9f13BLSgp83lhmpi4QHmx6piU+XgvNWAumi+i8OLsWS+7QQfuaf54foPP8\njh2zb1+AXgRYt07X8XOSx6NppQ0aOLufSGAM8Prr+lobPlwDu+bN9TUeysUFCky5croW56xZwL59\neffbvcA5ERFRoBjgUcA8Hi3X36zZmY+1aqXzUlasAO69t+i2HnlEqy2OHx96v2rU0DlKe/fq4rYP\nPqijVYFUcUxM1Cqby5YFtu/163UELNQAr0cP/W6lfW3apAU17BpVK6zQihPrdlmjvLNn29dmfrt3\naxBcWMn6WFO+vL7WS5bUCymff66FbSi8br4ZOHkSeP/9vPs2b9aAj/PviIjILQzwKCD792vlycJK\n0Q8dCtx5J/DKK1p4pSDr1unj48YFvjB4QeLiNLhcu1YXQQ90LtngwToSGWixlVALrFjq1NHg2ZqH\nZ82/s+tksVkzXcrCV4C3cqUW5whlJDW/Jk20EM6iRfa1mZ/1twp0LcRo16iRBuUpKaGvQUnBad1a\nl0LwHvV34kIJERFRIBjgUUC++kqrxhW11tikSUCXLjoitn69720eekiDKX9G+gLRsSPQokVwz61Q\nQdPePv1UF1731w8/6O/i71p8hYmP10I1mZl6sliliqbg2aFkSS2iUtAIXqgLnPsSH68jov6k7AZj\n8WKgalUtIFPcnH9+8K91skdios7vtZYYSUnRpSr4fyEiIrcwwKOAWBUoO3QofLvSpbVce+XKugj6\n4cOnP75qlabt3Xtv5JW1T0zU4OrDD/1/jh0FVizx8bqm36pVerLYuXPecg52iIvTOX7e5d1379YS\n+07MG4qP17X8UlPtbxvQEbwePexfUJrIH0OG6Ki4NervxDFLREQUCH4Ekd+OHQMWLNDRO38CmXPO\n0QWXf/9di554BxQTJmiVxXHjnOtvsNq10wD27bf9K7Zy6pSmm4aanmnp1k1PDmfN0tFPu1O94uJ0\nIeZNm/LuczKtzJpXmH/5Bzts3apVXXv2tL9tIn9UqqRp6TNm6BqFP/3E9EwiInIXAzzy24IFOrJU\nVHqmty5dgBde0Mqbzz6r9yUna1rd+PGRWxgiMVGDNn9GnX75RUf8ihrV9FfVqppmagWYTgR4wOlp\nmikpOupqV5DqrWZNoG1bZwI8q01rkXgiN9xyi14Au/tuvZDFAI+IiNzEAI/85vFo8NGtW2DPGzsW\nGDYMmDgRWLhQR+/q19elESLVsGFaoMWfYit2FVjxFh+vJ4zGaBEHOzVvrpVLvQO8lSu1/+XK2bsv\nS3y87uP4cXvbXbxYR4ovvNDedokC0amTVhCeOVNv233MEhERBYIBHvklKwv48kugXz8d6QmEMToa\n1aKFLkS9erUuau5UMGGHKlV0Lb+PPtL5Y4VJS9ORSF/LRgTLGpFq2VL7YqfSpYE2bfICvJMndaTS\nyVGH+Hjdz7ff2temiAZ48fFc/43cZYyO+gN6zFat6m5/iIioeGOAR35ZsQI4cCCw9ExvZ52la3WV\nKaNl80eOtLV7jkhM1ODuk08K3y4tTeft2VlU4dJLtaJnly72tektLk77LaJLSpw44ezCzF27AqVK\n2ZumuX49sGcP0zMpMgwfriPjTh2zRERE/irldgcoOng8evLSu3fwbTRrpssJlC0b+CigGy67TFP/\nkpKAUaN8b5OdDaxZowse26l8eQ2qGzSwt11LXBzw1ltaACcc63ZVqqRpbHYGeFZbLLBCkaBGDT2W\nnDpmiYiI/MURPCqSiAZ4vXqFXhSladPoOQGy0q5WrtR1rnzZtEkrUjpRnKR9ey1Q4gTvQisrV+qc\nyPr1ndmXJT5eA/xDh+xpLzlZX092LsxOFAonj1kiIiJ/McCjIq1ZA/zxR/DpmdFsxAgdbSyo2IoT\nBVbCoVUrTZlMS8tb4Nxp8fFaYXDZstDbysrSdpieSURERHQ6BnhUJI9H55f17+92T8Lv7LOBgQOB\nadN0KYT80tK0WEzz5uHvWyjKldNiEF99BWzf7uz8O0vnzpp6akeaZmoq8PffDPCIiIiI8mOAR0Xy\neHQ+Wq1abvfEHYmJwP79upZffmlpWpGyVBTOZu3QQRdlBsIzgle2rBZbsSPAs9ro3j30toiIiIhi\nCQM8KtTWrbrgd3FMz7RccYXO88qfpimiAV60pWdarH6XLatzh8KhZ0+dz7hrV2jtJCfr4unF9aID\nERERUUEY4FGhrFGrgQPd7YebSpYERo/WRdp//z3v/q1bgcOHoz/A69BBl68IByulcvHi4Ns4flwL\nwzA9k4iIiOhMDPCoUB4P0Lo1cN55bvfEXaNHa1XNd97Juy9aC6xY2rTR0btu3cK3z/btdRHoUNI0\nV67U+ZAM8IiIiIjOxACPCrR3r67FNmiQ2z1xX4MGQJ8+wNSpuvYdoAFe6dJakTIanXUW8N13wPjx\n4dtnyZJAjx4a4IkE10Zyss557NrV3r4RERERxQIGeFSgr77SsvbFef6dt8REID0dmD9fb6elaXBX\ntqy7/QpFmza6CHk4xcfrshve6a6BSE7WRdPD3W8iIiKiaMAAjwrk8WhxkXbt3O5JZOjXT5dNePvt\n6C+w4qaePfV7MGmahw7pEglMzyQiIiLyjQEe+XT0KLBggY7eGeN2byJDmTLATTcBX36pQca+fQzw\ngnHhhcA55wQX4C1frqPKDPCIiIiIfGOARz7Nnw+cOMH0zPxuvlnn4I0bp7cZ4AXOGA3QFi/WYC0Q\nycm6WHrnzs70jYiIiCjaMcAjnzweoFo1FrLI74IL9G+SkgKUKKFz2Chw8fFaxGfDhsCel5wMdOkS\n3fMeiYiIiJzEAC+G7dwZXKXCU6e0wEr//lqtkE53yy36vXlzoEIFd/sSrYKZh7drlwaETM8kIiIi\nKhgDvBj1/vtA3brAVVcB27YF9txvvgEOHuTyCAUZPFhHNy++2O2eRK+GDYGmTQML8KzF0RngERER\nERWMAV4MWrMGGDNGS/h/+y3QsiXw0kt567cVxePReU69ejnbz2hVoQLw/ffAc8+53ZPoFh8PLFsG\nZGX5t/3ixbpIevv2zvaLiIiIKJoxwIsxBw8C11wD1KihoyMbNujC0nffDVxyCbB2beHPF9EAr1cv\nph8W5rzzgOrV3e5FdIuPB/7+WyuS+iM5GejeXRdLJyIiIiLfGODFkJwcYPhwYMcO4NNPdc22hg21\nrP+MGbq4dMeOwPjxwPHjvtv48Ufgzz9ZPZOc16OHfvcnTXPrVk01ZnomERERUeEY4MWQxx8H5s4F\nXnnl9DLyxgBDhgC//AKMGAE8/TTQti2wdOmZbcyapdUh+/ULW7epmKpZU1+H/gR41jYM8IiIiIgK\nxwAvRsydC/zrX7oQ9623+t6menVg6lRg4UKdj9ejh1aEPHgwbxuPR5cBqFkzPP2m4i0+Hli5suAR\nZcvixbo4+oUXhqdfRERERNGKAV4M2LoVuOEGHQ154w0dsSvMFVcAP/0E3Hcf8M47Wu7/00+BzZuB\n9euZnknhEx8PZGZqMaCCiGiA17Nn0a9tIiIiouKOAV6UO3ZMy/YDwGefafVLf1SoADz7rFaDrFcP\nuO464Mor9TEGeBQu3brpWovWEgi+rF8P7NnD9EwiIiIifzDAi2IiwG23aWXMDz8EmjQJvI327YHV\nq7Xk/+7dWoSlUSPbu0rkU8WKup5gYfPwOP+OiIiIyH8M8KLYm28C06YBjzwCXH118O2UKgX885+a\n6vnVV/b1j8gfPXvqUgmHDvl+PDlZF0Vv2DC8/SIiIiKKRgzwotSqVcC4cRrYPfSQPW3WqQPUrm1P\nW0T+io/XJT6WLTvzsawsvb9nz/D3i4iIiCgaMcCLQnv2ANdeC9SvD7z/vi5rQBStOnfWuaO+5uGl\npupi6EzPJCIiIvKPgakVXgAAIABJREFUo6GBMaaPMeZXY8xmY8wDBWxzvTHmZ2PMBmPMR072JxZk\nZemadvv3a1GV6tXd7hFRaMqW1aU5fM3Ds+6zFkUnIiIiosI5FuAZY0oCeB3AVQBaABhmjGmRb5tm\nAB4EcJmItARwp1P9iRXjx+sC5W+9pQVSiGJBz57Ahg3Arl2n35+crMt/1KrlTr+IiIiIoo2TI3id\nAGwWka0ichLADAAD821zC4DXReQgAIjIHgf7E/U++0yrXd52G3DjjW73hsg+Vgqmd5rm8eO6CDrT\nM4mIiIj852SAVw/An163d+Te5+18AOcbY741xqwyxvTx1ZAxZowxJtUYk7p3716HuhvZfvkFGDlS\nS8q/9JLbvSGyV/v2QNWqpwd4K1fqIugssEJERETkP7fLc5QC0AxAdwDDALxtjKmafyMRmSwiHUWk\nY61imqs1dixQrhzw6ac6Z4kolpQsqfPsvOfhJSfrEh7durnXLyIiIqJo42SAlw6ggdft+rn3edsB\nYLaInBKR3wH8Bg34yMuWLXqye+edWjmTKBbFxwPbtul6jIC+5jt1AipVcrVbRERERFHFyQDvewDN\njDGNjTFlAAwFMDvfNh7o6B2MMTWhKZtbHexTVJo6VZdCGDnS7Z4QOcdKxUxO1kXPU1M5/46IiIgo\nUKWcalhEsowxtwOYD6AkgKkissEY8xiAVBGZnftYL2PMzwCyAdwrIvud6lM0ysoC3nlHFzSvl38G\nI1EMufBC4JxzdB5e7dq6+Dnn3xEREREFxrEADwBEZC6Aufnue9jrZwFwd+4X+fD118DOnUBiots9\nIXKWMTpit2CBLotQvjxwySVu94qIiIgourhdZIWKkJQE1KmjI3hEsS4+HtizB5g2DejShQWFiIiI\niALFAC+CZWQAc+YAo0YBpUu73Rsi51kpmYcPc/4dERERUTAY4EWwd98FsrOB0aPd7glReDRsCDRt\nqj9z/h0RERFR4BjgRaicHGDKFF0bzDrhJSoO+vbVtOS4OLd7QkRERBR9GOBFqKVLdT0wFleh4uaZ\nZ4C1a3XxcyIiIiIKjKNVNCl4SUlAtWrANde43ROi8CpXTr+IiIiIKHAcwYtA+/cDn30GDB/OE10i\nIiIiIvIfA7wI9MEHwMmTTM8kIiIiIqLAMMCLMCKantmpE9Cmjdu9ISIiIiKiaMIAL8J89x2wfj1H\n74iIiIiIKHAM8CJMUhJw1lnA0KFu94SIiIiIiKINA7wI8vffwPTpwJAhQKVKbveGiIiIiIiiDQO8\nCDJzJnD0KNMziYiIiIgoOAzwIkhSEtCyJdC5s9s9ISIiIiKiaMQAL0L89BOwerWO3hnjdm+IiIiI\niCga+RXgGWPGGWMqGzXFGJNmjOnldOeKkylTgDJldHFzIiIiIiKiYPg7gjdaRP4C0AtANQAjADzj\nWK+KmRMngPffBwYNAmrWdLs3REREREQUrfwN8KykwasBvC8iG7zuoxDNmgUcOMDiKkREREREFBp/\nA7wfjDELoAHefGNMJQA5znWreElKAho3Bnr2dLsnREREREQUzUr5ud3NANoB2Coix4wxNQCMcq5b\nxceWLcDixcATTwAlWPKGiIiIiIhC4G9IMRDAFhE5lHs7G0ATZ7pUvEydqoHdyJFu94SIiIiIiKKd\nvwHeIyJy2LqRG+g94kyXio+sLOCdd4Crrwbq1XO7N0REREREFO38DfB8bedveicV4OuvgZ07WVyF\niIiIiIjs4W+Al2qMedEYc17u14sAfnCyY8XB228DderoCB4REREREVGo/A3wxgI4CWAmgBkATgD4\nP6c6VRykpwNz5gCjRgGlS7vdGyIiIiIiigV+pVmKyFEADzjcl2LlvfeAnBxg9Gi3e0JERERERLHC\nrxE8Y8xCY0xVr9vVjDHznetWbMvJAaZMAXr0AJo2dbs3REREREQUK/xN0azptUQCROQggLOd6VLs\n++UXYOtWYPhwt3tCRERERESxxN8AL8cY09C6YYxpBECc6FBx8Oef+v2CC9ztBxERERERxRZ/lzqY\nAGCFMWYZAAOgK4AxjvUqxmVk6HeufUdERERERHbyt8jKPGNMR2hQ9yMAD4DjTnYslqWn6/dzznG3\nH0REREREFFv8CvCMMYkAxgGoD2ANgM4AUgD0dK5rsSs9HahZEyhb1u2eEBERERFRLPF3Dt44ABcB\n+ENEegBoD+BQ4U+hgqSnMz2TiIiIiIjs52+Ad0JETgCAMaasiGwEwBIhQcrIYIBHRERERET287fI\nyo7cdfA8ABYaYw4C+MO5bsW29HQgLs7tXhARERERUazxt8jKoNwfHzXGLAFQBcA8x3oVw06dAvbs\n4QgeERERERHZz98RvP8SkWVOdKS42LULEGGAR0RERERE9vN3Dh7ZxFoigQEeERERERHZjQFemFkB\nXt267vaDiIiIiIhiDwO8MMvI0O8cwSMiIiIiIrsxwAuz9HSgdGld6JyIiIiIiMhODPDCLD1d0zON\ncbsnREREREQUaxwN8IwxfYwxvxpjNhtjHihku8HGGDHGdHSyP5EgPZ3pmURERERE5AzHAjxjTEkA\nrwO4CkALAMOMMS18bFcJwDgAq53qSyTJyGCAR0REREREznByBK8TgM0islVETgKYAWCgj+0eB/As\ngBMO9iViWCmaREREREREdnMywKsH4E+v2zty7/svY0wcgAYiMqewhowxY4wxqcaY1L1799rf0zD5\n6y/gyBGO4BERERERkTNcK7JijCkB4EUA9xS1rYhMFpGOItKxVq1aznfOIVwigYiIiIiInORkgJcO\noIHX7fq591kqAWgFYKkxZhuAzgBmx3KhFWuRcwZ4RERERETkBCcDvO8BNDPGNDbGlAEwFMBs60ER\nOSwiNUWkkYg0ArAKwAARSXWwT66yAjzOwSMiIiIiIic4FuCJSBaA2wHMB/ALgI9FZIMx5jFjzACn\n9hvJOIJHREREREROKuVk4yIyF8DcfPc9XMC23Z3sSyTIyACqVgUqVHC7J0REREREFItcK7JSHHGJ\nBCIiIiIichIDvDBKT2d6JhEREREROYcBXhhlZDDAIyIiIiIi5zDAC5PsbGDnTqZoEhERERGRcxjg\nhcmePRrkcQSPiIiIiIicwgAvTDIy9DsDPCIiIiIicgoDvDDhGnhEREREROQ0BnhhYgV4nINHRERE\nREROYYAXJunpQMmSQO3abveEiIiIiIhiFQO8MMnIAOrU0SCPiIiIiIjICQzwwiQ9nemZRERERETk\nLAZ4YZKezgIrRERERETkLAZ4YZKRwQCPiIiIiIicxQAvDI4fBw4eZIBHRERERETOYoAXBlwigYiI\niIiIwoEBXhhwkXMiIiIiIgoHBnhhkJGh3xngERERERGRkxjghQFTNImIiIiIKBwY4IVBejpw1llA\n5cpu94SIiIiIiGIZA7wwsJZIMMbtnhARERERUSxjgBcG6elMzyQiIiIiIucxwAuD9HQWWCEiIiIi\nIucxwHOYSF6KJhERERERkZMY4Dls/37g5EkGeERERERE5DwGeA7jEglERERERBQuDPAcZgV4HMEj\nIiIiIiKnMcBzWEaGfmeAR0RERERETmOA5zBrBK9OHXf7QUREREREsY8BnsPS04GzzwbKlHG7J0RE\nREREFOsY4DmMSyQQEREREVG4MMBzWHo6K2gSEREREVF4MMBzWHo6R/CIiIiIiCg8GOA5KDMT2LuX\nAR4REREREYUHAzwH7dql3xngERERERFRODDAc5C1RALn4BERERERUTgwwHOQFeBxBI+IiIiIiMKB\nAZ6DMjL0OwM8IiIiIiIKBwZ4DkpPB8qWBapXd7snRERERERUHDDAc5C1Bp4xbveEiIiIiIiKAwZ4\nDuIaeEREREREFE4M8ByUkcEAj4iIiIiIwocBnkNE8lI0iYiIiIiIwsHRAM8Y08cY86sxZrMx5gEf\nj99tjPnZGLPOGJNsjDnXyf6E0+HDwLFjHMEjIiIiIqLwcSzAM8aUBPA6gKsAtAAwzBjTIt9mPwLo\nKCJtAHwKYJJT/Qk3LpFARERERETh5uQIXicAm0Vkq4icBDADwEDvDURkiYgcy725CkB9B/sTVtYi\n50zRJCIiIiKicHEywKsH4E+v2zty7yvIzQC+9vWAMWaMMSbVGJO6d+9eG7voHCvA4wgeERERERGF\nS0QUWTHGDAfQEcBzvh4Xkcki0lFEOtaqVSu8nQuSlaLJETwiIiIiIgqXUg62nQ6ggdft+rn3ncYY\ncwWACQAuF5FMB/sTVunpQLVqQPnybveEiIiIiIiKCydH8L4H0MwY09gYUwbAUACzvTcwxrQH8BaA\nASKyx8G+hB0XOSciIiIionBzLMATkSwAtwOYD+AXAB+LyAZjzGPGmAG5mz0HoCKAT4wxa4wxswto\nLuowwCMiIiIionBzMkUTIjIXwNx89z3s9fMVTu7fTRkZQJs2bveCiIiIiIiKk4goshJrsrKAXbtY\nYIWIiIiIiMKLAZ4Ddu8GcnKYoklEREREROHFAM8B1hIJDPCIiIiIiCicGOA5wFrknCmaREREREQU\nTgzwHGAFeBzBIyIiIiKicGKA54D0dKBkSeDss93uCRERERERFScM8ByQkfH/7Z17lCdVde8/exhA\nR2CAUQcUYRRExCgTXkMiLAgoorkLIYGoiQosiclFRcxNBK/EiZgYMDcqWRETgiI+QR4KMbwiIMbE\nYQaG4S2CPIQelAFGFBSFYd8/zuk1Nb+u6u5zuqp+p7u/n7VqdfWpvX977zr12/U7Vad2wbbbwhzt\nXSGEEEIIIUSPaAjSAXrJuRBCCCGEEGIYaIDXARrgCSGEEEIIIYaBBngdsHq1BnhCCCGEEEKI/tEA\nr2WefBIef1yvSBBCCCGEEEL0jwZ4LaNXJAghhBBCCCGGhQZ4LbN6dfirAZ4QQgghhBCibzTAa5nR\nO3iaoimEEEIIIYToGw3wWkZTNIUQQgghhBDDQgO8lhkZgc03D4sQQgghhBBC9IkGeC2jVyQIIYQQ\nQgghhoUGeC0zMqLn74QQQgghhBDDQQO8lhkZ0R08IYQQQgghxHDQAK9Fnn0WHnpIAzwhhBBCCCHE\ncNAAr0UeeQSeflpTNIUQQgghhBDDQQO8FtErEoQQQgghhBDDRAO8FtEATwghhBBCCDFMNMBrkdWr\nw19N0RRCCCGEEEIMAw3wWmRkBMxgm22G7YkQQgghhBBiNqIBXouMjMDChbDxxsP2RAghhBBCCDEb\n0QCvRVav1vN3QgghhBBCiOGhAV6LjIzo+TshhBBCCCHE8NAAr0VGRnQHTwghhBBCCDE8NMBriaee\ngkcf1QBPCCGEEEIIMTw0wGuJhx4KfzVFUwghhBBCCDEsNMBrCb3kXAghhBBCCDFsNMBrCQ3whBBC\nCCGEEMNGA7yWWL06/NUATwghhBBCCDEsNMBriZEReM5zYMsth+2JEEIIIYQQYraiAV5LjL4iwWzY\nngghhBBCCCFmKxrgtcTq1ZqeKYQQQgghhBguGuC1xMiIXpEghBBCCCGEGC4a4LWA+/opmkIIIYQQ\nQggxLDTAa4G1a+GppzTAE0IIIYQQQgwXDfBaYPQVCZqiKYQQQgghhBgmGuC1gF5yLoQQQgghhCiB\nTgd4ZnaImd1pZneb2Uk12zc1s/Pi9uvMbFGX/nSFBnhCCCGEEEKIEuhsgGdmGwGfAd4I7Aq8zcx2\nHRB7F7DW3XcCPgWc1pU/XaIpmkIIIYQQQogS6PIO3t7A3e5+j7v/BjgXePOAzJuBc+L6BcBBZtPv\nVeEjI7BgAWy66bA9EUIIIYQQQsxmuhzgvRh4oPL/g7GtVsbdnwEeBxYMfpCZvdvMrjez69esWdOR\nu/m84hVw+OHD9kIIIYQQQggx25k7bAcmg7ufCZwJsOeee/qQ3RnDCScM2wMhhBBCCCGE6PYO3gjw\nksr/28W2WhkzmwvMBx7t0CchhBBCCCGEmLF0OcBbAbzczF5qZpsAbwUuGZC5BDgqrh8BXO3uxd2h\nE0IIIYQQQojpQGdTNN39GTN7L3AFsBHweXe/zcxOAa5390uAzwFfMrO7gccIg0AhhBBCCCGEEBl0\n+gyeu18KXDrQ9pHK+lPAkV36IIQQQgghhBCzhU5fdC6EEEIIIYQQoj80wBNCCCGEEEKIGYIGeEII\nIYQQQggxQ9AATwghhBBCCCFmCBrgCSGEEEIIIcQMQQM8IYQQQgghhJgh2HR7r7iZrQHuH7YfNTwf\neKRjnRJtlOiTbMiGbLQnLxuyIRvDtVGiT7IhG7IxfHZw9xfUbnF3LS0shJe3d6pToo0SfZIN2ZCN\n6eWTbMiGbEwvn2RDNmSj7EVTNIUQQgghhBBihqABnhBCCCGEEELMEDTAa48ze9Ap0UaJPsmGbMhG\ne/KyIRuyMVwbJfokG7IhGwUz7YqsCCGEEEIIIYSoR3fwhBBCCCGEEGKGoAGeEEIIIYQQQswQNMAT\nQgghhBBCiBmCBnhCCCGEEEIIMUOYO2wHZgtmNh84BHhxbBoBrnD3n42jY8DeAzrLvaEyTqp8jl+Z\ncaTa6DwOMfswszcAh7HhMXKxu19eIzsXeBdwOPCiqjzwOXd/uiWdSftUahw5NvqII+rtArx5wMYl\n7n7HVH3K1cnwKUk+06fi4i7YRh8+lXjc5tgoMY7i8luJcRSe14s6B5aKqmhmkjKgMLN3AkuBK6Mc\nwHbA64GPuvsXa3QOBs4A7hrQ2Qk4zt2vnIp8jl+ZcaTa6DyOil5nSWK2nhSmoNN1HJ8Gdga+CDwY\nm7cD3gnc5e7vH5D/GvAz4JwB+aOArd39LTU+Jemk+lRwHDk2+ojjROBtwLkDOm8FznX3U6fiU2Yc\nqT4lyWf6VFzcBdvow6cSj9scG8XFEXVKzG/FxVFwXi/uHFgs7q4lcSEcSD8CPgucHJd/iW3vrJG/\nE9iypn0r4IcNNu4AFtW0vxS4Y6ryOX5lxpFqo/M44rZPA5cSTjb7xuWtse30Gvmvxf7eh/BF3y6u\nfxY4b6rymT4lyfcYR6qNPuJoOg6McFKYlPwEn5Wkk+rTdIsjx0bbcQAb17RvkmKj7f5I9SlFvs19\nO8y4S7bRh08lHrc5NkqLYzydpm25uaeP/dtlHMOMu1QbE20rbdEUzTw+DOzhA3frzGwr4DrClYUN\nNgFe8znPxm11zGX9lYMqI8DGLcjn+JUTR6pOH3EAvMnddx7zQWbnEU5Mg1fM9qiRfxBYZmY/rPn8\nVPkcn1Ll+4ojVaePOJ4ys73cfcVA+17AUzXyj5nZkcCF7v5s9GcOcCSwtkY+RyfVp1LjyLHRRxzP\nEu7u3j/Qvm3cNlWfcnRSfUqVz/GpxLhLtdGHTyUetzk2SowDysxvJcZRal4v8RxYJBrg5ZE6oPg7\nYKWZXQk8ENu2J0wh/FiDjc8DK8zs3IrOSwh3Nj7XgnyOXzlxpOr0EQd0nyRm60khR6ePOI4GPmtm\nm7P+AsJLgMfjtkHeCpwGnGFmawnf6y2Bq+O2OlJ1Un0qNY4cG33EcQJwlZndxYZ5YSfgvS34lKOT\n6lOqfI5PqfI5On3EUeK+yvGpxOM2x0aJcUCZ+a3EOErN633YyNEpDj2Dl4GZHQV8hPDM15gBhbt/\noUZnK+ANjH1mr/FqgJntChzK2AeUb29DPsevzDhSbfQRx+6E6Xx1SeI97n7DgPwiwhf+QMIAovqF\nP8nd752KfKZPSfI9xpFqo/M4KnrbUDlG3P0ndXIDOgsA3P3RiWRzdDJ9Ki6OTPlO44iD/sGCTSvc\nfV3LPk1aJ9WnnBhy4igt7lJt9OFTicdtpnyRcVT0ispvBcdRVF7vy0auTilogJdJ5kBnIRsekD+d\npK2tAdz9sY7kk/zKiSNTp9M4ok4fiWhWnhRSdbqOw9KrudZVgLvY3X8wjo0knVSfCo4jx0YfcaRW\nIi6uSnCqfKZPxcVdsI0+fCrxuO2jEnjncUSdEvNbcXEUnNeLOweWiN6Dl0kcyF1TXca5W7TYzJYB\n3yHcdfgEcK2ZLYt3L+p0tjezc83sYcJzfcvN7OHYtmiq8jl+ZcaRaqPzOCp684H9q4uZbTmO/C4W\nKoMtBZaa2YkxCbQin+lTknyPcaTa6DQOC5VWVwIHAPPi8nvADXHboPyJhOpvBiyPiwHnmtlJDTaS\ndFJ9KjiOHBt9xHEwoRrv3wBvistHgbvitin5lBlHqk9J8pk+FRd3wTb68KnE4zbHRnFxRJ0S81tx\ncRSc14s7BxaLF1DpZbotwGJgGaHi438C3wZ+ENt2r5FfBSypad8HuKnBxveBtwAbVdo2Isz/XTZV\n+Ry/MuNItdF5HHFbaiXUE6Odk4C3x+Wk0bapymf6lCTfYxypNvqII7Waax/V7/qoSttLFb8MG33E\nkVqJuLgqwanymT4VF3fBNvrwqcTjto9K4J3HEbeVmN+Ki6OnuEu1kaxT4qIiK3l8Afgzd7+u2mhm\n+wBnA7sNyD9vUBbA3ZeZ2fMabDzf3c8bkF9HuIJQVzgkVT7Hr5w4UnX6iAPSK6G+C3iVj32/2ieB\n24DB9xmlyuf4lCrfVxypOn3EkVoYqY/qd31Upe0jjhwbfcSRWpG3j/5QdeQNaTOOEvdVjk8lHrc5\nNkqMY3RbafmtxDhKzeslngOLRAO8PFIHFJeZ2X8QfqhWK0O+E7i8wcYNZnYG4UWLVZ2jgBtbkM/x\nKyeOVJ0+4oDuk8RsPSnk6PQRR2ql1T6q3/VRlbaPOHJs9BHH50mryFtileBU+RyfSoy7VBt9+FTi\ncdtHJfA+4oAy81uJcZSa10s8BxaJiqxkYGb/BOxI/YDiXncfcwCY2RsZ+8DmJe5+aYONTQh3Kcbo\nAJ9z919PRX4KfiXJp+r0GMdRJFRCNbNDgH8mPFMw5gvv7pdPRT7TpyT5HuNItdF5HFEntdJq59Xv\nUn0qOI4cG33EkVqJuLgqwanymT4VF3fBNvrwqcTjto9K4J3HEXVKzG/FxVFwXi/uHFgiGuBlkjPQ\nEWXRdZKYrSeFTBudxxF1Jl1p1az76nepPpUaR46NPuKo6E66Im/X/ZHjU6b8bK6OXOK+SvIpVaeP\n/suxEfVKi6O4/FZiHCXn9dLOgSWiKZqZuPtlwGWTkbVQIfBDhAHhQsJ0tIeBi4FTvaa0q5nNJdzJ\nOoyBMq2EO1mDzx4lyef4lRlHqo3O4xjF3dea2TVsmCQaBxTxc0eX0f/Hm4+dKp/sU0YMOX4lx5Gq\n03UcZraYULhlPuG5EAO2M7OfAce5+8oB+YOBMwh3CEdi83bATmZ2nLtfWWMjSSfVp4LjyLHRRxzb\nEyrqHkh4p6KZ2Rasf1fifVPxKTOOVJ+S5DN9Ki7ugm304VOJx22OjeLiiDol5rfi4ig4rxd3DiwW\nL6DSy3RbCAfWqYQqUY8Bj8b1U6mv7nMFoerfNpW2bQhV/65ssPE1QlXBfQgH1nZx/bPAeVOVz/Er\nM45UG53HEbenVkI9GLibMKg/Ky6Xx7aDpyqf6VOSfI9xpNroI47Uaq59VL/royptH3Hk2OgjjtRK\nxMVVCU6Vz/SpuLgLttGHTyUet31UAu88jritxPxWXBw9xV2qjWSdEpehOzAdF9IHLXeO81m122go\njdu0LVU+x6/MOFJtdB5HbO80SczWk0KmjT7iaCxtDNxdJw/MrWnfpE4+RyfVp5LjyLHRRxzj2Kgr\nC95Lf7ToU1OJ7zZ9Gkrc09RGHz6VeNxOm+/fqE6J+a20OPqKu1QbqTolLpqimccidz+t2uDuPwFO\nNbNjauTvN7MPAud4nCcc5w8fzfoCEYM8ZmZHAhe6+7NRZw5wJFA3dS1VPsevnDhSdfqIA9IrofZR\n3ryP11b0EUeqTh9xpFZa7aP6XR9VaduKY3vC1fi2Kj32EUdqRd4SqwSrOnJZNvrwqcTjto9K4H3E\nAf1Usu1j/7YRx3TM6yWey4tERVYysFCe9dvUDyhe7+6vG5DfinB3r/qM2E8JlSFP85oHj81sEXAa\n8HvA6DNkWwLXEOav39sgfyBhIGSEqaS18jl+ZcaRaiMp7gEbh0YbTMKvpEqoZvYh4I+Aui/81939\n76cin+lTTjXXNuIYPSk0xZFqo/M4ok5qpdVXNsi3Wf3uTQ3yrVSlnUIcSTqZNpJiz9i3yRV5U/dt\nqk6qTzkx5MRRWtyl2ujDpxKP20z5IuOIOqn5LacSamp+6yOOaZ/Xo05x5/IS0QAvg4FBywtj8+iA\n4lSvKQ5hZrsQnidb5u5PVNoP8ZqS7nHbEsKA6EfALsDvALeP94WPegvi6unu/vaEuPYjVA26xesf\nPF0C/MDdHzezeYR9sDvhxdIfd/fHa3SOB77h7k130gblNwHeBqwGVgKHAK+NNs70miIrUW9H4A8I\nP/LXAXcCX3X3n49jq9MkMVtPCpk2cgY60z4Bt4GZvdDdH+7YxgJ3f7RLG0IIIQLK62LKTHWOp5Yx\nc3SPqWk7njDg+CZwH/DmyraVDZ+zlFBk4nrg74GrgL8Gvgt8uEb+kprlidH1BhvLK+vHEqZNLAX+\nm3C3bFD+NuK8ZOBM4FPAvlHnogYbjxMGa/8F/G/g+RPsv68A50W/vwRcBLwD+ALhjmmdzvGEd6id\nDPwP8BnCyzBvBw4Y9jHR8/H3wh5sLBh2nBk+JxVGmuCzLmto3yJ+V78EvG1g2xk18tsQigd9BlgA\n/A1wM/B1YNsGG1vXLPcBWwFb18gfMrAPzoo2vgosbLBx6uj3FNgDuIfwTML9wP418ivjd+9lCftw\nL8Jd+S8TLsr8J+GO/Qrgt2vkNwNOiTnocWANIT8ePY6NucCfEQrx3ByXy4A/BzZO7PMzG9o3ijY+\nBvzuwLaTa+TnAR8E/gp4DmG62iWEaoObTdKXxueU4/bXVNY3jn1zCfBxYF6N/Hsr/b0j4RyzFrgO\neHWDjYuAP0nw+WWEaU8fi335b8CtwPnUPEsbdeYAxwDfAm6Kx9m5NOT0Nvu7qc+H0d8T9Xlqf+f0\neWp/5/R5an8ONzF0AAAM5klEQVRHndbyevy8MbmdxLwe25NyO4l5Peok5XZmTl4v7lxe6jJ0B2ba\nAvy4pu2W0cQILCIM2t4f/7+x4XNuIZxM5gE/B7aI7c8Fbq6RXxm/VAcA+8e/D8X1/Rts3FhZXwG8\nIK4/j3AXb1D+jqq9gW2rmmwQEvfBhLnLawjzpI8CNq+Rvzn+nUu4K7pR/N/q4q7uq7g+D/hOXN9+\nnP3baZLISRDMgJNC5Vic9ImBxJNC1Ek6MZBeGGn3hmUP4KEGGxfG/XUY4QfWhcCmdd+X2HY58L7o\nw83Rv5fEtosbbDwL3DuwPB3/3lPXF5X1s4C/BXYAPgB8s+n7VFm/Btgrru8MXF8jfy/w/4AfA8vj\nZ79ogj5fDryRcLf+AeCI2H4Q8P0a+YsJU+C3A/6CcLHr5YTnez7eYCO1EnHd92lrwnfxwQYbZxG+\nOycANwCfrNv3lbavA/9IKMF9FfDPwH7APwBfqpH/BSH//6KyrBttb/r+Vdb/kXBxbH/CBbkv1sjf\nVln/D+DwuH4A8N8NNkaACwi58+vA4cAm4/T3dwkX+E4i/Mj/S8Kx/i7g6gadswk5cF/g04Tv++sJ\nj0e8b6r9ndPnXfd3Tp+n9ndOn6f2d06fp/Z31MmpoJ2U20nM67E9KbeTmNdr+n3C3M7MyevFnctL\nXYbuwHRcWH91cHC5Bfh1jfxtA/9vFhPAJxlnYFS3Hv8fo0MYRH2A8ON4cWyrTQwVnZsIg4EFg1/w\nQZux7XziHUpCMt4zru9MeMF0nY3BgeDGhGl1XwPW1MjfSqhUtBXhhLZ1bH8OzVUbb6l8+baqxgLc\n2qDTaZLISRDMgJNC3JZ0YiDxpBC3JZ0YSK/muo7wvqZrapZfNXzOqoH/P0y4G76grs/Z8Dv+4/E+\nq9L+f+Jx8upK273jxLZyHP+abNzB+jv1ywa21V34qdrYj/Bj9idxX727wcZ4sdflnpsG/l8R/84h\nTBuvs5FaiXgd4QJG9fs0+v9vGj7n5sr6XMLMhouATRviWBX/WtxHVvm/7sLdPxGeTV1YaWvs75p9\nu4p492ocG3dW1lcMbGu6qHZj/LsFYYbFpYSLLGdT/5qSpP6usz16LMZ9W1cpN6cCc1Kfd93fOX2e\n2t85fZ7a3zl9ntrfg3FMdhuJuZ3EvD6J2Ot+vyXl9bg9Kbczc/J6cefyUpehOzAdF8KdpcWEH8bV\nZRGwukb+auKgq9I2l5DE1zXYuI44vQKYU2mfP94BRvjBez7hSuGYu4kDsvex/mR2D/EuEWEAWpcg\n5hOuDv4o+vd01LsW2K3BRu3JO26rmy70gfiZ9xOmXl5FmNpxC7C04XPeTxgQ/Rvh/Wmjg9AXAN9t\n0Ok0SeQkiAmS47Q4KdTYmPDEMEHcTT/+kk4MhCm8H2TDH00LCYPob9fI3wq8vMH2Aw3td1D5rsa2\nowl3Ge8fLwbgbyezb+O20e/4J4HNGedCDqHS6F/EY+Ue4g/MuK3px9/74v46kHBF/XTCHYGPUn+X\nqW7wuhHh+dmzG2x8n3BX/0jCd/2w2L4/9VeT/wfYN64fClxR2db0Q25Z/Pxq/pxDKBB0XY38XcD2\niX1ed6wtJXzX60rBr6qsf368Y7rSvgch9xwf/Z/owt09hOeR/5CBH8Z1NgjT2b9AmFL3fwl3p3Yg\nTpdrsFHX5wsI0yHr7s7cQLgotDfwCOsvDu40znF4A7BjXN+dSi4nPIs+pf7O6fM++ju1z2N/Hz7Z\n/s7p89T+HujzvSbT56n9HduT8nrcnpTbSczrg/udsbm96XifdF6P8km5nZmT14s7l5e6DN2B6bgQ\nphru27DtqzVt21G5UzSw7bUN7Zs2tD+fhuciBuR+n4Zb3JPQnQe8dJztWwC7EU5Ctc/xVGR3zrD/\nIuIdH0IFzSOAvSfQeVWU22WSNjpNEjkJgowf/BR2Uog6SScGEk8KcVvSiYFwZ/c0wgWAtYSpRnfE\ntrpn144AXtFg+7CG9k8Ar6tpP4T6H3+nUPNMC+EH0AWTOIYPJfyo/ck4MksHltFp2NvQMH0rbj+A\n8CzsjYSLK5cC76bmWSbg3Il8rdHZjXAX/TJCAanTCdNyb2Pg2aaK/PLYd98b7RvCRZzjG2wsijE8\nDPwwLg/HtjH5DXgPzReqmqaIfZnKtOdK+7HA0zXtZzX0+Y7A98bZX3MIP/b/i5qLiAOyZw8sCyt9\nflWDztGEi3aPEGZO3E54hmt+g3zthbNxfDqI8Bz6HYQpeBcSBlcPU3kmfUDnQMIsgLsIFyGXVPr8\nE+P095rY16OfX9vfOX3eV3+n9DlhoJbU33H7MZPt89T+nkSfj8mhlf6+O/b3PuP1d9yWlNejTlJu\nJzGvx23ZuZ1J5PUol5zb6T6vL2ZsXl9LyOtjfusyNq/vXOnzprxe3Lm81GXoDmjRMoxlIEk8NpAk\ntqqR10lh7ElhzItAo3zSiYHEH/tR5zUZJ4ZdgNcN7mNqfrBV5A+arPwEOm/swgbhmdzf6jGONm28\nMtHGK1P6L25bQrhrtIBQjfcvgTeNI78366ch70q4GNIon6PTIP/7VC62jCO/H/CRSfi0ZAo+vYpw\nAajtuJcM2Bi3L6Lc76T2R5RdEJcvTyRbo9t44aNN+ab+rpHfFni0S5+iTu0Fu5ZtfIuBC58D241K\nIbaMfbtfPHZrp4026Owbj6tJ6aTKZ9rYj/Ace9c2Jr2vMuNu3UbMI/Pj+jzC76ZvEX671V2cWMKG\nNSxOAf69Sb7GxqR0Slz0mgQhBjCzY9z97FLkJ6tjZs8lTHG5tSsbU5Efpo34uo73EAbxiwlFji6O\n21a6++5TkY/t7yNUp5usjST5zDhKtnEc4QLLZPtj0vKxfSnh2c65hGeT9wa+QyjccIW7/90E8ksI\n04pr5XN0WpAfN4aW4s6xUUIclwx+BuGu0NUA7n5ojY1BHSO8g7VWp2v5nDhaijvVRilxLHf3veP6\nsYS89U3CjJB/d/dTJ9D506jzjSadVPmWbByXGMexhBw8WRsT7quW4h43jtQYotxthLvuz5jZmcCT\nhLvDB8X2P5hA/peEgkG18rk6RTLsEaYWLaUtTPDsYt/ysjF1GyRWsk2Vl41ibaRUIk6S78NGiT4V\nbCOrknSKTtfyOXEUbKOPfZVUCTxHZ7baKNGnuC2pmnuqfK5OictchJiFmNnNTZsIz+L1Ki8b3dog\nTAt6AsDd7zOzA4ALzGyHqDNVedkoz8Yz7r4O+KWZ/cjdfx71f2Vmz7Yg34eNEn0q1caehIJbHwb+\nyt1Xmdmv3P3ahs+H8Bx5ik7X8jlxlGqjj301x8y2IjyvaO6+BsDdnzSzZ1rSma02SvQJoDpD6SYz\n29PdrzeznQmF/6Yqn6tTHBrgidnKQuANhGe4qhihgEff8rLRrY2fmtlid18F4O5PmNn/IryI99Ut\nyMtGeTZ+Y2bz3P2XhB+PAJjZfMIrRqYq34eNEn0q0oa7Pwt8yszOj39/ygS/cVJ1upaXjTQbhMre\nNxDyvpvZtu7+kJltRvOFn1Sd2WqjRJ8gFDQ63cxOJhQI+r6ZPUB4xdKxLcjn6pSHF3AbUYuWvhfS\nK6F2Ki8bndtIqmSbKi8bRdpIqkScKt+HjRJ9KtVGjVxyJelUna7lZaObSuBt6MxWG6X4REI19xz5\nXJ2SFhVZEUIIIYQQQogZwpxhOyCEEEIIIYQQoh00wBNCCCGEEEKIGYIGeEIIIUTLmNkBZvatYfsh\nhBBi9qEBnhBCCCGEEELMEDTAE0IIMWsxs7eb2XIzW2Vm/2pmG5nZE2b2KTO7zcyuMrMXRNnFZrbM\nzG42s2/EdzhhZjuZ2bfN7CYzW2lmO8aP38zMLjCzH5jZV8ysqfS3EEII0Roa4AkhhJiVmNkrgbcQ\nXrWwGFgH/AnwPOB6d38VcC2wNKp8ETjR3V8D3FJp/wrwGXffDfhd4KHY/tvACcCuwMuA13YelBBC\niFmPXnQuhBBitnIQ4R1HK+LNtecCDxNepH1elPkycFF8wfaW7n5tbD8HON/MNgde7O7fAHD3pwDi\n5y139wfj/6uARcD3ug9LCCHEbEYDPCGEELMVA85x9w9t0Gj21wNyuS+M/XVlfR065wohhOgBTdEU\nQggxW7kKOMLMXghgZlub2Q6Ec+MRUeaPge+5++PAWjPbL7a/A7jW3X8BPGhmh8XP2NTM5vUahRBC\nCFFBVxOFEELMStz9djM7GbjSzOYATwPvAZ4E9o7bHiY8pwdwFPAvcQB3D3BMbH8H8K9mdkr8jCN7\nDEMIIYTYAHPPnXkihBBCzDzM7Al332zYfgghhBA5aIqmEEIIIYQQQswQdAdPCCGEEEIIIWYIuoMn\nhBBCCCGEEDMEDfCEEEIIIYQQYoagAZ4QQgghhBBCzBA0wBNCCCGEEEKIGYIGeEIIIYQQQggxQ9AA\nTwghhBBCCCFmCP8f1huuQNEQc/sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOHm2K6nn-Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accs = []\n",
        "# tx = [x for x in range(100,2100,100)]\n",
        "# acc_max = [0,0]\n",
        "\n",
        "# x, y = dataset.test_set()\n",
        "\n",
        "# tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "# tmodel.compile(loss='categorical_crossentropy',\n",
        "#                          metrics=['accuracy'],\n",
        "#                          optimizer=Adam())\n",
        "\n",
        "# for e in tx:\n",
        "#   tmodel.load_weights(\"./models/discriminator_supervised-\"+ str(e) +\".h5\", by_name=False)\n",
        "#   _, acc = tmodel.evaluate(x, y)\n",
        "#   accs.append(acc)\n",
        "# print(max(accs))\n",
        "\n",
        "# plt.figure(figsize=(15, 5))\n",
        "# plt.plot(tx, accs, label=\"accs\", color='blue')\n",
        "# plt.xticks(tx, rotation=90)\n",
        "# plt.title(\"accs with epoch\")\n",
        "# plt.xlabel(\"epoch\")\n",
        "# plt.ylabel(\"accs\")\n",
        "# plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSbSVx1khsOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(iterations, batch_size, save_interval, iter_epochs, k):\n",
        "\n",
        "    x_test, y_test = dataset.test_set()\n",
        "\n",
        "    # Labels for real images: all ones\n",
        "    real = np.ones((batch_size, 1))\n",
        "\n",
        "    # Labels for fake images: all zeros\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        for _ in range(k):\n",
        "\n",
        "            # -------------------------\n",
        "            #  Train the Discriminator\n",
        "            # -------------------------\n",
        "\n",
        "            # Get labeled and unlabeled examples\n",
        "            imgs, labels = dataset.batch_labeled(batch_size)\n",
        "            imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
        "\n",
        "            # Generate a batch of fake images\n",
        "            z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "            fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "            fake_labels = to_categorical(fake_labels, num_classes=num_classes)\n",
        "            gen_imgs = generator.predict([z, fake_labels])\n",
        "\n",
        "            discriminator_supervised.trainable = True\n",
        "            discriminator_unsupervised.trainable = True\n",
        "\n",
        "            # Train on real labeled examples\n",
        "            datagen.fit(imgs)\n",
        "            discriminator_supervised.fit_generator(datagen.flow(imgs, labels, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=iter_epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)\n",
        "            loss_d_supervised, acc_d_supervised = history.losses[-1], history.accs[-1]\n",
        "\n",
        "            # Train on real unlabeled examples\n",
        "            # Error\n",
        "            # datagen.fit(imgs_unlabeled)\n",
        "            # discriminator_unsupervised.fit_generator(datagen.flow(imgs_unlabeled, real, batch_size=batch_size),\n",
        "            #             validation_data=(x_test, np.ones((len(x_test), 1))),\n",
        "            #             epochs=iter_epochs, verbose=1, workers=4,\n",
        "            #             callbacks=callbacks)\n",
        "            # loss_d_unsupervised_real, acc_d_unsupervised_real = history.losses[-1], history.accs[-1]\n",
        "            loss_d_unsupervised_real, acc_d_unsupervised_real = discriminator_unsupervised.train_on_batch(imgs_unlabeled, real)\n",
        "\n",
        "            # Train on fake examples\n",
        "            loss_d_unsupervised_fake, acc_d_unsupervised_fake = discriminator_unsupervised.train_on_batch(gen_imgs, fake)\n",
        "\n",
        "            # Calculate loss and acc\n",
        "            loss_d_unsupervised = 0.5 * np.add(loss_d_unsupervised_real, loss_d_unsupervised_fake)\n",
        "            loss_d = np.add(loss_d_supervised, loss_d_unsupervised)\n",
        "            acc_d_unsupervised = 0.5 * np.add(acc_d_unsupervised_real, acc_d_unsupervised_fake)\n",
        "            acc_d = np.add(acc_d_supervised, acc_d_unsupervised)\n",
        "        \n",
        "        # ---------------------\n",
        "        #  Train the Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Generate a batch of fake images\n",
        "        z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "        fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "        fake_labels = to_categorical(fake_labels, num_classes=num_classes)\n",
        "        gen_imgs = generator.predict([z, fake_labels])\n",
        "\n",
        "        discriminator_supervised.trainable = False\n",
        "        discriminator_unsupervised.trainable = False\n",
        "\n",
        "        # Train Generator\n",
        "        loss_g_unsupervised, acc_g_unsupervised = gan.train_on_batch([z,labels], real)\n",
        "\n",
        "        # Calculate loss and acc\n",
        "        loss_g = loss_g_unsupervised\n",
        "        acc_g = acc_g_unsupervised\n",
        "\n",
        "        if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "            # Save losses to be plotted after training\n",
        "            losses_d_supervised.append(loss_d_supervised)\n",
        "            losses_d_unsupervised.append(loss_d_unsupervised)\n",
        "            losses_d_unsupervised_real.append(loss_d_unsupervised_real)\n",
        "            losses_d_unsupervised_fake.append(loss_d_unsupervised_fake)\n",
        "            losses_d.append(loss_d)\n",
        "            losses_g.append(loss_g)\n",
        "            \n",
        "            iteration_checkpoints.append(iteration + 1)\n",
        "\n",
        "            # Output training progress\n",
        "            print(\n",
        "                \"%d [D loss supervised: %.4f, acc.: %.2f%%] [D loss unsupervised: %.4f, acc.: %.2f%%] [G loss: %f, acc.: %.2f%%]\"\n",
        "                % (iteration + 1, \n",
        "                   loss_d_supervised, 100 * acc_d_supervised,\n",
        "                   loss_d_unsupervised, 100 * acc_d_unsupervised, \n",
        "                   loss_g, 100 * acc_g))\n",
        "            \n",
        "            discriminator_supervised.save(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-\" + str(iteration+1) + \".h5\")\n",
        "            discriminator_unsupervised.save(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_unsupervised-\" + str(iteration+1) + \".h5\")\n",
        "            generator.save(\"./models/models-label-\" + str(num_labeled) + \"/generator-\" + str(iteration+1) + \".h5\")\n",
        "            file1 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_d_supervised.json\"\n",
        "            file2 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_d_unsupervised.json\"\n",
        "            file3 = \"./losses/losses-label-\" + str(num_labeled) + \"/losses_g.json\"\n",
        "            with open(file1, 'w') as json_file:\n",
        "                  json.dump(str(losses_d_supervised), json_file)\n",
        "            with open(file2, 'w') as json_file:\n",
        "                  json.dump(str(losses_d_unsupervised), json_file)\n",
        "            with open(file3, 'w') as json_file:\n",
        "                  json.dump(str(losses_g), json_file)\n",
        "\n",
        "            # x,y = dataset.training_set()\n",
        "            # _, acc = discriminator_supervised.evaluate(x,y)\n",
        "            # print(str(100*acc)+\"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T__5V6FJn6xB",
        "colab_type": "code",
        "outputId": "563d3ac9-16bf-4e27-8542-2d9ea17d6d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set hyperparameters\n",
        "iterations = 500 # 500\n",
        "iter_epochs = 1 # 1\n",
        "batch_size = 32 # 10\n",
        "save_interval = 10\n",
        "k = 1 # iteration of Discriminator\n",
        "\n",
        "losses_d_supervised = []\n",
        "losses_d_unsupervised = []\n",
        "losses_d_unsupervised_real = []\n",
        "losses_d_unsupervised_fake = []\n",
        "losses_d = []\n",
        "losses_g = []\n",
        "\n",
        "iteration_checkpoints = []\n",
        "\n",
        "# discriminator_supervised = load_model(\"./models/discriminator_supervised-1200.h5\")\n",
        "discriminator_supervised = load_model(\"./models/cifar10_model.035.h5\")\n",
        "starttime = time.clock()\n",
        "\n",
        "# Train the SCGAN-2D for the specified number of iterations\n",
        "train(iterations, batch_size, save_interval, iter_epochs, k)\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Training time: %.4fs\" % (endtime - starttime))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 13s 13s/step - loss: 0.5412 - acc: 0.8438 - val_loss: 0.5922 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.86680 to 0.87100, saving model to /content/models/cifar10_model.001.h5\n",
            "1 [D loss supervised: 0.5412, acc.: 84.38%] [D loss unsupervised: 0.2966, acc.: 100.00%] [G loss: 1.467857, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4403 - acc: 0.8750 - val_loss: 0.6075 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87100\n",
            "2 [D loss supervised: 0.4403, acc.: 87.50%] [D loss unsupervised: 0.3055, acc.: 95.31%] [G loss: 1.847920, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4125 - acc: 0.9375 - val_loss: 0.5997 - val_acc: 0.8712\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.87100 to 0.87120, saving model to /content/models/cifar10_model.001.h5\n",
            "3 [D loss supervised: 0.4125, acc.: 93.75%] [D loss unsupervised: 0.2800, acc.: 98.44%] [G loss: 1.937941, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6461 - acc: 0.8438 - val_loss: 0.6016 - val_acc: 0.8712\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87120\n",
            "4 [D loss supervised: 0.6461, acc.: 84.38%] [D loss unsupervised: 0.2759, acc.: 98.44%] [G loss: 1.776596, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3852 - acc: 0.9375 - val_loss: 0.5820 - val_acc: 0.8762\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.87120 to 0.87620, saving model to /content/models/cifar10_model.001.h5\n",
            "5 [D loss supervised: 0.3852, acc.: 93.75%] [D loss unsupervised: 0.2778, acc.: 100.00%] [G loss: 2.074960, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5386 - acc: 0.9062 - val_loss: 0.5823 - val_acc: 0.8759\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87620\n",
            "6 [D loss supervised: 0.5386, acc.: 90.62%] [D loss unsupervised: 0.2885, acc.: 100.00%] [G loss: 2.313745, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8502 - acc: 0.7500 - val_loss: 0.5816 - val_acc: 0.8768\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.87620 to 0.87680, saving model to /content/models/cifar10_model.001.h5\n",
            "7 [D loss supervised: 0.8502, acc.: 75.00%] [D loss unsupervised: 0.2650, acc.: 100.00%] [G loss: 2.742483, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4040 - acc: 0.9062 - val_loss: 0.5818 - val_acc: 0.8767\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "8 [D loss supervised: 0.4040, acc.: 90.62%] [D loss unsupervised: 0.3039, acc.: 95.31%] [G loss: 2.885997, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4880 - acc: 0.9062 - val_loss: 0.5840 - val_acc: 0.8763\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "9 [D loss supervised: 0.4880, acc.: 90.62%] [D loss unsupervised: 0.2845, acc.: 96.88%] [G loss: 3.023329, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5519 - acc: 0.8438 - val_loss: 0.5919 - val_acc: 0.8740\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "10 [D loss supervised: 0.5519, acc.: 84.38%] [D loss unsupervised: 0.2924, acc.: 96.88%] [G loss: 3.060005, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6786 - acc: 0.8750 - val_loss: 0.5933 - val_acc: 0.8738\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "11 [D loss supervised: 0.6786, acc.: 87.50%] [D loss unsupervised: 0.2811, acc.: 98.44%] [G loss: 3.202062, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4929 - acc: 0.9062 - val_loss: 0.5975 - val_acc: 0.8723\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "12 [D loss supervised: 0.4929, acc.: 90.62%] [D loss unsupervised: 0.2750, acc.: 98.44%] [G loss: 3.214714, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4662 - acc: 0.9062 - val_loss: 0.6052 - val_acc: 0.8699\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "13 [D loss supervised: 0.4662, acc.: 90.62%] [D loss unsupervised: 0.2734, acc.: 98.44%] [G loss: 2.979795, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4919 - acc: 0.9062 - val_loss: 0.6125 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "14 [D loss supervised: 0.4919, acc.: 90.62%] [D loss unsupervised: 0.2585, acc.: 98.44%] [G loss: 2.809040, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6754 - acc: 0.8438 - val_loss: 0.6155 - val_acc: 0.8649\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "15 [D loss supervised: 0.6754, acc.: 84.38%] [D loss unsupervised: 0.2473, acc.: 100.00%] [G loss: 2.770586, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3444 - acc: 0.9688 - val_loss: 0.6214 - val_acc: 0.8642\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "16 [D loss supervised: 0.3444, acc.: 96.88%] [D loss unsupervised: 0.2558, acc.: 100.00%] [G loss: 2.677388, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3676 - acc: 0.9375 - val_loss: 0.6306 - val_acc: 0.8618\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "17 [D loss supervised: 0.3676, acc.: 93.75%] [D loss unsupervised: 0.2545, acc.: 98.44%] [G loss: 2.710370, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4790 - acc: 0.8438 - val_loss: 0.6401 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "18 [D loss supervised: 0.4790, acc.: 84.38%] [D loss unsupervised: 0.2457, acc.: 100.00%] [G loss: 2.829528, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4061 - acc: 0.9375 - val_loss: 0.6502 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "19 [D loss supervised: 0.4061, acc.: 93.75%] [D loss unsupervised: 0.2506, acc.: 100.00%] [G loss: 2.792872, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3459 - acc: 0.9688 - val_loss: 0.6618 - val_acc: 0.8570\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "20 [D loss supervised: 0.3459, acc.: 96.88%] [D loss unsupervised: 0.2503, acc.: 100.00%] [G loss: 2.652853, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5463 - acc: 0.8750 - val_loss: 0.6679 - val_acc: 0.8540\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "21 [D loss supervised: 0.5463, acc.: 87.50%] [D loss unsupervised: 0.2639, acc.: 100.00%] [G loss: 2.879297, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3067 - acc: 0.9688 - val_loss: 0.6730 - val_acc: 0.8506\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "22 [D loss supervised: 0.3067, acc.: 96.88%] [D loss unsupervised: 0.2404, acc.: 100.00%] [G loss: 3.007036, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5239 - acc: 0.9375 - val_loss: 0.6751 - val_acc: 0.8501\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "23 [D loss supervised: 0.5239, acc.: 93.75%] [D loss unsupervised: 0.2663, acc.: 98.44%] [G loss: 2.940410, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3966 - acc: 0.9062 - val_loss: 0.6819 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "24 [D loss supervised: 0.3966, acc.: 90.62%] [D loss unsupervised: 0.2643, acc.: 100.00%] [G loss: 3.038638, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4977 - acc: 0.9375 - val_loss: 0.6807 - val_acc: 0.8477\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "25 [D loss supervised: 0.4977, acc.: 93.75%] [D loss unsupervised: 0.3124, acc.: 98.44%] [G loss: 2.881484, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4359 - acc: 0.9375 - val_loss: 0.6841 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "26 [D loss supervised: 0.4359, acc.: 93.75%] [D loss unsupervised: 0.2380, acc.: 100.00%] [G loss: 2.972910, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5997 - acc: 0.8438 - val_loss: 0.6922 - val_acc: 0.8449\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "27 [D loss supervised: 0.5997, acc.: 84.38%] [D loss unsupervised: 0.2348, acc.: 100.00%] [G loss: 3.014970, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4799 - acc: 0.9062 - val_loss: 0.6998 - val_acc: 0.8435\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "28 [D loss supervised: 0.4799, acc.: 90.62%] [D loss unsupervised: 0.2618, acc.: 96.88%] [G loss: 3.371656, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5829 - acc: 0.8750 - val_loss: 0.7101 - val_acc: 0.8398\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "29 [D loss supervised: 0.5829, acc.: 87.50%] [D loss unsupervised: 0.2311, acc.: 100.00%] [G loss: 3.457724, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2912 - acc: 1.0000 - val_loss: 0.7214 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "30 [D loss supervised: 0.2912, acc.: 100.00%] [D loss unsupervised: 0.2491, acc.: 100.00%] [G loss: 3.547090, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3684 - acc: 0.9375 - val_loss: 0.7339 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "31 [D loss supervised: 0.3684, acc.: 93.75%] [D loss unsupervised: 0.2562, acc.: 100.00%] [G loss: 3.359709, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3665 - acc: 0.9375 - val_loss: 0.7434 - val_acc: 0.8307\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "32 [D loss supervised: 0.3665, acc.: 93.75%] [D loss unsupervised: 0.2385, acc.: 100.00%] [G loss: 3.563681, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4998 - acc: 0.8438 - val_loss: 0.7488 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "33 [D loss supervised: 0.4998, acc.: 84.38%] [D loss unsupervised: 0.2882, acc.: 100.00%] [G loss: 3.271981, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5267 - acc: 0.8438 - val_loss: 0.7553 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "34 [D loss supervised: 0.5267, acc.: 84.38%] [D loss unsupervised: 0.2389, acc.: 100.00%] [G loss: 3.354815, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3029 - acc: 0.9688 - val_loss: 0.7611 - val_acc: 0.8249\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "35 [D loss supervised: 0.3029, acc.: 96.88%] [D loss unsupervised: 0.2297, acc.: 100.00%] [G loss: 3.283721, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3589 - acc: 0.9375 - val_loss: 0.7666 - val_acc: 0.8235\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "36 [D loss supervised: 0.3589, acc.: 93.75%] [D loss unsupervised: 0.2291, acc.: 100.00%] [G loss: 3.184906, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5882 - acc: 0.9062 - val_loss: 0.7770 - val_acc: 0.8210\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "37 [D loss supervised: 0.5882, acc.: 90.62%] [D loss unsupervised: 0.2596, acc.: 98.44%] [G loss: 2.819465, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4233 - acc: 0.9062 - val_loss: 0.7897 - val_acc: 0.8200\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "38 [D loss supervised: 0.4233, acc.: 90.62%] [D loss unsupervised: 0.2502, acc.: 98.44%] [G loss: 2.412357, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5395 - acc: 0.8750 - val_loss: 0.8009 - val_acc: 0.8187\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "39 [D loss supervised: 0.5395, acc.: 87.50%] [D loss unsupervised: 0.2354, acc.: 100.00%] [G loss: 1.752187, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3043 - acc: 0.9688 - val_loss: 0.8028 - val_acc: 0.8190\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "40 [D loss supervised: 0.3043, acc.: 96.88%] [D loss unsupervised: 0.2488, acc.: 100.00%] [G loss: 1.460318, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4471 - acc: 0.9062 - val_loss: 0.8039 - val_acc: 0.8193\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "41 [D loss supervised: 0.4471, acc.: 90.62%] [D loss unsupervised: 0.2656, acc.: 100.00%] [G loss: 1.768502, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3295 - acc: 0.9375 - val_loss: 0.8081 - val_acc: 0.8185\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "42 [D loss supervised: 0.3295, acc.: 93.75%] [D loss unsupervised: 0.2483, acc.: 100.00%] [G loss: 2.395546, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3427 - acc: 0.9688 - val_loss: 0.8156 - val_acc: 0.8170\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "43 [D loss supervised: 0.3427, acc.: 96.88%] [D loss unsupervised: 0.2479, acc.: 100.00%] [G loss: 2.637100, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5414 - acc: 0.9375 - val_loss: 0.8191 - val_acc: 0.8169\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "44 [D loss supervised: 0.5414, acc.: 93.75%] [D loss unsupervised: 0.2302, acc.: 100.00%] [G loss: 2.848704, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7280 - acc: 0.7812 - val_loss: 0.8291 - val_acc: 0.8140\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "45 [D loss supervised: 0.7280, acc.: 78.12%] [D loss unsupervised: 0.2346, acc.: 100.00%] [G loss: 2.688225, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3684 - acc: 0.9375 - val_loss: 0.8321 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "46 [D loss supervised: 0.3684, acc.: 93.75%] [D loss unsupervised: 0.2313, acc.: 100.00%] [G loss: 1.767336, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5553 - acc: 0.8750 - val_loss: 0.8340 - val_acc: 0.8115\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "47 [D loss supervised: 0.5553, acc.: 87.50%] [D loss unsupervised: 0.2451, acc.: 100.00%] [G loss: 1.347567, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5679 - acc: 0.9062 - val_loss: 0.8328 - val_acc: 0.8122\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "48 [D loss supervised: 0.5679, acc.: 90.62%] [D loss unsupervised: 0.2346, acc.: 100.00%] [G loss: 1.783210, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3857 - acc: 0.9062 - val_loss: 0.8291 - val_acc: 0.8134\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "49 [D loss supervised: 0.3857, acc.: 90.62%] [D loss unsupervised: 0.2338, acc.: 100.00%] [G loss: 2.011524, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3763 - acc: 0.9062 - val_loss: 0.8255 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "50 [D loss supervised: 0.3763, acc.: 90.62%] [D loss unsupervised: 0.2659, acc.: 98.44%] [G loss: 1.967727, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4267 - acc: 0.9375 - val_loss: 0.8222 - val_acc: 0.8151\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "51 [D loss supervised: 0.4267, acc.: 93.75%] [D loss unsupervised: 0.2539, acc.: 98.44%] [G loss: 2.368564, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5994 - acc: 0.8750 - val_loss: 0.8252 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "52 [D loss supervised: 0.5994, acc.: 87.50%] [D loss unsupervised: 0.2496, acc.: 98.44%] [G loss: 1.481684, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6179 - acc: 0.8125 - val_loss: 0.8336 - val_acc: 0.8141\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "53 [D loss supervised: 0.6179, acc.: 81.25%] [D loss unsupervised: 0.2510, acc.: 98.44%] [G loss: 1.813754, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3986 - acc: 0.9375 - val_loss: 0.8414 - val_acc: 0.8108\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "54 [D loss supervised: 0.3986, acc.: 93.75%] [D loss unsupervised: 0.2216, acc.: 100.00%] [G loss: 1.867898, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6275 - acc: 0.8438 - val_loss: 0.8298 - val_acc: 0.8129\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "55 [D loss supervised: 0.6275, acc.: 84.38%] [D loss unsupervised: 0.2331, acc.: 100.00%] [G loss: 2.000415, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5955 - acc: 0.9062 - val_loss: 0.8167 - val_acc: 0.8159\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "56 [D loss supervised: 0.5955, acc.: 90.62%] [D loss unsupervised: 0.2173, acc.: 100.00%] [G loss: 2.109390, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5838 - acc: 0.8438 - val_loss: 0.7960 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "57 [D loss supervised: 0.5838, acc.: 84.38%] [D loss unsupervised: 0.2125, acc.: 100.00%] [G loss: 1.754953, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3791 - acc: 0.9375 - val_loss: 0.7748 - val_acc: 0.8266\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "58 [D loss supervised: 0.3791, acc.: 93.75%] [D loss unsupervised: 0.2260, acc.: 100.00%] [G loss: 2.019485, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5186 - acc: 0.9062 - val_loss: 0.7554 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "59 [D loss supervised: 0.5186, acc.: 90.62%] [D loss unsupervised: 0.2299, acc.: 100.00%] [G loss: 1.532098, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4511 - acc: 0.9062 - val_loss: 0.7400 - val_acc: 0.8320\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "60 [D loss supervised: 0.4511, acc.: 90.62%] [D loss unsupervised: 0.2149, acc.: 100.00%] [G loss: 1.648492, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6258 - acc: 0.8750 - val_loss: 0.7235 - val_acc: 0.8367\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "61 [D loss supervised: 0.6258, acc.: 87.50%] [D loss unsupervised: 0.2139, acc.: 100.00%] [G loss: 1.084772, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5786 - acc: 0.8438 - val_loss: 0.7057 - val_acc: 0.8422\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "62 [D loss supervised: 0.5786, acc.: 84.38%] [D loss unsupervised: 0.2248, acc.: 100.00%] [G loss: 1.194712, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3326 - acc: 0.9375 - val_loss: 0.6933 - val_acc: 0.8440\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "63 [D loss supervised: 0.3326, acc.: 93.75%] [D loss unsupervised: 0.2162, acc.: 100.00%] [G loss: 0.987396, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3790 - acc: 0.9688 - val_loss: 0.6866 - val_acc: 0.8466\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "64 [D loss supervised: 0.3790, acc.: 96.88%] [D loss unsupervised: 0.2172, acc.: 100.00%] [G loss: 0.705806, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3564 - acc: 0.9375 - val_loss: 0.6830 - val_acc: 0.8469\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "65 [D loss supervised: 0.3564, acc.: 93.75%] [D loss unsupervised: 0.2164, acc.: 100.00%] [G loss: 0.822104, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3314 - acc: 0.9688 - val_loss: 0.6808 - val_acc: 0.8478\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "66 [D loss supervised: 0.3314, acc.: 96.88%] [D loss unsupervised: 0.2164, acc.: 100.00%] [G loss: 1.514272, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4638 - acc: 0.9062 - val_loss: 0.6797 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "67 [D loss supervised: 0.4638, acc.: 90.62%] [D loss unsupervised: 0.2141, acc.: 100.00%] [G loss: 0.785259, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3973 - acc: 0.9062 - val_loss: 0.6814 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "68 [D loss supervised: 0.3973, acc.: 90.62%] [D loss unsupervised: 0.2100, acc.: 100.00%] [G loss: 0.999223, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4036 - acc: 0.9062 - val_loss: 0.6835 - val_acc: 0.8463\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "69 [D loss supervised: 0.4036, acc.: 90.62%] [D loss unsupervised: 0.2098, acc.: 100.00%] [G loss: 1.022411, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4470 - acc: 0.9375 - val_loss: 0.6895 - val_acc: 0.8455\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "70 [D loss supervised: 0.4470, acc.: 93.75%] [D loss unsupervised: 0.2084, acc.: 100.00%] [G loss: 0.963734, acc.: 56.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3788 - acc: 0.9062 - val_loss: 0.6963 - val_acc: 0.8437\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "71 [D loss supervised: 0.3788, acc.: 90.62%] [D loss unsupervised: 0.2054, acc.: 100.00%] [G loss: 0.731563, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4456 - acc: 0.9062 - val_loss: 0.7073 - val_acc: 0.8408\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "72 [D loss supervised: 0.4456, acc.: 90.62%] [D loss unsupervised: 0.2125, acc.: 100.00%] [G loss: 0.673303, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3289 - acc: 0.9688 - val_loss: 0.7165 - val_acc: 0.8384\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "73 [D loss supervised: 0.3289, acc.: 96.88%] [D loss unsupervised: 0.2225, acc.: 98.44%] [G loss: 0.834085, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3970 - acc: 0.9062 - val_loss: 0.7239 - val_acc: 0.8370\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "74 [D loss supervised: 0.3970, acc.: 90.62%] [D loss unsupervised: 0.2053, acc.: 100.00%] [G loss: 0.649260, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3872 - acc: 0.9375 - val_loss: 0.7356 - val_acc: 0.8357\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "75 [D loss supervised: 0.3872, acc.: 93.75%] [D loss unsupervised: 0.2126, acc.: 100.00%] [G loss: 0.595431, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3982 - acc: 0.9062 - val_loss: 0.7419 - val_acc: 0.8350\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "76 [D loss supervised: 0.3982, acc.: 90.62%] [D loss unsupervised: 0.2113, acc.: 100.00%] [G loss: 0.582028, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4159 - acc: 0.9062 - val_loss: 0.7338 - val_acc: 0.8371\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "77 [D loss supervised: 0.4159, acc.: 90.62%] [D loss unsupervised: 0.2141, acc.: 100.00%] [G loss: 0.450163, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2562 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 0.8378\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "78 [D loss supervised: 0.2562, acc.: 100.00%] [D loss unsupervised: 0.2133, acc.: 100.00%] [G loss: 0.482822, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4406 - acc: 0.9062 - val_loss: 0.7235 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "79 [D loss supervised: 0.4406, acc.: 90.62%] [D loss unsupervised: 0.2100, acc.: 100.00%] [G loss: 0.348407, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4112 - acc: 0.9375 - val_loss: 0.7143 - val_acc: 0.8389\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "80 [D loss supervised: 0.4112, acc.: 93.75%] [D loss unsupervised: 0.2127, acc.: 100.00%] [G loss: 0.534153, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4056 - acc: 0.9375 - val_loss: 0.7027 - val_acc: 0.8412\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "81 [D loss supervised: 0.4056, acc.: 93.75%] [D loss unsupervised: 0.2076, acc.: 100.00%] [G loss: 0.334237, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4704 - acc: 0.9375 - val_loss: 0.6908 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "82 [D loss supervised: 0.4704, acc.: 93.75%] [D loss unsupervised: 0.2107, acc.: 100.00%] [G loss: 0.417596, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5775 - acc: 0.8125 - val_loss: 0.6759 - val_acc: 0.8492\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "83 [D loss supervised: 0.5775, acc.: 81.25%] [D loss unsupervised: 0.2404, acc.: 98.44%] [G loss: 0.255151, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3191 - acc: 0.9688 - val_loss: 0.6671 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "84 [D loss supervised: 0.3191, acc.: 96.88%] [D loss unsupervised: 0.2054, acc.: 100.00%] [G loss: 0.304271, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6767 - acc: 0.8438 - val_loss: 0.6640 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "85 [D loss supervised: 0.6767, acc.: 84.38%] [D loss unsupervised: 0.2104, acc.: 100.00%] [G loss: 0.313980, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4829 - acc: 0.8750 - val_loss: 0.6652 - val_acc: 0.8519\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "86 [D loss supervised: 0.4829, acc.: 87.50%] [D loss unsupervised: 0.2065, acc.: 100.00%] [G loss: 0.272075, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4375 - acc: 0.8750 - val_loss: 0.6667 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "87 [D loss supervised: 0.4375, acc.: 87.50%] [D loss unsupervised: 0.2078, acc.: 100.00%] [G loss: 0.303854, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3365 - acc: 0.9688 - val_loss: 0.6694 - val_acc: 0.8512\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "88 [D loss supervised: 0.3365, acc.: 96.88%] [D loss unsupervised: 0.2033, acc.: 100.00%] [G loss: 0.249633, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4010 - acc: 0.9375 - val_loss: 0.6717 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "89 [D loss supervised: 0.4010, acc.: 93.75%] [D loss unsupervised: 0.2057, acc.: 100.00%] [G loss: 0.279845, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4654 - acc: 0.9375 - val_loss: 0.6753 - val_acc: 0.8506\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "90 [D loss supervised: 0.4654, acc.: 93.75%] [D loss unsupervised: 0.2090, acc.: 100.00%] [G loss: 0.368382, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4061 - acc: 0.9375 - val_loss: 0.6834 - val_acc: 0.8476\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "91 [D loss supervised: 0.4061, acc.: 93.75%] [D loss unsupervised: 0.2010, acc.: 100.00%] [G loss: 0.308264, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4945 - acc: 0.9062 - val_loss: 0.6874 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "92 [D loss supervised: 0.4945, acc.: 90.62%] [D loss unsupervised: 0.2029, acc.: 100.00%] [G loss: 0.359028, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4439 - acc: 0.8750 - val_loss: 0.6924 - val_acc: 0.8446\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "93 [D loss supervised: 0.4439, acc.: 87.50%] [D loss unsupervised: 0.2046, acc.: 100.00%] [G loss: 0.330778, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3566 - acc: 0.9375 - val_loss: 0.6983 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "94 [D loss supervised: 0.3566, acc.: 93.75%] [D loss unsupervised: 0.2034, acc.: 100.00%] [G loss: 0.279690, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3906 - acc: 0.9062 - val_loss: 0.7040 - val_acc: 0.8428\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "95 [D loss supervised: 0.3906, acc.: 90.62%] [D loss unsupervised: 0.2004, acc.: 100.00%] [G loss: 0.295281, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3406 - acc: 0.9375 - val_loss: 0.7121 - val_acc: 0.8404\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "96 [D loss supervised: 0.3406, acc.: 93.75%] [D loss unsupervised: 0.2026, acc.: 100.00%] [G loss: 0.275100, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3651 - acc: 0.9688 - val_loss: 0.7189 - val_acc: 0.8391\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "97 [D loss supervised: 0.3651, acc.: 96.88%] [D loss unsupervised: 0.2045, acc.: 100.00%] [G loss: 0.299148, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3962 - acc: 0.9375 - val_loss: 0.7234 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "98 [D loss supervised: 0.3962, acc.: 93.75%] [D loss unsupervised: 0.2045, acc.: 100.00%] [G loss: 0.255254, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4212 - acc: 0.9375 - val_loss: 0.7246 - val_acc: 0.8376\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "99 [D loss supervised: 0.4212, acc.: 93.75%] [D loss unsupervised: 0.1991, acc.: 100.00%] [G loss: 0.302656, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7373 - acc: 0.8438 - val_loss: 0.7324 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "100 [D loss supervised: 0.7373, acc.: 84.38%] [D loss unsupervised: 0.1997, acc.: 100.00%] [G loss: 0.319725, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3458 - acc: 0.9688 - val_loss: 0.7409 - val_acc: 0.8325\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "101 [D loss supervised: 0.3458, acc.: 96.88%] [D loss unsupervised: 0.2005, acc.: 100.00%] [G loss: 0.248603, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5539 - acc: 0.8438 - val_loss: 0.7441 - val_acc: 0.8309\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "102 [D loss supervised: 0.5539, acc.: 84.38%] [D loss unsupervised: 0.1996, acc.: 100.00%] [G loss: 0.245983, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4667 - acc: 0.9062 - val_loss: 0.7504 - val_acc: 0.8285\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "103 [D loss supervised: 0.4667, acc.: 90.62%] [D loss unsupervised: 0.1998, acc.: 100.00%] [G loss: 0.271288, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4336 - acc: 0.9062 - val_loss: 0.7511 - val_acc: 0.8287\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "104 [D loss supervised: 0.4336, acc.: 90.62%] [D loss unsupervised: 0.2053, acc.: 100.00%] [G loss: 0.353889, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5071 - acc: 0.8750 - val_loss: 0.7443 - val_acc: 0.8283\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "105 [D loss supervised: 0.5071, acc.: 87.50%] [D loss unsupervised: 0.2021, acc.: 100.00%] [G loss: 0.250616, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3556 - acc: 0.9375 - val_loss: 0.7393 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "106 [D loss supervised: 0.3556, acc.: 93.75%] [D loss unsupervised: 0.2128, acc.: 100.00%] [G loss: 0.296752, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4795 - acc: 0.8438 - val_loss: 0.7337 - val_acc: 0.8285\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "107 [D loss supervised: 0.4795, acc.: 84.38%] [D loss unsupervised: 0.2065, acc.: 100.00%] [G loss: 0.243734, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5070 - acc: 0.8750 - val_loss: 0.7206 - val_acc: 0.8344\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "108 [D loss supervised: 0.5070, acc.: 87.50%] [D loss unsupervised: 0.2069, acc.: 100.00%] [G loss: 0.275559, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4149 - acc: 0.9688 - val_loss: 0.7086 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "109 [D loss supervised: 0.4149, acc.: 96.88%] [D loss unsupervised: 0.1985, acc.: 100.00%] [G loss: 0.335974, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4551 - acc: 0.8438 - val_loss: 0.6990 - val_acc: 0.8398\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "110 [D loss supervised: 0.4551, acc.: 84.38%] [D loss unsupervised: 0.1997, acc.: 100.00%] [G loss: 0.244767, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3797 - acc: 0.9688 - val_loss: 0.6902 - val_acc: 0.8436\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "111 [D loss supervised: 0.3797, acc.: 96.88%] [D loss unsupervised: 0.1982, acc.: 100.00%] [G loss: 0.255556, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3635 - acc: 0.9688 - val_loss: 0.6843 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "112 [D loss supervised: 0.3635, acc.: 96.88%] [D loss unsupervised: 0.2004, acc.: 100.00%] [G loss: 0.308300, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3744 - acc: 0.9375 - val_loss: 0.6802 - val_acc: 0.8478\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "113 [D loss supervised: 0.3744, acc.: 93.75%] [D loss unsupervised: 0.2015, acc.: 100.00%] [G loss: 0.276462, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3383 - acc: 0.9375 - val_loss: 0.6789 - val_acc: 0.8483\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "114 [D loss supervised: 0.3383, acc.: 93.75%] [D loss unsupervised: 0.1971, acc.: 100.00%] [G loss: 0.339244, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4243 - acc: 0.9062 - val_loss: 0.6795 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "115 [D loss supervised: 0.4243, acc.: 90.62%] [D loss unsupervised: 0.2055, acc.: 100.00%] [G loss: 0.396164, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3675 - acc: 0.9375 - val_loss: 0.6790 - val_acc: 0.8464\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "116 [D loss supervised: 0.3675, acc.: 93.75%] [D loss unsupervised: 0.2091, acc.: 100.00%] [G loss: 0.481619, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6154 - acc: 0.8438 - val_loss: 0.6726 - val_acc: 0.8480\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "117 [D loss supervised: 0.6154, acc.: 84.38%] [D loss unsupervised: 0.1942, acc.: 100.00%] [G loss: 0.584723, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2889 - acc: 0.9688 - val_loss: 0.6695 - val_acc: 0.8480\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "118 [D loss supervised: 0.2889, acc.: 96.88%] [D loss unsupervised: 0.2108, acc.: 100.00%] [G loss: 0.359756, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4314 - acc: 0.9688 - val_loss: 0.6659 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "119 [D loss supervised: 0.4314, acc.: 96.88%] [D loss unsupervised: 0.2001, acc.: 100.00%] [G loss: 0.458572, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3221 - acc: 0.9688 - val_loss: 0.6623 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "120 [D loss supervised: 0.3221, acc.: 96.88%] [D loss unsupervised: 0.1990, acc.: 100.00%] [G loss: 0.314739, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3814 - acc: 0.9062 - val_loss: 0.6567 - val_acc: 0.8492\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "121 [D loss supervised: 0.3814, acc.: 90.62%] [D loss unsupervised: 0.2017, acc.: 100.00%] [G loss: 0.328498, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3891 - acc: 0.8438 - val_loss: 0.6481 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "122 [D loss supervised: 0.3891, acc.: 84.38%] [D loss unsupervised: 0.1959, acc.: 100.00%] [G loss: 0.286401, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3348 - acc: 1.0000 - val_loss: 0.6405 - val_acc: 0.8534\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "123 [D loss supervised: 0.3348, acc.: 100.00%] [D loss unsupervised: 0.2152, acc.: 98.44%] [G loss: 0.279672, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3805 - acc: 0.9375 - val_loss: 0.6331 - val_acc: 0.8562\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "124 [D loss supervised: 0.3805, acc.: 93.75%] [D loss unsupervised: 0.1967, acc.: 100.00%] [G loss: 0.228480, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2982 - acc: 1.0000 - val_loss: 0.6264 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "125 [D loss supervised: 0.2982, acc.: 100.00%] [D loss unsupervised: 0.1993, acc.: 100.00%] [G loss: 0.258581, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4054 - acc: 0.9375 - val_loss: 0.6216 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "126 [D loss supervised: 0.4054, acc.: 93.75%] [D loss unsupervised: 0.2000, acc.: 100.00%] [G loss: 0.259475, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3528 - acc: 0.9375 - val_loss: 0.6178 - val_acc: 0.8588\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "127 [D loss supervised: 0.3528, acc.: 93.75%] [D loss unsupervised: 0.1982, acc.: 100.00%] [G loss: 0.231461, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3789 - acc: 0.9688 - val_loss: 0.6159 - val_acc: 0.8592\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "128 [D loss supervised: 0.3789, acc.: 96.88%] [D loss unsupervised: 0.1940, acc.: 100.00%] [G loss: 0.255032, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3868 - acc: 0.9375 - val_loss: 0.6151 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "129 [D loss supervised: 0.3868, acc.: 93.75%] [D loss unsupervised: 0.1964, acc.: 100.00%] [G loss: 0.242829, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3896 - acc: 0.9688 - val_loss: 0.6153 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "130 [D loss supervised: 0.3896, acc.: 96.88%] [D loss unsupervised: 0.1929, acc.: 100.00%] [G loss: 0.265448, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2778 - acc: 1.0000 - val_loss: 0.6169 - val_acc: 0.8616\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "131 [D loss supervised: 0.2778, acc.: 100.00%] [D loss unsupervised: 0.1965, acc.: 100.00%] [G loss: 0.325961, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3183 - acc: 0.9375 - val_loss: 0.6181 - val_acc: 0.8619\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "132 [D loss supervised: 0.3183, acc.: 93.75%] [D loss unsupervised: 0.1971, acc.: 100.00%] [G loss: 0.237766, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2879 - acc: 1.0000 - val_loss: 0.6203 - val_acc: 0.8617\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "133 [D loss supervised: 0.2879, acc.: 100.00%] [D loss unsupervised: 0.2004, acc.: 100.00%] [G loss: 0.336588, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2837 - acc: 1.0000 - val_loss: 0.6231 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "134 [D loss supervised: 0.2837, acc.: 100.00%] [D loss unsupervised: 0.1935, acc.: 100.00%] [G loss: 0.383740, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3477 - acc: 0.9375 - val_loss: 0.6249 - val_acc: 0.8618\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "135 [D loss supervised: 0.3477, acc.: 93.75%] [D loss unsupervised: 0.1920, acc.: 100.00%] [G loss: 0.435940, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2544 - acc: 1.0000 - val_loss: 0.6257 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "136 [D loss supervised: 0.2544, acc.: 100.00%] [D loss unsupervised: 0.1953, acc.: 100.00%] [G loss: 0.382984, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4684 - acc: 0.8750 - val_loss: 0.6282 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "137 [D loss supervised: 0.4684, acc.: 87.50%] [D loss unsupervised: 0.1976, acc.: 100.00%] [G loss: 0.427846, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3080 - acc: 0.9688 - val_loss: 0.6307 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "138 [D loss supervised: 0.3080, acc.: 96.88%] [D loss unsupervised: 0.1958, acc.: 100.00%] [G loss: 0.397323, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3093 - acc: 0.9688 - val_loss: 0.6342 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "139 [D loss supervised: 0.3093, acc.: 96.88%] [D loss unsupervised: 0.2162, acc.: 100.00%] [G loss: 0.252274, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3567 - acc: 0.9375 - val_loss: 0.6381 - val_acc: 0.8597\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "140 [D loss supervised: 0.3567, acc.: 93.75%] [D loss unsupervised: 0.2023, acc.: 100.00%] [G loss: 0.322514, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3004 - acc: 1.0000 - val_loss: 0.6415 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "141 [D loss supervised: 0.3004, acc.: 100.00%] [D loss unsupervised: 0.1968, acc.: 100.00%] [G loss: 0.612753, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3711 - acc: 0.9062 - val_loss: 0.6432 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "142 [D loss supervised: 0.3711, acc.: 90.62%] [D loss unsupervised: 0.1919, acc.: 100.00%] [G loss: 1.292829, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4939 - acc: 0.9062 - val_loss: 0.6379 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "143 [D loss supervised: 0.4939, acc.: 90.62%] [D loss unsupervised: 0.1931, acc.: 100.00%] [G loss: 0.810477, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2656 - acc: 0.9688 - val_loss: 0.6348 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "144 [D loss supervised: 0.2656, acc.: 96.88%] [D loss unsupervised: 0.2036, acc.: 100.00%] [G loss: 0.453584, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4490 - acc: 0.9375 - val_loss: 0.6342 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "145 [D loss supervised: 0.4490, acc.: 93.75%] [D loss unsupervised: 0.1991, acc.: 100.00%] [G loss: 0.728045, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4761 - acc: 0.9375 - val_loss: 0.6360 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "146 [D loss supervised: 0.4761, acc.: 93.75%] [D loss unsupervised: 0.1939, acc.: 100.00%] [G loss: 1.080369, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2963 - acc: 0.9688 - val_loss: 0.6402 - val_acc: 0.8566\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "147 [D loss supervised: 0.2963, acc.: 96.88%] [D loss unsupervised: 0.1921, acc.: 100.00%] [G loss: 1.166160, acc.: 40.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3404 - acc: 0.9688 - val_loss: 0.6440 - val_acc: 0.8545\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "148 [D loss supervised: 0.3404, acc.: 96.88%] [D loss unsupervised: 0.2031, acc.: 100.00%] [G loss: 1.266680, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2512 - acc: 1.0000 - val_loss: 0.6466 - val_acc: 0.8547\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "149 [D loss supervised: 0.2512, acc.: 100.00%] [D loss unsupervised: 0.1971, acc.: 100.00%] [G loss: 0.771612, acc.: 65.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3129 - acc: 0.9688 - val_loss: 0.6453 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "150 [D loss supervised: 0.3129, acc.: 96.88%] [D loss unsupervised: 0.2248, acc.: 98.44%] [G loss: 0.381371, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3201 - acc: 0.9375 - val_loss: 0.6444 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "151 [D loss supervised: 0.3201, acc.: 93.75%] [D loss unsupervised: 0.2045, acc.: 100.00%] [G loss: 0.567256, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2804 - acc: 1.0000 - val_loss: 0.6427 - val_acc: 0.8549\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "152 [D loss supervised: 0.2804, acc.: 100.00%] [D loss unsupervised: 0.1970, acc.: 100.00%] [G loss: 0.470065, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3649 - acc: 0.9375 - val_loss: 0.6434 - val_acc: 0.8541\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "153 [D loss supervised: 0.3649, acc.: 93.75%] [D loss unsupervised: 0.1944, acc.: 100.00%] [G loss: 1.304121, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2614 - acc: 1.0000 - val_loss: 0.6443 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "154 [D loss supervised: 0.2614, acc.: 100.00%] [D loss unsupervised: 0.1964, acc.: 100.00%] [G loss: 0.802815, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3192 - acc: 0.9688 - val_loss: 0.6419 - val_acc: 0.8565\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "155 [D loss supervised: 0.3192, acc.: 96.88%] [D loss unsupervised: 0.1960, acc.: 100.00%] [G loss: 0.777039, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2705 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "156 [D loss supervised: 0.2705, acc.: 100.00%] [D loss unsupervised: 0.1953, acc.: 100.00%] [G loss: 0.677087, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4270 - acc: 0.9375 - val_loss: 0.6281 - val_acc: 0.8617\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "157 [D loss supervised: 0.4270, acc.: 93.75%] [D loss unsupervised: 0.1960, acc.: 100.00%] [G loss: 0.591675, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3459 - acc: 0.9688 - val_loss: 0.6209 - val_acc: 0.8633\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "158 [D loss supervised: 0.3459, acc.: 96.88%] [D loss unsupervised: 0.1981, acc.: 100.00%] [G loss: 0.474534, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3588 - acc: 0.9375 - val_loss: 0.6187 - val_acc: 0.8644\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "159 [D loss supervised: 0.3588, acc.: 93.75%] [D loss unsupervised: 0.1914, acc.: 100.00%] [G loss: 0.322312, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3359 - acc: 0.9688 - val_loss: 0.6191 - val_acc: 0.8637\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "160 [D loss supervised: 0.3359, acc.: 96.88%] [D loss unsupervised: 0.2046, acc.: 100.00%] [G loss: 0.302545, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3394 - acc: 1.0000 - val_loss: 0.6172 - val_acc: 0.8644\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "161 [D loss supervised: 0.3394, acc.: 100.00%] [D loss unsupervised: 0.1927, acc.: 100.00%] [G loss: 0.451356, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3114 - acc: 0.9688 - val_loss: 0.6161 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "162 [D loss supervised: 0.3114, acc.: 96.88%] [D loss unsupervised: 0.1953, acc.: 100.00%] [G loss: 0.305910, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3899 - acc: 0.9375 - val_loss: 0.6193 - val_acc: 0.8623\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "163 [D loss supervised: 0.3899, acc.: 93.75%] [D loss unsupervised: 0.1900, acc.: 100.00%] [G loss: 0.238989, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5221 - acc: 0.8750 - val_loss: 0.6237 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "164 [D loss supervised: 0.5221, acc.: 87.50%] [D loss unsupervised: 0.1895, acc.: 100.00%] [G loss: 0.245507, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2577 - acc: 1.0000 - val_loss: 0.6282 - val_acc: 0.8588\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "165 [D loss supervised: 0.2577, acc.: 100.00%] [D loss unsupervised: 0.1977, acc.: 100.00%] [G loss: 0.251860, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3587 - acc: 0.9375 - val_loss: 0.6336 - val_acc: 0.8569\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "166 [D loss supervised: 0.3587, acc.: 93.75%] [D loss unsupervised: 0.1876, acc.: 100.00%] [G loss: 0.382869, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3111 - acc: 0.9688 - val_loss: 0.6396 - val_acc: 0.8562\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "167 [D loss supervised: 0.3111, acc.: 96.88%] [D loss unsupervised: 0.1875, acc.: 100.00%] [G loss: 0.278977, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4912 - acc: 0.9062 - val_loss: 0.6441 - val_acc: 0.8558\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "168 [D loss supervised: 0.4912, acc.: 90.62%] [D loss unsupervised: 0.1900, acc.: 100.00%] [G loss: 0.306897, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3906 - acc: 0.9688 - val_loss: 0.6441 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "169 [D loss supervised: 0.3906, acc.: 96.88%] [D loss unsupervised: 0.1888, acc.: 100.00%] [G loss: 0.262318, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3572 - acc: 0.9688 - val_loss: 0.6440 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "170 [D loss supervised: 0.3572, acc.: 96.88%] [D loss unsupervised: 0.2052, acc.: 100.00%] [G loss: 0.212178, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3802 - acc: 0.9375 - val_loss: 0.6423 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "171 [D loss supervised: 0.3802, acc.: 93.75%] [D loss unsupervised: 0.1890, acc.: 100.00%] [G loss: 0.191064, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2732 - acc: 0.9688 - val_loss: 0.6420 - val_acc: 0.8590\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "172 [D loss supervised: 0.2732, acc.: 96.88%] [D loss unsupervised: 0.2011, acc.: 100.00%] [G loss: 0.195483, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3600 - acc: 0.9375 - val_loss: 0.6437 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "173 [D loss supervised: 0.3600, acc.: 93.75%] [D loss unsupervised: 0.1900, acc.: 100.00%] [G loss: 0.219801, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2297 - acc: 1.0000 - val_loss: 0.6453 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "174 [D loss supervised: 0.2297, acc.: 100.00%] [D loss unsupervised: 0.1866, acc.: 100.00%] [G loss: 0.215623, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4170 - acc: 0.9688 - val_loss: 0.6451 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "175 [D loss supervised: 0.4170, acc.: 96.88%] [D loss unsupervised: 0.1860, acc.: 100.00%] [G loss: 0.314583, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6127 - acc: 0.8750 - val_loss: 0.6407 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "176 [D loss supervised: 0.6127, acc.: 87.50%] [D loss unsupervised: 0.1856, acc.: 100.00%] [G loss: 0.212004, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2965 - acc: 1.0000 - val_loss: 0.6404 - val_acc: 0.8620\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "177 [D loss supervised: 0.2965, acc.: 100.00%] [D loss unsupervised: 0.1863, acc.: 100.00%] [G loss: 0.423897, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3234 - acc: 0.9688 - val_loss: 0.6428 - val_acc: 0.8613\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "178 [D loss supervised: 0.3234, acc.: 96.88%] [D loss unsupervised: 0.1870, acc.: 100.00%] [G loss: 0.274281, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4329 - acc: 0.9375 - val_loss: 0.6436 - val_acc: 0.8614\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "179 [D loss supervised: 0.4329, acc.: 93.75%] [D loss unsupervised: 0.1866, acc.: 100.00%] [G loss: 0.253876, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3052 - acc: 0.9688 - val_loss: 0.6450 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "180 [D loss supervised: 0.3052, acc.: 96.88%] [D loss unsupervised: 0.1953, acc.: 100.00%] [G loss: 0.255276, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4774 - acc: 0.8438 - val_loss: 0.6527 - val_acc: 0.8584\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "181 [D loss supervised: 0.4774, acc.: 84.38%] [D loss unsupervised: 0.1852, acc.: 100.00%] [G loss: 0.245138, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4514 - acc: 0.9062 - val_loss: 0.6596 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "182 [D loss supervised: 0.4514, acc.: 90.62%] [D loss unsupervised: 0.1856, acc.: 100.00%] [G loss: 0.212038, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3280 - acc: 1.0000 - val_loss: 0.6663 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "183 [D loss supervised: 0.3280, acc.: 100.00%] [D loss unsupervised: 0.1847, acc.: 100.00%] [G loss: 0.245240, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3456 - acc: 0.9688 - val_loss: 0.6704 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "184 [D loss supervised: 0.3456, acc.: 96.88%] [D loss unsupervised: 0.1846, acc.: 100.00%] [G loss: 0.202802, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2775 - acc: 0.9688 - val_loss: 0.6731 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "185 [D loss supervised: 0.2775, acc.: 96.88%] [D loss unsupervised: 0.1889, acc.: 100.00%] [G loss: 0.233355, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3526 - acc: 0.9375 - val_loss: 0.6738 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "186 [D loss supervised: 0.3526, acc.: 93.75%] [D loss unsupervised: 0.1827, acc.: 100.00%] [G loss: 0.228480, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2884 - acc: 0.9375 - val_loss: 0.6728 - val_acc: 0.8528\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "187 [D loss supervised: 0.2884, acc.: 93.75%] [D loss unsupervised: 0.1893, acc.: 100.00%] [G loss: 0.196910, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3746 - acc: 0.9375 - val_loss: 0.6699 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "188 [D loss supervised: 0.3746, acc.: 93.75%] [D loss unsupervised: 0.1942, acc.: 100.00%] [G loss: 0.199235, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3055 - acc: 0.9688 - val_loss: 0.6694 - val_acc: 0.8525\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "189 [D loss supervised: 0.3055, acc.: 96.88%] [D loss unsupervised: 0.1842, acc.: 100.00%] [G loss: 0.208844, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3911 - acc: 0.9375 - val_loss: 0.6681 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "190 [D loss supervised: 0.3911, acc.: 93.75%] [D loss unsupervised: 0.1828, acc.: 100.00%] [G loss: 0.210852, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3731 - acc: 0.9375 - val_loss: 0.6577 - val_acc: 0.8560\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "191 [D loss supervised: 0.3731, acc.: 93.75%] [D loss unsupervised: 0.1825, acc.: 100.00%] [G loss: 0.253171, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3317 - acc: 0.9375 - val_loss: 0.6473 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "192 [D loss supervised: 0.3317, acc.: 93.75%] [D loss unsupervised: 0.1831, acc.: 100.00%] [G loss: 0.294286, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3568 - acc: 0.9688 - val_loss: 0.6407 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "193 [D loss supervised: 0.3568, acc.: 96.88%] [D loss unsupervised: 0.1823, acc.: 100.00%] [G loss: 0.239953, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4631 - acc: 0.9062 - val_loss: 0.6380 - val_acc: 0.8616\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "194 [D loss supervised: 0.4631, acc.: 90.62%] [D loss unsupervised: 0.1816, acc.: 100.00%] [G loss: 0.243206, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3706 - acc: 0.9375 - val_loss: 0.6385 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "195 [D loss supervised: 0.3706, acc.: 93.75%] [D loss unsupervised: 0.1827, acc.: 100.00%] [G loss: 0.246963, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3047 - acc: 0.9375 - val_loss: 0.6383 - val_acc: 0.8584\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "196 [D loss supervised: 0.3047, acc.: 93.75%] [D loss unsupervised: 0.1808, acc.: 100.00%] [G loss: 0.249767, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2442 - acc: 1.0000 - val_loss: 0.6415 - val_acc: 0.8559\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "197 [D loss supervised: 0.2442, acc.: 100.00%] [D loss unsupervised: 0.1808, acc.: 100.00%] [G loss: 0.226455, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4332 - acc: 0.9375 - val_loss: 0.6450 - val_acc: 0.8543\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "198 [D loss supervised: 0.4332, acc.: 93.75%] [D loss unsupervised: 0.1814, acc.: 100.00%] [G loss: 0.303439, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4836 - acc: 0.9375 - val_loss: 0.6493 - val_acc: 0.8530\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "199 [D loss supervised: 0.4836, acc.: 93.75%] [D loss unsupervised: 0.1803, acc.: 100.00%] [G loss: 0.221888, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2867 - acc: 0.9688 - val_loss: 0.6537 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "200 [D loss supervised: 0.2867, acc.: 96.88%] [D loss unsupervised: 0.1813, acc.: 100.00%] [G loss: 0.210411, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2726 - acc: 1.0000 - val_loss: 0.6582 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "201 [D loss supervised: 0.2726, acc.: 100.00%] [D loss unsupervised: 0.1830, acc.: 100.00%] [G loss: 0.254184, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4526 - acc: 0.8750 - val_loss: 0.6611 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "202 [D loss supervised: 0.4526, acc.: 87.50%] [D loss unsupervised: 0.1848, acc.: 100.00%] [G loss: 0.201694, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3353 - acc: 1.0000 - val_loss: 0.6597 - val_acc: 0.8498\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "203 [D loss supervised: 0.3353, acc.: 100.00%] [D loss unsupervised: 0.1802, acc.: 100.00%] [G loss: 0.205894, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2964 - acc: 0.9688 - val_loss: 0.6554 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "204 [D loss supervised: 0.2964, acc.: 96.88%] [D loss unsupervised: 0.1821, acc.: 100.00%] [G loss: 0.208413, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3589 - acc: 0.9375 - val_loss: 0.6510 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "205 [D loss supervised: 0.3589, acc.: 93.75%] [D loss unsupervised: 0.1860, acc.: 100.00%] [G loss: 0.210445, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3753 - acc: 0.9062 - val_loss: 0.6455 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "206 [D loss supervised: 0.3753, acc.: 90.62%] [D loss unsupervised: 0.1799, acc.: 100.00%] [G loss: 0.194537, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2679 - acc: 1.0000 - val_loss: 0.6411 - val_acc: 0.8549\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "207 [D loss supervised: 0.2679, acc.: 100.00%] [D loss unsupervised: 0.1807, acc.: 100.00%] [G loss: 0.194039, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2348 - acc: 1.0000 - val_loss: 0.6373 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "208 [D loss supervised: 0.2348, acc.: 100.00%] [D loss unsupervised: 0.1833, acc.: 100.00%] [G loss: 0.214562, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3968 - acc: 0.9375 - val_loss: 0.6329 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "209 [D loss supervised: 0.3968, acc.: 93.75%] [D loss unsupervised: 0.1789, acc.: 100.00%] [G loss: 0.259103, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3537 - acc: 0.9688 - val_loss: 0.6310 - val_acc: 0.8583\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "210 [D loss supervised: 0.3537, acc.: 96.88%] [D loss unsupervised: 0.1797, acc.: 100.00%] [G loss: 0.279172, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3816 - acc: 0.9688 - val_loss: 0.6293 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "211 [D loss supervised: 0.3816, acc.: 96.88%] [D loss unsupervised: 0.1815, acc.: 100.00%] [G loss: 0.204386, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2637 - acc: 1.0000 - val_loss: 0.6297 - val_acc: 0.8596\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "212 [D loss supervised: 0.2637, acc.: 100.00%] [D loss unsupervised: 0.1807, acc.: 100.00%] [G loss: 0.245599, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3912 - acc: 0.9375 - val_loss: 0.6306 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "213 [D loss supervised: 0.3912, acc.: 93.75%] [D loss unsupervised: 0.1782, acc.: 100.00%] [G loss: 0.389351, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2547 - acc: 1.0000 - val_loss: 0.6331 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "214 [D loss supervised: 0.2547, acc.: 100.00%] [D loss unsupervised: 0.1779, acc.: 100.00%] [G loss: 0.230548, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3575 - acc: 0.9062 - val_loss: 0.6369 - val_acc: 0.8611\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "215 [D loss supervised: 0.3575, acc.: 90.62%] [D loss unsupervised: 0.1808, acc.: 100.00%] [G loss: 0.224265, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3692 - acc: 0.9688 - val_loss: 0.6424 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "216 [D loss supervised: 0.3692, acc.: 96.88%] [D loss unsupervised: 0.1779, acc.: 100.00%] [G loss: 0.376576, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2907 - acc: 0.9688 - val_loss: 0.6501 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "217 [D loss supervised: 0.2907, acc.: 96.88%] [D loss unsupervised: 0.1780, acc.: 100.00%] [G loss: 0.213649, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4467 - acc: 0.9062 - val_loss: 0.6580 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "218 [D loss supervised: 0.4467, acc.: 90.62%] [D loss unsupervised: 0.1809, acc.: 100.00%] [G loss: 0.212965, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2963 - acc: 0.9688 - val_loss: 0.6670 - val_acc: 0.8531\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "219 [D loss supervised: 0.2963, acc.: 96.88%] [D loss unsupervised: 0.1810, acc.: 100.00%] [G loss: 0.397975, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2310 - acc: 1.0000 - val_loss: 0.6755 - val_acc: 0.8493\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "220 [D loss supervised: 0.2310, acc.: 100.00%] [D loss unsupervised: 0.1773, acc.: 100.00%] [G loss: 0.224362, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2809 - acc: 0.9688 - val_loss: 0.6814 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "221 [D loss supervised: 0.2809, acc.: 96.88%] [D loss unsupervised: 0.1776, acc.: 100.00%] [G loss: 0.282925, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3885 - acc: 0.9375 - val_loss: 0.6834 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "222 [D loss supervised: 0.3885, acc.: 93.75%] [D loss unsupervised: 0.1770, acc.: 100.00%] [G loss: 0.260175, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4146 - acc: 0.9062 - val_loss: 0.6789 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "223 [D loss supervised: 0.4146, acc.: 90.62%] [D loss unsupervised: 0.1778, acc.: 100.00%] [G loss: 0.296069, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3304 - acc: 0.9688 - val_loss: 0.6741 - val_acc: 0.8513\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "224 [D loss supervised: 0.3304, acc.: 96.88%] [D loss unsupervised: 0.1791, acc.: 100.00%] [G loss: 0.406790, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3849 - acc: 0.9375 - val_loss: 0.6707 - val_acc: 0.8510\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "225 [D loss supervised: 0.3849, acc.: 93.75%] [D loss unsupervised: 0.1795, acc.: 100.00%] [G loss: 0.268861, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2390 - acc: 1.0000 - val_loss: 0.6685 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "226 [D loss supervised: 0.2390, acc.: 100.00%] [D loss unsupervised: 0.1828, acc.: 100.00%] [G loss: 0.433112, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3501 - acc: 0.9688 - val_loss: 0.6675 - val_acc: 0.8516\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "227 [D loss supervised: 0.3501, acc.: 96.88%] [D loss unsupervised: 0.1804, acc.: 100.00%] [G loss: 0.469741, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2605 - acc: 1.0000 - val_loss: 0.6685 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "228 [D loss supervised: 0.2605, acc.: 100.00%] [D loss unsupervised: 0.1784, acc.: 100.00%] [G loss: 1.918772, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4677 - acc: 0.8125 - val_loss: 0.6673 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "229 [D loss supervised: 0.4677, acc.: 81.25%] [D loss unsupervised: 0.1773, acc.: 100.00%] [G loss: 1.407270, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2935 - acc: 1.0000 - val_loss: 0.6668 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "230 [D loss supervised: 0.2935, acc.: 100.00%] [D loss unsupervised: 0.1835, acc.: 100.00%] [G loss: 1.111043, acc.: 50.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3796 - acc: 0.9375 - val_loss: 0.6677 - val_acc: 0.8531\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "231 [D loss supervised: 0.3796, acc.: 93.75%] [D loss unsupervised: 0.1782, acc.: 100.00%] [G loss: 0.504281, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3619 - acc: 0.9375 - val_loss: 0.6654 - val_acc: 0.8513\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "232 [D loss supervised: 0.3619, acc.: 93.75%] [D loss unsupervised: 0.1822, acc.: 100.00%] [G loss: 0.696184, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2880 - acc: 1.0000 - val_loss: 0.6627 - val_acc: 0.8527\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "233 [D loss supervised: 0.2880, acc.: 100.00%] [D loss unsupervised: 0.1799, acc.: 100.00%] [G loss: 0.876953, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4407 - acc: 0.9062 - val_loss: 0.6582 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "234 [D loss supervised: 0.4407, acc.: 90.62%] [D loss unsupervised: 0.2005, acc.: 98.44%] [G loss: 0.672852, acc.: 71.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3146 - acc: 1.0000 - val_loss: 0.6539 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "235 [D loss supervised: 0.3146, acc.: 100.00%] [D loss unsupervised: 0.1774, acc.: 100.00%] [G loss: 0.404501, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2451 - acc: 1.0000 - val_loss: 0.6501 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "236 [D loss supervised: 0.2451, acc.: 100.00%] [D loss unsupervised: 0.1759, acc.: 100.00%] [G loss: 0.520752, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2824 - acc: 1.0000 - val_loss: 0.6484 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "237 [D loss supervised: 0.2824, acc.: 100.00%] [D loss unsupervised: 0.1769, acc.: 100.00%] [G loss: 0.668116, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2763 - acc: 1.0000 - val_loss: 0.6496 - val_acc: 0.8565\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "238 [D loss supervised: 0.2763, acc.: 100.00%] [D loss unsupervised: 0.1801, acc.: 100.00%] [G loss: 0.805557, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3715 - acc: 0.9062 - val_loss: 0.6530 - val_acc: 0.8569\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "239 [D loss supervised: 0.3715, acc.: 90.62%] [D loss unsupervised: 0.1761, acc.: 100.00%] [G loss: 2.572074, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2527 - acc: 1.0000 - val_loss: 0.6589 - val_acc: 0.8554\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "240 [D loss supervised: 0.2527, acc.: 100.00%] [D loss unsupervised: 0.1830, acc.: 100.00%] [G loss: 2.996155, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3641 - acc: 0.9688 - val_loss: 0.6675 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "241 [D loss supervised: 0.3641, acc.: 96.88%] [D loss unsupervised: 0.1767, acc.: 100.00%] [G loss: 1.944279, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3168 - acc: 0.9688 - val_loss: 0.6786 - val_acc: 0.8501\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "242 [D loss supervised: 0.3168, acc.: 96.88%] [D loss unsupervised: 0.1751, acc.: 100.00%] [G loss: 2.000528, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2790 - acc: 1.0000 - val_loss: 0.6902 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "243 [D loss supervised: 0.2790, acc.: 100.00%] [D loss unsupervised: 0.1742, acc.: 100.00%] [G loss: 1.099450, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3209 - acc: 0.9688 - val_loss: 0.7017 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "244 [D loss supervised: 0.3209, acc.: 96.88%] [D loss unsupervised: 0.1741, acc.: 100.00%] [G loss: 1.344966, acc.: 43.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2402 - acc: 1.0000 - val_loss: 0.7147 - val_acc: 0.8405\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "245 [D loss supervised: 0.2402, acc.: 100.00%] [D loss unsupervised: 0.1741, acc.: 100.00%] [G loss: 1.168115, acc.: 59.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2250 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "246 [D loss supervised: 0.2250, acc.: 100.00%] [D loss unsupervised: 0.1906, acc.: 100.00%] [G loss: 0.800429, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3079 - acc: 0.9375 - val_loss: 0.7400 - val_acc: 0.8358\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "247 [D loss supervised: 0.3079, acc.: 93.75%] [D loss unsupervised: 0.1733, acc.: 100.00%] [G loss: 1.048049, acc.: 62.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4442 - acc: 0.9062 - val_loss: 0.7469 - val_acc: 0.8350\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "248 [D loss supervised: 0.4442, acc.: 90.62%] [D loss unsupervised: 0.1764, acc.: 100.00%] [G loss: 0.605763, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2853 - acc: 0.9688 - val_loss: 0.7581 - val_acc: 0.8329\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "249 [D loss supervised: 0.2853, acc.: 96.88%] [D loss unsupervised: 0.1755, acc.: 100.00%] [G loss: 0.566263, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3852 - acc: 0.9375 - val_loss: 0.7653 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "250 [D loss supervised: 0.3852, acc.: 93.75%] [D loss unsupervised: 0.1734, acc.: 100.00%] [G loss: 0.293063, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2978 - acc: 1.0000 - val_loss: 0.7737 - val_acc: 0.8300\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "251 [D loss supervised: 0.2978, acc.: 100.00%] [D loss unsupervised: 0.1732, acc.: 100.00%] [G loss: 0.632126, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3617 - acc: 0.9688 - val_loss: 0.7845 - val_acc: 0.8264\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "252 [D loss supervised: 0.3617, acc.: 96.88%] [D loss unsupervised: 0.1844, acc.: 100.00%] [G loss: 0.612837, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3852 - acc: 0.9062 - val_loss: 0.7860 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "253 [D loss supervised: 0.3852, acc.: 90.62%] [D loss unsupervised: 0.1734, acc.: 100.00%] [G loss: 0.706996, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4115 - acc: 0.9375 - val_loss: 0.7805 - val_acc: 0.8259\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "254 [D loss supervised: 0.4115, acc.: 93.75%] [D loss unsupervised: 0.1756, acc.: 100.00%] [G loss: 0.559516, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3644 - acc: 0.9688 - val_loss: 0.7792 - val_acc: 0.8263\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "255 [D loss supervised: 0.3644, acc.: 96.88%] [D loss unsupervised: 0.1733, acc.: 100.00%] [G loss: 0.376396, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3950 - acc: 0.9375 - val_loss: 0.7738 - val_acc: 0.8282\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "256 [D loss supervised: 0.3950, acc.: 93.75%] [D loss unsupervised: 0.1724, acc.: 100.00%] [G loss: 0.699161, acc.: 75.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4330 - acc: 0.8750 - val_loss: 0.7595 - val_acc: 0.8314\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "257 [D loss supervised: 0.4330, acc.: 87.50%] [D loss unsupervised: 0.1712, acc.: 100.00%] [G loss: 0.593054, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3780 - acc: 0.9375 - val_loss: 0.7296 - val_acc: 0.8380\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "258 [D loss supervised: 0.3780, acc.: 93.75%] [D loss unsupervised: 0.1713, acc.: 100.00%] [G loss: 0.331796, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4104 - acc: 0.9062 - val_loss: 0.7060 - val_acc: 0.8434\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "259 [D loss supervised: 0.4104, acc.: 90.62%] [D loss unsupervised: 0.1711, acc.: 100.00%] [G loss: 0.534459, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3210 - acc: 0.9375 - val_loss: 0.6853 - val_acc: 0.8483\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "260 [D loss supervised: 0.3210, acc.: 93.75%] [D loss unsupervised: 0.1707, acc.: 100.00%] [G loss: 0.612633, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2868 - acc: 0.9688 - val_loss: 0.6664 - val_acc: 0.8521\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "261 [D loss supervised: 0.2868, acc.: 96.88%] [D loss unsupervised: 0.1709, acc.: 100.00%] [G loss: 0.363803, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2913 - acc: 0.9688 - val_loss: 0.6558 - val_acc: 0.8538\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "262 [D loss supervised: 0.2913, acc.: 96.88%] [D loss unsupervised: 0.1712, acc.: 100.00%] [G loss: 0.458299, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2892 - acc: 0.9688 - val_loss: 0.6503 - val_acc: 0.8555\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "263 [D loss supervised: 0.2892, acc.: 96.88%] [D loss unsupervised: 0.1709, acc.: 100.00%] [G loss: 0.449144, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2428 - acc: 1.0000 - val_loss: 0.6485 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "264 [D loss supervised: 0.2428, acc.: 100.00%] [D loss unsupervised: 0.1705, acc.: 100.00%] [G loss: 0.302191, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4171 - acc: 0.9062 - val_loss: 0.6505 - val_acc: 0.8549\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "265 [D loss supervised: 0.4171, acc.: 90.62%] [D loss unsupervised: 0.1758, acc.: 100.00%] [G loss: 0.264099, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2615 - acc: 1.0000 - val_loss: 0.6544 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "266 [D loss supervised: 0.2615, acc.: 100.00%] [D loss unsupervised: 0.1694, acc.: 100.00%] [G loss: 0.257174, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2358 - acc: 1.0000 - val_loss: 0.6604 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "267 [D loss supervised: 0.2358, acc.: 100.00%] [D loss unsupervised: 0.1779, acc.: 100.00%] [G loss: 0.464080, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3693 - acc: 0.9375 - val_loss: 0.6652 - val_acc: 0.8516\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "268 [D loss supervised: 0.3693, acc.: 93.75%] [D loss unsupervised: 0.1704, acc.: 100.00%] [G loss: 0.383687, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4360 - acc: 0.9375 - val_loss: 0.6690 - val_acc: 0.8493\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "269 [D loss supervised: 0.4360, acc.: 93.75%] [D loss unsupervised: 0.1707, acc.: 100.00%] [G loss: 0.273488, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2974 - acc: 0.9688 - val_loss: 0.6717 - val_acc: 0.8497\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "270 [D loss supervised: 0.2974, acc.: 96.88%] [D loss unsupervised: 0.1693, acc.: 100.00%] [G loss: 0.278982, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2995 - acc: 0.9688 - val_loss: 0.6770 - val_acc: 0.8486\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "271 [D loss supervised: 0.2995, acc.: 96.88%] [D loss unsupervised: 0.1696, acc.: 100.00%] [G loss: 0.269656, acc.: 93.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2542 - acc: 1.0000 - val_loss: 0.6823 - val_acc: 0.8477\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "272 [D loss supervised: 0.2542, acc.: 100.00%] [D loss unsupervised: 0.1685, acc.: 100.00%] [G loss: 0.324545, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4098 - acc: 0.9375 - val_loss: 0.6852 - val_acc: 0.8469\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "273 [D loss supervised: 0.4098, acc.: 93.75%] [D loss unsupervised: 0.1696, acc.: 100.00%] [G loss: 0.256478, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2421 - acc: 1.0000 - val_loss: 0.6879 - val_acc: 0.8464\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "274 [D loss supervised: 0.2421, acc.: 100.00%] [D loss unsupervised: 0.1680, acc.: 100.00%] [G loss: 0.352953, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4109 - acc: 0.9062 - val_loss: 0.6902 - val_acc: 0.8454\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "275 [D loss supervised: 0.4109, acc.: 90.62%] [D loss unsupervised: 0.1681, acc.: 100.00%] [G loss: 0.266654, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2221 - acc: 1.0000 - val_loss: 0.6939 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "276 [D loss supervised: 0.2221, acc.: 100.00%] [D loss unsupervised: 0.1676, acc.: 100.00%] [G loss: 0.359775, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4414 - acc: 0.9062 - val_loss: 0.6985 - val_acc: 0.8417\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "277 [D loss supervised: 0.4414, acc.: 90.62%] [D loss unsupervised: 0.1691, acc.: 100.00%] [G loss: 0.287203, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2655 - acc: 1.0000 - val_loss: 0.7050 - val_acc: 0.8403\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "278 [D loss supervised: 0.2655, acc.: 100.00%] [D loss unsupervised: 0.1672, acc.: 100.00%] [G loss: 0.542694, acc.: 84.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3244 - acc: 0.9375 - val_loss: 0.7088 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "279 [D loss supervised: 0.3244, acc.: 93.75%] [D loss unsupervised: 0.1691, acc.: 100.00%] [G loss: 0.613879, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3546 - acc: 0.9375 - val_loss: 0.7108 - val_acc: 0.8378\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "280 [D loss supervised: 0.3546, acc.: 93.75%] [D loss unsupervised: 0.1669, acc.: 100.00%] [G loss: 0.254461, acc.: 100.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2518 - acc: 1.0000 - val_loss: 0.7140 - val_acc: 0.8364\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "281 [D loss supervised: 0.2518, acc.: 100.00%] [D loss unsupervised: 0.1680, acc.: 100.00%] [G loss: 0.350174, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3814 - acc: 0.9375 - val_loss: 0.7138 - val_acc: 0.8367\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "282 [D loss supervised: 0.3814, acc.: 93.75%] [D loss unsupervised: 0.1667, acc.: 100.00%] [G loss: 0.359523, acc.: 96.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3081 - acc: 0.9688 - val_loss: 0.7097 - val_acc: 0.8384\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "283 [D loss supervised: 0.3081, acc.: 96.88%] [D loss unsupervised: 0.1670, acc.: 100.00%] [G loss: 0.540897, acc.: 90.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3098 - acc: 0.9688 - val_loss: 0.7114 - val_acc: 0.8378\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "284 [D loss supervised: 0.3098, acc.: 96.88%] [D loss unsupervised: 0.1668, acc.: 100.00%] [G loss: 0.664151, acc.: 81.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2807 - acc: 0.9688 - val_loss: 0.7135 - val_acc: 0.8376\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "285 [D loss supervised: 0.2807, acc.: 96.88%] [D loss unsupervised: 0.1669, acc.: 100.00%] [G loss: 0.800738, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4104 - acc: 0.9688 - val_loss: 0.7122 - val_acc: 0.8373\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "286 [D loss supervised: 0.4104, acc.: 96.88%] [D loss unsupervised: 0.1661, acc.: 100.00%] [G loss: 0.537691, acc.: 87.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2670 - acc: 1.0000 - val_loss: 0.7083 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "287 [D loss supervised: 0.2670, acc.: 100.00%] [D loss unsupervised: 0.1668, acc.: 100.00%] [G loss: 0.747716, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2753 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.8396\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "288 [D loss supervised: 0.2753, acc.: 100.00%] [D loss unsupervised: 0.1659, acc.: 100.00%] [G loss: 1.402482, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3673 - acc: 0.9375 - val_loss: 0.6962 - val_acc: 0.8414\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "289 [D loss supervised: 0.3673, acc.: 93.75%] [D loss unsupervised: 0.1668, acc.: 100.00%] [G loss: 0.643325, acc.: 78.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3570 - acc: 0.9688 - val_loss: 0.6942 - val_acc: 0.8407\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "290 [D loss supervised: 0.3570, acc.: 96.88%] [D loss unsupervised: 0.1671, acc.: 100.00%] [G loss: 1.278895, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2709 - acc: 1.0000 - val_loss: 0.6920 - val_acc: 0.8434\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "291 [D loss supervised: 0.2709, acc.: 100.00%] [D loss unsupervised: 0.1664, acc.: 100.00%] [G loss: 1.427744, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2531 - acc: 1.0000 - val_loss: 0.6936 - val_acc: 0.8426\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "292 [D loss supervised: 0.2531, acc.: 100.00%] [D loss unsupervised: 0.1670, acc.: 100.00%] [G loss: 0.821489, acc.: 68.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2633 - acc: 1.0000 - val_loss: 0.6960 - val_acc: 0.8442\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "293 [D loss supervised: 0.2633, acc.: 100.00%] [D loss unsupervised: 0.1658, acc.: 100.00%] [G loss: 1.776463, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2473 - acc: 1.0000 - val_loss: 0.6977 - val_acc: 0.8448\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "294 [D loss supervised: 0.2473, acc.: 100.00%] [D loss unsupervised: 0.1653, acc.: 100.00%] [G loss: 2.199261, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3225 - acc: 0.9688 - val_loss: 0.7006 - val_acc: 0.8428\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "295 [D loss supervised: 0.3225, acc.: 96.88%] [D loss unsupervised: 0.1668, acc.: 100.00%] [G loss: 1.099059, acc.: 50.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2757 - acc: 1.0000 - val_loss: 0.7024 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "296 [D loss supervised: 0.2757, acc.: 100.00%] [D loss unsupervised: 0.1657, acc.: 100.00%] [G loss: 1.987286, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2377 - acc: 1.0000 - val_loss: 0.7049 - val_acc: 0.8414\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "297 [D loss supervised: 0.2377, acc.: 100.00%] [D loss unsupervised: 0.1697, acc.: 100.00%] [G loss: 1.735085, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3714 - acc: 0.9688 - val_loss: 0.7038 - val_acc: 0.8416\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "298 [D loss supervised: 0.3714, acc.: 96.88%] [D loss unsupervised: 0.1660, acc.: 100.00%] [G loss: 1.375732, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5475 - acc: 0.7812 - val_loss: 0.6933 - val_acc: 0.8442\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "299 [D loss supervised: 0.5475, acc.: 78.12%] [D loss unsupervised: 0.1703, acc.: 100.00%] [G loss: 2.571230, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3273 - acc: 0.9688 - val_loss: 0.6886 - val_acc: 0.8447\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "300 [D loss supervised: 0.3273, acc.: 96.88%] [D loss unsupervised: 0.1656, acc.: 100.00%] [G loss: 3.750202, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2623 - acc: 1.0000 - val_loss: 0.6851 - val_acc: 0.8456\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "301 [D loss supervised: 0.2623, acc.: 100.00%] [D loss unsupervised: 0.1661, acc.: 100.00%] [G loss: 4.190045, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2852 - acc: 1.0000 - val_loss: 0.6803 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "302 [D loss supervised: 0.2852, acc.: 100.00%] [D loss unsupervised: 0.1670, acc.: 100.00%] [G loss: 3.624425, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2527 - acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.8452\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "303 [D loss supervised: 0.2527, acc.: 100.00%] [D loss unsupervised: 0.1692, acc.: 100.00%] [G loss: 2.806790, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3425 - acc: 0.9375 - val_loss: 0.6767 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "304 [D loss supervised: 0.3425, acc.: 93.75%] [D loss unsupervised: 0.1761, acc.: 100.00%] [G loss: 2.003493, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3110 - acc: 0.9688 - val_loss: 0.6725 - val_acc: 0.8475\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "305 [D loss supervised: 0.3110, acc.: 96.88%] [D loss unsupervised: 0.1713, acc.: 100.00%] [G loss: 2.283381, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2510 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 0.8476\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "306 [D loss supervised: 0.2510, acc.: 100.00%] [D loss unsupervised: 0.1782, acc.: 100.00%] [G loss: 1.937716, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3729 - acc: 0.9688 - val_loss: 0.6673 - val_acc: 0.8478\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "307 [D loss supervised: 0.3729, acc.: 96.88%] [D loss unsupervised: 0.1662, acc.: 100.00%] [G loss: 2.071823, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2813 - acc: 1.0000 - val_loss: 0.6670 - val_acc: 0.8485\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "308 [D loss supervised: 0.2813, acc.: 100.00%] [D loss unsupervised: 0.1652, acc.: 100.00%] [G loss: 2.144446, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3043 - acc: 0.9688 - val_loss: 0.6717 - val_acc: 0.8477\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "309 [D loss supervised: 0.3043, acc.: 96.88%] [D loss unsupervised: 0.1663, acc.: 100.00%] [G loss: 1.929560, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3117 - acc: 0.9688 - val_loss: 0.6767 - val_acc: 0.8457\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "310 [D loss supervised: 0.3117, acc.: 96.88%] [D loss unsupervised: 0.1677, acc.: 100.00%] [G loss: 2.389674, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4195 - acc: 0.9688 - val_loss: 0.6835 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "311 [D loss supervised: 0.4195, acc.: 96.88%] [D loss unsupervised: 0.1637, acc.: 100.00%] [G loss: 1.888204, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2226 - acc: 1.0000 - val_loss: 0.6903 - val_acc: 0.8440\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "312 [D loss supervised: 0.2226, acc.: 100.00%] [D loss unsupervised: 0.1643, acc.: 100.00%] [G loss: 2.098484, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2653 - acc: 1.0000 - val_loss: 0.6953 - val_acc: 0.8432\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "313 [D loss supervised: 0.2653, acc.: 100.00%] [D loss unsupervised: 0.1637, acc.: 100.00%] [G loss: 2.415478, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2692 - acc: 0.9688 - val_loss: 0.6984 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "314 [D loss supervised: 0.2692, acc.: 96.88%] [D loss unsupervised: 0.1645, acc.: 100.00%] [G loss: 2.503240, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2510 - acc: 1.0000 - val_loss: 0.7019 - val_acc: 0.8436\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "315 [D loss supervised: 0.2510, acc.: 100.00%] [D loss unsupervised: 0.1733, acc.: 100.00%] [G loss: 2.712358, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2582 - acc: 1.0000 - val_loss: 0.7056 - val_acc: 0.8429\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "316 [D loss supervised: 0.2582, acc.: 100.00%] [D loss unsupervised: 0.1643, acc.: 100.00%] [G loss: 3.908401, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3157 - acc: 1.0000 - val_loss: 0.7083 - val_acc: 0.8421\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "317 [D loss supervised: 0.3157, acc.: 100.00%] [D loss unsupervised: 0.1624, acc.: 100.00%] [G loss: 4.493382, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3376 - acc: 0.9375 - val_loss: 0.7080 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "318 [D loss supervised: 0.3376, acc.: 93.75%] [D loss unsupervised: 0.1621, acc.: 100.00%] [G loss: 3.596434, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3272 - acc: 0.9375 - val_loss: 0.7052 - val_acc: 0.8446\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "319 [D loss supervised: 0.3272, acc.: 93.75%] [D loss unsupervised: 0.1620, acc.: 100.00%] [G loss: 3.337653, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2935 - acc: 1.0000 - val_loss: 0.7033 - val_acc: 0.8455\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "320 [D loss supervised: 0.2935, acc.: 100.00%] [D loss unsupervised: 0.1742, acc.: 98.44%] [G loss: 2.666442, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3687 - acc: 0.9375 - val_loss: 0.6994 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "321 [D loss supervised: 0.3687, acc.: 93.75%] [D loss unsupervised: 0.1680, acc.: 100.00%] [G loss: 2.819689, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3197 - acc: 0.9688 - val_loss: 0.6969 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "322 [D loss supervised: 0.3197, acc.: 96.88%] [D loss unsupervised: 0.1624, acc.: 100.00%] [G loss: 3.654212, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3249 - acc: 0.9688 - val_loss: 0.6916 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "323 [D loss supervised: 0.3249, acc.: 96.88%] [D loss unsupervised: 0.1623, acc.: 100.00%] [G loss: 2.816136, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3208 - acc: 0.9688 - val_loss: 0.6876 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "324 [D loss supervised: 0.3208, acc.: 96.88%] [D loss unsupervised: 0.1639, acc.: 100.00%] [G loss: 2.760268, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2679 - acc: 0.9688 - val_loss: 0.6852 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "325 [D loss supervised: 0.2679, acc.: 96.88%] [D loss unsupervised: 0.1630, acc.: 100.00%] [G loss: 3.443612, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2374 - acc: 1.0000 - val_loss: 0.6839 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "326 [D loss supervised: 0.2374, acc.: 100.00%] [D loss unsupervised: 0.1616, acc.: 100.00%] [G loss: 3.249836, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2559 - acc: 1.0000 - val_loss: 0.6830 - val_acc: 0.8533\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "327 [D loss supervised: 0.2559, acc.: 100.00%] [D loss unsupervised: 0.1622, acc.: 100.00%] [G loss: 3.019246, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2799 - acc: 0.9688 - val_loss: 0.6799 - val_acc: 0.8533\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "328 [D loss supervised: 0.2799, acc.: 96.88%] [D loss unsupervised: 0.1642, acc.: 100.00%] [G loss: 3.172407, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2690 - acc: 1.0000 - val_loss: 0.6771 - val_acc: 0.8545\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "329 [D loss supervised: 0.2690, acc.: 100.00%] [D loss unsupervised: 0.1620, acc.: 100.00%] [G loss: 3.282761, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2694 - acc: 0.9688 - val_loss: 0.6754 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "330 [D loss supervised: 0.2694, acc.: 96.88%] [D loss unsupervised: 0.1607, acc.: 100.00%] [G loss: 2.836027, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2751 - acc: 0.9688 - val_loss: 0.6755 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "331 [D loss supervised: 0.2751, acc.: 96.88%] [D loss unsupervised: 0.1631, acc.: 100.00%] [G loss: 2.609496, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2111 - acc: 1.0000 - val_loss: 0.6768 - val_acc: 0.8520\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "332 [D loss supervised: 0.2111, acc.: 100.00%] [D loss unsupervised: 0.1610, acc.: 100.00%] [G loss: 2.534936, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2426 - acc: 1.0000 - val_loss: 0.6786 - val_acc: 0.8499\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "333 [D loss supervised: 0.2426, acc.: 100.00%] [D loss unsupervised: 0.1618, acc.: 100.00%] [G loss: 2.855857, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2514 - acc: 1.0000 - val_loss: 0.6815 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "334 [D loss supervised: 0.2514, acc.: 100.00%] [D loss unsupervised: 0.1624, acc.: 100.00%] [G loss: 2.753378, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2579 - acc: 1.0000 - val_loss: 0.6857 - val_acc: 0.8474\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "335 [D loss supervised: 0.2579, acc.: 100.00%] [D loss unsupervised: 0.1614, acc.: 100.00%] [G loss: 3.662387, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2480 - acc: 1.0000 - val_loss: 0.6904 - val_acc: 0.8453\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "336 [D loss supervised: 0.2480, acc.: 100.00%] [D loss unsupervised: 0.1660, acc.: 100.00%] [G loss: 3.041087, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3409 - acc: 0.9688 - val_loss: 0.6908 - val_acc: 0.8453\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "337 [D loss supervised: 0.3409, acc.: 96.88%] [D loss unsupervised: 0.1629, acc.: 100.00%] [G loss: 2.672217, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2280 - acc: 1.0000 - val_loss: 0.6918 - val_acc: 0.8449\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "338 [D loss supervised: 0.2280, acc.: 100.00%] [D loss unsupervised: 0.1613, acc.: 100.00%] [G loss: 2.524186, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2965 - acc: 0.9688 - val_loss: 0.6906 - val_acc: 0.8458\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "339 [D loss supervised: 0.2965, acc.: 96.88%] [D loss unsupervised: 0.1623, acc.: 100.00%] [G loss: 2.624174, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2452 - acc: 1.0000 - val_loss: 0.6893 - val_acc: 0.8465\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "340 [D loss supervised: 0.2452, acc.: 100.00%] [D loss unsupervised: 0.1610, acc.: 100.00%] [G loss: 2.698624, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3019 - acc: 0.9375 - val_loss: 0.6830 - val_acc: 0.8496\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "341 [D loss supervised: 0.3019, acc.: 93.75%] [D loss unsupervised: 0.1612, acc.: 100.00%] [G loss: 1.669277, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2693 - acc: 1.0000 - val_loss: 0.6751 - val_acc: 0.8522\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "342 [D loss supervised: 0.2693, acc.: 100.00%] [D loss unsupervised: 0.1704, acc.: 100.00%] [G loss: 4.340105, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2313 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.8526\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "343 [D loss supervised: 0.2313, acc.: 100.00%] [D loss unsupervised: 0.1663, acc.: 100.00%] [G loss: 5.235507, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2628 - acc: 0.9688 - val_loss: 0.6631 - val_acc: 0.8532\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "344 [D loss supervised: 0.2628, acc.: 96.88%] [D loss unsupervised: 0.1854, acc.: 98.44%] [G loss: 5.492744, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3989 - acc: 0.9688 - val_loss: 0.6598 - val_acc: 0.8557\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "345 [D loss supervised: 0.3989, acc.: 96.88%] [D loss unsupervised: 0.1618, acc.: 100.00%] [G loss: 5.442096, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2877 - acc: 0.9688 - val_loss: 0.6575 - val_acc: 0.8560\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "346 [D loss supervised: 0.2877, acc.: 96.88%] [D loss unsupervised: 0.1628, acc.: 100.00%] [G loss: 5.697756, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3193 - acc: 0.9375 - val_loss: 0.6568 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "347 [D loss supervised: 0.3193, acc.: 93.75%] [D loss unsupervised: 0.1581, acc.: 100.00%] [G loss: 5.394989, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2997 - acc: 0.9688 - val_loss: 0.6588 - val_acc: 0.8546\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "348 [D loss supervised: 0.2997, acc.: 96.88%] [D loss unsupervised: 0.1576, acc.: 100.00%] [G loss: 5.322198, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4745 - acc: 0.9062 - val_loss: 0.6619 - val_acc: 0.8540\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "349 [D loss supervised: 0.4745, acc.: 90.62%] [D loss unsupervised: 0.1678, acc.: 100.00%] [G loss: 5.165796, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3399 - acc: 0.9688 - val_loss: 0.6642 - val_acc: 0.8523\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "350 [D loss supervised: 0.3399, acc.: 96.88%] [D loss unsupervised: 0.1576, acc.: 100.00%] [G loss: 4.754653, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2516 - acc: 1.0000 - val_loss: 0.6690 - val_acc: 0.8524\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "351 [D loss supervised: 0.2516, acc.: 100.00%] [D loss unsupervised: 0.1610, acc.: 100.00%] [G loss: 4.092860, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2894 - acc: 0.9688 - val_loss: 0.6740 - val_acc: 0.8508\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "352 [D loss supervised: 0.2894, acc.: 96.88%] [D loss unsupervised: 0.1585, acc.: 100.00%] [G loss: 4.107539, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3900 - acc: 0.9375 - val_loss: 0.6781 - val_acc: 0.8505\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "353 [D loss supervised: 0.3900, acc.: 93.75%] [D loss unsupervised: 0.1587, acc.: 100.00%] [G loss: 3.533521, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2504 - acc: 1.0000 - val_loss: 0.6827 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "354 [D loss supervised: 0.2504, acc.: 100.00%] [D loss unsupervised: 0.1712, acc.: 100.00%] [G loss: 3.594002, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2948 - acc: 0.9688 - val_loss: 0.6846 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "355 [D loss supervised: 0.2948, acc.: 96.88%] [D loss unsupervised: 0.1569, acc.: 100.00%] [G loss: 3.686290, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3592 - acc: 0.9375 - val_loss: 0.6896 - val_acc: 0.8482\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "356 [D loss supervised: 0.3592, acc.: 93.75%] [D loss unsupervised: 0.1572, acc.: 100.00%] [G loss: 3.348302, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3714 - acc: 0.9375 - val_loss: 0.6947 - val_acc: 0.8488\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "357 [D loss supervised: 0.3714, acc.: 93.75%] [D loss unsupervised: 0.1570, acc.: 100.00%] [G loss: 3.466629, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2335 - acc: 1.0000 - val_loss: 0.6998 - val_acc: 0.8481\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "358 [D loss supervised: 0.2335, acc.: 100.00%] [D loss unsupervised: 0.1597, acc.: 100.00%] [G loss: 3.709291, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2647 - acc: 0.9688 - val_loss: 0.7051 - val_acc: 0.8484\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "359 [D loss supervised: 0.2647, acc.: 96.88%] [D loss unsupervised: 0.1556, acc.: 100.00%] [G loss: 3.690846, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2297 - acc: 1.0000 - val_loss: 0.7142 - val_acc: 0.8453\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "360 [D loss supervised: 0.2297, acc.: 100.00%] [D loss unsupervised: 0.1552, acc.: 100.00%] [G loss: 3.862269, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2388 - acc: 1.0000 - val_loss: 0.7254 - val_acc: 0.8419\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "361 [D loss supervised: 0.2388, acc.: 100.00%] [D loss unsupervised: 0.1552, acc.: 100.00%] [G loss: 3.894103, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3270 - acc: 0.9688 - val_loss: 0.7363 - val_acc: 0.8399\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "362 [D loss supervised: 0.3270, acc.: 96.88%] [D loss unsupervised: 0.1544, acc.: 100.00%] [G loss: 4.062887, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2900 - acc: 0.9688 - val_loss: 0.7478 - val_acc: 0.8365\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "363 [D loss supervised: 0.2900, acc.: 96.88%] [D loss unsupervised: 0.1555, acc.: 100.00%] [G loss: 3.587575, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3414 - acc: 0.9375 - val_loss: 0.7592 - val_acc: 0.8342\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "364 [D loss supervised: 0.3414, acc.: 93.75%] [D loss unsupervised: 0.1552, acc.: 100.00%] [G loss: 3.461124, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3266 - acc: 0.9375 - val_loss: 0.7711 - val_acc: 0.8313\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "365 [D loss supervised: 0.3266, acc.: 93.75%] [D loss unsupervised: 0.1541, acc.: 100.00%] [G loss: 3.225020, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2462 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.8280\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "366 [D loss supervised: 0.2462, acc.: 100.00%] [D loss unsupervised: 0.1540, acc.: 100.00%] [G loss: 3.540123, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2575 - acc: 0.9688 - val_loss: 0.7971 - val_acc: 0.8261\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "367 [D loss supervised: 0.2575, acc.: 96.88%] [D loss unsupervised: 0.1539, acc.: 100.00%] [G loss: 3.476610, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2360 - acc: 1.0000 - val_loss: 0.8096 - val_acc: 0.8232\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "368 [D loss supervised: 0.2360, acc.: 100.00%] [D loss unsupervised: 0.1546, acc.: 100.00%] [G loss: 2.924460, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5089 - acc: 0.9062 - val_loss: 0.8248 - val_acc: 0.8182\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "369 [D loss supervised: 0.5089, acc.: 90.62%] [D loss unsupervised: 0.1538, acc.: 100.00%] [G loss: 2.785222, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2117 - acc: 1.0000 - val_loss: 0.8364 - val_acc: 0.8166\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "370 [D loss supervised: 0.2117, acc.: 100.00%] [D loss unsupervised: 0.1529, acc.: 100.00%] [G loss: 2.634441, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2440 - acc: 1.0000 - val_loss: 0.8455 - val_acc: 0.8144\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "371 [D loss supervised: 0.2440, acc.: 100.00%] [D loss unsupervised: 0.1630, acc.: 100.00%] [G loss: 3.149295, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3517 - acc: 0.9688 - val_loss: 0.8510 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "372 [D loss supervised: 0.3517, acc.: 96.88%] [D loss unsupervised: 0.1526, acc.: 100.00%] [G loss: 2.881303, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2790 - acc: 0.9688 - val_loss: 0.8533 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "373 [D loss supervised: 0.2790, acc.: 96.88%] [D loss unsupervised: 0.1521, acc.: 100.00%] [G loss: 3.009426, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2218 - acc: 1.0000 - val_loss: 0.8541 - val_acc: 0.8129\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "374 [D loss supervised: 0.2218, acc.: 100.00%] [D loss unsupervised: 0.1520, acc.: 100.00%] [G loss: 2.955455, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2817 - acc: 0.9688 - val_loss: 0.8612 - val_acc: 0.8121\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "375 [D loss supervised: 0.2817, acc.: 96.88%] [D loss unsupervised: 0.1525, acc.: 100.00%] [G loss: 2.211748, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2761 - acc: 1.0000 - val_loss: 0.8651 - val_acc: 0.8113\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "376 [D loss supervised: 0.2761, acc.: 100.00%] [D loss unsupervised: 0.1516, acc.: 100.00%] [G loss: 2.608203, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3885 - acc: 0.9062 - val_loss: 0.8589 - val_acc: 0.8131\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "377 [D loss supervised: 0.3885, acc.: 90.62%] [D loss unsupervised: 0.1515, acc.: 100.00%] [G loss: 2.669611, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3561 - acc: 0.9375 - val_loss: 0.8499 - val_acc: 0.8159\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "378 [D loss supervised: 0.3561, acc.: 93.75%] [D loss unsupervised: 0.1520, acc.: 100.00%] [G loss: 2.696965, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3964 - acc: 0.9375 - val_loss: 0.8337 - val_acc: 0.8183\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "379 [D loss supervised: 0.3964, acc.: 93.75%] [D loss unsupervised: 0.1513, acc.: 100.00%] [G loss: 2.621931, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2520 - acc: 1.0000 - val_loss: 0.8161 - val_acc: 0.8228\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "380 [D loss supervised: 0.2520, acc.: 100.00%] [D loss unsupervised: 0.1512, acc.: 100.00%] [G loss: 2.034041, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2262 - acc: 1.0000 - val_loss: 0.8011 - val_acc: 0.8275\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "381 [D loss supervised: 0.2262, acc.: 100.00%] [D loss unsupervised: 0.1512, acc.: 100.00%] [G loss: 1.971328, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2903 - acc: 0.9688 - val_loss: 0.7817 - val_acc: 0.8306\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "382 [D loss supervised: 0.2903, acc.: 96.88%] [D loss unsupervised: 0.1510, acc.: 100.00%] [G loss: 2.264974, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2553 - acc: 1.0000 - val_loss: 0.7655 - val_acc: 0.8332\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "383 [D loss supervised: 0.2553, acc.: 100.00%] [D loss unsupervised: 0.1507, acc.: 100.00%] [G loss: 1.910738, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4048 - acc: 0.8750 - val_loss: 0.7520 - val_acc: 0.8362\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "384 [D loss supervised: 0.4048, acc.: 87.50%] [D loss unsupervised: 0.1505, acc.: 100.00%] [G loss: 2.457308, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2358 - acc: 0.9688 - val_loss: 0.7394 - val_acc: 0.8406\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "385 [D loss supervised: 0.2358, acc.: 96.88%] [D loss unsupervised: 0.1508, acc.: 100.00%] [G loss: 2.360926, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3001 - acc: 0.9688 - val_loss: 0.7283 - val_acc: 0.8429\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "386 [D loss supervised: 0.3001, acc.: 96.88%] [D loss unsupervised: 0.1506, acc.: 100.00%] [G loss: 1.781089, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2780 - acc: 1.0000 - val_loss: 0.7191 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "387 [D loss supervised: 0.2780, acc.: 100.00%] [D loss unsupervised: 0.1498, acc.: 100.00%] [G loss: 2.109504, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4583 - acc: 0.9375 - val_loss: 0.7092 - val_acc: 0.8470\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "388 [D loss supervised: 0.4583, acc.: 93.75%] [D loss unsupervised: 0.1500, acc.: 100.00%] [G loss: 1.565225, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3631 - acc: 0.9062 - val_loss: 0.6987 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "389 [D loss supervised: 0.3631, acc.: 90.62%] [D loss unsupervised: 0.1582, acc.: 100.00%] [G loss: 3.389671, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3211 - acc: 0.9375 - val_loss: 0.6892 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "390 [D loss supervised: 0.3211, acc.: 93.75%] [D loss unsupervised: 0.1500, acc.: 100.00%] [G loss: 4.000185, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2868 - acc: 0.9688 - val_loss: 0.6852 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "391 [D loss supervised: 0.2868, acc.: 96.88%] [D loss unsupervised: 0.1496, acc.: 100.00%] [G loss: 4.762583, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2279 - acc: 1.0000 - val_loss: 0.6826 - val_acc: 0.8511\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "392 [D loss supervised: 0.2279, acc.: 100.00%] [D loss unsupervised: 0.1491, acc.: 100.00%] [G loss: 4.836833, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2172 - acc: 1.0000 - val_loss: 0.6806 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "393 [D loss supervised: 0.2172, acc.: 100.00%] [D loss unsupervised: 0.1500, acc.: 100.00%] [G loss: 4.562516, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2716 - acc: 0.9688 - val_loss: 0.6795 - val_acc: 0.8510\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "394 [D loss supervised: 0.2716, acc.: 96.88%] [D loss unsupervised: 0.1513, acc.: 100.00%] [G loss: 4.759452, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2521 - acc: 1.0000 - val_loss: 0.6786 - val_acc: 0.8511\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "395 [D loss supervised: 0.2521, acc.: 100.00%] [D loss unsupervised: 0.1497, acc.: 100.00%] [G loss: 4.162257, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2705 - acc: 0.9688 - val_loss: 0.6784 - val_acc: 0.8518\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "396 [D loss supervised: 0.2705, acc.: 96.88%] [D loss unsupervised: 0.1506, acc.: 100.00%] [G loss: 4.086682, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2272 - acc: 1.0000 - val_loss: 0.6780 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "397 [D loss supervised: 0.2272, acc.: 100.00%] [D loss unsupervised: 0.1504, acc.: 100.00%] [G loss: 4.116241, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2939 - acc: 0.9375 - val_loss: 0.6778 - val_acc: 0.8526\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "398 [D loss supervised: 0.2939, acc.: 93.75%] [D loss unsupervised: 0.1494, acc.: 100.00%] [G loss: 4.009306, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2475 - acc: 1.0000 - val_loss: 0.6777 - val_acc: 0.8533\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "399 [D loss supervised: 0.2475, acc.: 100.00%] [D loss unsupervised: 0.1492, acc.: 100.00%] [G loss: 4.119387, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3682 - acc: 0.9062 - val_loss: 0.6766 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "400 [D loss supervised: 0.3682, acc.: 90.62%] [D loss unsupervised: 0.1487, acc.: 100.00%] [G loss: 3.901102, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2599 - acc: 0.9688 - val_loss: 0.6770 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "401 [D loss supervised: 0.2599, acc.: 96.88%] [D loss unsupervised: 0.1500, acc.: 100.00%] [G loss: 4.127256, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2282 - acc: 1.0000 - val_loss: 0.6788 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "402 [D loss supervised: 0.2282, acc.: 100.00%] [D loss unsupervised: 0.1480, acc.: 100.00%] [G loss: 3.826200, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3044 - acc: 0.9688 - val_loss: 0.6799 - val_acc: 0.8544\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "403 [D loss supervised: 0.3044, acc.: 96.88%] [D loss unsupervised: 0.1475, acc.: 100.00%] [G loss: 3.884667, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3233 - acc: 0.9062 - val_loss: 0.6797 - val_acc: 0.8555\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "404 [D loss supervised: 0.3233, acc.: 90.62%] [D loss unsupervised: 0.1501, acc.: 100.00%] [G loss: 3.970012, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2668 - acc: 0.9688 - val_loss: 0.6753 - val_acc: 0.8564\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "405 [D loss supervised: 0.2668, acc.: 96.88%] [D loss unsupervised: 0.1478, acc.: 100.00%] [G loss: 3.942588, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3937 - acc: 0.9375 - val_loss: 0.6726 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "406 [D loss supervised: 0.3937, acc.: 93.75%] [D loss unsupervised: 0.1477, acc.: 100.00%] [G loss: 3.656971, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2757 - acc: 1.0000 - val_loss: 0.6700 - val_acc: 0.8573\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "407 [D loss supervised: 0.2757, acc.: 100.00%] [D loss unsupervised: 0.1475, acc.: 100.00%] [G loss: 4.533122, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3523 - acc: 0.9688 - val_loss: 0.6668 - val_acc: 0.8577\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "408 [D loss supervised: 0.3523, acc.: 96.88%] [D loss unsupervised: 0.1472, acc.: 100.00%] [G loss: 3.887986, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2160 - acc: 1.0000 - val_loss: 0.6653 - val_acc: 0.8588\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "409 [D loss supervised: 0.2160, acc.: 100.00%] [D loss unsupervised: 0.1469, acc.: 100.00%] [G loss: 3.734803, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2278 - acc: 1.0000 - val_loss: 0.6656 - val_acc: 0.8597\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "410 [D loss supervised: 0.2278, acc.: 100.00%] [D loss unsupervised: 0.1467, acc.: 100.00%] [G loss: 4.272110, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2921 - acc: 0.9688 - val_loss: 0.6658 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "411 [D loss supervised: 0.2921, acc.: 96.88%] [D loss unsupervised: 0.1464, acc.: 100.00%] [G loss: 4.293713, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2982 - acc: 0.9375 - val_loss: 0.6672 - val_acc: 0.8608\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "412 [D loss supervised: 0.2982, acc.: 93.75%] [D loss unsupervised: 0.1463, acc.: 100.00%] [G loss: 4.482901, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2454 - acc: 0.9688 - val_loss: 0.6678 - val_acc: 0.8626\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "413 [D loss supervised: 0.2454, acc.: 96.88%] [D loss unsupervised: 0.1459, acc.: 100.00%] [G loss: 4.349250, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3288 - acc: 0.9688 - val_loss: 0.6667 - val_acc: 0.8622\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "414 [D loss supervised: 0.3288, acc.: 96.88%] [D loss unsupervised: 0.1466, acc.: 100.00%] [G loss: 4.232227, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2871 - acc: 0.9688 - val_loss: 0.6673 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "415 [D loss supervised: 0.2871, acc.: 96.88%] [D loss unsupervised: 0.1473, acc.: 100.00%] [G loss: 4.339596, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2526 - acc: 1.0000 - val_loss: 0.6677 - val_acc: 0.8607\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "416 [D loss supervised: 0.2526, acc.: 100.00%] [D loss unsupervised: 0.1460, acc.: 100.00%] [G loss: 4.687909, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2214 - acc: 1.0000 - val_loss: 0.6674 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "417 [D loss supervised: 0.2214, acc.: 100.00%] [D loss unsupervised: 0.1454, acc.: 100.00%] [G loss: 4.723396, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3188 - acc: 0.9688 - val_loss: 0.6661 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "418 [D loss supervised: 0.3188, acc.: 96.88%] [D loss unsupervised: 0.1451, acc.: 100.00%] [G loss: 4.592272, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2721 - acc: 0.9688 - val_loss: 0.6643 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "419 [D loss supervised: 0.2721, acc.: 96.88%] [D loss unsupervised: 0.1450, acc.: 100.00%] [G loss: 4.607597, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2456 - acc: 1.0000 - val_loss: 0.6640 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "420 [D loss supervised: 0.2456, acc.: 100.00%] [D loss unsupervised: 0.1447, acc.: 100.00%] [G loss: 5.015951, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3323 - acc: 0.9688 - val_loss: 0.6645 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "421 [D loss supervised: 0.3323, acc.: 96.88%] [D loss unsupervised: 0.1452, acc.: 100.00%] [G loss: 4.512965, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2333 - acc: 1.0000 - val_loss: 0.6656 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "422 [D loss supervised: 0.2333, acc.: 100.00%] [D loss unsupervised: 0.1445, acc.: 100.00%] [G loss: 4.577627, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2474 - acc: 1.0000 - val_loss: 0.6664 - val_acc: 0.8586\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "423 [D loss supervised: 0.2474, acc.: 100.00%] [D loss unsupervised: 0.1444, acc.: 100.00%] [G loss: 4.749954, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2469 - acc: 1.0000 - val_loss: 0.6666 - val_acc: 0.8583\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "424 [D loss supervised: 0.2469, acc.: 100.00%] [D loss unsupervised: 0.1443, acc.: 100.00%] [G loss: 4.740180, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2741 - acc: 0.9688 - val_loss: 0.6679 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "425 [D loss supervised: 0.2741, acc.: 96.88%] [D loss unsupervised: 0.1444, acc.: 100.00%] [G loss: 4.534158, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2265 - acc: 1.0000 - val_loss: 0.6693 - val_acc: 0.8579\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "426 [D loss supervised: 0.2265, acc.: 100.00%] [D loss unsupervised: 0.1438, acc.: 100.00%] [G loss: 4.683218, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2266 - acc: 1.0000 - val_loss: 0.6704 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "427 [D loss supervised: 0.2266, acc.: 100.00%] [D loss unsupervised: 0.1438, acc.: 100.00%] [G loss: 4.597580, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2689 - acc: 0.9688 - val_loss: 0.6712 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "428 [D loss supervised: 0.2689, acc.: 96.88%] [D loss unsupervised: 0.1437, acc.: 100.00%] [G loss: 4.690327, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2805 - acc: 1.0000 - val_loss: 0.6714 - val_acc: 0.8592\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "429 [D loss supervised: 0.2805, acc.: 100.00%] [D loss unsupervised: 0.1433, acc.: 100.00%] [G loss: 4.519864, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3387 - acc: 0.9688 - val_loss: 0.6693 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "430 [D loss supervised: 0.3387, acc.: 96.88%] [D loss unsupervised: 0.1430, acc.: 100.00%] [G loss: 4.560594, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2282 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "431 [D loss supervised: 0.2282, acc.: 100.00%] [D loss unsupervised: 0.1430, acc.: 100.00%] [G loss: 4.746303, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2812 - acc: 0.9688 - val_loss: 0.6681 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "432 [D loss supervised: 0.2812, acc.: 96.88%] [D loss unsupervised: 0.1434, acc.: 100.00%] [G loss: 4.752958, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2283 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "433 [D loss supervised: 0.2283, acc.: 100.00%] [D loss unsupervised: 0.1426, acc.: 100.00%] [G loss: 5.075414, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3194 - acc: 0.9688 - val_loss: 0.6681 - val_acc: 0.8612\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "434 [D loss supervised: 0.3194, acc.: 96.88%] [D loss unsupervised: 0.1423, acc.: 100.00%] [G loss: 5.178544, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2634 - acc: 1.0000 - val_loss: 0.6681 - val_acc: 0.8617\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "435 [D loss supervised: 0.2634, acc.: 100.00%] [D loss unsupervised: 0.1429, acc.: 100.00%] [G loss: 4.946586, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2843 - acc: 1.0000 - val_loss: 0.6679 - val_acc: 0.8615\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "436 [D loss supervised: 0.2843, acc.: 100.00%] [D loss unsupervised: 0.1430, acc.: 100.00%] [G loss: 4.856692, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3601 - acc: 0.9688 - val_loss: 0.6684 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "437 [D loss supervised: 0.3601, acc.: 96.88%] [D loss unsupervised: 0.1420, acc.: 100.00%] [G loss: 4.918026, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2458 - acc: 1.0000 - val_loss: 0.6698 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "438 [D loss supervised: 0.2458, acc.: 100.00%] [D loss unsupervised: 0.1440, acc.: 100.00%] [G loss: 4.955874, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2460 - acc: 1.0000 - val_loss: 0.6733 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "439 [D loss supervised: 0.2460, acc.: 100.00%] [D loss unsupervised: 0.1419, acc.: 100.00%] [G loss: 4.845293, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2816 - acc: 0.9688 - val_loss: 0.6719 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "440 [D loss supervised: 0.2816, acc.: 96.88%] [D loss unsupervised: 0.1422, acc.: 100.00%] [G loss: 4.851287, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2269 - acc: 1.0000 - val_loss: 0.6700 - val_acc: 0.8598\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "441 [D loss supervised: 0.2269, acc.: 100.00%] [D loss unsupervised: 0.1415, acc.: 100.00%] [G loss: 4.664833, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3090 - acc: 0.9375 - val_loss: 0.6749 - val_acc: 0.8597\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "442 [D loss supervised: 0.3090, acc.: 93.75%] [D loss unsupervised: 0.1414, acc.: 100.00%] [G loss: 4.568464, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2410 - acc: 1.0000 - val_loss: 0.6804 - val_acc: 0.8577\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "443 [D loss supervised: 0.2410, acc.: 100.00%] [D loss unsupervised: 0.1412, acc.: 100.00%] [G loss: 4.806532, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2992 - acc: 0.9688 - val_loss: 0.6862 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "444 [D loss supervised: 0.2992, acc.: 96.88%] [D loss unsupervised: 0.1408, acc.: 100.00%] [G loss: 4.464635, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2389 - acc: 1.0000 - val_loss: 0.6944 - val_acc: 0.8529\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "445 [D loss supervised: 0.2389, acc.: 100.00%] [D loss unsupervised: 0.1417, acc.: 100.00%] [G loss: 4.717868, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2453 - acc: 1.0000 - val_loss: 0.7032 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "446 [D loss supervised: 0.2453, acc.: 100.00%] [D loss unsupervised: 0.1408, acc.: 100.00%] [G loss: 4.764218, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2472 - acc: 1.0000 - val_loss: 0.7082 - val_acc: 0.8501\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "447 [D loss supervised: 0.2472, acc.: 100.00%] [D loss unsupervised: 0.1402, acc.: 100.00%] [G loss: 4.537995, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2629 - acc: 1.0000 - val_loss: 0.7075 - val_acc: 0.8505\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "448 [D loss supervised: 0.2629, acc.: 100.00%] [D loss unsupervised: 0.1404, acc.: 100.00%] [G loss: 4.905994, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2276 - acc: 1.0000 - val_loss: 0.7048 - val_acc: 0.8509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "449 [D loss supervised: 0.2276, acc.: 100.00%] [D loss unsupervised: 0.1400, acc.: 100.00%] [G loss: 4.760175, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2231 - acc: 1.0000 - val_loss: 0.7020 - val_acc: 0.8511\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "450 [D loss supervised: 0.2231, acc.: 100.00%] [D loss unsupervised: 0.1400, acc.: 100.00%] [G loss: 4.980199, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4558 - acc: 0.9062 - val_loss: 0.6979 - val_acc: 0.8518\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "451 [D loss supervised: 0.4558, acc.: 90.62%] [D loss unsupervised: 0.1397, acc.: 100.00%] [G loss: 4.940465, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2989 - acc: 0.9688 - val_loss: 0.6918 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "452 [D loss supervised: 0.2989, acc.: 96.88%] [D loss unsupervised: 0.1395, acc.: 100.00%] [G loss: 4.937975, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2465 - acc: 1.0000 - val_loss: 0.6839 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "453 [D loss supervised: 0.2465, acc.: 100.00%] [D loss unsupervised: 0.1394, acc.: 100.00%] [G loss: 5.102133, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2733 - acc: 1.0000 - val_loss: 0.6758 - val_acc: 0.8570\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "454 [D loss supervised: 0.2733, acc.: 100.00%] [D loss unsupervised: 0.1391, acc.: 100.00%] [G loss: 5.016792, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2287 - acc: 1.0000 - val_loss: 0.6693 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "455 [D loss supervised: 0.2287, acc.: 100.00%] [D loss unsupervised: 0.1388, acc.: 100.00%] [G loss: 5.239878, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2935 - acc: 0.9688 - val_loss: 0.6635 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "456 [D loss supervised: 0.2935, acc.: 96.88%] [D loss unsupervised: 0.1397, acc.: 100.00%] [G loss: 5.558189, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2238 - acc: 1.0000 - val_loss: 0.6602 - val_acc: 0.8596\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "457 [D loss supervised: 0.2238, acc.: 100.00%] [D loss unsupervised: 0.1387, acc.: 100.00%] [G loss: 5.147485, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2268 - acc: 1.0000 - val_loss: 0.6585 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "458 [D loss supervised: 0.2268, acc.: 100.00%] [D loss unsupervised: 0.1388, acc.: 100.00%] [G loss: 4.853664, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2229 - acc: 1.0000 - val_loss: 0.6584 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "459 [D loss supervised: 0.2229, acc.: 100.00%] [D loss unsupervised: 0.1391, acc.: 100.00%] [G loss: 4.322186, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2737 - acc: 1.0000 - val_loss: 0.6594 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "460 [D loss supervised: 0.2737, acc.: 100.00%] [D loss unsupervised: 0.1388, acc.: 100.00%] [G loss: 4.049326, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3187 - acc: 0.9688 - val_loss: 0.6646 - val_acc: 0.8581\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "461 [D loss supervised: 0.3187, acc.: 96.88%] [D loss unsupervised: 0.1400, acc.: 100.00%] [G loss: 2.220240, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2505 - acc: 0.9688 - val_loss: 0.6718 - val_acc: 0.8565\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "462 [D loss supervised: 0.2505, acc.: 96.88%] [D loss unsupervised: 0.1393, acc.: 100.00%] [G loss: 2.249941, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4185 - acc: 0.9375 - val_loss: 0.6780 - val_acc: 0.8551\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "463 [D loss supervised: 0.4185, acc.: 93.75%] [D loss unsupervised: 0.1389, acc.: 100.00%] [G loss: 2.582822, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2693 - acc: 0.9688 - val_loss: 0.6839 - val_acc: 0.8540\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "464 [D loss supervised: 0.2693, acc.: 96.88%] [D loss unsupervised: 0.1390, acc.: 100.00%] [G loss: 2.103788, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2342 - acc: 1.0000 - val_loss: 0.6910 - val_acc: 0.8532\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "465 [D loss supervised: 0.2342, acc.: 100.00%] [D loss unsupervised: 0.1385, acc.: 100.00%] [G loss: 2.594411, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4510 - acc: 0.9688 - val_loss: 0.6953 - val_acc: 0.8516\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "466 [D loss supervised: 0.4510, acc.: 96.88%] [D loss unsupervised: 0.4548, acc.: 89.06%] [G loss: 7.661736, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2573 - acc: 1.0000 - val_loss: 0.6991 - val_acc: 0.8516\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "467 [D loss supervised: 0.2573, acc.: 100.00%] [D loss unsupervised: 3.5930, acc.: 50.00%] [G loss: 6.902751, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2884 - acc: 1.0000 - val_loss: 0.7025 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "468 [D loss supervised: 0.2884, acc.: 100.00%] [D loss unsupervised: 2.7185, acc.: 51.56%] [G loss: 4.337932, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2478 - acc: 0.9688 - val_loss: 0.7066 - val_acc: 0.8511\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "469 [D loss supervised: 0.2478, acc.: 96.88%] [D loss unsupervised: 1.3844, acc.: 56.25%] [G loss: 2.658898, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2339 - acc: 1.0000 - val_loss: 0.7106 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "470 [D loss supervised: 0.2339, acc.: 100.00%] [D loss unsupervised: 0.6416, acc.: 70.31%] [G loss: 1.650034, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2526 - acc: 1.0000 - val_loss: 0.7117 - val_acc: 0.8493\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "471 [D loss supervised: 0.2526, acc.: 100.00%] [D loss unsupervised: 0.4064, acc.: 90.62%] [G loss: 1.551754, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2684 - acc: 0.9688 - val_loss: 0.7068 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "472 [D loss supervised: 0.2684, acc.: 96.88%] [D loss unsupervised: 0.3367, acc.: 95.31%] [G loss: 1.214458, acc.: 18.75%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2897 - acc: 0.9688 - val_loss: 0.7001 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "473 [D loss supervised: 0.2897, acc.: 96.88%] [D loss unsupervised: 0.3922, acc.: 90.62%] [G loss: 1.595357, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2964 - acc: 0.9688 - val_loss: 0.6926 - val_acc: 0.8536\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "474 [D loss supervised: 0.2964, acc.: 96.88%] [D loss unsupervised: 0.2680, acc.: 100.00%] [G loss: 2.101987, acc.: 0.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2453 - acc: 1.0000 - val_loss: 0.6851 - val_acc: 0.8552\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "475 [D loss supervised: 0.2453, acc.: 100.00%] [D loss unsupervised: 0.2171, acc.: 100.00%] [G loss: 2.277400, acc.: 6.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2537 - acc: 1.0000 - val_loss: 0.6764 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "476 [D loss supervised: 0.2537, acc.: 100.00%] [D loss unsupervised: 0.2274, acc.: 98.44%] [G loss: 2.517119, acc.: 3.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2535 - acc: 1.0000 - val_loss: 0.6680 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "477 [D loss supervised: 0.2535, acc.: 100.00%] [D loss unsupervised: 0.2394, acc.: 98.44%] [G loss: 2.303618, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2715 - acc: 0.9688 - val_loss: 0.6632 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "478 [D loss supervised: 0.2715, acc.: 96.88%] [D loss unsupervised: 0.2022, acc.: 100.00%] [G loss: 2.013140, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3229 - acc: 0.9688 - val_loss: 0.6580 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "479 [D loss supervised: 0.3229, acc.: 96.88%] [D loss unsupervised: 0.2472, acc.: 98.44%] [G loss: 2.174323, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3364 - acc: 0.9688 - val_loss: 0.6546 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "480 [D loss supervised: 0.3364, acc.: 96.88%] [D loss unsupervised: 0.2114, acc.: 98.44%] [G loss: 2.309388, acc.: 15.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2189 - acc: 1.0000 - val_loss: 0.6541 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "481 [D loss supervised: 0.2189, acc.: 100.00%] [D loss unsupervised: 0.2291, acc.: 96.88%] [G loss: 2.534171, acc.: 12.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3876 - acc: 0.9688 - val_loss: 0.6546 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "482 [D loss supervised: 0.3876, acc.: 96.88%] [D loss unsupervised: 0.2166, acc.: 98.44%] [G loss: 2.278991, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2825 - acc: 1.0000 - val_loss: 0.6555 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "483 [D loss supervised: 0.2825, acc.: 100.00%] [D loss unsupervised: 0.1847, acc.: 100.00%] [G loss: 1.896575, acc.: 37.50%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3679 - acc: 0.9062 - val_loss: 0.6558 - val_acc: 0.8592\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "484 [D loss supervised: 0.3679, acc.: 90.62%] [D loss unsupervised: 0.1920, acc.: 100.00%] [G loss: 2.221781, acc.: 9.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4336 - acc: 0.9688 - val_loss: 0.6550 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "485 [D loss supervised: 0.4336, acc.: 96.88%] [D loss unsupervised: 0.1979, acc.: 100.00%] [G loss: 2.156103, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2294 - acc: 1.0000 - val_loss: 0.6544 - val_acc: 0.8594\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "486 [D loss supervised: 0.2294, acc.: 100.00%] [D loss unsupervised: 0.2054, acc.: 100.00%] [G loss: 1.599647, acc.: 40.62%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2300 - acc: 1.0000 - val_loss: 0.6536 - val_acc: 0.8604\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "487 [D loss supervised: 0.2300, acc.: 100.00%] [D loss unsupervised: 0.1835, acc.: 100.00%] [G loss: 1.822977, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2535 - acc: 0.9688 - val_loss: 0.6542 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "488 [D loss supervised: 0.2535, acc.: 96.88%] [D loss unsupervised: 0.2088, acc.: 98.44%] [G loss: 1.552279, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2216 - acc: 1.0000 - val_loss: 0.6549 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "489 [D loss supervised: 0.2216, acc.: 100.00%] [D loss unsupervised: 0.1720, acc.: 100.00%] [G loss: 1.513780, acc.: 53.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3555 - acc: 0.9375 - val_loss: 0.6532 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "490 [D loss supervised: 0.3555, acc.: 93.75%] [D loss unsupervised: 0.1954, acc.: 98.44%] [G loss: 1.531944, acc.: 46.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2147 - acc: 1.0000 - val_loss: 0.6524 - val_acc: 0.8602\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "491 [D loss supervised: 0.2147, acc.: 100.00%] [D loss unsupervised: 0.1861, acc.: 100.00%] [G loss: 1.661533, acc.: 25.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2522 - acc: 1.0000 - val_loss: 0.6522 - val_acc: 0.8605\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "492 [D loss supervised: 0.2522, acc.: 100.00%] [D loss unsupervised: 0.1844, acc.: 100.00%] [G loss: 1.850374, acc.: 28.12%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2721 - acc: 0.9688 - val_loss: 0.6514 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "493 [D loss supervised: 0.2721, acc.: 96.88%] [D loss unsupervised: 0.2019, acc.: 98.44%] [G loss: 1.870528, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2437 - acc: 1.0000 - val_loss: 0.6499 - val_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "494 [D loss supervised: 0.2437, acc.: 100.00%] [D loss unsupervised: 0.1927, acc.: 98.44%] [G loss: 1.664862, acc.: 34.38%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2408 - acc: 1.0000 - val_loss: 0.6483 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "495 [D loss supervised: 0.2408, acc.: 100.00%] [D loss unsupervised: 0.1980, acc.: 100.00%] [G loss: 1.210494, acc.: 50.00%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2748 - acc: 0.9688 - val_loss: 0.6473 - val_acc: 0.8612\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "496 [D loss supervised: 0.2748, acc.: 96.88%] [D loss unsupervised: 0.1951, acc.: 98.44%] [G loss: 1.759200, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2233 - acc: 1.0000 - val_loss: 0.6463 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "497 [D loss supervised: 0.2233, acc.: 100.00%] [D loss unsupervised: 0.1917, acc.: 98.44%] [G loss: 1.907724, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2499 - acc: 0.9688 - val_loss: 0.6461 - val_acc: 0.8599\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "498 [D loss supervised: 0.2499, acc.: 96.88%] [D loss unsupervised: 0.1834, acc.: 98.44%] [G loss: 1.604475, acc.: 31.25%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2468 - acc: 1.0000 - val_loss: 0.6474 - val_acc: 0.8598\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "499 [D loss supervised: 0.2468, acc.: 100.00%] [D loss unsupervised: 0.1774, acc.: 98.44%] [G loss: 1.538978, acc.: 21.88%]\n",
            "Epoch 1/1\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4775 - acc: 0.9062 - val_loss: 0.6483 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "500 [D loss supervised: 0.4775, acc.: 90.62%] [D loss unsupervised: 0.1845, acc.: 98.44%] [G loss: 1.581404, acc.: 21.88%]\n",
            "Training time: 1852.0433s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfUFnOB4qLYj",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rt3ZhdCn6mk",
        "colab_type": "code",
        "outputId": "e0a9b039-a46b-4686-c3a5-a2b4fcfd723c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "tmodel.compile(loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'],\n",
        "                         optimizer=Adam())\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-300.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 22s 448us/step\n",
            "Training Accuracy: 88.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO7jfk1Pa-J8",
        "colab_type": "code",
        "outputId": "e8ae5ac1-25da-4a46-8b40-88cac26b3f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-300.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the test set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 385us/step\n",
            "Test Accuracy: 85.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN3Q_FxXLCN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_supervised_loss = np.array(losses_d_supervised)\n",
        "d_unsupervised_loss = np.array(losses_d_unsupervised)\n",
        "d_unsupervised_real_loss = np.array(losses_d_unsupervised_real)\n",
        "d_unsupervised_fake_loss = np.array(losses_d_unsupervised_fake)\n",
        "d_loss = np.array(losses_d)\n",
        "g_loss = np.array(losses_g)  # Generator unsupervised loss\n",
        "all_loss = np.add(d_loss, g_loss)\n",
        "\n",
        "# Plot Discriminator supervised loss\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(iteration_checkpoints, d_supervised_loss, label=\"Discriminator supervised loss\", color='blue', linestyle='dashed')\n",
        "plt.plot(iteration_checkpoints, d_unsupervised_loss, label=\"Discriminator unsupervised loss\", color='green', linestyle='dashed')\n",
        "# plt.plot(iteration_checkpoints, d_unsupervised_real_loss, label=\"Discriminator unsupervised real loss\", color='yellow')\n",
        "# plt.plot(iteration_checkpoints, d_unsupervised_fake_loss, label=\"Discriminator unsupervised fake loss\", color='yellow')\n",
        "plt.plot(iteration_checkpoints, g_loss, label=\"Generator unsupervised loss\", color='tab:red', linestyle='dashed')\n",
        "plt.plot(iteration_checkpoints, all_loss, label=\"All losses\", color='black')\n",
        "\n",
        "plt.xticks(iteration_checkpoints, rotation=90)\n",
        "\n",
        "plt.title(\"SCGAN-2D's Discriminator Loss + Generator Loss, num_labeled=%d\" % num_labeled)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk87Xx_Aa-Bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82c3a30e-e34a-4bb6-d980-fe13456033da"
      },
      "source": [
        "div = 1   # 1\n",
        "accs = []\n",
        "tx = [x for x in range(1*div, len(iteration_checkpoints)+1, div)]\n",
        "acc_max = [0,0]\n",
        "\n",
        "for e in tx:\n",
        "  tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/discriminator_supervised-\"+ str(e) +\".h5\", by_name=False)\n",
        "  _, acc = tmodel.evaluate(x, y)\n",
        "  accs.append(acc)\n",
        "print(max(accs))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(tx, accs, label=\"accs\", color='blue')\n",
        "plt.xticks(tx, rotation=90)\n",
        "plt.title(\"SCGAN-2D's accs with epoch, num_labeled=%d\" % num_labeled)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accs\")\n",
        "plt.legend()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 431us/step\n",
            "10000/10000 [==============================] - 4s 411us/step\n",
            "10000/10000 [==============================] - 4s 408us/step\n",
            "10000/10000 [==============================] - 4s 402us/step\n",
            "10000/10000 [==============================] - 4s 404us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 399us/step\n",
            "10000/10000 [==============================] - 4s 392us/step\n",
            "10000/10000 [==============================] - 4s 393us/step\n",
            "10000/10000 [==============================] - 4s 412us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 399us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 405us/step\n",
            "10000/10000 [==============================] - 4s 411us/step\n",
            "10000/10000 [==============================] - 4s 402us/step\n",
            "10000/10000 [==============================] - 4s 397us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 393us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 397us/step\n",
            "10000/10000 [==============================] - 4s 397us/step\n",
            "10000/10000 [==============================] - 4s 397us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 403us/step\n",
            "10000/10000 [==============================] - 4s 415us/step\n",
            "10000/10000 [==============================] - 4s 402us/step\n",
            "10000/10000 [==============================] - 4s 400us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 401us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 394us/step\n",
            "10000/10000 [==============================] - 4s 399us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 399us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 397us/step\n",
            "0.874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29ce5bd710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFWCAYAAAA2SU9mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXfwxMiWbBLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "7ea93829-d5ca-4b9c-d4a4-f1ce6f32b5f5"
      },
      "source": [
        "# d_supervised_loss = np.array(losses_d_supervised)\n",
        "# d_unsupervised_loss = np.array(losses_d_unsupervised)\n",
        "# d_unsupervised_real_loss = np.array(losses_d_unsupervised_real)\n",
        "# d_unsupervised_fake_loss = np.array(losses_d_unsupervised_fake)\n",
        "# d_loss = np.array(losses_d)\n",
        "# g_loss = np.array(losses_g)  # Generator unsupervised loss\n",
        "# all_loss = np.add(d_loss, g_loss)\n",
        "\n",
        "# # Plot Discriminator supervised loss\n",
        "# plt.figure(figsize=(15, 5))\n",
        "# plt.plot(iteration_checkpoints, d_supervised_loss, label=\"Discriminator supervised loss\", color='blue', linestyle='dashed')\n",
        "# plt.plot(iteration_checkpoints, d_unsupervised_loss, label=\"Discriminator unsupervised loss\", color='green', linestyle='dashed')\n",
        "# # plt.plot(iteration_checkpoints, d_unsupervised_real_loss, label=\"Discriminator unsupervised real loss\", color='yellow')\n",
        "# # plt.plot(iteration_checkpoints, d_unsupervised_fake_loss, label=\"Discriminator unsupervised fake loss\", color='yellow')\n",
        "# plt.plot(iteration_checkpoints, g_loss, label=\"Generator unsupervised loss\", color='tab:red', linestyle='dashed')\n",
        "# plt.plot(iteration_checkpoints, all_loss, label=\"All losses\", color='black')\n",
        "\n",
        "# plt.xticks(iteration_checkpoints, rotation=90)\n",
        "\n",
        "# plt.title(\"SCGAN-2D's Discriminator Loss + Generator Loss, num_labeled=%d\" % num_labeled)\n",
        "# plt.xlabel(\"Iteration\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.legend()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29ce2026a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAAFWCAYAAAAR586OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq-YzbJRqOMH",
        "colab_type": "text"
      },
      "source": [
        "## Generate Pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB2PSr3uEFw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMF87KVVEFuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# z = np.random.normal(0, 1, (batch_size, z_dim))\n",
        "# fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "# fake_labels = to_categorical(fake_labels, num_classes=num_classes)\n",
        "# gen_imgs = generator.predict([z, fake_labels])\n",
        "\n",
        "d_name = {0:\"airplane\", 1:\"automobile\", 2:\"bird\", 3:\"cat\", 4:\"deer\", 5:\"dog\", 6:\"frog\", 7:\"horse\", 8:\"ship\", 9:\"truck\"}\t\n",
        "\n",
        "def sample_images(image_grid_rows=2, image_grid_columns=5):\n",
        "\n",
        "    # Sample random noise\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "\n",
        "    # Get image labels 0-9\n",
        "    fake_labels = [0,1,2,3,4,5,6,7,8,9]\n",
        "    fake_labels_category = to_categorical(fake_labels, num_classes=num_classes)\n",
        "\n",
        "    # Generate images from random noise\n",
        "    gen_imgs = generator.predict([z, fake_labels_category])\n",
        "\n",
        "    # Rescale image pixel values to [0, 1]\n",
        "    # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    # gen_imgs = (gen_imgs+1) * 255/2\n",
        "\n",
        "    # Set image grid\n",
        "    fig, axs = plt.subplots(image_grid_rows,\n",
        "                            image_grid_columns,\n",
        "                            figsize=(10, 4),\n",
        "                            sharey=True,\n",
        "                            sharex=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            # Output a grid of images\n",
        "            axs[i, j].imshow(gen_imgs[cnt])\n",
        "            axs[i, j].axis('off')\n",
        "            axs[i, j].set_title(\"Class: \" + str(d_name[fake_labels[cnt]]))\n",
        "            cnt += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx4Ocr7DLE0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "3e79b096-9a7a-4c86-b2b6-0c1909a0b395"
      },
      "source": [
        "sample_images()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAD1CAYAAABUdy/PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOxdd3gc1fU9T71ZtmRZslzl3o0B00wz\nYLppoYfeW0IILUBIIITQEgLkRwuBYHoJofdqgzHGNthgcC9y70WSZVt1fn/Mes6ZjVaWYYXl5Z7v\n0/cdzb6ZffPazN7z7r3O8zwYDAaDwWAwJDKStncFDAaDwWAwGJob9sJjMBgMBoMh4WEvPAaDwWAw\nGBIe9sJjMBgMBoMh4WEvPAaDwWAwGBIe9sJjMBgMBoMh4RH3Fx7n3M3Ouafjfd14wDl3g3Pu0R9x\nfou9t21FIt3LTwnnXKlzbkSMz/Z1zs1sStkdAdt7jDjnPOdczxifneace38brzfaOXd+fGq342J7\n96vhh6Ol9d2ONqd+0AuPc+6XzrlJzrkNzrllzrl3nHP7xLty8Ybnebd5nrfDdM6PxY7aT1tDS32R\n8DzvM8/z+mzvemwLdtQx4nneM57nHbK969FSsaP2a2No7AU4kZCIfddSsM0vPM65KwHcC+A2AEUA\nugB4EMAx8a3aTwvnXMr2rkM8kaj9ZIgfEnWMJNpc3lYkar/+HGB958M5l9wsF/Y8r8l/AFoD2ADg\nxEbK3Azgafn/PwCWAygD8CmAAfLZEQCmAagAsATA1ZHjBQDeBLAewFoAnwFIamId7wOwCEA5gK8A\n7NtQ3QCUAPAAnAdgYaRuW45dCGApgGVb6vQD7m0UgAcAvBW5vy8B9JDP+wL4IHJ/MwGctC19keD9\nNArArfL/cACLI/wpAPUANkXu8drI8aMBfB+py2gA/eT8UgDXAPgWQCWAx+AvJu9E7ulDAHlSfmvX\nuj7SHusAPA4gI7qeUnZEhCcBuA7AXABrALwIID9efZ6gY8QDcDmAeQBWA/jrlnMBnA1gbFTZywDM\nBjA/cuxgADMi9b0fwBgA52+vNrd+Da45AFz7VgC4IXJ8dwBfRK65LNJnaZHPPo30cWXk/k7e3m39\nM+27RucUgHMBTIe/Nr4HoKt8FvOZB3/NfwjA25E+HtEsbbyNHXIYgFoAKdvQIecCaAUgHf6b6xT5\nbBkiDzoAeQB2ifDbATwMIDXyty8AF/nsQQAPNvL9pwNoCyAFwFWRwZARXTfw5eZJANkAMuXYc5Fj\ngwCsAh9a23Jvo+A/2HaP1OUZAM9HPsuG/7A/J/LZzvAX9P5xmjg7ej+NQowXnsj/pZAJAaA3/Ely\ncKQe1wKYAy6WpQDGw3/J6QhgJYCvI+2eAeBjADdtw7W+A9AZQD6Az7fUtbF6AvhNpA6dIm38TwDP\nNcekTqAx4gH4JNLOXQDMQmRxRcMvPB9EymbCX9QrAJwQ+d7fRu430V94WnS/Rr5nGfw5nxH5f4/I\nZ7sC2BP+mlAC/8F5RVQf99zebfwz7rtG5xR8K9QcAP0ifXgjgHGRzxp95sFf88sA7A3/x2FGs7Tx\nNnbIaQCWb6VMqEOiPmsTGbStI/8vBHARgNyocrcAeC0egxv+m+ZO0XUDX266S9ktx/rKsbsAPPYD\n7m0UgEfl8yMAzIjwkwF8FnX+PxF56Mbhnnf0fhqFbXvh+QOAF+X/JPi/aIZL+dPk8/8CeEj+/zWA\nV7fhWhdH9evcrdUT/uJ9kHxWDKAGjSxuzfm3I4yRyPUPk/8vBfBRhJ+N/33hOVD+PxPAePnfAViM\nxH/hadH9CuBUAJObWPYKAK9E9XEiv/C09L5rdE7Bt5ifJ58nAdgIoCu28syDv+Y/2dxtvK17eNYA\nKGiqRu6cS3bO3eGcm+ucK4f/AAD8N0UAOB7+A2OBc26Mc26vyPG/wn9TfN85N885d11TK+icu9o5\nN905V+acWw/fTFjQyCmLtnJsAYAOP+DeAN9qsQUbAeREeFcAezjn1m/5gz/Y2zd2b9uAROynxtAB\nfj8BADzPq4ffhx2lzArhmxr4f0vfNOVaWx0fDaArgFekv6cDqINvddoeaPFjJIJtaWst20H/9/xV\ntaG5nmho6f3aGb6s21Bdejvn3nTOLY/U5Tb88DVhR0RL77utzamuAO6TNW4t/JeijmjaM6/Z5+e2\nvvB8AaAKwLFNLP9L+GauEfAfaCWR4w4APM+b6HneMQAKAbwKf18DPM+r8DzvKs/zusPfT3Glc+6g\nrX2Zc25f+BLESfD3ZLSBbyZzjZzmNXCss/Au8PfzbNO9bQWLAIzxPK+N/OV4nndJE85tCnb0fqoE\nkCWnRL8IRvfZUvgTasv1Hfw+XLK1ujSAplyrKeMjGosAHB7V5xme5/2QOsYDLXqMCLalrXVcLNNz\npR8THS29XxcB6B7js4fg7w/p5XleLoAb0LT1NFHQ0vtua3NqEYCLota4TM/zxqFpz7yGnsVxxTa9\n8HieVwbgjwAecM4d65zLcs6lOucOd87d1cApreB34Br4D7DbtnzgnEtzfiyN1p7n1cDfvFof+Wyk\nc65npEHL4P8Srm9CFVvB1xRXAUhxzv0RQO623GMEf4jc2wD4muML23JvTcCbAHo7586ItF+qc243\n51y/H1DX/0EC9NMUAEc45/Kdc+3hm7YVKxBeNF8EcKRz7iDnXCr8/QFVAMY1oS7RaMq1LnPOdXLO\n5QP4PRoeH9F4GMBfnHNdAcA51845t908L3aAMbIF1zjn8pxzneHvg2pKWwO+s8AA59wvIr+YL0f8\nLKgtFjtAv74JoNg5d4VzLt0518o5t4fUpRzABudcXwDRPwCj531CYQfou63NqYcBXB95bsI519o5\nd2Lks2Z95jUV2+yW7nne3QCuhL8haRX8N7dfwX+DjMaT8M3QS+DvFh8f9fkZAEoj5riL4Zu4AKAX\nfM+ZDfDfeh/0PO8TAHDOPeycezhG9d4D8C78zY0LAGzGDzOTjYFv8vsIwN88z2sowNnW7i0mPM+r\nAHAIgFPg/2JdDuBO+BvP4oIdvJ+eAvANfBPt+/jfh9ztAG6MmEav9jxvJvxN0P8HfyPcUQCO8jyv\nOsb3x0QTr/VspF7z4Jvnb23Cpe8D8Dp8M3IF/Dbeo/FTmhctfIxswWvwvfimwF9wH2viva0GcCKA\nO+A/EHrB32Ce8GjJ/RpZ+w6GP6+Ww/eqOyDy8dXwrRYVAP6F/533NwN4IjLvT2q0EXZQtPC+a3RO\neZ73Cvzn2POR7/wOwOGRz5r9mdcUbNmZbQDgnCsBMB9Aqud5tdu3NgaDwWAwGOIFy6VlMBgMBoMh\n4WEvPAaDwWAwGBIeJmkZDAaDwWBIeJiFx2AwGAwGQ8LDXngMBoPBYDAkPBqN6OhciuhddaT9pdC0\nONcI8LPhbMFa9Vqrarh8hvDNTfwOjd+5OlYhiXnVU5pijsRaGiHe1B8eQf7Y2wHt9caVAa+5kh7u\nORNvCHhlf4bxqX7j1IAvfuCGuAXeSt7TBTeRu2D34Pj6yycEvO8UhryZ0fVFnjxxaEBTzn6D5Rcx\nSGf9Ed8GvP0sxs7a96A5Ad9cc2TAiwq7sHxVq4B3zOBYK61leIhWqTlQJFWzaXJS2fGTK8sD3jk7\nO+BrNnCgtM9h+fI1NbyfdixfXcPYh+1S+V31tRwLBSlM6lsn46VaYmgtrKHD335paXHpz79M7R18\nwcrkZ4PjR/eSy9cyZElaBudRRR1/5/SRnMSrZYjnu7SAs0WAPLnHjXI8TbguKqnCtXx0KmQX47N1\nMa5VIzxTeJm0e75cVV0udbmIdVyDksjKh/XCi/04JnGBc8nS+vLtA6TQ99oyWitBaF3rRJ60uMHL\nY2/hU3YiH/gN+dR2AU0+blXAW03eP+Dre48JVSP5W1Y8ab/vA54zeueArxswmSdMPjSgKee/F/CO\nL45kmd+/GdDUT+8LeJeL3w142uSTA150+IyA1y/4RcDrilh+yUd9Az76ghPj0p/OuYb3iWjEmemh\nh1zDF5Luw2KulchYSK7Pu8NJc77eK+AbDvsi4PnT9gl4m9PG8oTZ5wc0ba+o6A3fsE1T92RUiPp3\njg541vFs06ovfhfwvONeC3j2e3w+9jqf4zFzwXkBb9ufMyx9WZuAd+zCrqnZxPG4Oa2Mt7BoU8Bv\n7dGrwb40C4/BYDAYDIaEx1ZydsT4FRHTqqO/BSt/QHUiCL3wqlVHX9r4Ep0kb7n64yUlqW3osrUp\nawLeU6w6c0Kl5E0afJNOWZgn15Ho9nNOJN9ldkB3Xv4Iyw9m2qb+1fw1Xtp2ZcAPqn8m4I/m8408\nnqif/suAb96vIuCDvr8l4NnpQRopdO39j4Av8Jj+pmvyaQHPTWFmhLZ5DwW8rC1/m2cm8Xvb1PI3\ndS9Hq85K+VHUXX4410s/d4z6Qf2dvK73d/ydvzStdcB7OhZak8pr7eJoLfoqj6OmRH4DLJQf1N3k\ne9fJrNERpr/+28tYXZ6iton44Mkp/HW2z4G0RHXxyMul/oVSn1nSjGoQUCuN3tcG4WpvTQlx+QUm\nfZYsx7N1zkZlDNBztLXyhOvxMuGthOt1NTeJriKx7kHr6mLUR1e4+CJGoNvv9R9dj1sLl9YIWav5\nKzqjvjDgm1O57rSS66dVcl3Lyjws4Is60wLccyPN+6mVXOPzCi8MVXtBe56zS9qeAa/M4LqTmcdz\n1vWZGvBhab8J+JL95wW8qPr1gFf0W8brJ3OdmtGX1t1B3nEBn5BF++Kx+FXAbykKr/7xgY4qsSFO\n1zL6kGsnnBY06T7os6i9o+lneRsWKpQMZXm1TONYm06r/foiFsqrk+QAtRxDmW3/pV+MNYUcJAPy\n+NmMfl/xDrKeD/i6EtZpWBYtcVMO4uDsXndGwJcVcK7tH2THAL4r5Hgf6HEWfi7G0ENkRo7LiaEA\nCczCYzAYDAaDIeFhLzwGg8FgMBgSHo3G4dHNV0fL8dcbKAsAWeCmNwduequU3VetxFRcIQmoO8p1\nNH10rI2KMQy66IbigM/HMij2kM++lM86SBlNxVwixvJSMU0WiRCwQsyX+2Rzk+jYXSjpXD6I5rt/\ndOXG3gcK+M2XvVUa8D09mta/ePmp+G2MLGZ//jqPmwofGUiT5cFtaX5eX8/76dSFpuznc2h+vm0d\n5aoP95sf8Cs70IR+fg5v4bNW3LT8ThZ79LRkmi+vrKfocH8SpacHXFhivVSEiks9vrvfL6LF7+Sc\nv9RT+/yn48i6QsScl6W1uVUPmCm/DXTPvhigUShcx3C+jPkslxSX/iz+5tLgoq8VXhQc31jAXH5D\nkikIVTuOU936PU1knCFyXGUszeq6QrhmDdTNv2rQrxCu0pPOZSA8z2Odo3XSe1AVRyU6FdVVitKk\naCrj1UvPJDXsrhHaUO3iummZc1Mzyr7WQFkf2ltThPcJWKaMu03Scx3ljpZIa+yEngH/RvYt7JFW\nEvAvq0sDfgwOZj17fxCq3QkrBgf8pVSueUdWcDPtW914/PTyXQL+dG8evzjt7IA/vDc3Id+Zxk3O\nf9+NEsoj7ejwcWEe7/lZ6apDpnOEXb6GT4+/n3Jh3Dcty5ZrvNlAWR9dA9YZ3FKwSIT0bjLi54Pt\nMERm5xRwy8ZI7Bfwd/p+GvCzW/H4YwWTAv7bNDrW3LPLZ6Ha3eHRYeW6LH52TxUlyd/243j59yau\nkNd0Y9/8N/34gJ/am33wST2fy09kcyW4yuPG7n/KonKRx9XjFnEgOWoD739E2+62adlgMBgMBsPP\nE/bCYzAYDAaDIeGxFUlrQPDhNWLifFqM1n3FwD9aTHNeaEs6TVYZoEmsSnxB8sXHpZVcf53IFtVi\n4ksS812yCGLFYu7bHOUJkiwG6RQxolem0yBfXUXf//Jk1im3jqbD1GKa1Dal9+D3DaCo0b9uUMC9\nEeQDshkr4H0wBsTBU8YF/OkCtql369FxM5vnu3OD/jxlyMfB8YGDDgj4mLoTWNdC3uc/8ikH7dWe\nct2qNN7//vXstzlFvLcDunKMZbRhGx0oUte7yeybEan0WKlK4jt5t6jX87fEsWUfaaWlwvsJv0OG\n+lVynP4MQG85rr5yw4SrJKIePyqgFgufLbx3nGSQO19YEtxN/70pXR1QxGgylXX8qgLRbr6W6+wk\ntVHJSL2jYklG9TK/kkQ+qZXjKdD1Jfath2UjnuOFPKe0riyj8pb6OiXFiIuU1kg9Gr4OUaveW3GV\ntHYJLnwRGJ/mQymTL+vFV2AssPqQK5eMyHRKzKgSUc+Jd5VH0XBzW8oMyWu4Pro2XBPbV8r9D+HG\ngqrZ4iIEIK0j43xlltETKq07pfSqzfRUWtae3rEdK7kFInU/yurtOvQK+Fd5XI8vyOD6v6AnhdYj\nUrmm3Cl65a9n89lxbiu2V90+HeIkabEvj5e+1Hm0CLyXSgk8tyK0WsjIzqeXVuZaif2Vxyp3Lufc\nr+vKVSp5GY9n92TspNRMrtdthjM+T3J9yD0MZcX7BrxLDVeJ8j7ss4GZHC9vZtI/8twsjpFlRVxV\nTsnjePyrqPz3JnO2zUnm8aHSMzdL3a7bzPF4qczNF7OTTdIyGAwGg8Hw84S98BgMBoPBYEh4NNlL\nq2nQcGVrYpZqCLGyQ8TyxtKgYhqyXoKji5+Yjz7CZwrvK1G+Z0g8qFjeW8PyaJobt47yTu8OfH+c\n1ZFG8VMPGBHw516nkXok4/fhTdVPUg8MqPfqR3E0m2cE/ZkvUuFe++8R8LecRJXMYzh2LBF/kR4S\nYi+DXl1JZWzxPY+l+X2OR3nzrhEPBDxr4b8DPmkwvQfmVdC0flvB1QEv3zQ6dD8rMmkW/aSGo+DK\n9KMCXlpHE3FyEuW0CeJXdLYrCfgmETOyRFpVzyEN4hcjXFxoTOqvipw4ySAvTPy/oC+nd6V3zUXi\nhdE/jTNphni77QPKqiPFf+kcqWlPMQ9/ITOyRBI5dJLyqVJ+kfBMKaOrQ3QjlMs5NfKpnqOLkXp5\nqRQXDjXayBfGAQ7N46XVNKjIOi5mqW2Bypia0iNWFp5jCjimXlutvQAMk5YZJ3Lq8b25cr89lbOk\nfwnLfC2L/lV7UoJ5aBLTV+x/Dtestz0GOfzbgX8J+C3fvRrws3ei/PKPiQzaObTVNQGfeMyVzZta\nQqGLQn1X+WdBdMlGoXKu9kBv4bOE95fvnSHPvQsPZfs8866krgBwlMSU/K+opPeMpMfto2OYSmn/\nE+mb9h/HwJFPDroj4G9IqpMD2wwP+GuOz5YbkwcGfKKsqD1lO8or9Xwr6CLy7HkpbU3SMhgMBoPB\n8POEvfAYDAaDwWBIeDQqaRWIaU6T6r4eM2fWucL/LZzWJQ2G1V1KqIdLkXDNjtFVhK+5YmYvlvRX\nVWKN61UctmpNW8PvbiXpSzZJlLi83jSKz1xHWa6tRFmrlehrHXqUBPxrJ3UaQPNaUim9DjrvQpNu\n6Sp6nW2sotS18HWe65VPiJvZPEX6s4ccn4V75L+/kra+mXwjgw3iABELJzAAWuer6O9UUcr7LD6M\nBtb+oymB5ZzFRl0+i3bvVYfRpn3mdPZ5xaBwju2NtJZi+QDKT7uLmppXIOdUsP8L80RqEV2qk/wE\nULlKpVU9Hiswph6fIbx/nCSt4fv+J7iZIdn0oqi/h7NnINMKYQLjumFvcUu7SXTbF6V8qdxwG9GS\nx9NhB5eKa9VizdslDTFaGuIXstSsjmqFbGnUeZojTcpo++ovtdQYPDmWjtVwSr4mHa+T4ykufkJZ\nG5mbg+X4Z6EsbqIn4HzhjwoPaSUBy5WqlqfzJkpkgS2VMwcJnyqRJ4eK+rJYTtizQDclAJNlLWwv\n0sk6OadrVw6m+XX0KmozlGtw0loKaq13o4y1YAPl6bzhrGDu9/TYStub6+jyBbxOeivKKRPfYV6x\n6nsuiUt/tpK+DHtrxgqve7zw/271+m1lQ8eaAko9O0n0z29EUx9eSLFycjbFyl6ie62dyXWjz64q\nsQHLN1M4S9uPcnjq93yC5x/MBWb9SnZ4wUhuJOm4kotK9/4c17WbuXb3zuNC4uR+uqWya+bKuqPr\n9R/K+cHbeSkmaRkMBoPBYPh5wl54DAaDwWAwJDya7KX1sRw/8CL555+kA+SwhsJSxPLGiuVd1Vn4\nIuG7C58gXCz3oQBrQOwcNXqtGXRCweBNNLmOzeDu8WGbaVKcW0jb4T7l/QL+3470TBq+8ZCAJ+W8\nH/A9BtN0+NwE7s4vlRv1PK9ZPEFuE3+WG25j4EHc8FJAO7ZnDpYlyw9nmS5/J1/4Bvlw9uIui6ib\nfD2PpvhWAzlKioZR0ioG2zpNgg2uH8F6tq3QTE5Az040kW5cQB2r6ICdAz62gl5a17ffLeBrPWqf\nQwqYE+gLRxv/KY79rGM1W7y3SuW4egHqWF0h0sKeruGAWNuKpOd7Bn25S/sXguN1QygxTpnMMfX4\nzjQhn/OFZADbVbTdCpq7HyimGfz3q6lpPZtE+eCIQsoQYyTg3TnVPP5yEqXKAzNoo37T04xbwE11\nFKz+JsLUn1N5/Dg5p6Njmw6U320aqFCDGWqesxCkN2IFG9QlUiX2zGbKpfWeHD/0GvlH1ObuoIw5\nD5r7SENhaohMVrW95F9aLgFf9Uy9zyGScWyKXLOf9NP0qOxoRwmXFQJDhes6f0gyJZW3WnOen1DJ\nWTV2MH1rT8qgi+vL2c8E/OCi3/L6uZTqT+x5ZsCfeOLJgC9I4Zqw8cv4bB/QvnxSjp/5G/nnPtI2\nknFrfSjjlmaSU79PjuwBso5/L57ROt5XCj9AxPlPxO95mGTG+yYUihU4ux09bh+rpEB/Vheus6/m\nMcDiFX3o1vVG9iMBP3P/J3idblyzbu/8+4CPruZYHt6Osu1THq9/fSrXsjvncn33JA/X450OMknL\nYDAYDAbDzxP2wmMwGAwGgyHhsRVJa0Tw4SR8FBx/XcqkgkHP/imeA4txW8CTQC+l+tY0S/Ys447s\njWIq7ZVJM/vkTTS/q2SmoZGKJWTWkiSa5TtERYVbJJ4knepo/lqcS3NsJ/FUmSPyVtdN/I413eQ7\nxHFikXgjdBfPlg0SJTFTItjVi3mxPpknfC22+PhKWjcG/fk2GKBrGs4J+CLJgXYfaIIEThB+GWne\nHXKcYwGbxWC96TApw+BhSGdARtSJAFl7kNSZHhVeN3ppAEByIRu/LoUeELsWMk/NonZ8p+/ck0b7\nTgUUS3cbSp+13Ys4LmZncMAMl+BpomiF8nt9I1Opu/DHpD+vT4uPDOLc4yI3U4Z86iiaivd4g/Lp\nxTsfy5MnSxjNIeKmNUXyId3DOdv/tww3N02M5ckifNSdT8/Nwx5lCLR3c+jhsccGNsSXN4Ylrev/\nwTl4+/nsg9+KNn7PfZJz5xtObu8IdsJImeMdRD/XoGwaSM8L5QMjYuX2EjEQhXGVtE4IvmSCeOp8\nImVqxGPrTlAfqcCtUorB2pAzOqCpG3hujXh7dQddXOfJqtpL8g7Oltbo6rjILchhlNbuGpkTwEJZ\nO3vQsQfLJTJkF/Gm/E46pc9arrX1/bnW5n/HMqWSJK9HKXtubV92equ5fKYsbyv5CVdw/C/ayB6N\n11rr3BFBX76Ed4LjUn0sk778J86TT24TLhs0irhxo9UKtk9FEuW/HvVcA+dm0Aush+jxc2Xada9l\nZywsYmf0DO8cwAxxFOy5lNJjaj8+LNMXcYyU9uN1S9ZQDmt7NOXDIlmvl/ehT2C/9Zz7dSLD90ni\n9b9O4nMzfVJpwN+uYvctuWqwSVoGg8FgMBh+nrAXHoPBYDAYDAmP+ObS6nUx+eyHGywSKy9LaFe5\nmKW7iglugbgOxNqFXiK8NOq7Y30WK+9IN/Ecmp9Jb4bDN9M8+k4ac0/1qeLdzezMu+uziGbjmWI2\npoEPmCiOUmrHbi4vrTCOFC5m1PwLyNdKdEfcIvxm4eKyB/HkgkhXGCv8EuEqjV0qXATUYknqAgDL\nxO3Bcac/PMktNFRCZk6i9IPLeD+/OIT5egZl0LQ7fjf+HuiwgVJB9w7suf09mo7fEwes8kpqYFPT\n6RXzSWrn+JjNf3c7+/KuowP6iPiKXaguSEfLb5vXKU8DOvBeEH6K8FHCzxD+EGnGr8g3vytlVM78\nB+mh6rIC4D2t00HCJYDpeZRe8Rhz96T8H70ga89k/83LpvzyXBLljTMlcJuT33wSWzS0DmiY1U+F\nn95MXlpNQoHMr9VXygex8jLF8sFSqFdQRYwyRMdkjvElddWhz0Tdh6QnjOl1WyT+uytSqcEcmMbx\n/LHjdoiuG9hbC7rRq6jvMsrqMzbPCbjEy8T6A+UfcT+On6S1jX3ZSWSsxTfIB6FaC48V+Feho5nt\nE6uHu0qPLQj1WOwMmT3lO+bId7STMbiqhGPw9H709H1xOaW+PgfvGvCpS7ienjLiiIBPGMt1oJgO\nivhc4uFiEwM4eg+8ZJKWwWAwGAyGnyfshcdgMBgMBkPCo1FJq4OY5u6U42eK/JCF6wK+EW9LqSOE\nN5xxaIB4V83ozN34xZJDo0ySbO0vngOj23DXdqG4YGj+jS6SAwYAvhaprL1YdStkF3tJBs3ds4sZ\n7Km4kvdQVM97KF9Ds96Sepr1ajzuJG8vAZ4Wizmyi5gjGVYpjHhKWjtJf+bI8XG4P+DdcVXA5+F5\nKXWc8FjmcZUiVKIoEV4qfB/hKnV1Er5YeD+EMV34EOGzYhxXHxt6ZmW1kwCGZzB44p7f0AA8/haG\nUvvVPPbhG8PpjnLsDHoOTR7IwfbpJA5Qb2RhXPrziNZXBX055TLe18rbKfvtkU25dVzlMDlbMyX9\nWviLwq8VLhHvcLVwlSF/J1w9TR4Qfrbw/0MYKoGqd+DRwlVKfVW45PBrI5N5HE3cj23i/F0zhDr5\ncerJKetDKzm+VH4WPiTryyOp8ZO02svc1Ja/CneH/iPUV1bbKBZkE0CmbALQiJryKBgkv4WnIsrd\nNQJdQ/pG/XSeIh5yORIzT1eL3rKOzOzMT9qVcT7mJnPubFhPQazSKw34RhFdWstauwziKtYEiS5e\na22PGDkonxLPuhyJPLgBuv1DtoXEhMhVWRIkcOP/lgSAXUUu/CqLHZ4bo192Sdd2A77IoptdDh/T\nIc/HvtIHMwopfGVvZL6tzru8fmIAACAASURBVG04wdan09urbj29BsuG0Ktrl3mU2b7ZQHkS2fQm\nzVtDT7GlFRyRnldhkpbBYDAYDIafJ+yFx2AwGAwGQ8KjyV5aml2jvThb4HLS4aD30mhMw7ZgsERz\n+xa0G8fap64G+nGimPWRlC4zEYYa8nVzd7GYVpeJabVwESWXlf0puXSfxiBu80KZb/Yk7SSuVovl\nOMYHTP2eFsZwX2suL61J4s0z9FppqbtIT8T1Af8Pbpcr6QC4X7h6aY0Urhll1DNLvYLUW0gznf1W\n+CMI4yThKnGcLPwt4XoPmu1HpNj2dAFIXc7fAzXXiGn2GEpd3dI4fxbPpf668TXyzI40xc/72zHx\n8QR5hl985enMb/PuG5Rkpx31WMDfB+WdQ0Jt+rLwe4SrsKIzZ4pwDZg2SrjOzs+F6/dKMiEAwKnC\nnxMeK8ve4zHOZS6iX/yO3oHeTjTln3EkA5uW5rCPhzry5R5lnM0S0OxfSVwfPk3Papa5qUFVu2hM\nwRtJDxXPx/fwoRSKJQfraiP7BGStDfu+MvqchBOFCAsxPbEaOydZgq3Wtaf8lLuceZnKu1PgL5zH\n+1wZWrX3Ii2WbIrLdpYyOvdDlSDq6GnmeVVx99LSYIMDr5N/RA0+RNa+90OhJnsI176USIAhTzwN\nl6mCIyWpjsKXhErz+bshNCaAbiINzpfzQ+PFlZBrnrzWUqcy8fdKkU6olbHZS66/Qu6hxyTyydqq\nlLQKwYCzK7xZJmkZDAaDwWD4ecJeeAwGg8FgMCQ8Uhr/mAHg0vBgwO8QGUvTyl8S8uXSwGVqQ6QJ\nKk12j3+bQZNz2800M67JZECrErF2TZRXtRKRsRZJzqMh4VhYmCLnFNVTQ1qWSQ1pT0mINb41ZazO\n0/YLeJXIJwVg0LMeycxd9M1ieiz1AwPhqTeWCgULRcZSASy+oLm/u0hO4+6idFeIoQH/EyTCU8hs\nLgnEQh5REtgvFBBLJSoNE6lePgr10pkn/MmocmpIf1O4muz/Ivy/wtX8K4HyltMsuqtIXeP/yrr2\nmUxXhc87cvxvekcSsa3UEF3ikfS3YxAPHP4GReY/DaU0+LuvKOdli7T3AooDPkxM0eNCQrF6Tp0u\nXO/lW+Ha3+rtNVG4mKJDHlsqh/k1IWYIl2RaIflYgmKGxBVKZS/fyYBmd7VlmLt7V7LPLh8q+Xck\n/c78Uq5Z3y0RLyV1PlTntR8Nerllyzp6p8hYw0DPlgtCwTm1T1oLVxlEl3pZMGOEAtSrqCSlWwx0\n9nWJ+u08J+TZxXxtdWAeq36SWGt6KlfGvHn7SnmuO1lg4LqdwLX2i2UMnNpDcvVJZriQCDRfpn4x\noh4ScQG9FHPBQIL3ynLXT7Z/XINfyLk69sXVLeRHpf2nEpPkxZN2Tpe+VxkrT46vExmra0gOA+aH\n/LFUZpMW9lo1fLxMozx+RlrL52YJKL2XzmbOxjyMZv0mU2JNkneIsP/gbGwNZuExGAwGg8GQ8LAX\nHoPBYDAYDAmP+ObSKhHPiVLJexPTP4rQUEebNGjVZprfN4gcIsoVqhm/EMXr+MmyKHNl6JzQJ+rZ\n0FG4+nmpya4vGsbupL3FzDxrtJTZegAsxU+TSysW1CispsxXhGtAQpUc1IPqfeGai+lB4ZpvS6+v\nge7+GFU/DcT2gXB1h/iT8CticPXwUo8f8YDYlXICvvqCPEckgQ0aGK8MDSFe/fn08NeDvjxjDG3l\n94oceEU485NwNfCrT5BmldOxr/mwtI/VI0alKx0TKmdqHUYhDO0Plb60j1UCVY+vPwh/NGAdcX7A\nl0hbnD+Csu2j91H+3FfypX2WNjrg/e+gBjLtU3Jv6SnbcW5qUFDdPnCscG37wcLVyyVLeMOSSOw1\nS+aEeHU1DnVHlfVS14jkEvI6/Q6tq3jvFYlQs0LlVBXjto7tlksr5nqqfalr1B7CvxSu/af5tjQi\noYpailg52KKh8rEGoNV1Xb1p9R50HGkmSVkru8jDfKGOX/X23Dpi9aVZeAwGg8FgMCQ87IXHYDAY\nDAZDwqNRLy3dI66ZWw7BG/KfBHArVbOpomEzWhEYzG1FHr1xcjbzPUxlrCFippuSTy+gDrKBvTKJ\nYtU+9eGcIGNjBU0KeTPoPagHi5oRvxau5n7xCJpF020/MeVNFzPuaWDArGdi5BuLJ9RX7ibhfwzJ\nF32EN5xD538DAG6Beu2opKPBCdWrS025CpU0VFZ7N6qcuLaFghiq7KL5usYLF1kqlENKTa0ijX1F\naSVXwnCWb+B46yL3vFC898IeYfHBZWPYdpfIvVwRkmdVMjxNuI5lbRP1vtPAoRpsUCUDlUb0Ou8I\n18CG2s4qeQLhMXWhcB0L2qYa5JJzMA3/DvgS8VJLE4+7Rz9hfrXLzmDCvQd250Kym6Q3mrgrPWpQ\nrx6A8YMuxM8IPzlmziwNJKjQtldlRVdzHY8iIcg6kCvySHlMSYsyVq7mdwJQHgpVq2uKrjUqUUmw\nu7oSOa5rrQYn/ZtUgxJtsYzhZZJ7r5fk3du6L8+Pg7b0NcL/HFq/9LkR9ooiXo1xfFOM47pRQyVJ\n3VISS9KijNVRPDr9M3TM62fqQakymD43dY3+WLhuERlFupDPxzRZd6oxPOA9xXtrDjRhpnoGNwyz\n8BgMBoPBYEh42AuPwWAwGAyGhEejktZm4f30g9+IjCUpcQ6UndpqvIr1NSskqFzBOpo3V8fIcz9F\nTFaDJOqV+n2VCB8bZfoL+yComXY/4WpmVa8V9SJS2UM9tiSwksh100Mm3YcCtlJNmdkS3KlSPRPi\nBzVkqy/SH2+V+kmgs75YFXANhxWOuKYm9F8J/5fwm4U/JTyWdKEeOOpFpB4MQDjnkpqI1QSrOb00\nl5Z6tkjAQM3RE/LYo7xXri1ZSAP5spUHSflewtch3igXM/B5YMKlh14RLeY4jv+eIm/MCY1TDcao\nnh0i44TMxupZo9B220W4BlrUeaYByYBw/w0Qrv2k7asSCkN1VuMIOZ4ux7WqDLD3SAeR64YdGtCJ\nb4jwMU9Wv3UqiOia8OOg2Yt21Q8uEBlLptQgCW4X9nvVtlfZVgN46kqoXjeca+USbC5d5PaqkPRe\nLeUb9kr0of6xOgZUTtM1T6XLIcK1ZdQrkOvxMhwqx+mxty70XTofNfBifKDPTc3q9+ezZYyPIi2R\n4IqloStdJlzXR/V0040KOh7Vi0+3SKh8JrmtJIzkktB6GA19Pu4vXNdKHVOas1CfgzoORgvn+K0O\nrTXMi1YVei5rUMRY3tOEWXgMBoPBYDAkPOyFx2AwGAwGQ8JjK7m0aJDLEC+Yg0XGul7MYieHAoMd\nL1zNbkSuZGxZLSbRHDGhbxDzmu5+nyoxj4qraK4sTaG5MqdWTfHA0iQx1dWr6VcDtKnZTXeYa/A8\nDXIn8k6OmIoLKe8NnPf7gOf2ZwC/9Pk0rR8nG8xfaXIQr20F8011FqnnlRtpEt4DZwf8d7Ijf0bI\nBKneWArxnAiZPh+MLhjBbTGOqweOenWNiiqnpnIJehnKxaXSpXqtaJ1UZlOzcHfhFwn/O+kJlFxy\nH2Qd1krSJS8kCKoPzo8BPQuHiGfW4tOZS6hA5uA/5LfNtSEpUb021MtBhRLNoPSVcA08prmw1KtL\nc5zpPAuL3jly/oZQkDFtLw1upl5A6s2inn/M73WSSGgvjh8e8FtqGWzw+gO5Hu2+hJ4/E0JtpPnc\nLkH8wMCLbXBvwH8tMtbxYsq/MpSLbKxwzVWn0Dhs6sETy0OIa2VV6LiOBd16EH0d3U6gv6t1DGg9\nVHT8RLhK5vcKFwmsNXNR5ZYxCGV6LwYnzJ3NcatCzkzJHxY/cH0oxpUB/8MoljhM5NnfydgsxbNy\nHW0Hhc4v3agwObpgBDNiHNc1WtfJ1tEFBSqPjRGufanevW8JV49DXVv1Oc01Kx3XB7z9weJpNp73\nv0cFv/fLUB0ahll4DAaDwWAwJDzshcdgMBgMBkPCI765tAbcQz5XPG02M5hfah4DydWsU5FKds4n\n0SSWms9cHDWr1QwuJtBC7otPW9lNSkRLQ+phoF4FulNfvVPUfH+x8FuFaw4g3SWuQdzuxA/Fds2l\n1UfaaKaaOdVjQD0JNK+L5jeScaFufaFz1ZtHTddqun8UYWhYr7uEXylcgkFKbqWwqVU9hlQS0Xqc\nGaNO6p2kXjEKmm89b+5PmK9HvCXy6XGHtSoxa5AwbR81rWuYSs0Xpu2vY3xP4aOFq+eaBi0DgLOE\na4BClVJ1/mvgPQ16pt443wiX3EshSfYE4SqFan1U5uR1PO9v229u9hOta/oF8oF4tiQx2B7qNaCq\nej5qO5YI1zZVuVKDuapXn66tQHg7gPqg6TmxckKpVKjjSr0s1UtP5ZjL8UOx3XJpdRWvyQX7ygfq\nuahBCzWI6IfCdYxrgED1ZNLy6k2lMpR6gQHhnGQqP6mkqR5bKkP+TvjNwrUvVSbTd4Jr8UNhubQM\nBoPBYDD8bGEvPAaDwWAwGBIe9sJjMBgMBoMh4dGoW7qqpKrE/Takv9F1DN93jXElargp6+jWWJLK\nBGKzs9aweBmPu9V0Oe0A7s9Z2oZ7ZJJWUleulr0zrUOaNFDmSgOeJyrrupBrorq20eWvh+zbmRty\ns9cIptRZ8yUqaKpEf12BbwPeR1yL10ldV4YSQMYPGstUHbEPCbl+SxTLmaH4tILnYxx/SLi68et+\nEE0SqQnkSoXfLVzGRWhfEBDWllXv1Wvp3h51sNWwCdre6gatLr7qZvsb4bJPIrQfoqfw+EfO1m9S\n59BuoXuUKKcSmTyMp4Xr3pZLhet8171MusfpROG6p0JHmran7n0DIMk9w9GfNXmkJojVaLA3C9eI\nrzrWugnX1hslXLde6L4YjezaHG7MgK6cVwm/HP8n/9HNHtM1WrJC3JTrue8uT9bgdclyD3X6m1fD\nAUgbOdnf4akbNPszKypi8UYZh7ojZHWo3zTiN/dhdpR9O0tCoQ80Qa0mrtXIzJpgle7YqbLG1YTq\nGk4wHQ9oz+huz3NDY1wigi/Qe1RoAl91IdcwCStiHNf1d6Bw3buqzzFdIKK3v/Cc1sLDsbVfE84x\nUiRzc0UodIHuj9X9fEcK1310DJORJH1ZH2pti7RsMBgMBoPBYC88BoPBYDAYEh+NSloay/Qk4b+9\nT2Qsse73xtUBV5FEzcDVYu6eXUNJo6CMEtBqMa9Vo13Al4rres56GoE3hMyklMzKolKxISRjKTS6\n8kw0hLmhyJAqY6mpnAnt1obM+mrKp4F3piTnDMswsczVPw5q/NxbP3hbTPZiab1R3KzVNBt2U9bo\nt5oq78sYZdS9Ukz0IVf338fg0W6K6n6uCUclEnLI9VXdlLWN1aSq7vcqV40SrjKLumlreU0yGX9J\nSx2LQ2LCPDGPy5CdL9KgjthwBGlKRr8X9+a/hOQqdS3XNtd21vmofa8mfQ1PAIRnpCYJbSdck/aq\ne6xKm2rWV3doDRNxunBdqSYIV9lWk5nGP9kkEHYC13Splz8uc+Qc0sEi+3wLha4plOfXoZCH6zSU\ngkZOTm34uKcuy1UNltnYiNS3OvRfifDSBssvCdVJwybo2NPo0voNOu/4jKgJHde6qrt+fKCbIlQ4\nP/dVWVwZbQX7S2R5lafDbaUzXt3MhwpXGV1dxvX5ppKkCqkqMcVGWWh9VLGytMHyK0J9pn2gbvO6\nLuj41bnJe6iXrSDha5Y0WAeFWXgMBoPBYDAkPOyFx2AwGAwGQ8JjK8lDGXk0W3ZM/0NkrJ44IOAX\n4To5d6Rwyjv6hXUSVXF1yKQmicJCSQxpct0gJvBkMYHWYVnAi0I724EVuWLmK1eTuMpYskM9nRpY\n2yqaxNWXY23Is0HEgsGMEJu/kJ5m7bNoop22VD1KVCbTyKbxBL0iMsCInnOPoLm7vZhXrw8JX9on\nYSM6MVr4zBjHtZ9HCd8sXL26tPyfor5P5YvHhM+NwRU0C6uRtiwkj+iufw76zlK/xeI54mmU25Cn\n0XPC9d5+DGjiThKPmqru9LpKxcEB/0hSJrbGPgEvE1+LnlL+L9I+V0hU6ntD0pNGlta+UAlXpYeP\nhEvSXQCtxaxdFop4rCbuG4SrbFYSsMEiH34rclhvMb/PEunuMrm3B0KePyoVaMJQlTOvRvzAOmWL\nNPyyyFglInZdjF/JuYfGuKZKUeplqPegUbF17KsHJddvJ2utJ33TLmqtXdVK1toKja5cGqOuRL7I\nWBqDtyIUaVv02kKuTW3Kue7k13Duz6tTWVk3a8Ray34MOJYzZY/ApyJjleCPAb8Yp8q5bwiPJROq\npKWJQfWZphKuylgqjekc0nmmMiLCTlueeu7GWlu1RiyjgumakHwsc601nznpUqfOOazTnCVD5Nz3\nY/CGYRYeg8FgMBgMCQ974TEYDAaDwZDwiG/y0D6jyWcOlw/2Ea4m7h7C1U9BAyVpUCbdjS8m2n5i\nspuuhjM1swNJsiu9PmSaD4dQ2gL149Gd97F8CMKQYHZZcg8bS6WM+suo3ZA7z7dr8tBBYjqdqkGj\nYiVZnCj8OOGasO5m4eLth9uEawLAO4RrUCog7Emj8qAGDywRXoqtQ7xZQtKMJpXVgGAqfaipXEcJ\nzbqet3H7JCjsInNkoQYcU28OlSXUw0mDBGqwQZWw1Y9P+1W92HSshCWtcIJZlRLVE08lQ11HYkED\nBs6KWYpQr0FKC0kYFvB68XX0vA+339zsLx6H0zRppG4leFO46Cl4VfgvhOsarPNd1tGe4qU1R9dm\nlcOAPPHOWReaRw2vtRrkVmeRhgXcFJJsVI4RiSNFfFFr1S9VvYJUKGPdtlvy0KEiM03SoJjqTagB\nQnUeqVx+oXCVuvIaPt5RvKyWqKSl2wsAIE243tp0NAT1q1wle1hyZEnZELMvZY4XyfEVKsnquSrb\n6nOzypKHGgwGg8Fg+HnCXngMBoPBYDAkPBr10tJ9+i8KPxyT5b+dSWeqRKVYHuO4BrHSneQqS2kA\nOzF8pss1p9PElSYm5+qQcQ2oF0kjXaSLKrXwN5yKBnuJJVaNshslIFK1SAKpPWiaK15Cz7G1rRgc\nakOF5oZR462a4psHmqGqrQhzHUSKWTpV+0HxQIzjGp5SzZRqjlXZS/MEaS6WScLVE0B39gPhUIpZ\naBilAWsrR1Wu1Lv8OmTK109oLs7BlIBvyOaVkiuZi6oum96LqIzlRRMfqPiUIv/dIF6Qty1UC68O\neM2Sp7hZuEojZwtXDxf1LFTPRZW9VNrU4HdAWD7kGEwCvULqRcbqECpNk3uhlB8t6044bCjrd5Bc\n8yPxWDpM1qZ324vss1zXqfhBxaFPhe8RkiZE6psWKzhpLOkuludnqXD13hJpJUkklzlcU9NCAWXD\na+06kRcyZeZtQsPwZPruJCqrCq7zJLBenUorbSjptVvP9aIsux/rV6kSqPpl9kO8obNLw+J1DwXM\nky0Pk7Q+iikxjr8lXL2m1MtwtHCViGU8LVHPNV1Lw32pHlxp8lmsTItOBvPu8ojXvvwutEVA+rI7\n18pua7mRZHNnSlfLFr0n56pUGQqn2yDMwmMwGAwGgyHhYS88BoPBYDAYEh6NSlqaDeoQ/WCVyFhi\n/TpXhK9/h66kHjS6m19lHM3Fozlz1EAoUk+Vmu/43lYdMo1rkKUwqqRca7FSq1zVU/75UlKulIgl\nP6OYga6qqVyhZi7zMy3sQ2kB8yWfSsgoeJrwB2PWO15QHyKsExlLNvS/JZJF2D9KA2WpzKSB4VSK\nOkG4egCcL1wDFWp+J72m5mUCgL8IV08CNZx7DTBgqlqyQ84GGgBSQelnQ0+aoHPnsD/L9d4q1dtC\npYL4I/SrpZJT+jaJ97ZcvBLbh+TjC4RrYLdLhR8lXD0o1atpX+EHCte+1KBq/0QY6l3EOV+PhqFe\nk0vzOI+mhZLkUVYN9+rRAftIvPgOlDH09bHiyTNeJYfSGDX6cVBxX/3+sFbkiHzSq0D59O7QlTRv\nkspbuwrXLQYjhGtri2dt/WdynDJIdUhuUwk7jE0ioIdi2AkfIHrHx7L8dxAFvL6VzCN9OK3nfa7q\nIH21VGVTXWvVY+0lxBuxslVhvchYsgDfAUo0KgCHpSh93umzUme/zkF9bmofa0BUXQQ/EB5b0qoO\nBShsGF1kME+Q5aJYbiErids5Nuqwm0cP2Pn7yCaE7zWfnU5y9QbWe2sYZuExGAwGg8GQ8LAXHoPB\nYDAYDAmPreTSYiAqJ8a5tWLxaiWBj64KmQpvEq5J71Xe0oBI6rGkBl71CFMPn617S6SE/MyA2kyx\ng4rqocZODTunu8oPFhlLzeldlvF+qqU5Z0leorz59ArJz6Fnw6K1dE2oDrVRc4HmQie75DdJN6SJ\nrHE/RMcLtaWasncRLsHQ8LBwFQofEq6mSTWba64YlSXvQ2zEDgG5BRrcrL/IWNrP80Xi6IPKgI+X\nYIg7zaEkkH4WzdQTJovk+q3mmXpZeLxyaan3Ik3ctdk0ayfhKSmtsoz4LB3Eduv7EcfsjEs4H/d6\niF5KX4Q8tlTqGi1cg0WKnBvKDfRbhKHzWb1H1qAhDBPureM47Sxj/EW5zo0SPO/WLAbOvHcjZayx\n93ONWzmXpvK205kDbM1yHeOnIH5oeK0tExkrW9ba60OmfBVC1ENOR7z+ttU1Vb0b1StIJWnVj2Ih\n6lGibmdVaBCaYUs9DQ+VZV5HTF0FvYA3yqpdgYMCnrGUnoCdiyi/zF6hzx191oQ00DihNGBO1pMN\nImNlSPDHW3G4nCsdju+Fq1ee9qXKxLpufiJcA6XKvouQN6willd106Cy5eEiY+lVs+q5BqXJ/UzH\nMQHv8Q2F6IIDuP3ly/cl/9tmfW7qvTUMs/AYDAaDwWBIeNgLj8FgMBgMhoRHk3NpqaFtbawTDhRx\n6GP1mtGcR2oG1vw7uvtbdrOH8ruExYcAA3lu5nfMt7UpyjSn4ov6zWhAOjWghxx5xDFtV6nScrlo\n3Yc0u60Uj4f6gWLTrRRDrieePKU05QHvsog3uVny9YTyncQ64RIxND+kJms1o6qsoSHT1ByruX7U\nvKrShXpcXSb8N8KjvbQ0AKJKbg2bqUuEl4r61FFceJaobT0W+rPTu+/N75pXy8BoeFw9LCgJeN7j\ncc/XEysPUQjvimR0p3hwfCKeWVe8E9Bf1t4Y8GdflVmxRGaLp1KleoWoXPVn4epB9GhUBTV/mt5R\nw15zKodUyuKUJotTrMBoYVAO/OVd7Kdne9KrqdUvmPOuQvLfed7ZzTI3Y61HIRwsXmQfaIDM14Uf\nLVylZPXe6hXjuPbnV6QFsg6sVtkr7E/XRtZtFZtjZVBSH5zvZa0dJMv86s7ky6aqZiZyT7bIGqnq\ni1pCul49AunZ43lfx31u6qaNmOLZ0bLovK7rrHqQqaer+kBrH6hPmIY8VFlZtw5ogFuV3QdFVfAT\nbAtCGexk6e8vfblO+nKtPCqSHD/YtD+7o1Ux15qK9eKl9o7mo2RgR89703JpGQwGg8Fg+HnCXngM\nBoPBYDAkPJosaakPRbLsqT9Rduf/J2TWVNPcNcLvjPFt7WLw1cLVKCgmXfE06FTI+0leGc7cokZQ\nNd6miAW9VjQBDVu1UWyxWaLWFRUzQFf+VBpvP+umWhcD0q3IoqE9YwbLOwmEuCJkmitrFrN5rP68\nVvrtrlB/ql/M1aRtxNS6nuemtWO7VK9SKUPzL6kpXuWwJhn1YyNGdLN+MgDayPF1on1kJFFmy6tn\nu0zNonTXLosayrpDmHtrxSSOQ5ciOaCmcQx73n1xN5trLyVJz46VcKH7SGCxNPwn4NV3sJ/y2jGQ\n4JmVlFhfq+ME6f9hQcDH1NB7qfJ9vS2d7+pN9Irw6FxQS9EwOKbyZZyqIbtLBtt97WbK3lMkz84B\nIty+KjLbCSI6rPgD5+wiSS2U0539/d3rFGK8z3f+SefmmdIWT4Z6XYUizY32hxjfpuuryocqPmmA\nUBW9M2KUaRpSxCmsVnYoSOY5rBI5LTubrVHQnt45dXM5XqbnM1Lh5nou4CtaiWeidGiKeDPVigjs\neet/srl5odzjI6FSuvapp/MVMb5N+08k9dBWkFh92TzQ56b692VKnOF2XbnutJ3BZ99XvRnI1aXz\nGb++L9uo8nO2Y6tK8Xou47153kSTtAwGg8FgMPw8YS88BoPBYDAYEh5bCTxIhOxDNSJjiSoxTgJX\nDQuZ6dRLR6HyhnrmXC/8XeF6nd8L587uxSv1mmEMF66SVheRseaJtbenWP+eEoeHo98irz5obMDr\nppYEfFPKkwHPdDxe3p3muw4zJNBbKHBb8yNWf94l/fmVBMfaVYN19WMwwMzpNBvvcgzLfP7aCyy/\n32Hkn46WL9ZgYBrQ7X7hKo+cizBuQUNQuUqN9LuIs9wzMpT2lK9edQBN31Oo2CBl46iA1+dTUFkr\njh0dltAwv7SyVL5ZR1tjwRPjgFqayveX2b3q478FvN2B1wb8zBM5fvv1oGfSiLkMNlg6le4Vr93F\nPksZQH+MfhKkcXrIG0u971RiPi+q4jr/aabPFG/MtWIgVwnkvbbURlozviBSJRDZq1BwfXkpjd59\nA/58aMBL9xJXoUd0nGrAx+bJeRdrbj4pc3OiBGHdLRRwLpS9SaDBBiVvX+pf5btkwGOIcPWU1FyA\n7wsPe2kNFIles0B1FxlLZ4X6NH5yDiWLw5/h8c2HcX1JeoAerkn19LSqrxK/qGL2bSoYtLAmJPGo\np2Ezo0ZkLOnLSeIzPDS0bUODhYpfYvY48krJNdjmKvL1o+VczX93iXDNc6frkubqAtpLMFr1Ao3l\ncad9+bikXTxKU13tz3Vn3Qx6CtZvvDfgVemcg0uq+A29y5gbbFblVLno1rc/mIXHYDAYDAZDwsNe\neAwGg8FgMCQ8tiJpSVAyHBiwGjHHJctO8nkhM6gGtGLept5iCFt35mMBX/WsBBir1cBKGiKQAZB6\ni3FtlpoB06hb9IiKj1ScCgAAIABJREFUPKZvdxroSpxQMEBsdlr+MknZsTiFeUD6z6YBr7UE0lvS\nlZpJ1zZ0TdirNT1VFjjqZ3Uey88OyTvxxD+F05wZ7s/HA75OcqOdgdMD/tRxNIs+dCLDM3Y/hN4s\nh46k2XHTK+yT4lTKYWtryKtCpmXt/8XCwxJWLJNqnViCC+Wyasg+eQ75EvGY6DGTg6Et6JE0tSvl\nnt0qWH51KqNmrahUc/RM4XoP8cKlwimt1KbweBLodVV3MmWm5Tgn4Isy6RXSvZSm7Jx2vMdeuZwt\nY2pFL3xwv4CmvcU+vvgtztNvwLxVYXlavUgAJ+FM1WMxmY5W6Cox5TSg29EiYy0VQWiNSAI5oARS\nKjni+lZTivle6/SF+oHpOqjehPGUtD4QTqk7PDcZqHURdpPyIiKk7B3Qo2oZQG7aeZSf5r4oK1uF\nBioc3SDPFU/Z8pCMxcWyW9SjRDN0lQivobKEnhIzT8PUXiHx9lbI2YXTekl5ylWbduZaVryBnj0V\nBcwVtXQ6G3KhSIBbz8D3Q/C2cEqA4b78e8AXhULiitY+mGvokevIs67hto3/yPYKvKcBYVXE1QyR\nKvv8R3ilcB3v4XChocCmdFBFW1FVNWTlJTLlV6TRM7PLYsrhufLcrBjIbQudkvgFe+QzR9q0Os7x\nrlKJBU1YZ83CYzAYDAaDIeFhLzwGg8FgMBgSHk0OPKgJ7N9poCwA4CkJmXUGDVv5Yi7LFiPi1fk0\ntf1mrbhE7S8GzjESAWxn8q6TadJc8K8JAd/vAh7/9IizQtU74G3KFZ/sL/ZxzTAvttjdxKNgo8R9\nGjSGJnF3OM2L9Z/SxL+hhqbvjC53BDxtNCWjl3NpXuwl5t3vxBTveXOaJbiZ7OfH3bFOWCA5XmbT\ns2XqrJsDPnYf9vOhbWmzvXUKBaSqUo6LZy5T073KBurNoyZeNQ9/HqumTcK+wj/7JfkxtJbiI4nd\nVSnOEGqwz5csazmYHnDNagMJegeRxjzv27gHN9OW+706uP2KdHo9++BsCWY3Vu5sDtRUTCyR6I1e\nFSWg4Yt5x+m9eI/z5X6BO4RfJ1zLAOEAo4RYzUO+SOql9Yn800OckeY2Sa/gPSeL7FUXktxGCGd7\ned47zTI3j5XjrzZQFgDwtKy1p3MODhBxt0pkwmsz6Wl24SYGa3ODKQx731JiRhsufsnrOV7qbqWE\nO/BGeg59N/yCUPX2Hc18iJ/tJ0mUPkWD2E/4d3QixDEvch6tP45rdtUrDEJYUU/vrerWHPSdp74X\n8Jda897allE2WiMLvud9Eve5ebIcf6GBsgCAT6Qv/8i+vOQzjvh1w7k/45J92Wcn3M3+zpTUbgsf\nFHmngzzIloqn5Kkiuz+nWwqkAxCVg1DVsZVoECq2zpK0ese9Rvl83cF89lW9RSm9KodekK6ID922\nE54L+H868dlSMJvbQlaL0O15EyzwoMFgMBgMhp8n7IXHYDAYDAZDwqPJklY4Jwj/2yjvTFlyfJR4\nVBVeTG+Bd4+mt9cRYHC+5zfSe+mMr+jt9VLxmwEfcju9Ebxf03Zd/B3zPC3aj6a5ojfC+XlWdJsR\n8Mn3MyfMetBMmyZBz/oNplzRvSvdC5au4T2n9RkZ8NaPvxbw6ieZ0yb5A5piF53SJuBz7uZu+ILO\n9HKZ8RE9095dNLdZzOax+nMzzgz4edI/9x4j9ssXaEacX8t765VC8/P4pTQ7FlfxFp5+lf05+R7u\n2q9eSflxk0hGmeIVUh7y5QAKu9HkWypW83wpkwwmcOnfnebczsuYWGt5JudA2Vr28waRqza1ojm2\nXQW/4atOlGZmLp4W8CLxOhNRFp7nNWu+nj9Lvp4bxS9t0xq2Q6amQ5L8NiJghiS8avmgTn4iTfyQ\nHjH3fsBaTLybY2gp6N2WgT8FfLN4bgJAVu5XAS8Ql7tWUkadLiUsYEhKbCNcPffUYK+eJnuJ9PiB\nfFt9yONDJAER2Tyv4iedm5tkrc2U46/KHKk7e2jAJx1Fb699cp8K+HPLGM3vjK+Z+eiV/AcC3v12\nrtNplzBIXJc5BwV8qUhVbT8KB31b1odr6rx/cpCt2sQ1uV4G386DKLN1y6S0uKRGctK15f2kf0ix\nr+xmBq1MfYP9NvUcympz76Y0PqALu23qOMo6E6pXNXMura0/Nz+UwJZtJlB6+zL/9oAflEmp5/Hl\nDN948iJKOq9vfDbgxfdyTVuxG9ut8GsGJFzcgx5tqa9FaVUD+Dz6dDzF7jSRfWsliOxu3dkH3fPo\n47Wyiuuva8sgn2lj+ExYe9OFAc/8mM+WWSfwWfHtIwyQ2b01Z/bU8fT0nlXX8Nw0C4/BYDAYDIaE\nh73wGAwGg8FgSHg0OZdWCBK4KuskHl7/IBNntLmUptWlR1CiGP8Uza99r50dcHfvxQFffRFt6P8e\nRjls5HP0xpp2Ks1xV45nALD/O40BjfZ+/KFQtTufS9Nn2qs033597P4B3+soumy1nkDbf+k5zBO2\n6UrKIUmZNPctPo3B+QYU0TT5wdnMJZU+gwGnajtRuuvenmbA5xafgeZGSMicxP7MGEpJb+1atsu9\nLzBA2Q21dH/JdCyflMTjya3YdlW5lOserOAe/tb/ZpadZSNp4ux7PD0qJv2XQanaitkbALKn0oQ7\n+xAG/St6n14MdSJsHC2xLSdexTrVi5vaqgzKWCskUuGQ9pS0SgfwmitXsCWzJNhmlsikmhuqOaBS\n1E2r6eVRVsDoinfmUZbYXEvJKV1GghOPpRo5Xp1M/p04lLwzkLmtXttZ+kbaM6ctowJuWKM+Vyr0\nARmiPy3k9EI3yX8mqiVGCn9VUkN1l9xLKmjrLzvtje8l31Z9KPiaihHqcdc8oepi4lmRscSzcP29\nxwe88ArKTwuPpQfpzGcZlW6n6zkeX32PASlrTqcs+ehQromHPMlcXTPPpMzwq0+4pv59JOWKYa89\nHap2j8t4zuaHHwn4pLNkzduDa2r+BD6Kpt1HaXjz5bym25XjedWewwM+pD0n9oe/ocdP+eQXA+4V\n0KurMIvry8QaDasXf4TW2ffkucnlDus/YscOvY5r/8RcetnNXMgtEm0GU8bKW8NtHmt35Xx8ZuT5\nAe93Gz1jJx1Jv7GzXqHn04PHUV4cfAflZQAYfB196Lw/0M1u2p8ZgLe4M/ugnayzM26nZFgtKTLT\nd/4X6z30kID3acf194uz+L3lU7m9IruGY7x9Kp8hL9dT8owFs/AYDAaDwWBIeNgLj8FgMBgMhoTH\nD/LSegJ/DvhZoGfSeFByGiC+E48/wwBzhyzj8bSzaBJbs5Am19I0er7UzmL+px5JzOG0PJVBpbq6\nzgEfu5mG7JL/UIYAgKkDaNbf9bWXA/7iOpqpp81le6Rm0TvjpDp6BL0kXkcdsymnDb6Q9fi6H+WW\nLkWUGVrPocnu8Rlsr52/olbwVXuaIOe9Na/ZPUE+lNw9IyTs2SLJt1UknirLVlKaaLuaV0rpxffn\ntcupRSxI5b3VT6Gn3OYc9vMrbzBPVnE2r//ZdJql2z8XNj9/ujNN3IdNpnQyRl7jl8mNlsi5+wj/\nSHiShLTr04Zi0QftKMvu2pZ9WD+BksA4CYCWJcJJufgFNYeXlkpaiyRoZVeZg3VPcjwmT2UV6pme\nCUkiH3mMKYd6iQm4VuSt7Gls3AWF1P9Gn3BXwD/vTjN76fh7A161Meyl9VUWZYyDxElkvAQ6y5Xj\nFK7DnlyawSxd+qBWgvDNEC/APSVvXQ0YdfIrSLI1DBVOb5Z49SXQ1LWWEtXnEoRzJ7nrxx5lyxz1\nrWwZ+APl1or5XGvn5EpQzOmUGTrlnMcyNUyI1CeZnk/j1pUGvNt7GpEO+KwHpY8D3mDOplHl1C5n\ncRqhQMJKHi3XeVN4rnj59T+Oa/vHg7juDi7k+Mz4jnLHk7NHB3znsfT2HNeV3luVM5vXg/K/+E3A\njxdJdyqow5aIxPrBN5RSd13FZ1T2MPoiLl7OSbEqk/e1uZRbR4rrudpNWsvndf8aBl38aCllsq6P\naaY6YOoAPo92eYtRWjUo5rR1XHSL5K5FuQtl0suV4Ia7H8f7/LAXtzAM6MDnRtZnnKdPLOI86D2B\ndZ3UjpFiq1c23Jdm4TEYDAaDwZDwsBceg8FgMBgMCY9GJS2DwWAwGAyGRIBZeAwGg8FgMCQ87IXH\nYDAYDAZDwsNeeAwGg8FgMCQ87IXHYDAYDAZDwsNeeAwGg8FgMCQ87IXHYDAYDAZDwqNFvPA45252\nzj299ZI/DZxzo51z52+9pCEa27svnXN7O+dmO+c2OOeO3foZBqBF9JvnnOu59ZKGH4Lt3b+x4Jwb\n5Zy7tZHPNzjnusf6/OeEltqH8YBzriSyBvywhOZNxE/2wuOc+6VzblJkAC9zzr3jnNtn62caWhpa\neF/eAuB+z/NyPM97daulf0Zo4f1m+JFIxP6NzON5Wy+ZGGjJfZgIP0p+khce59yVAO4FcBuAIgBd\nADwI4Jif4vsN8cMO0JddAXzf0AfOR4uwav7U2AH6LS5o7l+ILRU/l/5NZOzofbhDzD3P85r1D0Br\nABsAnNhImZsBPC3//wfAcgBlAD4FMEA+OwLANAAVAJYAuDpyvAB+rrn1ANYC+AxAUhPreDCAGZHv\nux/AGADnRz5LAnAjgAUAVgJ4EkBrOffMyGdrAPwBQCmAEc3drtvjr6X3JYC58PP1bYrUMx3AaAB/\nAfB55HhPAB0AvB659hwAF8g1MgE8AWAdgOkArgWweHu3fSL3W+RcD8DFAGZHzn8AjAQfcw7Czwnr\nATgPwMJIXTMAPB2Zk+sBTARQJG3xGIBlkbrfCiB5e/dRIvcvAAfgnkjflQOYCmBg5LNRkb5+K/J9\nXwLoETUuekrZhwF8ECk7BkDX7d3+P5M+/DTSF5WRep4MYDiAxQB+F6nHUwDOBjA26lztw0wAd0fm\nchmAsZFjW+ZxSqTc8fCfpQPj2c4/xa/dveAvQK9swznvAOgFoBDA14Ckk/UXq4s8z2sFYCCAjyPH\nr4Lf+O3gvx3fAL8B4Zx70Dn3IBqAc64AwMvwF9QC+A/NvaXI2ZG/AwB0B5AD/6UIzrn+8N/ATwNQ\nDH/QdtyG+9zR0KL70vO8HvAfekd5vil8S/7vMwBcCD+x9gIAz0eu3wHACQBuc84dGCl7E/zJ1x3+\ni/Dp23CvLRUtut8EIwHsBmAwgJPAZMtnI8YcFOwPoF/knLPgz8XOANrCf5HaFCk3Cn6C+Z4AdgZw\nCIAdfb9eS+/fQwDsBz/JfWv4fbtGPj8FwJ8A5MH/AfKXRup9GoA/w1+rp0TVe0dGi+5Dz/P2i9Cd\nImvrC5H/2wPIh29Zv7AJdf4bgF0BDIucdy3CSeXhnDsHwJ3wDQff/c8Vfgx+gjfX0wAs30qZmyFv\nrlGftYHfIVt+0S0EcBGA3KhytwB4DZE3yW2o35kAxsv/Dv6A2GLh+QjApfJ5HwA1AFIA/BHAc/JZ\nFoBqJK6Fp0X3ZeTcUm1/+BaeW+T/zgDqALSSY7cDGBXh8wAcKp+djx3fwrMj9JsHYB/5/0UA10V4\nY3OwJHJud/n8XADjAAyO+o4iAFUAMuXYqQA+2d59lMj9C+BAALMA7IkoawL8F9BH5f8jAMyIGhdq\n4XlePsuJzOXO27sPEr0Po/si8v9w+M+7DDl2NmJYeOBbajfBf2mKvvaWeXw1fMtUp+Zo55/CwrMG\nQEFT9T3nXLJz7g7n3FznXDn8Bxjgv9EDvqnrCAALnHNjnHN7RY7/Ff6vg/edc/Occ9c1sX4dACza\n8o/nt/6iqM8XyP8L4C+0RQ2cuxHhXy6Jhpbel7EQ3Z9rPc+rkGMLQMtch6jyyndU7Cj9tlz4RvgP\nNKDxObgF2k9PAXgPwPPOuaXOubucc6nwf4WmAljmnFvvnFsP4J/wfyHvyGjR/et53sfwLXIPAFjp\nnHvEOZcrRWL1e0PQ9XYDfFmmQ1Pq0cLRovuwEazyPG9zE8sWwLdizW2kzDUAHvA8b/GPrFeD+Cle\neL6A/6uqqS7Cv4S/SWsEfPNnSeS4AwDP8yZ6nncM/EXqVfi/BOF5XoXneVd5ntcdwNEArnTOHdSE\n71sG/1e//yXOOf0fwFL4C+UWdIFvEl8RObeTnJsJ34SeqGjpfRkLnvClAPKdc63kWBf4OjcQ1acI\nj4UdFTtqv21BY3NwC4I+9jyvxvO8P3me1x++6XwkfEvuIvjtUOB5XpvIX67neQPiUMftiRbfv57n\n/cPzvF0B9IcvbV3TxLpGQ9fqHPiyyNIfeK2WhBbfhzHgRf1fCV/p8CvjXHv5bDWAzQB6NHK9QwDc\n6Jw7/kfUKSaa/YXH87wy+NLPA865Y51zWc65VOfc4c65uxo4pRX8jl8Dv+Fu2/KBcy7NOXeac661\n53k18DfA1Uc+G+mc6xl5YSmDb+qs/5+r/y/eAjDAOfeLyNv15fB1yS14DsBvnXPdIhPsNgAveJ5X\nC+AlAEc554Y559LgmxxdkxtnB8MO0JdNuYdF8OWO251zGc65wfA3vG6Jb/EigOudc3nOuY4AfhWP\n792eSIB+a2wO/g+ccwc45wY555Ij9asBUO953jIA7wO42zmX65xLcs71cM7tH4c6bje09P51zu3m\nnNsjYmWrhP/Q+6Hj4gjn3D6R9fbP8Lcj7PBW2JbehxGsgL+HrjF8A/95OsQ5lwH/mbjlHusB/BvA\n351zHSJWqr2cc+ly/vcADou0w9FNrFeT8ZO46HqedzeAK+FvDF4F/5fWr+C/eUbjSfgm6yXwtbzx\nUZ+fAaA0Ysa7GL72Cfibtz6Ev4P8CwAPep73CQA45x52zj0co26rAZwI4A74g6cXfI+eLfg3fBP5\npwDmw5+sv46c+32EPw/fMrABvidCFRIULbkvtwGnwv9FtBT+JsGbPM/7MPLZLfD3cM2P1OElJEB/\n7uD9FnMOxkB7+P1WDt/TbkzkfMC39KRF7mtdpFzxD6xXi0EL799cAP+C395bPFr/uu13CQB4Fr5j\nwVr4m18TwakAQIvvQ8B/eXnC+XLwSTHuYRb8NfRD+B6XY6OKXA3fS28i/D68E1HvIZ7nfQPfKvsv\n59zhjdRnm7HF7dMQB0R+fa4H0MvzvPnbuz6GHw/n3CUATvE8b4e2AhgMOzqcc6PgOxDcuL3rYtgx\n8bMMwhZPOOeOipgfs+G73E0FN5AZdjA454qdn54iyTnXB74b57a4ihoMBoOhBcJeeH48joEvjSyF\nby48xTOz2Y6MNPieOxXwY1e8Bj/WksFgMBh2YJikZTAYDAaDIeFhFh6DwWAwGAwJD3vhMRgMBoPB\nkPBoNKqj280Felfmgt2C45uunBjwPl9cEvBZQ/8b8MwpRwW87bkvBrzLcm6wzz5sdcA7rzgy4Hv0\nXRvw8ureAS/OZUDNgtqMgLdLpSy3oJahOfJSWAYA6msZIicnmeWmVVWyfhmZAS+rYvMUpDNUQflG\nntsjiyEEqutZPldeJavreW7rJH5QLSF7qiV+07zqmoCPSE+PW1yf27/rHXzJ8qTnguMje/K7a2oY\nZiE5k/ezvoZ8YBrvZ0kdq1eUzPbOkXsrEr5R7jNLjutAVK7+4MkIQxtG39wrheu16oSnCd8gXEO8\n1gjX8hr8RQNI1MXg64V39ONf/GjsdSPnZs2qq4LjSed+EPBeS4PQHFjT/bOAV5TuFPBhu08IePVm\nztnMjgw+3GNTfsB3asWWXlvPudIqOTvgBR5vMV/udrmE+8iIWnrSQuOCWOCxJds4joA6UeJby3cs\nk/LFUl7nmvZxhUj6raVrNHSszs3SGvb+fmlpcZubzrmG9xbsI3zszvLP5IYvtJ/wscPIDxhHPo5x\n3wpuZ9Db9isvDniro1cFvGjtcQHvPYghb5aX9Ql4m45tQtWoXcog2K3aTgn41Glssja9FgZ8xRfD\nA95ur48CXvcBY0LudsqmgGeuPTjgHdvzmtmbOK66ZnN21sjaXJfEpp67kSvML7Kz49KfMfuyv/Bp\nTbjQnqTpU/oFvKrndH4wq0tAO17P9mw9+5SAJ53K43kr6cXfZY8ZAV+zkNdv2yfcDGXzB7EehR8G\nfNVolkuVa60e88uAtzqMHvV5L+4e8J2v4jPerTgz4CUSkjC7nP3XP49rTU09V+O6JK4p8yq5Yp+Y\nk9VgX5qFx2AwGAwGQ8Kj8bwd3/FNrXb4uoAPnHNLwLNzmeKmb9dHA76ynr8E8lPOCXh62rKAF2de\nFPDyzOqAt07K4/U9vsH1cakBXyXvbyVS5Xp5hdP8AAAwUz7rJSlL1qTSMtFTyk8Vk4LGnp/Fl81Q\navTlruHj65N4oTw5rkm3Osgv0AUpak+IH578mvEU9xzBm+jm8Tf1mhT+OGnn2GDfS1to4qFkuWcN\nT61WDWkupMp96l2qNSVZymTIr+ukqCDWdfKZnpMtx1Ogv9p5XG1/+taf1oTjOmn0e51cXy0/em/x\nwrSxdBzrfSTTEu2znHOq0vFXen0erUBlZbSBVXliia2kXaNLEq0665N5X8XSKq3ld2w7qdsa6SYd\n70lybnSypFXSjvlyvFbmqV5rsXxHgRzX8prjZa1wtUUki1VHc43oT/RCqdvSlFQ0DzQdlGRKCIVt\nU6vOENJcWlDwDUdqWhrNCF2yGLR27q5TA5634YqAF61n2yW1YYqlyspyls/geKks5zjqmhbOqPN9\n5saA751Jq/F37bn+98kYGfDyTswSMjyLwc3HHMSe6yGr6loZQEOlz1fIYqPrv46XPnJ8TpraE+MF\nXadkJMW06shqUUCLU7Zk+8vPpVUnq+/wgC/NZ18WZB4T8MJUPjc3Fd8f8Iwq9mWbfJZPKmP7d8oL\nZ36Ys459sEsRrYCfDPkm4DsVnBXwbwfQojQ8/6aATz2RfV+SNDDgq2XCD3NcmZe1Ytt1kjZdKM3b\nX9aU+elbT0NmFh6DwWAwGAwJD3vhMRgMBoPBkPBoNA6Py+Pmq/OzuTnqsS40WZ0ymBuRvk7hrqxD\ne5D/o/PXAX96M1PgvL4bNy1fW0Bb5IWp3AD5bvquAf9ArMnHOm5OvNWjKesmkb1eikrkerxsN71b\n3vWuku2w/5ZzzpGtp29L+aOFc8tnaI8ZFgjvJnylcJUBZgrvInXIdklx2xjZ8dsLgwu/2pabzTcU\nUqQanEyBoFraMkfq9L2YF3cRTtETaCflF0mZLlJGN/+qMXKjcDU410W1hCgtoU2mKldVyzlpUl43\nNmcLrxae1oTj9XJ92QsZ2rSsvyqS4rRpOf2CguDbbu/ItDazhtJk3bs9Nxvmpw8P+PoObNWvpLWv\nRK+AL2jFHtk7ha17nwg/fxDzc6nUrYdsTv5I7v5gKTMPYegcGS38AOHfCVeJWYWeXYQvFK7jTlNr\nq/RcLjxX+BLhec00N3Wj65Fy/C3hWtclItjsLevX5zLXhkurjs6h/HBqa0pMzw2bFPDbs/8W8NdP\nnBXwmzrvHfCzU6mzvJ19YsAvaEO5AgAeq+OMOXgzz3mjtm/A98zhOR+vYpkb8jhmnqjic+Qq0cyf\nlA3zH6VwrB4DrlnfSlvsJP32pdSzXz1nan5yatw3LeszQZNdhfuSOE5G6ivJHMGH1nED+nvtuAH9\nzCR+w5M78Rv+VHV7wN86j8/fm9rtFfDz2nLbyVvu8oCf23k5FI+KU8/Z9XyCPbF2KOvXgcdfWszy\nd7SXtWMly18xkO3+RD1n26fplPeO9rjSTpNlc6D0Jd2ngH7q4JDUcF+ahcdgMBgMBkPCw154DAaD\nwWAwJDwalbRKsg4PPhzUn4bjoZ32Dfh7HejJtW8Or/V0J5oWD+xA8+b6VjRpjhTvqLFFjNtwMq31\ncFkUHPaSzeyjxcS1v7y2bVSvoSij1mi51b3k+Eop11mOvyD8JOHqgaSy1AzhfYWrl476eKhpXX00\nvhc+ME4SCADc/uySoAUG70efl+GF7Icy0Y0Kpb0/luvsJzVSGatI+GLh6i2ho03ftmtDMXm0VOzb\nrxfelDf3sCzF7/BCnlZaJ2Lr+/8Rs9Y18klanPpz+IiHg4seeAjvbMTuTOr+7XxKGjvvRNnj0jS2\n1pX/3955x1lVXut/TZ+hDAxtBhiKSgepIhZUBEussWLsNWr0WhITNbHEEo0aS6xRVMQeIxrFBFFR\nQVSq1KErDH3ozAwD05jz++P+7n6+79w5wNVD/HzG9fz1zGafc/Z+296s533Wai1XyOoyzbXTG+ky\nx6fqs6dkYW7iVvLQAYW4zva4W7YnnXtm4VzgOGIeJsqb34FTDqO0yfMpJdNlGK+POa7pDlsK3iWB\nczM16YCoYYdB8KNjbVojCXyttqtlFjZTa+Rs16yo7KRzUhboeEpf5Vxp10wSdvbBQyPeK0ezdmU3\nrZYDc9ViKbkSZvplcnaZvYBcKSfV6DoKstTzxyMX2tUVkiOeSFdPLMrUijk8XePwRfzWDVyPwNnP\nk8EpM/GZMCw5Mf3ZMKklJC1t29gRnLWf1YUyPC0yWjaJeFV7ZQtLXarVtaKz5Mb+SP4WGyD5KK+V\nnlKrWh4T8aPa6eYb5cuf3CYr7MtXY+qzcyBVrmysB0R/bDG5sVLnPAAH2upG6sthWRofj6DV74JK\nvC1OX84AHwDO7SWHxpmbHuFxOBwOh8NR7+EvPA6Hw+FwOOo9du/Swm7zLjje6Wi5OcY2UsguGQmm\naprBB7NLYs+gXudHPG2t0k63HS4Px8IdEnWe6qfgZWrxcxFf00pJq+ZVKwB9XYa+v7iG3iezncna\nDT49pjTlZyXJCbDFivV78O+shCxxEILlVXGT3AlMshavtVnegG+hjRMYNn996l+in1+a3zE6fnmT\nn0W8Z6b6bVayHDknmlwUbZJ0/BGELDtBIJgFMaKFMbGjQplpEKXo8WjA5HY4XrshGCKmNEGHDdub\nzikGbYPUYwlr7bqRZAmStC49MLq1snfkCfzDfc9H/Iwd8vgcc6ASg40ve0lfdKA8QU3KFTi+r41G\n8NgG30S8M/yAymJMAAAgAElEQVRRlzUYFPGWNQqzf5iCPo5J9jglSeJQimn+mZnNx3jZink3BGOn\nCr22CWNnFVxKh2M81sSRLdn3dOjF4nDKapRREzk3udayhMou6my09qxEkD9GwW7P2B98GbIwXnS6\nUvJ9N1FrZ5t7lVRwRZHSpd5xzqMR//qLR4LfaDJEUsvo1fJFPdRNCTPf3vCviPfMUU2Msen6jaey\nzo14ESo27Ic1iPL5gdg0sBO9yISnq9CLTDbZNiklIf0Zt7QE0RG8UJR9E2wXyNSlLSrX13fHOWsx\nPs45WE/sxZ/Jcdf1Dp2zAIvmLaf+PuIFCx8KLrX5IVdEfFLxyxG/Ov/9iH+zQ2tEm0w5tyenSW69\nPuOsiG9AE7VN0hNyFfqsD54VXC3S0ZfrsKpn4rnRNo6D0iM8DofD4XA46j38hcfhcDgcDke9x15L\nWnQjbbSr8RfSKf3sEvEyeJmOUUGYA8ZLumpyrUSJ0vkSItoM7xjxAVN6R7zlSQqtbi9SrLe6p8LY\nh23RO1xK8/B9blMJah0huVVb2KhaIqtcJUJ+LRFa5reyLg8lk8w4xxmhpgzDMDZq4VrPBIbNjz7k\npagBDk5SP2x5QR6x/ig69M3B+ul+Ui7t3dbit0kBtEroTzWoA7MFGtOxaIzNuOlsHF+M46j3HMh+\nZmYZGLqs39TG9ozkuDxOc8cpj7M3x1nZOzUpMaJZTlJryM2SN6bZBzhLYWa7Xq4Nm4tg+aXq8NZv\nKaBedb+kzaypGs0bTpMs9eQMiYGTB6sV85fr68f0VGc+g5+dSfuRmbVU2S+bBLXmIuhJpXANZkEz\nLofli+5IyqHsmsw4xylJVwd12oRvwRPp0srEWss6bCXBXWCyBWkcZ4Jj4kGw69YGkkgj9fkgLOzr\nVytRZa8zxJeganWrX8i9lf+F5M1GPw9n3eq54juPlmSRX6AVsOlALSSxVZKZ9u+tVbU9Moce2FCf\nTYK22BoTmGsqtxLU3Spm72IAnJcgl1Yu+pLPhyXglNGPRrrMrejLnShplfGdLq3dAM3BqcXqyx4o\nBLm1QHd/6MnyMq2okCuv5XAtzE1naptK/pn0sZltWqAxWDNYfZC3TOMi60D1f8UGNWqHfE3OxujL\n9lmaVRXoS7o96W6m9MjnANtxLPryjDh96REeh8PhcDgc9R7+wuNwOBwOh6PeY68lrRtNobC/3oLA\n8YOSq5oP+nvENy9SXRbrPlB8ASrWnCnZ66JSOaW+WvZ6xHuceGvEM9tKPju4nUK6JdvkUqkafGLE\ni4t1bWZmR7ZS6HDtJu0e79zp1Ih/sEv1S36Xrrom62K67u5pHSP+DQSroQh+72DNHbxX0lHQAXwV\n+A64CLonyDlgZpb0vPrzlKZqy6Jj1C7T58+L+Gtd+kX8gqWF+qLOuPJd0rreaCLJ8fNyOS2u2Cn9\n4qZWClQ+USNx4faYtIvHENS/MkPt+7cYxQWzlxHA/i/UU3sdRa0GQaZojT5pi+OUHOkGYAK8AOiR\neMkPOa3o8slKkAyS1Ex9eVnNTdHxkS+qRpr9Rs6sXhd/EvGCe5/QOdfg/Gc+jWiLvynJ3aZPvoj4\nkRV9Iv7FmUqQ99t2kswe3qI0gjckK5Xn44do9N9WxhSfZs/F8Jlitfxz3TWOjt0ugaBpA83HE+HY\nKWusEPp2NPUJmJupgaooDtU2mJt0EM7DGDphH9XS+hOO334V/pBJ1Vqa/mEj/yHw+WA0Q8bqt11t\nPwsiXRfYwJa2VYWnixpqTf23jY34cf1Uf2lRJcaUmR3XSdse3ln+bMTPHvJgxF+pVmrX+7v+LuJf\nN3sz4pd3lUt3XKbGyK/SlLhvKTyx3ZP0nJqImX0c+nl8jdagpCStISclN0rM3ERfvozjF1+MP/AP\nx+Mw5ZrZ4KwRtwlbCvqu7xjxsTWFER8MQa8wX996RaocVOO6KFXfIW3VXyUt1F9mZoNbycE1LlU1\nuo7fT+vFuLZ/0W80+nXEJ2T9LeK/aPZKxMdkSve+MEVjdgkq2nVPUvG0KVjrj8Rc/rJGfZ8GnfPI\n5MYuaTkcDofD4fhpwl94HA6Hw+Fw1HvsQdK6KvrHO21EdLwkTSHOgqqCiI8Pqk9dLtoUfD+FtTIq\nFVqtqFB4PGeD5KqtrSWxZDZRrZfyZpKxmq7rG/GubRT62tq4V3A/O7rKedIiJntCn85yHrREjY81\n7SW59GkkyaRXWx3v3UCRs1kIoh2OV8kKcNYEWQC+H7SRt9AlV6QmMrnZU9E3f2VPRsc/u1zy1gEv\nvh3x885SwikbjepFl3QUXwiR7iaFk/s+JUfJ7PWSunpVq38KzpD8MOx9hd8/bai992cuU8O880xY\n0epPoxWyvv0XCnPip+1OFEF7AtpEA5SyGYT+aY6fYGJDemUsTu0tSmMpkD4olbRMlKSVdH/0Ax/Z\nbdHx2S3HRXzrxpsj/oB9hU/fBv5rcCV5s4OuFJ8xAef8HBxWnAytCVYBd5gdCa45a+0OtACrUKWq\nmewpadvUC1XnSNLKgTtl60mSwP60v5wnDQbBEQT1aTCsHRSM20AxXYk5iNJ+9ld08j3piZybZ0S/\nco/9MzpeAl/nHIisnwROWSaKg0DSWWMheanapQaVy9qZthusajY94nkl6oOiNpL5226Wg2dnvtaE\n9J2a42Zmm9qpoXK3SdJu0kYzKRlZFcs7y2LUqaWSFnY/TnW8Dmul9WJJM3mthmEWbkc9qV6Y1/9G\nH3Yv1R9P45pfa54YiTIpqWf0A89iladLazWqNi5D+sD5JpmoazO1SWWlJMaWFVpDl2doMHfJ1Pnr\nG0oyyt0gj9oKPMf2y5Izq7Sd1tkmpWEzLOmkxXJAkdo94xhtbWmP9p3WQUkPD03ROOowWNJV3wxN\ntk8b6nl6XI1+u6SxzumKvvwYz8rOJfpjNM55uHndW0E8wuNwOBwOh6Pew194HA6Hw+Fw1HvstUuL\nybAqbCj+Ok00B8nNtjJl3CngTIxGC8Lb4C3AmSaKe9VfBD8UHJkDO/IazKwQu8+zsWW+B+p+5cDl\nsN/n4t0VTn70zEsifuAuhYe/zlNYN7tKW+kHZirE1zomCWhCkkJ226oUmluUorDviJRWiQubX3V2\n1J/JI27Qb6Bdr2D7DUeM/x8j8U3ng98vmgKpZNedOOf2us9ve6/4mudxDuQUk6vDTr3VAowZgz9O\nBYe0evs54u9OiGjuIwqb7xqqkO/MVLX9GDg4hrNd8P8E5s8rAud8QWpOOzlhkpasaKlIz5hvGuOF\nTHvWC2JqAZPWvQH+X+AvgN8Efg845TA6he4G/yM4ZJjGqOdlZlb6B/yBcWHXiPZ4XHwB5vL+vxC/\ndEJEjz1cffxlD9Xz+2WNnGbluervy2OqsvVyshykjXaqHR9K1ziIpbbYJy6teMlJzWDPyUU/rP9l\n3ecE/jJWXWJqUwKZ6wK/UFHtE+v4zupa/waJEvWtzNT2loHskRU4Z6jEnxsvxNjbOjGiK8+UJLp0\nnSSRq3pLlq3ZIOfYkjw5sz6dIzk0Of+SiBe0OSfhLq18HF+dgz9o3Wx5nPiKjyPKVI5tsNDMQHLY\nOJ4869hG43TyWo3rzjiHtbra5ciRvHjrSiNa4BGchUdl3wHHRHzHwvERLzxIfbOll7akPHShBMTq\nOXJxT/656mIWrdPz8YKueobENuiZMz9PElvBfMnqxW1Vz+3jvLNd0nI4HA6Hw/HThL/wOBwOh8Ph\nqPfYraR1KEJza3B8lf024j1MoakFgVvgZtszBoFPBWe1G4Q9g5Arq9qgmE4Q2GMAzywMs/K7NoOr\ndpfl4ntPURjtqGqlJUu6UPLegHkSMlZeqN8+ZpukoWWt9I7Zcb1krHU4/vhSxTu39W+YsLD5aUkX\nR/254Fzt4l/1plKdnZA5OeL/LEeoNZATTwJfDA5XlzERGdw/Ngqc0hUlLcom14M/YCGeAR8Bfhk4\n07h9CH5hxFJOUNvnvnhUxB/ainpt3dSHR7M2Fv7LkInjZei1UXAV3JGSGEnrpKT86NcKMDtXok16\n2lMRn2+P4dNMddYVnHPqEvBXwSFhw01kBlnJ/g5O+XMU+AUW4h3w34FDArWzwSeD9wBHCs/OJ0S0\nNarurHta4/S69Zrjrw1V7P6yb9VpYw9Q3y/8WjH92Nk5CZub+2OtRek5m4M5kokxXm534CxKgPGA\nwkz2XdyzhLB64p6QFFSuMosFkhi3JUATofyWCftbG62vvVpona4+TLJLk++01s65UtLl8LnaVjDu\nQH3nofOV0G61TFT2zSuS62JvX5iQ/mRfcvT/CX8dYEquuwZjvNwk7XZCPGI7Upz2aS+hbFqaJKAO\neGxuni8+oIH6ZmxD9Us72FCT0S3tmoZxkBnJ+u1W6Kat+PzBORq183pKu2vWSX05YKek99L+utjS\nJfq9kvPl/Bo0T/09t728rrlLxWswN98eLXvurpevdUnL4XA4HA7HTxP+wuNwOBwOh6PeY69dWh+a\n6iqdcP0snQTlIt+0a3u1ade22aXg08EpadDVcwP4a+C/Ab8W/D7wv4HfZSHoQqHriCH018FHg6Oy\nUjuF0ZodqR3wx2epTsmaCxRR69RT8lZ5ucLD5SUKLyZ9rNBkUabCyV9efVLinCC/VX8++4h2zz/7\npvbrzz5XTqt30A9nBm1XAE75iZLm4eCfgVP2YqUZSiXvg3PsvGIh4MCyf4Cjdlsw3lgjhoVtlJTv\nnIfVhw0GSlr8xUCFyjdmIiEWkp6VINngzmodfylJDpHRqRkJd4KMtr9Gx8+6AhLjC5oLF0IOeTWY\nd8vB6cbi/GCSQEpJ7DPKhf3AKVXz/H9bCCYoZJJEOjD5XUy8R4cXHYFcL+RYanwzEqadrXD94Q3k\n2Bo3R7JPbJqkzVXpkthjDyZwbqI/WQFwMKcLjHPtbVjEVyJZndnB4OzbYeAfg/cFRyLJoK/o2Dsa\nHLqJHWUh2L8ng3MtoOsSfZ6BSmYVsDP1Uj80L9AWg82XaX7tP0if3RKTi7PbB3L+Fs3SQyt5rdaB\n72KjEj43C3G847v44wzRE+Dl+jCotii0BV+DR9Gw9ZKPPoXvqitiGYshhw3G93CcdQHnNZuZ9cJ3\nzQyqB8I6lqdnVl6R3HtFvVSvq3+mntkLmqsxDlt3iX77XDnxeraWTL65TBOh/ac6P+M7rX3r5uj8\nj2JvuqTlcDgcDofjpwl/4XE4HA6Hw1Hvkbr7f5ak083OivhnT8jZkY0Q5+MIp74aOJ9YZYhyyCTw\nbeAzwOkoYHIzghIIQ4Lv1jqPjq+vwelBoxNoHDhC7qtUHyXldUlxDQ5RosLSG+QCanKGkkAV5il8\n+eVYyVvV7yv83JCumKvpiPph6PaCfu8CuOjO+kTJ4TLhunsFaa1aQq7caChWFYSukSTONoBTVvoC\nfCI4w/KUQ+n4uc5C8LsWgc+O8138POLCSGL51p2SgZ44RI6/Mdcpcd9p3fX/hDJE3+duUhS1eBOk\n4q/w/woqsT8IusdhkCUWvCD5oan9OeL/FbjsfgY+D5zzhS4qunTY3/zsKHDOQcqWHAeUIM3CQDrl\nMVYgotOMdfsY8J8Grnl6BmSZdx+SNDoMCt3IQxtHvPFDchatC6qhwfX3YOLmJqX4PPtVxNGdlm8D\nIn4n+nBl4K5jgkz2G89B5rpgneZ90jVHLAPnHC+odd6OOOfxNzi3seZXHIHjmMsFF0W0c5baa/NI\nSZftpmi8rNsiF9jUIsl43MSRHYzPUZYYyFmajD0fIyFj5cKh/FbgetX62wjJHEubqT07rNfZMxtJ\nxuqxXQkyv2um52kvdDer3NGHV4S8j32qLMD0QMYKxLWIZRfpQ0V07hYoGfEqzJ0MU5HD5K7qg9jd\n6vvM/pqcpavknv5o1Zv6LK4mLxhPb1pd8AiPw+FwOByOeg9/4XE4HA6Hw1HvsQdJSzLWfsHxxXH4\nheBwctnl4HTaMLEda2kxnE4nAN1b/E46EArBD7EQY8HpHKDzhAkTKd0weZ7CrBuR9PDFKUqS1fli\nSSmP/QXJEIcg5PwvupoUfi414u+WKJxfPCrijUy1jC4aeWLEX7H38AkmA3wtznFKjtB3ghHDEDWT\nStIzwKow7E/WfeppIbqB02dABxbdP2fG+e05EWu2Q9d3/Wc6fuVg9dtJA+Wu++UW3efTKRrzF0xS\nOPqdRQwJc8x/f7SBPJcT/Atr1VHqZd06SrVMKkiwfdi2dMbdE+c4ZWHOZc5x1uMzC5OEss9ZI439\nynsYDk7JRVLfu/zsIZJfnpgEWb1K7r7thrpwtha8ge0bSMbqFPccChKsV7YCnC4q+nDotOOWAdYb\nZHUl9udfwNuDs34WKz+ZhfW6uA6zvhfXWrp0fw7ONUV1uKbszNPhbpJ7Ji6gbEpplfKrUFLn0R8K\nyVhcoXYE58BxmI/7Xa8r2g5pqQOWEPZ2HvI7LmgsGat9hZxSBegLRjh24umfXSWBa/puE01y+4ck\n4JJgvHBN0VaAjWyNJpIbxy/GiD9XT7/lb0K7CyoSVlpd2Fzn0RAe4XE4HA6Hw1Hv4S88DofD4XA4\n6j12K2kxcw/9N0/bTPxF90e8cO9bcY5/Eef4G+CFe3E+HR90BHxd+0SA0g1DxUyMRakLNbYgB5kh\ntGqPRmzpy5IcuiFwuuhfaqM2CB2uDUL3++Y99F5TIi4Gkx+yE/EXZUP6GSgNMbxIUMYsBKcbiwHZ\nj8BZ54zy2SfgtV13TFDHvqbz4nRwOk9Y++npiG0JEq5JThzxkBxPt8xUgrqnT1Ws+eS3FBb+vCuS\ncq1mXaHEYDPai9XGngjkRkpaSOAWOHlYg4yg/LsAnH1AeYJSGoPLT4NzfNSWaik5sEbXGHCOU7qx\nuC7Q4UX3C2S2KXL1HASJdcYUSc/9IGPNQu3AoFbXPsLvwf8c3BvnYGOrG/+Mc3x5nOPsk5XgdUtA\noQOS4nt+7RMBJjTkFgiuC3RZchvDv8ApbyHZ7CLKKbwHSSUdcJ8rAvmctb0SA4r2o8CHB3PkFNHV\n7FdCYvW6bZIbj2gqmWhSCz3vWsGNtWmLZKyDMN9n5EgOykT3leNZdESt58+kwKWVAc7+Z7tXxOG4\n/2LWxcPcfFN1/ppg3SmGQ7EbnsuLkfwwFtRsqxse4XE4HA6Hw1Hv4S88DofD4XA46j32upYWg9o9\nHsYfiPbmI8nbaiSqC8PPrPVCyYg1cxg2Za0XOjOYPO2vcfgvLQSdFwz3jwKn2EPHA0P83IV+fpzf\nYzid9WAKxQtScA5rTyk8GIuN2Cf1epbCddZ5LGKhJ8rl0AXXscQa4ZvozmCIE260ILEfZUZkuAoS\nQfYBp9OCrqbakhbCwkESS9aKomRDyZWyC2up3QsOZ9OgW8S7aNymXSrnV9XfkeRwhkKzVqAQfazi\nxITX6wlmyyO4x5vkC2mHPlgF50TYZ5DhjA6JA8ALwRlCZjI7OvQojXA+cf6ZhS4ihscpsbIWGiUU\nJr1DPwV9eR44XV1IeNm1l/hiSi90DcnhFIuN3Cdzk77HA2jkxNLUy56KeEFQ5+5+cNYYowuKLjrW\nHqTzlfUJuW4ycya3KtSupUX5mN/FuU1Zmb9NSZrbDYaAXwZOBy0TG7IlKaXTaSbEYpMSPje5yjRn\naUYZoO0c/PFWUL8xGUyyUo3K+lmnzZK9vg1cdnWDM5mt0wbr8loLMw9ypq22FvirIzidnJShHwHn\nvKZzlxtmuKWA64ukzWxcX0nwLNK1xetLj/A4HA6Hw+Go9/AXHofD4XA4HPUee0g8KBmnIxwSb/1W\nCboOtUsj/geECl8LElq9Huf7GWal3PBS7RP/Px6Kc5wJzQrB4zkWzMKwKc9jiIxuFiZMHAVOWeUg\n8Jsi1tAej3jZcQoJpxXIwVIVhPiZGCyei+b7QIm49kegsuhE3X8OZIPHMDxuDepQMTTJOmkUV+io\nYFiabcr7ZMiZDjo6wujYMgtrBdFdR5fXRVY32N6UK6XRDsQYnj5VUuzvp+re/ny84svtRigx4qrg\n2lAQKXAa/RCo7Xpg3E2/SbpHZ7h6bkW7PxvIsOwDylvsA8qZrKVF0ClJVxrHL4PoL1oIhsoplVDG\n7A7O5GOUZejqobRJmU3Sc3fIewsPVYK8bovlylsUtBHXppGWOGgNyzM5WF65WeviIXZFxO9CLaaC\noF0o+xPsn8o4x4ln4xxnzTvKR9Nqnxjnmig9M6EjpXH2OR27vE9KKBzP8LgdpedU5kQ5i8uD9Wtf\n4MmIZWDdfBYy1mC4cm8JJEmucfJ71eTITbbfZm1DCWWsduB1uwk5A1Mxr9diztb2Wq8O/qLszXnB\nbQtc4yltfgzONRpJKzPVLtnlt0a84Qk9Ir5+vBx3nark7mO1uHjwCI/D4XA4HI56D3/hcTgcDofD\nUe+x1y6tvUIHhNdWsMLPY+C/BmetFzoBngBnSJxOCyYuYk0fOhPoWDAzuwv8j+B06TwJzvpD3HlO\nBxrDr7xW1m2ie4t1gmpLNP8DySex2NR94gTZKzREwqkyvhvTe0CJhuFquigoX3BH/lPgTGDJJIKU\nIlifxyzc0c9wKWtxwTkVVClizaVscEprlOUYsj8DnKF/1mdjDSklzYrFbky4E2Sv0AbOi7V0ytVd\neyqUhilnMpEgHTt0R7IOF5OtUfKtnbySThtK1BxflNmYrI2hdSaV429w3lHOZl/yPrkOEKoHFIst\n/PHmZmckElzKOXIJ+CjwP4FTiuN8pCRN1yjXR667lLfoZDMLZWK68zgeLgHnPHoQ/Gpw9gl9w6xY\nRVcfJbDaa8f/RiwW+3Hm5lF4DkzkONUWkbzBkuGKvqSsRKcv5ngy1sYaOiXRbpmQsMspW9cWtSib\ncRcMJXDWS+NaSYceU2qyvylt9gCniy+ev4xQQthYbJu7tBwOh8PhcPw04S88DofD4XA46j38hcfh\ncDgcDke9x25t6S3BaSI7PigA11V0RZihUXgzznHqeCwkNwqcllO+n1H34/fQHseU0GahwY5ZWLeB\nc1/JDnDuH2LBUNrVuf+D4L6iJeDM+MkM1NRTE4e24FPB8wObKvYnlcWTorknh9/EfU4cMdwnwM+y\nTVnEj2kC2De/sRD8bY4B7umgLZJaNPcJUOunhbwjOG2zHDu87hvBqTlT604MWoOztQ4JMh7DprqW\n6QMI7q8rAWcRUqaVOD3Oce6p4b6gP4Pz+7k3w8xsDjizndNs+ih4MTj3EnEPAOcm92NxHWFfrgGn\n7ZlZhJm2InHgjkeWVT0+KO7ZT3RpvKX7c3Dag7lfkP3DfTgsvMp5xzQD/H7au1kI2CzcZ8F2ZXb1\nUeDqzyyMjZ2BDXoCOIuN8kn1K3DuKSS4l6xpnHO+P1jWlTs8j41XCHYinwNZ4LJrV3wpi3q3/ZXC\nYVExCnlvVlsl14yKeCq+p5JrEbsCfZwZXINZOfYG5YCHeZ05TrX3sxn27WwJvpdpRPhZ7gXj/joW\nKubY4t5PZmuvGx7hcTgcDofDUe/hLzwOh8PhcDjqPXYraTFXLEt92YeQsU4QvdG+ijhNqqEdnFYz\nfDiQJ64Ap62YGSkZrqal/Q7w2hIIP0/5gQXOUEAwuKYm4EvBaWmm9ZHBTNqsadPj9zDs29n2BfgL\nFOVsGULfcPWuwAigIGB2PbjkyhtgB388sAEPAGefUAaBBT6QTdiOta3ClAeZUZkZvAeB027Jtme/\n0bJdCM40BrRHsxgiJYFMcMphiQEDvDST2+eQAOAGfhfSEAPFZneDK01EBzsn4isCuZnFXFkgl/Oa\n38n+5gisnTWd2XKZ0oBWafYlreWU8WhX5hhkgVGuThPAKcPSPk2pmvJn4kB5IFhrP4eMhf68GsJX\nmBOZNn5uB+AM5ohhEWa2EVMsUBri6GF70RpuFs5NFoamnEbxR8VqdwapBXg+5a354FzNaInmc4Rb\nINifFIcTg1Jw1huw8VjvsHPgKhRzfS6QvyVXVWPbwaJNknRal2i0rIPEWIP+qAxkd2Q1DuRZSd7l\nu5FttwZrWbziwTzKdZD3xg0WFOUr4/Ch4JRbOYZ4ft3wCI/D4XA4HI56D3/hcTgcDofDUe+xh+Kh\nkmIyEJxbdoKSGOba6IjfFUgUPcEp6dCBxEzLDNKzQCGzRDJDKF0adIswLFs70zJdV/wuhtprFzX8\nH8ix1BxHNwfBaDqtlF25C+55WYpC9NW7mM30GfDJ4Azd/1AoPJyMsHH5/mqLdMgUk1HQMRMhxXLc\nc74Nj/jjrVRM8KgNkjcnBn1LJxczUNNB9xU4i0HSUWQWFiWlt6UCnC4cBpsVHu+AsPYKTInGyPJc\niky1V0J0GJGD0P1WZhtluJ+SEO/5h0CupnTrE/FNR18c8SbIHDwiyDJN0YTSgwpproDkl4esuUWB\no2ICODNdUz54Pc45gUXEQomCTrlC8FvB6TqT+yMPIe4iK8I5kOGRjXcgnJLTA+fIQHBKmLyHULj/\nYZgQsQwbEvEFkLHaQtK9OcjkzuzXlGsoOVAanAvObNQsOMkCrlxr6faiI5YOpNqgq3dt3LMErS98\nWmwP5hG3HqjgZDoKmiZDiisPHLFsC0qXiYLmSwYkxsmQsfZHcelrg60W3MIhmWhXkvoyu0TP361Z\nE3T6Tq0DoeuRUiClp7B1hd1J8HxlqFvGIlphnnPGbg6kSsi2DeSIbL5TMnzOQXp2fzudLrtX4/zy\nG3Ue9QiPw+FwOByOeg9/4XE4HA6Hw1HvkdjioX0QFpvDcBmLgdLhQ+niLHCGjenmYOFROnbo6mCY\nmTu7zcLwF0Oc/wCnG4uh3HiIV9SsNzhDyMeDU8bhrnWdH4ut+/EKFPZFEHI2i9RxlzwTd1FKYp+8\nBP5b8Af24ji/h4nnzMKkdqeCXwhOt8ko2zM4Zihx0GlCyfEW0Qbq/6N2SDKciPaKxZ77cQoUdoCD\nYQUT0lHSYrK9TeB0zVEC4FymfMxivnRDci6zX8xC1yXnAp1GdC/SZRcPlJjp3mGyMiRug5QUrk08\nX46+WI6ZlmQAABfjSURBVKz4x5ubR0BOmETJ4mJwyuG3g7NN4xVzZgFYFgLlPKC8xXXTLPSd0Ukz\n2eoCVxdKHxRQqgMHJZPc0iFGqYTjmdsZOL50z7FYzY8zN7sUii/piH8YAj4BnMVi6UxiO3BMcMuG\n3HDWDw7jWXRyMUFobbQCn1vnGfTMFaHr07GjoDJwN/P34DLsgjG0Bu8TZUxgyJiNJNlYbIYXD3U4\nHA6Hw/HThL/wOBwOh8PhqPfYg0tLCEUMxaY6I1y5dA5D5cTIOMeZLI4hSjo7GGZlpJA1khh+Zu0d\nOrbMQrfALKsbkrEYvKNwwz3s84JgbC64HDJpcAVUBYmumFSP0hhD6PsGTC2ViiDyfZD6bpvNqCDv\nmon9CCaZoxOC/cMw6DhwyphsU0ootfuMEuL74JRjRkUMlaVsPaoXDUH4/WP0PyuzzIMMcBpkkPk9\n5Crou0v3ua4/XD4FDKcnHgxGN0Ryr8PhXvpqRbz/29wd5zgTAdL5wyRhdFDS3Uipgw5Nzr/aLgqG\n5tOsbkjGolOSqc1Yk6ogWLW4NknGyUFfbsXYbwaH15bA1ca6WvsGHL0t4IRpAZli0yQm0SQWxTk+\nApxSPZOrcq3dDM7kmpRAeaXskdqfz7Y9oRGWl65Qxjm25we17biCnR2xLNz/zmTU2Kqh85dtB+vU\nPgDFpLYYU60g/GxYwlpgxKY4xzlXIG1mYCZUMAkqkw1izZylPktCf8X+Vy1HOrg22p7A3s6FjMWn\n93eQm3dhzSrvq1pa3UokUZXBZLpqDtagJLj1YrWTX/5veITH4XA4HA5HvYe/8DgcDofD4aj32GtJ\nKwhKFkPGwub8j1HHhhV3zM4Fp9TBhEtMYnQ2OKUUfg92mwfS2O/BWWreLHSJMGxXYXWB4fHFob4B\nMMRL6Dqq2uoemq9RzaHNQW0R1rfZXRKvxCB40y2ThHQbcpWtR5/kBm1EJwhD6HSCXADOhFi/A2et\nI94zHVuUtGrLIKytxParO7kZ06pZS8hYQZRWyQyDbrabI/beAI3/S1uKLztXIegZ4yHLzdsbt9/3\nBz0LtgUyFowaM5HALxRMOUcoJf8BnLXGOLM5iui6Yj0rzk067ugOMguTCjJh3jarCxQ01sC8tSYw\nb+15bm5NlpybV3NexIsC2YByM11d+wb011gJZCwswq/A7cQWtiDBJOUq9jrqaiVDeq2htEKHG9fg\nHuBMIhpU57NQ0tqd6+e/0RbLyzT8RBaHUlxn3lMR25kLGX49nb98vjDhK6XwxCOo1FUMGQvPzWfh\ngrs6+HQwEgAmUNWYtV2UFbkhg2I+11lJQLEgUSqffGahpLXL9gRWbfsExcRyoG5nI8Ei09LabM33\nRZdJYs6axRp2EMdidKxRSq8bHuFxOBwOh8NR7+EvPA6Hw+FwOOo99iBpUa5Q+Ksc4bg01GIZZQw7\nMdkUk0EhcVU63B+VTCRIuYruAl4Pw1eF4EzmV7v2ErF5N//23+Be/mHQNyhETUa79MWu+lmolTJw\njZxjScPl5Nr8BWSfIt7PaHCGGn8o6JhRrLG64RkRT0ZdnlmBNw0h8fPUAgPf0C756fcouVvvOyWV\nzLW38T2UK+n4YcJIOmrYn0xiVxt7lo1YHalqozTKAyFevYq6LnfCY3HPIarJNWqKJsDirxVGHl0o\nd9HJDSU5jG7NkHCiQMearrmimaZ0GpLtvR0k2mTImvWmkPTrINUtSp4hV15NcP5d4LeBsw4T5z7n\nNSWs2ijbzb/9N5hSLm2pZmoaEsxNRP2s47FGfARJ64QarQMlV8jNUvQNHB+zPsevvQnOtemHgo5D\nSWg7IWOl26cRfzqQZZj0jzXJ+sQ55znRGjrw6JqkoEuXFh2X9N3s2b1TGxQu6cscBhmLcscKuLRy\nIDmutnMinrdeztycg2sivnA6EorG6AhlPb5EgdKb9NYydEEmZKyRQbJTCtQcE5Aqk/LF0+COrByC\n8yeAx6ulxXOIH7ZeUfT6GR45FOKWQDLtAZfsArhDD/xEa0fu2WqX8Ruhk62ms3DPfekRHofD4XA4\nHPUe/sLjcDgcDoej3mOva2lxz/eGeB+4Bd6JB6mWMUngmaLJiHfV0FHRE5zH6axiPRj6FK4Fp5vI\nzOxxcIZ463aCcP/3csTQmyNKv5l2kXhorPB42+PU3mvKkBBqHEPUknFisZf2Sb0e7qRfUce5ZmY2\nHTf3jvrzwAcklcx7Utd6b7XqhN3xgSSm1IWSN6vXMVzKQPa94HRp8UqZqNEsdP0cCT7G9ilOlLR2\n63WSOx7oIGmw762SumaP0eCJxY5NeL0eSgNxxaCHkdjzt0zsB7mxmZxZTZvIHbdt+XKcTxdQPBnj\nL+Ccg5eAX1XrM6z7RDF5mdWFIEgPg1BjqGale1XRSFJfp0v1gW/TIeE+h+RmkK1jsWf3ydykkFz3\nymRm12BuPsO1lnUBh4smo45gzUqcw/lFCaUGnBIQV0VKYGwjs3hOU/q96PukRLkEf3SC4fLbvVJa\nINd2R0vWYMQspqNQ9fJisS8SPjdZtWtNHeeamdl1mJtPcm6yBuGlor3hNp6LNTQDWwEquBKwpbEt\nJBttVUI3LOVvs1DG3DO4QnyLabQf8o5W4/G7Cn2cigSW1ceLt2uumbCqId4Pnqf7UPcWi/3La2k5\nHA6Hw+H4acJfeBwOh8PhcNR77LWkxQBnMvZh3w1Z4o/BWZQY4K7pimRQyFrYsKOSyJUto7uAbhSG\n6SaDY9d64Or5YWAqO9brYRqtdNQpaYzd7VPs9Ijvj/fKFcN0z+UzFJZOr1HbVZbKabKvJK14/TkB\niayGwJHSBmHNpI8UUmyYqaRfN1QOjvjzWyVj9Z8sieL1KklAFU9RuqA8hVB8EKKvXZNnzwnN2Hh0\naeWlSaQtq5JIW4Dg+nFw8r2aJQn1vCQ57TJH7h/xmSWSFlp1VGj64zHyJ8Se7JjwsDldESlIyfcE\nTJjXBz2Otk67RPwsuUUOWi0nxMpWqh+VNENB+vVZk/TZRUzURwmbs4hJR/cSaK3GWKqYCpB+UI6I\nMrh69oNHZBLGeFeMqS3nK4S+sUBztlG2xummSdLMYrHb/6Nz8w9Ya+8PzmINIbrfOKeE9OzeEa8s\nibd9gHIlJTDKZ3uj59dCHE2LV8FfqEILN41JakmD2DfbhkU8O0UjYFUnyli8VjqV9D2x2OyEz814\nfXkz+vKh4Kyu4JD2cyABb5V0ldtNLVexSONgWyrqSFZTGGX6Vd7uXum/e4Vh4Nwu0QK8bbqe9w0r\ndU1v5f4q4h2yNQbX95I8mbxAc7lxid4PVq7TOh6LzXdJy+FwOBwOx08T/sLjcDgcDoej3uP7SVrY\nVG7YVD4X7pjedqr+4fBHI9r6q7sj3u8quX3GvqakWvbzg8TfQGguCLvdBU5XyB3gcISZWbI9EHHe\nD4UShsSvAH8BCl13GBBKcamrZ1idSG8gGasyV/Jb5nKFlsuDtEySj2KxLfs+bI5ob2vEk+cuURLC\nll3En96sxIhNhytoOehdSSIvLlM48s95Ckd2vVB1mfpvU1qxN2ew394DZ7JB1l4zMySpCmsFMVGc\n4uan4+g41OtpjkRn9AEyzWWAo1RP6uhCyVtzL9D977hPIuhO1F+KxR7at2HzOHNzUX+N/W4zIXs8\n80REj71GTqnTXlFSyD9+oOvfdASKyl2vpKPhzHkC/H7w+8DPsBB06dGDVbe35Rzwd6CHdETeve1Q\nxovm1Pk1lpGnakcVW1VzqHFzhdxL17JRJePFYgX/0blJrWeuKeFabxuMk54Cx9xpj+SBKx8W7wT3\nz7fcPsC6TKyrdjn4SHBuQzDLhYNrfXDc6jx+IfirR4gPhZF3zdHiG1SKCWnrzFpkaK3d1FrST5NC\nCdrFgfdNyepisfIfZW5Ow/aMg5mY1/4M/ozoKUjY+gGem0MHiH9Gxx0TudL5dQg4Xc/9jMiH444b\nRuhzZtrXX4I/D5PmITRiosPXvSqfaTW2rezsKzl8S3utA30mnhbxucVK4BjDWhGLxVzScjgcDofD\n8dOEv/A4HA6Hw+Go99hDLS3Wt7ouYlUIx6XARbPNlNDpV3ZNxP/2M/FHTlBI/IDjtW97+rFyheyc\nLumqZxcF0UqXKCa4FlVWtgVhOtYxecAIBmnpQahG/qVsxkeByyFjrUY8cmdBx4i3gyAyrbkScQ0u\nU2BzR5LCbstRD6bcKN3FuYgfjPPA34hYdervIp5sV0Z8153ywmxBcsftaQpBNnlbroIGDRRFbNVF\n7rWCSvXn9lvlJGgyU0nPZsxQvHqpjcJ1vg/OOkFmYQrMcVYXGNekUHIyZCyGYxfA8dfTlNFufktp\nl0MnyrUzp5/G2+b7mBmN9dBYwwxJw34QWLtKUlFVmsLXnJtlMyUxv2wtI/5YrmLOd79/SsQP6Kt7\nf7L/kIifvEJjNvtCTZwWn6pNnlyrYPdG+zuuk5pvbY2J8X7IWLpUg2mDioCdgWHBEZFUqPGVCzFl\nTp6ceIcVSfJc01JJDtev5RxkLSlkT0so6q43V40VOtlej/gW1MLrbJg7Z0or+H2lkiTmXqR+u3EG\n9NxRdM6xThhcMaifVhNc57o4PKzWxpasRAbbdugsbla4DP25KknPiP6rtYKXYSPCnI6ScnqXyQlV\n3ED1wDbCFVUcuM6YlC9RYP1D1UsMn5tafzfaIJyPPRJnSz68apf6svuVko/vP0z9uuFdSc9JmUo0\nGStXHar2qK+3Mkg0yS0VYdJIiNiBpEXnMp2imLJ2A2SsjRhTNdN1z0dhBR49UNsFjq/ROlKcKSl5\nXbFW9SaQ6+Im6QQ8wuNwOBwOh6Pew194HA6Hw+Fw1HvstUur7gB6LWyEpWCldn0vX6HQ3Gd9FFo8\npqnitSOXKTS3ab3C20+frF30TRHI3mbP4odRTCdISLibGiCMx5XXfcpQ8M9gCBr6ofgk5Imqwk9z\nX3wjBAVzTVrKwiAQ2Blcskos9tk+cYI8huO/ZokqmGfW1ej67kHQ+Um8J9NpwcRSm8GrkFTxuG1K\n+pV9o7KQTX+NVWf+Ck6vHELxZmZoy70BvSxfDhFvPEGcgd34kFzXz3ZGfFYQvEdoGnJKvBov/1ew\nL+mhub+Oc83M+uzQnJpTMTXixTFd56dZmo9D0tTHn1dqHKzfpu+55WHJsF0flZw7w07ELyPRaCBV\nUsIyC4XFPSOYm1Bqh36E4x1x0jdWJ5ogOWEzK4z48uAsVgfi3Px8n8zNK3F8RLwPLMLaMXpIRN9/\nTQ1QgLx1Z3bRXLv+HY3Zkt76nimXf6sPJGNRrJFUYj0hB82niPB8cHntwFcFf1id4NycAZvPWf8W\nn36weOV7ktWT4OypNiXJbG4TI07/Wbi5QeJbLLY04XPzOhx/so5zzcysAH35sraFvPasEngu+4Pm\n4/nHaJ7e8QK2eQzXOjtrmOZT7jXSDtc/o3W8+Fb1d/IDWslrarlh9wdfxkdtkdUJ+swmazeLnQdz\n2VoYqEufksMvJU9Sd3IHtV77qc9F/B/N9K7QcItkrzLIlrHYZndpORwOh8Ph+GnCX3gcDofD4XDU\ne3zPWlqo+4Qg+r0Irv/m1wp3Jj+o3dnfVkvs6JSq0OL0jQpTsTLWPz+XTlT4ipwgaz+7WidV7xfR\nNPs44puCKjtmzfLlJJiH7ebcVc48X0dA9kov1x+lDRTu3b5DMks5JJbihhJ4mpUp7FbQQ4nO5i1Q\nqLgH3ALLIHXtjJNA6fsgXn++hd8bDqmhcoeEuXT6+cDDOk5CBX8Ad/DFcn3izRkaey//4lf4QG/w\nX4N3MSILqQH55t4enL4pRMRtLnhr8HWmMZZqqmlGP8MQ+L0mQ8grDdwf1Ek1DmOxkv9YvZ4q1LT6\nurGkpUHvQU46WjLxhl36bKtk9eYKKSDWIEV99tnXimnP+Ldua+qjquFUAqm2qb0Y8TWQkszMkvfT\n3EmFnsTSS1ngHCFUp8sw5XeUaiSUoG9iGKk5Jil1XrZWgoUlci91QZsWQqyuiFX8B2pp6a9ytGUj\nuFEXJGl0ZmzUWjgvWc6WAelydf1jg6TXY8s0md/7Tg6s7Ic0rhfGJICnfKNkcBWdlP0vbQHrHJrV\nHC6n3fyv5KjKwAqbDKdVz24aSx2rpJtsgJO1olhbA3ZsklxVfJhElGZfo8bWz+SUnTVOSXE7p+ka\nFlapb8sStNbuTV/uMElyDSDJzYQLMGeDpNQp6UqmemyaZLtXSiXCn7VN4/qjXdJwO/9dM2RGezlG\nO07QjFrUU1JSzmtcx8w299TWkNlv65oyIPyWYl4clSNHWeNsrdnb0nU8JVOO0Mx5/4r4ht9o+0vj\nz3X+/LP1VrDqRSWmzW0u6W7yNCXBXe6JBx0Oh8PhcPxU4S88DofD4XA46j32kHhQCISvRXpPSu+m\nUOm27Z9FfMQ4hZ1uqFKYsXEK0r8lKYFSRiOFxIpjCmOOiimMG7tT4bglHyvZVs9LtQd//kvadd+j\nT2gJiCHX2TLUZSlB6SX6Ds6DKjH+Fv2R+qCOF2coFI8cZta7rcK16/L02aJ1ktUaG2qfwEdQDhfQ\nvgI9MuduUSh0eTNpfb/LVNi4oubciKdjNCRBr6IcWJ2sc2YjrvtxM7XFy8dzmz+EiRw0/FamvaKA\nZvBHhaBDjInoUN3N3oGRqFzlWGwbZCymJGOloKXpcpqVxiDkVTGKigxr/0cH0v8VDJvbEl1PWhfJ\nhKWbR0V8fqHmZu9dasXGyQpx70JvpqWrL4sge42By3Lc9UryVvaoxnXPKwojPuUFSUy53cMEflkL\nJSV+11l9kL9Ua80C3OkJ+OzEa8Ubq+SbrYOMtQPnd2ipflqfrXNWQv9MKZEcUmnfgtPhs28QrLWT\ndf+ZsL8UL5Ob57xHJTn9I6axmVx5uD6buTbi7VIkV21qq5b558ifRzz7LtVo+vQ4Jc87/Ullkvvn\ndXIfHn6t5DMzs/ynlfSx5ApJDdte6BjxVjmFOh+F6xbfpXWh+i4d35Gr9WhltuZXz67SMZd1kUS5\nvkBuxEapaovUBpIDdxQzHWniEfTl1+rLBnpsWvECJYs87E7VP5uM7R8NKoboAy3kqGpXrvG4DH35\nzgOqh5VxrqxuCw6XJDn0vVERH3G0tl0c9La2hZiZ9Tlb42LXM0oEO/saJPbsrj5uqHKJtuSuJREv\nv0HHMw/WOCoaqCSEB/fS2v9xL60j5RtUj3NnU0l6HXIl575ZSyavCx7hcTgcDofDUe/hLzwOh8Ph\ncDjqPb6XS+srOynih9ulEd9op0e8KVwqm7YoVJ69Vd+U0l7vWxs3SmRZlQ6n0FLJUkkZ8my8/8Ej\nEc9N1S73qdOUFbDl+wpLm5lN6a46Ikct1O72iTiHFa2OAu8JzuBtzIZEvFcj3fO4fPlIerVUSDx9\nliSBT7frl9uYMhiuxU79eGXuvw/Yn5S0VsPX1AH+pV1jJMulQB2sQWa0ZKhMMWRbrIaGgC63zBX6\nY2VziUYjfqOQ5dIKFU1aNO2JiDdYw9SGZgtNu/jpwEJ0PEgkOAScchXljnKk2cpAxbU58AUdhoSW\n5dY94jMNsVzj2NOoSlR/xpubU00unUGm5J8lnY6JeKONcP6skSyVhoZIgnJTuk1rxHp0eEqh5LAt\nDTX233tBfZaRIlFx2rRXIt7ga/aY2ZgOGnenLZIE+KWGoJVJAQ/SdDLF4yfgTSFENmmu656VLKfJ\ngDyFxKsWqV0mVamgUx76smgf9KVZ/P4ca5KSTzRJCMuQ/rUtJNOCNXLEdlivrQEZvTQ512zRerkJ\ncmXJStU6a7FLbTS5QPJDfoXW4C8KtNbmPkXR1+ybI1TbbuBEzchPsIliMTRwVe0L5ykr5GWZ3H+9\n+0sCH99eWwAGtpKkV/m51t0P10q3bl4mX+ZyZELc13NzjCmj4qmQjBfbCxFvh+Slk1dLbutRovnV\noLPuvbBEfbkzVY27abPGaftKrQljS7R29S+FJL1WjuE+L1OON1vQSS6qg9+R1Pke3h1mbdL9tMfT\nRZWxzMaDZ2H89j1P7sjJqMHYu53eD1InaD/KqG+VXLPbZLXL9OwpEd9W7C4th8PhcDgcP1H4C4/D\n4XA4HI56j91KWg6Hw+FwOBz1AR7hcTgcDofDUe/hLzwOh8PhcDjqPfyFx+FwOBwOR72Hv/A4HA6H\nw+Go9/AXHofD4XA4HPUe/sLjcDgcDoej3uP/AQVmN4U6mcyjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAD1CAYAAABUdy/PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYpjIMLIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQdwFLMvBd-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_images_specific(image_grid_rows=2, image_grid_columns=5, label=0):\n",
        "\n",
        "    # Sample random noise\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "\n",
        "    # Get image labels 0-9\n",
        "    fake_labels = [label] * 10\n",
        "    fake_labels_category = to_categorical(fake_labels, num_classes=num_classes)\n",
        "\n",
        "    # Generate images from random noise\n",
        "    gen_imgs = generator.predict([z, fake_labels_category])\n",
        "\n",
        "    # Rescale image pixel values to [0, 1]\n",
        "    # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    # gen_imgs = (gen_imgs+1) * 255/2\n",
        "\n",
        "    # Set image grid\n",
        "    fig, axs = plt.subplots(image_grid_rows,\n",
        "                            image_grid_columns,\n",
        "                            figsize=(10, 4),\n",
        "                            sharey=True,\n",
        "                            sharex=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            # Output a grid of images\n",
        "            axs[i, j].imshow(gen_imgs[cnt])\n",
        "            axs[i, j].axis('off')\n",
        "            axs[i, j].set_title(\"Class: \" + str(d_name[fake_labels[cnt]]))\n",
        "            cnt += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Qw77TpBvcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "21bd40f1-7ffb-49d7-90e9-07a203fb9663"
      },
      "source": [
        "sample_images_specific(2,5,0)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAD1CAYAAABUdy/PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgIT1giiqQU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def plot_images_labels_prediction(images,labels,prediction,idx,num=10):\n",
        "#     fig=plt.gcf()\n",
        "#     fig.set_size_inches(12,14)\n",
        "#     if num>25: num=25\n",
        "#     for i in range(0,num):\n",
        "#         ax = plt.subplot(5,5,i+1)\n",
        "#         ax.imshow(images[idx],cmap='binary') \n",
        "#         title= str(i)+' '+label_dict[labels[i][0]]   #\n",
        "#         if len(prediction)>0:\n",
        "#             title+= '=>'+label_dict[prediction[i]]   #\n",
        "#         ax.set_title(title,fontsize=10)\n",
        "#         ax.set_xticks([])\n",
        "#         ax.set_yticks([])\n",
        "#         idx+=1\n",
        "#     plt.show()\n",
        "\n",
        "# plot_images_labels_prediction(x_train,y_train,[],0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZNbvo9zqSZB",
        "colab_type": "text"
      },
      "source": [
        "# Pseudo Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYa-jKsACxRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pseudo_model = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "pseudo_model.compile(loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'],\n",
        "                         optimizer=Adam())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjVlrccQCxOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pseudo_train(iterations, batch_size, save_interval, alpha_f, t1, t2, iter_epochs):\n",
        "\n",
        "    x_test, y_test = dataset.test_set()\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        # Get unlabeled examples and pseudo labels\n",
        "        imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
        "        pseudo_label = pseudo_model.predict(imgs_unlabeled)\n",
        "\n",
        "        # -------------------------\n",
        "        #  Supervised Training\n",
        "        # -------------------------\n",
        "\n",
        "        # Get labeled examples\n",
        "        imgs_labeled, labels = dataset.batch_labeled(batch_size)\n",
        "\n",
        "        # Train on labeled examples\n",
        "        alpha = 1\n",
        "        # loss_labeled, acc_labeled = pseudo_model.train_on_batch(imgs_labeled, labels)\n",
        "        datagen.fit(imgs_labeled)\n",
        "        pseudo_model.fit_generator(datagen.flow(imgs_labeled, labels, batch_size=batch_size),\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=iter_epochs, verbose=1, workers=4,\n",
        "                    callbacks=callbacks)\n",
        "        loss_labeled, acc_labeled = history.losses[-1], history.accs[-1]\n",
        "\n",
        "\n",
        "        loss_unlabeled = -1\n",
        "        acc_unlabeled = -1\n",
        "\n",
        "        # -------------------------\n",
        "        #  Supervised Training\n",
        "        # -------------------------\n",
        "\n",
        "        # Set alpha\n",
        "        if iteration < t1: alpha = 0\n",
        "        else:\n",
        "            if t1 <= iteration < t2: alpha = (iteration - t1)/(t2 - t1) * alpha_f\n",
        "            else: alpha = alpha_f\n",
        "\n",
        "            # Train on unlabeled examples\n",
        "            loss_unlabeled, acc_unlabeled = pseudo_model.train_on_batch(imgs_unlabeled, pseudo_label)\n",
        "\n",
        "        if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "          # Save losses\n",
        "          losses_pseudo_labeled.append(loss_labeled)\n",
        "          losses_pseudo_unlabeled.append(loss_unlabeled)\n",
        "          losses_pseudo.append(loss_labeled + alpha * loss_unlabeled)\n",
        "          accs_pseudo_labeled.append(acc_labeled)\n",
        "          accs_pseudo_unlabeled.append(acc_unlabeled)\n",
        "          accs_pseudo.append((acc_labeled + alpha*acc_unlabeled)/(1 + alpha))\n",
        "          iteration_checkpoints.append(iteration + 1)\n",
        "\n",
        "          # Output training progress\n",
        "          print(\n",
        "              \"%d [supervised loss: %.4f, acc: %.2f%%] [unsupervised loss: %.4f, acc: %.2f%%]\"\n",
        "              % (iteration + 1, loss_labeled, 100 * acc_labeled, \n",
        "                  loss_unlabeled, 100 * acc_unlabeled))\n",
        "          \n",
        "          pseudo_model.save(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-\" + str(iteration+1) + \".h5\")\n",
        "          file1 = \"./losses/losses-label-\" + str(num_labeled) + \"/p_supervised_losses.json\"\n",
        "          file2 = \"./losses/losses-label-\" + str(num_labeled) + \"/p_unsupervised_losses.json\"\n",
        "          file3 = \"./losses/losses-label-\" + str(num_labeled) + \"/p_losses.json\"\n",
        "          with open(file1, 'w') as json_file:\n",
        "                json.dump(str(losses_pseudo_labeled), json_file)\n",
        "          with open(file2, 'w') as json_file:\n",
        "                json.dump(str(losses_pseudo_unlabeled), json_file)\n",
        "          with open(file3, 'w') as json_file:\n",
        "                json.dump(str(losses_pseudo), json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GnU0n4JCxMB",
        "colab_type": "code",
        "outputId": "70b8912e-33ef-4402-f870-379a5994b8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set hyperparameters\n",
        "iterations = 50 # 30\n",
        "batch_size = 32\n",
        "save_interval = 1\n",
        "alpha_f = 3\n",
        "t1 = 2 # 500\n",
        "t2 = 4 # 1000\n",
        "iter_epochs = 10\n",
        "\n",
        "losses_pseudo_labeled = []\n",
        "losses_pseudo_unlabeled = []\n",
        "losses_pseudo = []\n",
        "accs_pseudo_labeled = []\n",
        "accs_pseudo_unlabeled = []\n",
        "accs_pseudo = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "discriminator_supervised.trainable = True\n",
        "pseudo_model = load_model(\"./models/cifar10_model.035.h5\")\n",
        "\n",
        "starttime = time.clock()\n",
        "\n",
        "# Train the SGGAN for the specified number of iterations\n",
        "pseudo_train(iterations, batch_size, save_interval, alpha_f, t1, t2, iter_epochs)\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Training time: %.4fs\" % (endtime - starttime))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 15s 15s/step - loss: 0.5187 - acc: 0.8438 - val_loss: 0.6246 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4502 - acc: 0.8750 - val_loss: 0.6295 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4992 - acc: 0.8750 - val_loss: 0.6264 - val_acc: 0.8596\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3824 - acc: 0.9062 - val_loss: 0.6310 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3377 - acc: 0.9375 - val_loss: 0.6443 - val_acc: 0.8542\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2767 - acc: 1.0000 - val_loss: 0.6573 - val_acc: 0.8505\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2750 - acc: 1.0000 - val_loss: 0.6726 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2612 - acc: 1.0000 - val_loss: 0.6912 - val_acc: 0.8393\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2600 - acc: 1.0000 - val_loss: 0.7119 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2472 - acc: 1.0000 - val_loss: 0.7324 - val_acc: 0.8273\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "1 [supervised loss: 0.2472, acc: 100.00%] [unsupervised loss: -1.0000, acc: -100.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7185 - acc: 0.7812 - val_loss: 0.7439 - val_acc: 0.8237\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7609 - acc: 0.8438 - val_loss: 0.7525 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5938 - acc: 0.8438 - val_loss: 0.7622 - val_acc: 0.8166\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4963 - acc: 0.8438 - val_loss: 0.7738 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3935 - acc: 0.9688 - val_loss: 0.7816 - val_acc: 0.8130\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3495 - acc: 0.9688 - val_loss: 0.7909 - val_acc: 0.8095\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3013 - acc: 0.9688 - val_loss: 0.7963 - val_acc: 0.8065\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2611 - acc: 1.0000 - val_loss: 0.8001 - val_acc: 0.8050\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2802 - acc: 1.0000 - val_loss: 0.8044 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2478 - acc: 1.0000 - val_loss: 0.8090 - val_acc: 0.8029\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "2 [supervised loss: 0.2478, acc: 100.00%] [unsupervised loss: -1.0000, acc: -100.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7037 - acc: 0.8750 - val_loss: 0.7997 - val_acc: 0.8053\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5812 - acc: 0.9062 - val_loss: 0.7883 - val_acc: 0.8101\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5407 - acc: 0.9062 - val_loss: 0.7737 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4879 - acc: 0.9375 - val_loss: 0.7600 - val_acc: 0.8174\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4591 - acc: 0.9062 - val_loss: 0.7526 - val_acc: 0.8184\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3662 - acc: 0.9688 - val_loss: 0.7494 - val_acc: 0.8223\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3193 - acc: 0.9688 - val_loss: 0.7395 - val_acc: 0.8241\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2533 - acc: 1.0000 - val_loss: 0.7334 - val_acc: 0.8265\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2616 - acc: 1.0000 - val_loss: 0.7296 - val_acc: 0.8267\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2465 - acc: 1.0000 - val_loss: 0.7273 - val_acc: 0.8262\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "3 [supervised loss: 0.2465, acc: 100.00%] [unsupervised loss: 1.0317, acc: 75.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4629 - acc: 0.9062 - val_loss: 0.7357 - val_acc: 0.8232\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4436 - acc: 0.9062 - val_loss: 0.7432 - val_acc: 0.8209\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4260 - acc: 0.9062 - val_loss: 0.7543 - val_acc: 0.8177\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2789 - acc: 1.0000 - val_loss: 0.7671 - val_acc: 0.8140\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3172 - acc: 0.9688 - val_loss: 0.7793 - val_acc: 0.8098\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2691 - acc: 1.0000 - val_loss: 0.7918 - val_acc: 0.8076\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2652 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 0.8052\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2488 - acc: 1.0000 - val_loss: 0.8168 - val_acc: 0.8020\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2639 - acc: 1.0000 - val_loss: 0.8292 - val_acc: 0.7989\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2353 - acc: 1.0000 - val_loss: 0.8408 - val_acc: 0.7947\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "4 [supervised loss: 0.2353, acc: 100.00%] [unsupervised loss: 0.6375, acc: 96.88%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4921 - acc: 0.9062 - val_loss: 0.8606 - val_acc: 0.7905\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4898 - acc: 0.8750 - val_loss: 0.8694 - val_acc: 0.7881\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3901 - acc: 0.9375 - val_loss: 0.8764 - val_acc: 0.7874\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3687 - acc: 0.9375 - val_loss: 0.8807 - val_acc: 0.7865\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3743 - acc: 0.9688 - val_loss: 0.8854 - val_acc: 0.7842\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3083 - acc: 0.9688 - val_loss: 0.8906 - val_acc: 0.7828\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3799 - acc: 0.9375 - val_loss: 0.8944 - val_acc: 0.7839\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3279 - acc: 0.9688 - val_loss: 0.8988 - val_acc: 0.7839\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2737 - acc: 1.0000 - val_loss: 0.9044 - val_acc: 0.7831\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2769 - acc: 0.9688 - val_loss: 0.9096 - val_acc: 0.7830\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "5 [supervised loss: 0.2769, acc: 96.88%] [unsupervised loss: 0.7566, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6808 - acc: 0.8750 - val_loss: 0.9036 - val_acc: 0.7853\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7193 - acc: 0.8125 - val_loss: 0.8800 - val_acc: 0.7887\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5221 - acc: 0.9062 - val_loss: 0.8555 - val_acc: 0.7964\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5153 - acc: 0.9062 - val_loss: 0.8301 - val_acc: 0.8036\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3917 - acc: 0.9375 - val_loss: 0.8131 - val_acc: 0.8085\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4908 - acc: 0.9688 - val_loss: 0.7988 - val_acc: 0.8120\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3810 - acc: 0.9375 - val_loss: 0.7891 - val_acc: 0.8120\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2739 - acc: 1.0000 - val_loss: 0.7859 - val_acc: 0.8116\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3639 - acc: 0.9688 - val_loss: 0.7851 - val_acc: 0.8117\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2716 - acc: 1.0000 - val_loss: 0.7876 - val_acc: 0.8121\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "6 [supervised loss: 0.2716, acc: 100.00%] [unsupervised loss: 0.9091, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7527 - acc: 0.8125 - val_loss: 0.8065 - val_acc: 0.8060\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7241 - acc: 0.9062 - val_loss: 0.8046 - val_acc: 0.8065\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4780 - acc: 0.8750 - val_loss: 0.8022 - val_acc: 0.8087\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7295 - acc: 0.8438 - val_loss: 0.7975 - val_acc: 0.8072\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3980 - acc: 0.9375 - val_loss: 0.7962 - val_acc: 0.8093\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4474 - acc: 0.9375 - val_loss: 0.7972 - val_acc: 0.8078\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3447 - acc: 0.9688 - val_loss: 0.8002 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2867 - acc: 1.0000 - val_loss: 0.8070 - val_acc: 0.8050\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2804 - acc: 1.0000 - val_loss: 0.8172 - val_acc: 0.8019\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2396 - acc: 1.0000 - val_loss: 0.8265 - val_acc: 0.8002\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "7 [supervised loss: 0.2396, acc: 100.00%] [unsupervised loss: 0.6325, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6480 - acc: 0.8438 - val_loss: 0.8336 - val_acc: 0.7977\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6685 - acc: 0.8125 - val_loss: 0.8241 - val_acc: 0.7984\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5017 - acc: 0.9062 - val_loss: 0.8126 - val_acc: 0.7999\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4281 - acc: 0.9375 - val_loss: 0.8007 - val_acc: 0.8014\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4488 - acc: 0.8750 - val_loss: 0.7935 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3246 - acc: 0.9375 - val_loss: 0.7937 - val_acc: 0.8063\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3096 - acc: 0.9688 - val_loss: 0.8002 - val_acc: 0.8059\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2957 - acc: 0.9688 - val_loss: 0.8132 - val_acc: 0.8029\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2878 - acc: 0.9688 - val_loss: 0.8316 - val_acc: 0.7989\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2322 - acc: 1.0000 - val_loss: 0.8542 - val_acc: 0.7929\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "8 [supervised loss: 0.2322, acc: 100.00%] [unsupervised loss: 0.7895, acc: 87.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7514 - acc: 0.8750 - val_loss: 0.8655 - val_acc: 0.7905\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7200 - acc: 0.8438 - val_loss: 0.8687 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6679 - acc: 0.8438 - val_loss: 0.8759 - val_acc: 0.7873\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4953 - acc: 0.8750 - val_loss: 0.8817 - val_acc: 0.7864\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5462 - acc: 0.9062 - val_loss: 0.8847 - val_acc: 0.7843\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3288 - acc: 0.9688 - val_loss: 0.8941 - val_acc: 0.7794\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2838 - acc: 1.0000 - val_loss: 0.9075 - val_acc: 0.7772\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2790 - acc: 1.0000 - val_loss: 0.9223 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2455 - acc: 1.0000 - val_loss: 0.9396 - val_acc: 0.7686\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2442 - acc: 1.0000 - val_loss: 0.9593 - val_acc: 0.7628\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "9 [supervised loss: 0.2442, acc: 100.00%] [unsupervised loss: 0.8021, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6101 - acc: 0.8438 - val_loss: 0.9846 - val_acc: 0.7583\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4511 - acc: 0.9062 - val_loss: 0.9857 - val_acc: 0.7576\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6921 - acc: 0.8438 - val_loss: 0.9702 - val_acc: 0.7616\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4361 - acc: 0.8750 - val_loss: 0.9482 - val_acc: 0.7676\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3500 - acc: 0.9062 - val_loss: 0.9270 - val_acc: 0.7736\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3253 - acc: 0.9688 - val_loss: 0.9124 - val_acc: 0.7791\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2867 - acc: 0.9688 - val_loss: 0.9032 - val_acc: 0.7841\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2718 - acc: 0.9688 - val_loss: 0.8990 - val_acc: 0.7879\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2650 - acc: 0.9688 - val_loss: 0.8971 - val_acc: 0.7878\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2357 - acc: 1.0000 - val_loss: 0.8993 - val_acc: 0.7879\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "10 [supervised loss: 0.2357, acc: 100.00%] [unsupervised loss: 0.8588, acc: 87.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8206 - acc: 0.8438 - val_loss: 0.9156 - val_acc: 0.7860\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7687 - acc: 0.7812 - val_loss: 0.9406 - val_acc: 0.7824\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7149 - acc: 0.7812 - val_loss: 0.9890 - val_acc: 0.7735\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4073 - acc: 0.9375 - val_loss: 1.0640 - val_acc: 0.7616\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3399 - acc: 0.9688 - val_loss: 1.1736 - val_acc: 0.7421\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3403 - acc: 0.9375 - val_loss: 1.3096 - val_acc: 0.7163\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2960 - acc: 0.9688 - val_loss: 1.4745 - val_acc: 0.6921\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2509 - acc: 1.0000 - val_loss: 1.6522 - val_acc: 0.6692\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2911 - acc: 0.9688 - val_loss: 1.8452 - val_acc: 0.6474\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2384 - acc: 1.0000 - val_loss: 2.0318 - val_acc: 0.6299\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "11 [supervised loss: 0.2384, acc: 100.00%] [unsupervised loss: 1.1306, acc: 68.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8202 - acc: 0.8125 - val_loss: 2.3062 - val_acc: 0.6044\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6360 - acc: 0.8125 - val_loss: 2.3658 - val_acc: 0.5993\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5099 - acc: 0.8750 - val_loss: 2.3687 - val_acc: 0.5992\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4819 - acc: 0.9062 - val_loss: 2.3175 - val_acc: 0.6061\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3894 - acc: 0.9688 - val_loss: 2.2081 - val_acc: 0.6167\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3093 - acc: 0.9688 - val_loss: 2.1359 - val_acc: 0.6240\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2856 - acc: 1.0000 - val_loss: 2.0826 - val_acc: 0.6295\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2648 - acc: 1.0000 - val_loss: 2.0427 - val_acc: 0.6322\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2737 - acc: 1.0000 - val_loss: 2.0122 - val_acc: 0.6359\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2548 - acc: 1.0000 - val_loss: 1.9835 - val_acc: 0.6380\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "12 [supervised loss: 0.2548, acc: 100.00%] [unsupervised loss: 1.7774, acc: 65.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8787 - acc: 0.7188 - val_loss: 2.1469 - val_acc: 0.6197\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8187 - acc: 0.8125 - val_loss: 2.1467 - val_acc: 0.6177\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7901 - acc: 0.8750 - val_loss: 2.0738 - val_acc: 0.6222\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5794 - acc: 0.9062 - val_loss: 2.0202 - val_acc: 0.6254\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5625 - acc: 0.9062 - val_loss: 1.9614 - val_acc: 0.6294\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3780 - acc: 0.9688 - val_loss: 1.9381 - val_acc: 0.6273\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3641 - acc: 0.9688 - val_loss: 1.9262 - val_acc: 0.6264\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3713 - acc: 0.9375 - val_loss: 1.9082 - val_acc: 0.6244\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3040 - acc: 0.9688 - val_loss: 1.8969 - val_acc: 0.6211\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2684 - acc: 1.0000 - val_loss: 1.8902 - val_acc: 0.6169\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "13 [supervised loss: 0.2684, acc: 100.00%] [unsupervised loss: 1.5994, acc: 62.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6032 - acc: 0.8438 - val_loss: 1.8438 - val_acc: 0.6154\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5265 - acc: 0.8750 - val_loss: 1.7776 - val_acc: 0.6224\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4985 - acc: 0.8750 - val_loss: 1.6993 - val_acc: 0.6346\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3760 - acc: 0.9375 - val_loss: 1.6207 - val_acc: 0.6453\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5315 - acc: 0.9375 - val_loss: 1.5413 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3852 - acc: 0.9375 - val_loss: 1.4719 - val_acc: 0.6707\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3163 - acc: 1.0000 - val_loss: 1.4097 - val_acc: 0.6814\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3006 - acc: 1.0000 - val_loss: 1.3579 - val_acc: 0.6917\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2962 - acc: 1.0000 - val_loss: 1.3157 - val_acc: 0.6994\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2503 - acc: 1.0000 - val_loss: 1.2814 - val_acc: 0.7066\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "14 [supervised loss: 0.2503, acc: 100.00%] [unsupervised loss: 1.7767, acc: 68.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8204 - acc: 0.8125 - val_loss: 1.3025 - val_acc: 0.7038\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7945 - acc: 0.8125 - val_loss: 1.2915 - val_acc: 0.7050\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4566 - acc: 0.9375 - val_loss: 1.2757 - val_acc: 0.7082\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5190 - acc: 0.8750 - val_loss: 1.2571 - val_acc: 0.7098\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4165 - acc: 0.9062 - val_loss: 1.2388 - val_acc: 0.7124\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3912 - acc: 0.9688 - val_loss: 1.2224 - val_acc: 0.7171\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3031 - acc: 0.9688 - val_loss: 1.2158 - val_acc: 0.7185\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2948 - acc: 1.0000 - val_loss: 1.2088 - val_acc: 0.7197\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2398 - acc: 1.0000 - val_loss: 1.2094 - val_acc: 0.7173\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2443 - acc: 1.0000 - val_loss: 1.2110 - val_acc: 0.7145\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "15 [supervised loss: 0.2443, acc: 100.00%] [unsupervised loss: 0.9956, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4498 - acc: 0.9062 - val_loss: 1.2294 - val_acc: 0.7092\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3811 - acc: 0.9688 - val_loss: 1.2442 - val_acc: 0.7046\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3703 - acc: 0.9375 - val_loss: 1.2596 - val_acc: 0.7015\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3970 - acc: 0.9375 - val_loss: 1.2765 - val_acc: 0.6998\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3023 - acc: 1.0000 - val_loss: 1.2938 - val_acc: 0.6969\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2667 - acc: 1.0000 - val_loss: 1.3128 - val_acc: 0.6935\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2721 - acc: 1.0000 - val_loss: 1.3337 - val_acc: 0.6908\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2880 - acc: 1.0000 - val_loss: 1.3524 - val_acc: 0.6893\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2479 - acc: 1.0000 - val_loss: 1.3637 - val_acc: 0.6886\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2290 - acc: 1.0000 - val_loss: 1.3752 - val_acc: 0.6862\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "16 [supervised loss: 0.2290, acc: 100.00%] [unsupervised loss: 0.7974, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7117 - acc: 0.8125 - val_loss: 1.4603 - val_acc: 0.6733\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7596 - acc: 0.8125 - val_loss: 1.5282 - val_acc: 0.6621\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5000 - acc: 0.9375 - val_loss: 1.6375 - val_acc: 0.6500\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4860 - acc: 0.9062 - val_loss: 1.7594 - val_acc: 0.6396\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4359 - acc: 0.9375 - val_loss: 1.9158 - val_acc: 0.6246\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5074 - acc: 0.9375 - val_loss: 2.0745 - val_acc: 0.6082\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3902 - acc: 0.9375 - val_loss: 2.1822 - val_acc: 0.6007\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3062 - acc: 0.9688 - val_loss: 2.3050 - val_acc: 0.5887\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2823 - acc: 1.0000 - val_loss: 2.3818 - val_acc: 0.5842\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2521 - acc: 1.0000 - val_loss: 2.4356 - val_acc: 0.5803\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "17 [supervised loss: 0.2521, acc: 100.00%] [unsupervised loss: 1.1480, acc: 75.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9379 - acc: 0.8750 - val_loss: 2.5090 - val_acc: 0.5717\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8150 - acc: 0.8750 - val_loss: 2.3903 - val_acc: 0.5777\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7231 - acc: 0.9062 - val_loss: 2.2131 - val_acc: 0.5892\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5064 - acc: 0.9375 - val_loss: 2.0349 - val_acc: 0.6011\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5182 - acc: 0.9375 - val_loss: 1.8667 - val_acc: 0.6180\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3301 - acc: 0.9688 - val_loss: 1.7374 - val_acc: 0.6329\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2827 - acc: 1.0000 - val_loss: 1.6598 - val_acc: 0.6477\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2664 - acc: 1.0000 - val_loss: 1.6344 - val_acc: 0.6573\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2449 - acc: 1.0000 - val_loss: 1.6452 - val_acc: 0.6565\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2383 - acc: 1.0000 - val_loss: 1.6809 - val_acc: 0.6526\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "18 [supervised loss: 0.2383, acc: 100.00%] [unsupervised loss: 1.8860, acc: 62.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4914 - acc: 0.8750 - val_loss: 1.8243 - val_acc: 0.6305\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3919 - acc: 0.9375 - val_loss: 1.8222 - val_acc: 0.6309\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5040 - acc: 0.8750 - val_loss: 1.7791 - val_acc: 0.6370\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3347 - acc: 0.9688 - val_loss: 1.7439 - val_acc: 0.6408\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3104 - acc: 0.9688 - val_loss: 1.7310 - val_acc: 0.6434\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2780 - acc: 0.9688 - val_loss: 1.7386 - val_acc: 0.6420\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2455 - acc: 1.0000 - val_loss: 1.7588 - val_acc: 0.6401\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2562 - acc: 1.0000 - val_loss: 1.7867 - val_acc: 0.6369\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2428 - acc: 1.0000 - val_loss: 1.8187 - val_acc: 0.6332\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2530 - acc: 1.0000 - val_loss: 1.8493 - val_acc: 0.6297\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "19 [supervised loss: 0.2530, acc: 100.00%] [unsupervised loss: 1.7833, acc: 56.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6002 - acc: 0.8438 - val_loss: 1.8954 - val_acc: 0.6231\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5479 - acc: 0.8438 - val_loss: 1.9430 - val_acc: 0.6152\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3524 - acc: 1.0000 - val_loss: 1.9874 - val_acc: 0.6093\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4593 - acc: 0.8750 - val_loss: 2.0459 - val_acc: 0.6023\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3364 - acc: 1.0000 - val_loss: 2.0974 - val_acc: 0.5968\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3131 - acc: 0.9688 - val_loss: 2.1415 - val_acc: 0.5901\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3017 - acc: 1.0000 - val_loss: 2.1780 - val_acc: 0.5852\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3244 - acc: 0.9688 - val_loss: 2.1948 - val_acc: 0.5853\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2505 - acc: 1.0000 - val_loss: 2.2110 - val_acc: 0.5845\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2647 - acc: 1.0000 - val_loss: 2.2036 - val_acc: 0.5832\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "20 [supervised loss: 0.2647, acc: 100.00%] [unsupervised loss: 1.6970, acc: 53.12%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5756 - acc: 0.8438 - val_loss: 2.3149 - val_acc: 0.5699\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4993 - acc: 0.8750 - val_loss: 2.1551 - val_acc: 0.5902\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3491 - acc: 0.9688 - val_loss: 2.0081 - val_acc: 0.6070\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3148 - acc: 0.9688 - val_loss: 1.8867 - val_acc: 0.6187\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3661 - acc: 0.9688 - val_loss: 1.7561 - val_acc: 0.6360\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2550 - acc: 1.0000 - val_loss: 1.6516 - val_acc: 0.6478\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2698 - acc: 0.9688 - val_loss: 1.5634 - val_acc: 0.6578\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2319 - acc: 1.0000 - val_loss: 1.4944 - val_acc: 0.6660\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2494 - acc: 1.0000 - val_loss: 1.4407 - val_acc: 0.6733\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2580 - acc: 1.0000 - val_loss: 1.3992 - val_acc: 0.6768\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "21 [supervised loss: 0.2580, acc: 100.00%] [unsupervised loss: 2.0369, acc: 68.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5114 - acc: 0.9062 - val_loss: 1.4310 - val_acc: 0.6701\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4519 - acc: 0.9062 - val_loss: 1.4498 - val_acc: 0.6665\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4453 - acc: 0.9375 - val_loss: 1.4754 - val_acc: 0.6613\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3248 - acc: 0.9688 - val_loss: 1.5037 - val_acc: 0.6563\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3946 - acc: 0.9375 - val_loss: 1.5331 - val_acc: 0.6526\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4036 - acc: 0.9688 - val_loss: 1.5584 - val_acc: 0.6485\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3267 - acc: 0.9375 - val_loss: 1.5712 - val_acc: 0.6467\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2413 - acc: 1.0000 - val_loss: 1.5859 - val_acc: 0.6447\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2730 - acc: 0.9688 - val_loss: 1.5997 - val_acc: 0.6412\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2586 - acc: 1.0000 - val_loss: 1.6160 - val_acc: 0.6374\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "22 [supervised loss: 0.2586, acc: 100.00%] [unsupervised loss: 1.4378, acc: 71.88%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7828 - acc: 0.8438 - val_loss: 1.6970 - val_acc: 0.6272\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7055 - acc: 0.8750 - val_loss: 1.6896 - val_acc: 0.6289\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6836 - acc: 0.8438 - val_loss: 1.6404 - val_acc: 0.6356\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3543 - acc: 0.9688 - val_loss: 1.5867 - val_acc: 0.6444\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5349 - acc: 0.9062 - val_loss: 1.5374 - val_acc: 0.6525\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3765 - acc: 0.9688 - val_loss: 1.4723 - val_acc: 0.6657\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2973 - acc: 1.0000 - val_loss: 1.4084 - val_acc: 0.6787\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2678 - acc: 1.0000 - val_loss: 1.3531 - val_acc: 0.6903\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2595 - acc: 1.0000 - val_loss: 1.3053 - val_acc: 0.7010\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2508 - acc: 1.0000 - val_loss: 1.2646 - val_acc: 0.7086\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "23 [supervised loss: 0.2508, acc: 100.00%] [unsupervised loss: 1.4586, acc: 75.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5499 - acc: 0.8438 - val_loss: 1.3188 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4926 - acc: 0.9375 - val_loss: 1.3526 - val_acc: 0.6884\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4681 - acc: 0.9375 - val_loss: 1.3835 - val_acc: 0.6834\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3564 - acc: 0.9688 - val_loss: 1.4289 - val_acc: 0.6755\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3586 - acc: 0.9688 - val_loss: 1.4856 - val_acc: 0.6649\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2927 - acc: 1.0000 - val_loss: 1.5608 - val_acc: 0.6522\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2736 - acc: 1.0000 - val_loss: 1.6438 - val_acc: 0.6430\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2838 - acc: 1.0000 - val_loss: 1.7328 - val_acc: 0.6340\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2828 - acc: 1.0000 - val_loss: 1.8277 - val_acc: 0.6220\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2294 - acc: 1.0000 - val_loss: 1.9168 - val_acc: 0.6165\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "24 [supervised loss: 0.2294, acc: 100.00%] [unsupervised loss: 1.3844, acc: 71.88%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8616 - acc: 0.7188 - val_loss: 1.7878 - val_acc: 0.6295\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7370 - acc: 0.8438 - val_loss: 1.6521 - val_acc: 0.6453\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5880 - acc: 0.8750 - val_loss: 1.5065 - val_acc: 0.6660\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5643 - acc: 0.9062 - val_loss: 1.3791 - val_acc: 0.6847\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4999 - acc: 0.9375 - val_loss: 1.2632 - val_acc: 0.7041\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3766 - acc: 0.9375 - val_loss: 1.1895 - val_acc: 0.7187\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3309 - acc: 0.9688 - val_loss: 1.1423 - val_acc: 0.7283\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3476 - acc: 0.9062 - val_loss: 1.1153 - val_acc: 0.7326\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2638 - acc: 1.0000 - val_loss: 1.1070 - val_acc: 0.7352\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2646 - acc: 1.0000 - val_loss: 1.1127 - val_acc: 0.7349\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "25 [supervised loss: 0.2646, acc: 100.00%] [unsupervised loss: 2.0392, acc: 75.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6795 - acc: 0.8438 - val_loss: 1.1271 - val_acc: 0.7298\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5865 - acc: 0.7812 - val_loss: 1.1229 - val_acc: 0.7300\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5506 - acc: 0.8125 - val_loss: 1.1224 - val_acc: 0.7327\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4794 - acc: 0.9062 - val_loss: 1.1252 - val_acc: 0.7321\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3865 - acc: 0.9688 - val_loss: 1.1293 - val_acc: 0.7315\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2936 - acc: 0.9688 - val_loss: 1.1351 - val_acc: 0.7331\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2867 - acc: 1.0000 - val_loss: 1.1441 - val_acc: 0.7305\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2837 - acc: 0.9688 - val_loss: 1.1508 - val_acc: 0.7291\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2558 - acc: 1.0000 - val_loss: 1.1581 - val_acc: 0.7264\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2902 - acc: 0.9688 - val_loss: 1.1649 - val_acc: 0.7248\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "26 [supervised loss: 0.2902, acc: 96.88%] [unsupervised loss: 0.9359, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6745 - acc: 0.8125 - val_loss: 1.2032 - val_acc: 0.7146\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4149 - acc: 0.9688 - val_loss: 1.2169 - val_acc: 0.7107\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5489 - acc: 0.8750 - val_loss: 1.2455 - val_acc: 0.7032\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5152 - acc: 0.8750 - val_loss: 1.2815 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4293 - acc: 0.9375 - val_loss: 1.3264 - val_acc: 0.6853\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3169 - acc: 0.9688 - val_loss: 1.3758 - val_acc: 0.6752\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2963 - acc: 1.0000 - val_loss: 1.4305 - val_acc: 0.6641\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2848 - acc: 1.0000 - val_loss: 1.4871 - val_acc: 0.6566\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2493 - acc: 1.0000 - val_loss: 1.5427 - val_acc: 0.6472\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2340 - acc: 1.0000 - val_loss: 1.5956 - val_acc: 0.6375\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "27 [supervised loss: 0.2340, acc: 100.00%] [unsupervised loss: 1.2431, acc: 78.12%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6002 - acc: 0.8750 - val_loss: 1.7686 - val_acc: 0.6101\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5903 - acc: 0.8125 - val_loss: 1.8067 - val_acc: 0.6047\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5797 - acc: 0.9062 - val_loss: 1.8392 - val_acc: 0.6011\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5154 - acc: 0.9375 - val_loss: 1.8624 - val_acc: 0.5976\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3739 - acc: 0.9375 - val_loss: 1.8720 - val_acc: 0.5978\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3189 - acc: 0.9375 - val_loss: 1.8810 - val_acc: 0.5969\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2837 - acc: 0.9688 - val_loss: 1.8803 - val_acc: 0.5972\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2751 - acc: 1.0000 - val_loss: 1.8762 - val_acc: 0.5978\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2392 - acc: 1.0000 - val_loss: 1.8689 - val_acc: 0.5976\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2359 - acc: 1.0000 - val_loss: 1.8579 - val_acc: 0.6021\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "28 [supervised loss: 0.2359, acc: 100.00%] [unsupervised loss: 1.6014, acc: 62.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5386 - acc: 0.9062 - val_loss: 1.9710 - val_acc: 0.5863\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5041 - acc: 0.8750 - val_loss: 1.9932 - val_acc: 0.5865\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5706 - acc: 0.8750 - val_loss: 2.0076 - val_acc: 0.5882\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4411 - acc: 0.9688 - val_loss: 2.0155 - val_acc: 0.5923\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3296 - acc: 1.0000 - val_loss: 2.0155 - val_acc: 0.5937\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3014 - acc: 1.0000 - val_loss: 2.0345 - val_acc: 0.5927\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2927 - acc: 1.0000 - val_loss: 2.0546 - val_acc: 0.5923\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2561 - acc: 1.0000 - val_loss: 2.0689 - val_acc: 0.5926\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2478 - acc: 1.0000 - val_loss: 2.0799 - val_acc: 0.5910\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2468 - acc: 1.0000 - val_loss: 2.0842 - val_acc: 0.5901\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "29 [supervised loss: 0.2468, acc: 100.00%] [unsupervised loss: 1.8560, acc: 53.12%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5570 - acc: 0.8750 - val_loss: 2.1329 - val_acc: 0.5825\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6259 - acc: 0.8438 - val_loss: 2.1223 - val_acc: 0.5849\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6919 - acc: 0.8438 - val_loss: 2.0594 - val_acc: 0.5920\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3874 - acc: 0.9688 - val_loss: 2.0002 - val_acc: 0.6001\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3824 - acc: 0.9375 - val_loss: 1.9479 - val_acc: 0.6060\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3409 - acc: 0.9688 - val_loss: 1.8917 - val_acc: 0.6151\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3159 - acc: 0.9688 - val_loss: 1.8460 - val_acc: 0.6210\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2571 - acc: 1.0000 - val_loss: 1.8043 - val_acc: 0.6248\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2720 - acc: 1.0000 - val_loss: 1.7660 - val_acc: 0.6292\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2421 - acc: 1.0000 - val_loss: 1.7293 - val_acc: 0.6318\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "30 [supervised loss: 0.2421, acc: 100.00%] [unsupervised loss: 1.9166, acc: 62.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5609 - acc: 0.9062 - val_loss: 1.7081 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8048 - acc: 0.7188 - val_loss: 1.6165 - val_acc: 0.6438\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6857 - acc: 0.9062 - val_loss: 1.4878 - val_acc: 0.6658\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4353 - acc: 0.9688 - val_loss: 1.3688 - val_acc: 0.6875\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4320 - acc: 0.9688 - val_loss: 1.2718 - val_acc: 0.7060\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3306 - acc: 0.9688 - val_loss: 1.2036 - val_acc: 0.7175\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3322 - acc: 1.0000 - val_loss: 1.1570 - val_acc: 0.7235\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2890 - acc: 1.0000 - val_loss: 1.1318 - val_acc: 0.7285\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2492 - acc: 1.0000 - val_loss: 1.1242 - val_acc: 0.7284\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2446 - acc: 1.0000 - val_loss: 1.1327 - val_acc: 0.7292\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "31 [supervised loss: 0.2446, acc: 100.00%] [unsupervised loss: 1.7883, acc: 71.88%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9339 - acc: 0.8750 - val_loss: 1.1961 - val_acc: 0.7114\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9021 - acc: 0.8438 - val_loss: 1.2342 - val_acc: 0.7037\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6647 - acc: 0.8125 - val_loss: 1.2670 - val_acc: 0.6982\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4548 - acc: 0.9062 - val_loss: 1.2979 - val_acc: 0.6939\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3741 - acc: 0.9062 - val_loss: 1.3233 - val_acc: 0.6895\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4131 - acc: 0.9375 - val_loss: 1.3454 - val_acc: 0.6862\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3265 - acc: 1.0000 - val_loss: 1.3646 - val_acc: 0.6806\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2585 - acc: 1.0000 - val_loss: 1.3779 - val_acc: 0.6775\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3076 - acc: 0.9688 - val_loss: 1.3895 - val_acc: 0.6746\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3430 - acc: 0.9688 - val_loss: 1.4019 - val_acc: 0.6709\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "32 [supervised loss: 0.3430, acc: 96.88%] [unsupervised loss: 0.7618, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.2553 - acc: 0.6875 - val_loss: 1.4283 - val_acc: 0.6641\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.0712 - acc: 0.8438 - val_loss: 1.4585 - val_acc: 0.6592\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7294 - acc: 0.7812 - val_loss: 1.5036 - val_acc: 0.6523\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5712 - acc: 0.8750 - val_loss: 1.5595 - val_acc: 0.6457\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3496 - acc: 0.9688 - val_loss: 1.6179 - val_acc: 0.6394\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3001 - acc: 1.0000 - val_loss: 1.6799 - val_acc: 0.6297\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2763 - acc: 1.0000 - val_loss: 1.7378 - val_acc: 0.6227\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3239 - acc: 0.9688 - val_loss: 1.7922 - val_acc: 0.6144\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2995 - acc: 0.9688 - val_loss: 1.8385 - val_acc: 0.6081\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2967 - acc: 0.9688 - val_loss: 1.8740 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "33 [supervised loss: 0.2967, acc: 96.88%] [unsupervised loss: 1.4789, acc: 68.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6175 - acc: 0.9375 - val_loss: 1.9641 - val_acc: 0.5883\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7321 - acc: 0.8438 - val_loss: 1.9400 - val_acc: 0.5884\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4500 - acc: 0.9375 - val_loss: 1.9044 - val_acc: 0.5912\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4819 - acc: 0.9062 - val_loss: 1.8684 - val_acc: 0.5940\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3680 - acc: 0.9688 - val_loss: 1.8254 - val_acc: 0.5983\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3477 - acc: 0.9688 - val_loss: 1.7883 - val_acc: 0.6018\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3369 - acc: 0.9375 - val_loss: 1.7491 - val_acc: 0.6066\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2695 - acc: 1.0000 - val_loss: 1.7137 - val_acc: 0.6124\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2370 - acc: 1.0000 - val_loss: 1.6830 - val_acc: 0.6164\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2342 - acc: 1.0000 - val_loss: 1.6561 - val_acc: 0.6204\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "34 [supervised loss: 0.2342, acc: 100.00%] [unsupervised loss: 1.7524, acc: 56.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6178 - acc: 0.8438 - val_loss: 1.6788 - val_acc: 0.6146\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7887 - acc: 0.8438 - val_loss: 1.6469 - val_acc: 0.6167\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3952 - acc: 0.9688 - val_loss: 1.6275 - val_acc: 0.6176\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4645 - acc: 0.9375 - val_loss: 1.6323 - val_acc: 0.6132\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3434 - acc: 0.9688 - val_loss: 1.6502 - val_acc: 0.6109\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2860 - acc: 1.0000 - val_loss: 1.6768 - val_acc: 0.6086\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2537 - acc: 1.0000 - val_loss: 1.7089 - val_acc: 0.6016\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2563 - acc: 1.0000 - val_loss: 1.7432 - val_acc: 0.5957\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2485 - acc: 1.0000 - val_loss: 1.7799 - val_acc: 0.5901\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2371 - acc: 1.0000 - val_loss: 1.8204 - val_acc: 0.5845\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "35 [supervised loss: 0.2371, acc: 100.00%] [unsupervised loss: 1.3952, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7405 - acc: 0.7812 - val_loss: 1.9832 - val_acc: 0.5603\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7494 - acc: 0.8125 - val_loss: 2.0725 - val_acc: 0.5485\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6010 - acc: 0.8438 - val_loss: 2.1817 - val_acc: 0.5324\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7304 - acc: 0.8438 - val_loss: 2.3063 - val_acc: 0.5185\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4814 - acc: 0.8750 - val_loss: 2.4332 - val_acc: 0.5041\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3289 - acc: 1.0000 - val_loss: 2.5632 - val_acc: 0.4878\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3404 - acc: 0.9688 - val_loss: 2.6954 - val_acc: 0.4723\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2977 - acc: 1.0000 - val_loss: 2.8292 - val_acc: 0.4569\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2541 - acc: 1.0000 - val_loss: 2.9506 - val_acc: 0.4432\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2517 - acc: 1.0000 - val_loss: 3.0502 - val_acc: 0.4346\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "36 [supervised loss: 0.2517, acc: 100.00%] [unsupervised loss: 2.5246, acc: 56.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5836 - acc: 0.9062 - val_loss: 3.4606 - val_acc: 0.3968\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5245 - acc: 0.8438 - val_loss: 3.4745 - val_acc: 0.3985\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4471 - acc: 0.9375 - val_loss: 3.3990 - val_acc: 0.4079\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6031 - acc: 0.9375 - val_loss: 3.2642 - val_acc: 0.4260\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3724 - acc: 0.9375 - val_loss: 3.0794 - val_acc: 0.4492\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2931 - acc: 0.9688 - val_loss: 2.9557 - val_acc: 0.4660\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2947 - acc: 0.9688 - val_loss: 2.8413 - val_acc: 0.4806\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2739 - acc: 0.9688 - val_loss: 2.7294 - val_acc: 0.4960\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2575 - acc: 1.0000 - val_loss: 2.6341 - val_acc: 0.5118\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2254 - acc: 1.0000 - val_loss: 2.5625 - val_acc: 0.5231\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "37 [supervised loss: 0.2254, acc: 100.00%] [unsupervised loss: 2.9869, acc: 43.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.0633 - acc: 0.6875 - val_loss: 2.6579 - val_acc: 0.5177\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8126 - acc: 0.7812 - val_loss: 2.5162 - val_acc: 0.5390\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8259 - acc: 0.7500 - val_loss: 2.3084 - val_acc: 0.5677\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7560 - acc: 0.8125 - val_loss: 2.1634 - val_acc: 0.5929\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5374 - acc: 0.9375 - val_loss: 2.0724 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5191 - acc: 0.9062 - val_loss: 2.0397 - val_acc: 0.6097\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3929 - acc: 0.9375 - val_loss: 2.0670 - val_acc: 0.6034\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3096 - acc: 1.0000 - val_loss: 2.1259 - val_acc: 0.5946\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2962 - acc: 0.9688 - val_loss: 2.2027 - val_acc: 0.5850\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2704 - acc: 1.0000 - val_loss: 2.2869 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "38 [supervised loss: 0.2704, acc: 100.00%] [unsupervised loss: 1.6722, acc: 53.12%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7534 - acc: 0.7188 - val_loss: 2.6170 - val_acc: 0.5289\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7550 - acc: 0.7812 - val_loss: 2.7130 - val_acc: 0.5165\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5069 - acc: 0.9062 - val_loss: 2.7603 - val_acc: 0.5107\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5684 - acc: 0.8750 - val_loss: 2.7774 - val_acc: 0.5089\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4021 - acc: 0.9062 - val_loss: 2.8130 - val_acc: 0.5068\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3160 - acc: 0.9688 - val_loss: 2.8714 - val_acc: 0.5015\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3457 - acc: 0.9062 - val_loss: 2.9548 - val_acc: 0.4960\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2716 - acc: 1.0000 - val_loss: 3.0599 - val_acc: 0.4875\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2447 - acc: 1.0000 - val_loss: 3.1724 - val_acc: 0.4808\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2705 - acc: 1.0000 - val_loss: 3.2779 - val_acc: 0.4746\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "39 [supervised loss: 0.2705, acc: 100.00%] [unsupervised loss: 2.0836, acc: 65.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9547 - acc: 0.8750 - val_loss: 3.4970 - val_acc: 0.4547\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8526 - acc: 0.8438 - val_loss: 3.4045 - val_acc: 0.4598\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8452 - acc: 0.8750 - val_loss: 3.1649 - val_acc: 0.4789\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6830 - acc: 0.9062 - val_loss: 2.8412 - val_acc: 0.5049\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4323 - acc: 0.9688 - val_loss: 2.5132 - val_acc: 0.5319\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3923 - acc: 0.9375 - val_loss: 2.2482 - val_acc: 0.5562\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3324 - acc: 0.9375 - val_loss: 2.0786 - val_acc: 0.5734\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3201 - acc: 0.9688 - val_loss: 1.9777 - val_acc: 0.5834\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2484 - acc: 1.0000 - val_loss: 1.9369 - val_acc: 0.5834\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2449 - acc: 1.0000 - val_loss: 1.9250 - val_acc: 0.5808\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "40 [supervised loss: 0.2449, acc: 100.00%] [unsupervised loss: 3.7949, acc: 40.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6666 - acc: 0.7812 - val_loss: 2.1702 - val_acc: 0.5504\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6215 - acc: 0.8438 - val_loss: 2.2214 - val_acc: 0.5399\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5410 - acc: 0.8750 - val_loss: 2.2337 - val_acc: 0.5343\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4642 - acc: 0.9062 - val_loss: 2.2160 - val_acc: 0.5326\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3546 - acc: 0.9688 - val_loss: 2.1796 - val_acc: 0.5348\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3891 - acc: 0.9688 - val_loss: 2.1208 - val_acc: 0.5391\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2891 - acc: 0.9688 - val_loss: 2.0581 - val_acc: 0.5463\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2755 - acc: 1.0000 - val_loss: 2.0089 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2717 - acc: 1.0000 - val_loss: 1.9673 - val_acc: 0.5565\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2584 - acc: 1.0000 - val_loss: 1.9328 - val_acc: 0.5581\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "41 [supervised loss: 0.2584, acc: 100.00%] [unsupervised loss: 2.0592, acc: 62.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.0488 - acc: 0.8750 - val_loss: 1.8996 - val_acc: 0.5614\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8118 - acc: 0.8438 - val_loss: 1.8004 - val_acc: 0.5754\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7723 - acc: 0.8438 - val_loss: 1.7003 - val_acc: 0.5908\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8421 - acc: 0.9062 - val_loss: 1.6042 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5774 - acc: 0.9062 - val_loss: 1.5099 - val_acc: 0.6216\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4571 - acc: 0.8438 - val_loss: 1.4234 - val_acc: 0.6385\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4388 - acc: 0.9375 - val_loss: 1.3563 - val_acc: 0.6509\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3077 - acc: 1.0000 - val_loss: 1.3067 - val_acc: 0.6622\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3379 - acc: 0.9688 - val_loss: 1.2692 - val_acc: 0.6706\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2640 - acc: 1.0000 - val_loss: 1.2404 - val_acc: 0.6777\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "42 [supervised loss: 0.2640, acc: 100.00%] [unsupervised loss: 1.6064, acc: 65.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8114 - acc: 0.7500 - val_loss: 1.2544 - val_acc: 0.6716\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7558 - acc: 0.8438 - val_loss: 1.2201 - val_acc: 0.6780\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6294 - acc: 0.8750 - val_loss: 1.1859 - val_acc: 0.6845\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5632 - acc: 0.9062 - val_loss: 1.1548 - val_acc: 0.6929\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6211 - acc: 0.8750 - val_loss: 1.1316 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6181 - acc: 0.8750 - val_loss: 1.1131 - val_acc: 0.7046\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3400 - acc: 0.9688 - val_loss: 1.1049 - val_acc: 0.7065\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3092 - acc: 1.0000 - val_loss: 1.1055 - val_acc: 0.7075\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3054 - acc: 1.0000 - val_loss: 1.1119 - val_acc: 0.7075\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2931 - acc: 0.9688 - val_loss: 1.1229 - val_acc: 0.7049\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "43 [supervised loss: 0.2931, acc: 96.88%] [unsupervised loss: 0.9050, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7595 - acc: 0.8125 - val_loss: 1.1345 - val_acc: 0.7018\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6994 - acc: 0.8125 - val_loss: 1.1100 - val_acc: 0.7093\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7157 - acc: 0.8438 - val_loss: 1.0836 - val_acc: 0.7176\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5599 - acc: 0.8750 - val_loss: 1.0646 - val_acc: 0.7236\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5777 - acc: 0.8125 - val_loss: 1.0533 - val_acc: 0.7258\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3704 - acc: 0.9375 - val_loss: 1.0516 - val_acc: 0.7267\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3482 - acc: 1.0000 - val_loss: 1.0533 - val_acc: 0.7264\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2894 - acc: 1.0000 - val_loss: 1.0567 - val_acc: 0.7254\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2809 - acc: 1.0000 - val_loss: 1.0598 - val_acc: 0.7256\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2684 - acc: 1.0000 - val_loss: 1.0635 - val_acc: 0.7251\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "44 [supervised loss: 0.2684, acc: 100.00%] [unsupervised loss: 1.3506, acc: 78.12%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8768 - acc: 0.7812 - val_loss: 1.0454 - val_acc: 0.7312\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7326 - acc: 0.8750 - val_loss: 1.0354 - val_acc: 0.7329\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7710 - acc: 0.7500 - val_loss: 1.0292 - val_acc: 0.7362\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6317 - acc: 0.8438 - val_loss: 1.0284 - val_acc: 0.7355\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4582 - acc: 0.9688 - val_loss: 1.0402 - val_acc: 0.7315\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3456 - acc: 0.9688 - val_loss: 1.0645 - val_acc: 0.7262\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3697 - acc: 0.9375 - val_loss: 1.1078 - val_acc: 0.7153\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3325 - acc: 0.9688 - val_loss: 1.1700 - val_acc: 0.7003\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2744 - acc: 1.0000 - val_loss: 1.2476 - val_acc: 0.6812\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2615 - acc: 1.0000 - val_loss: 1.3360 - val_acc: 0.6656\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "45 [supervised loss: 0.2615, acc: 100.00%] [unsupervised loss: 0.9194, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7870 - acc: 0.7812 - val_loss: 1.5268 - val_acc: 0.6311\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6165 - acc: 0.9375 - val_loss: 1.5834 - val_acc: 0.6206\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6145 - acc: 0.8750 - val_loss: 1.6375 - val_acc: 0.6150\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3741 - acc: 0.9688 - val_loss: 1.6898 - val_acc: 0.6092\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3677 - acc: 1.0000 - val_loss: 1.7414 - val_acc: 0.6019\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3403 - acc: 0.9375 - val_loss: 1.7935 - val_acc: 0.5952\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3125 - acc: 1.0000 - val_loss: 1.8382 - val_acc: 0.5893\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2936 - acc: 0.9688 - val_loss: 1.8719 - val_acc: 0.5837\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2738 - acc: 1.0000 - val_loss: 1.9025 - val_acc: 0.5808\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2392 - acc: 1.0000 - val_loss: 1.9319 - val_acc: 0.5775\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "46 [supervised loss: 0.2392, acc: 100.00%] [unsupervised loss: 1.5033, acc: 78.12%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8248 - acc: 0.7812 - val_loss: 2.0975 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5692 - acc: 0.8438 - val_loss: 2.1428 - val_acc: 0.5494\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6661 - acc: 0.9062 - val_loss: 2.1018 - val_acc: 0.5571\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5473 - acc: 0.8750 - val_loss: 2.0368 - val_acc: 0.5686\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4252 - acc: 0.9375 - val_loss: 1.9823 - val_acc: 0.5786\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3410 - acc: 0.9688 - val_loss: 1.9412 - val_acc: 0.5863\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2819 - acc: 0.9688 - val_loss: 1.9049 - val_acc: 0.5945\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2768 - acc: 0.9688 - val_loss: 1.8775 - val_acc: 0.6006\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2503 - acc: 1.0000 - val_loss: 1.8590 - val_acc: 0.6029\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2680 - acc: 1.0000 - val_loss: 1.8482 - val_acc: 0.6039\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "47 [supervised loss: 0.2680, acc: 100.00%] [unsupervised loss: 1.7593, acc: 62.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.0117 - acc: 0.7500 - val_loss: 1.9936 - val_acc: 0.5823\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9416 - acc: 0.7812 - val_loss: 2.0536 - val_acc: 0.5770\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9296 - acc: 0.8125 - val_loss: 2.1070 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6724 - acc: 0.7812 - val_loss: 2.1635 - val_acc: 0.5671\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6204 - acc: 0.8438 - val_loss: 2.2230 - val_acc: 0.5603\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4316 - acc: 0.9375 - val_loss: 2.2632 - val_acc: 0.5572\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3486 - acc: 1.0000 - val_loss: 2.2827 - val_acc: 0.5545\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3117 - acc: 0.9688 - val_loss: 2.2862 - val_acc: 0.5553\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3144 - acc: 1.0000 - val_loss: 2.2969 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2822 - acc: 0.9688 - val_loss: 2.3154 - val_acc: 0.5546\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "48 [supervised loss: 0.2822, acc: 96.88%] [unsupervised loss: 1.2567, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5521 - acc: 0.8750 - val_loss: 2.3764 - val_acc: 0.5519\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9336 - acc: 0.7500 - val_loss: 2.3967 - val_acc: 0.5511\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6166 - acc: 0.9062 - val_loss: 2.3935 - val_acc: 0.5538\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5469 - acc: 0.8750 - val_loss: 2.3629 - val_acc: 0.5585\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5463 - acc: 0.9375 - val_loss: 2.3058 - val_acc: 0.5627\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3304 - acc: 0.9688 - val_loss: 2.2504 - val_acc: 0.5668\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3239 - acc: 1.0000 - val_loss: 2.1973 - val_acc: 0.5705\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3414 - acc: 0.9688 - val_loss: 2.1525 - val_acc: 0.5761\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3266 - acc: 0.9688 - val_loss: 2.1083 - val_acc: 0.5788\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2511 - acc: 1.0000 - val_loss: 2.0669 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "49 [supervised loss: 0.2511, acc: 100.00%] [unsupervised loss: 1.5377, acc: 62.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5863 - acc: 0.8438 - val_loss: 2.1497 - val_acc: 0.5727\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6399 - acc: 0.8438 - val_loss: 2.1449 - val_acc: 0.5767\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5304 - acc: 0.8438 - val_loss: 2.1395 - val_acc: 0.5834\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4831 - acc: 0.9062 - val_loss: 2.1293 - val_acc: 0.5889\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3888 - acc: 0.9688 - val_loss: 2.1271 - val_acc: 0.5910\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3068 - acc: 1.0000 - val_loss: 2.1347 - val_acc: 0.5918\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3390 - acc: 1.0000 - val_loss: 2.1450 - val_acc: 0.5959\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2855 - acc: 0.9688 - val_loss: 2.1625 - val_acc: 0.5962\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2798 - acc: 1.0000 - val_loss: 2.1808 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2456 - acc: 1.0000 - val_loss: 2.2033 - val_acc: 0.5952\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "50 [supervised loss: 0.2456, acc: 100.00%] [unsupervised loss: 1.5870, acc: 68.75%]\n",
            "Training time: 1525.8914s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbIxExOyCxJy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "7d8ec5d7-197f-4668-c5ea-939688bfa2f4"
      },
      "source": [
        "plot_pseudo_supervised_losses = np.array(losses_pseudo_labeled)\n",
        "plot_pseudo_unsupervised_losses = np.array(losses_pseudo_unlabeled)\n",
        "plot_pseudo_all_losses = np.array(losses_pseudo)\n",
        "\n",
        "# Plot losses\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(iteration_checkpoints, plot_pseudo_all_losses, label=\"All loss\", color='black')\n",
        "plt.plot(iteration_checkpoints, plot_pseudo_supervised_losses, label=\"Supervised loss\", color='tab:blue', linestyle='dashed')\n",
        "plt.plot(iteration_checkpoints, plot_pseudo_unsupervised_losses, label=\"Unsupervised loss\", color='tab:green', linestyle='dashed')\n",
        "\n",
        "plt.xticks(iteration_checkpoints, rotation=90)\n",
        "\n",
        "plt.title(\"Pseudo Label's Supervised and Unsupervised Loss, num_labeled=%d\" % num_labeled)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29c9c985c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAAFPCAYAAADqcOfCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-4ZGValCxGj",
        "colab_type": "code",
        "outputId": "475a1cbb-8a96-4869-9d7e-fb4a3a5dd660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "# tmodel = load_model(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-8000.h5\")\n",
        "tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "tmodel.compile(loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'],\n",
        "                         optimizer=Adam())\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-30.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 25s 505us/step\n",
            "Training Accuracy: 75.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-jD1xtbCw7H",
        "colab_type": "code",
        "outputId": "a5fcf47f-880b-47d5-b261-abad697b5333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "# tmodel = load_model(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-6000.h5\")\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-30.h5\", by_name=False)\n",
        "\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 459us/step\n",
            "Test Accuracy: 74.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeX3mD5qC5TQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d8ec0a4-8673-4dbb-da2b-4704024ad707"
      },
      "source": [
        "accs = []\n",
        "# tx = [x for x in range(1,31,1)]\n",
        "tx = [x for x in range(1, len(iteration_checkpoints)+1, 1)]\n",
        "acc_max = [0,0]\n",
        "\n",
        "for e in tx:\n",
        "  # tmodel = load_model(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-\"+ str(e) +\".h5\")\n",
        "  tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/pseudo-\"+ str(e) +\".h5\", by_name=False)\n",
        "  _, acc = tmodel.evaluate(x, y)\n",
        "  accs.append(acc)\n",
        "print(max(accs))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(tx, accs, label=\"accs\", color='blue')\n",
        "plt.xticks(tx, rotation=90)\n",
        "plt.title(\"Pseudo Label's accs with epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accs\")\n",
        "plt.legend()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 410us/step\n",
            "10000/10000 [==============================] - 4s 393us/step\n",
            "10000/10000 [==============================] - 4s 383us/step\n",
            "10000/10000 [==============================] - 4s 383us/step\n",
            "10000/10000 [==============================] - 4s 392us/step\n",
            "10000/10000 [==============================] - 4s 389us/step\n",
            "10000/10000 [==============================] - 4s 388us/step\n",
            "10000/10000 [==============================] - 4s 384us/step\n",
            "10000/10000 [==============================] - 4s 381us/step\n",
            "10000/10000 [==============================] - 4s 379us/step\n",
            "10000/10000 [==============================] - 4s 377us/step\n",
            "10000/10000 [==============================] - 4s 377us/step\n",
            "10000/10000 [==============================] - 4s 380us/step\n",
            "10000/10000 [==============================] - 4s 382us/step\n",
            "10000/10000 [==============================] - 4s 375us/step\n",
            "10000/10000 [==============================] - 4s 376us/step\n",
            "10000/10000 [==============================] - 4s 373us/step\n",
            "10000/10000 [==============================] - 4s 375us/step\n",
            "10000/10000 [==============================] - 4s 374us/step\n",
            "10000/10000 [==============================] - 4s 374us/step\n",
            "10000/10000 [==============================] - 4s 370us/step\n",
            "10000/10000 [==============================] - 4s 375us/step\n",
            "10000/10000 [==============================] - 4s 375us/step\n",
            "10000/10000 [==============================] - 4s 373us/step\n",
            "10000/10000 [==============================] - 4s 376us/step\n",
            "10000/10000 [==============================] - 4s 375us/step\n",
            "10000/10000 [==============================] - 4s 374us/step\n",
            "10000/10000 [==============================] - 4s 374us/step\n",
            "10000/10000 [==============================] - 4s 374us/step\n",
            "10000/10000 [==============================] - 4s 383us/step\n",
            "10000/10000 [==============================] - 4s 388us/step\n",
            "10000/10000 [==============================] - 4s 391us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 395us/step\n",
            "10000/10000 [==============================] - 4s 398us/step\n",
            "10000/10000 [==============================] - 4s 401us/step\n",
            "10000/10000 [==============================] - 4s 406us/step\n",
            "10000/10000 [==============================] - 4s 396us/step\n",
            "10000/10000 [==============================] - 4s 383us/step\n",
            "10000/10000 [==============================] - 4s 379us/step\n",
            "10000/10000 [==============================] - 4s 378us/step\n",
            "10000/10000 [==============================] - 4s 374us/step\n",
            "10000/10000 [==============================] - 4s 373us/step\n",
            "10000/10000 [==============================] - 4s 368us/step\n",
            "10000/10000 [==============================] - 4s 369us/step\n",
            "10000/10000 [==============================] - 4s 373us/step\n",
            "10000/10000 [==============================] - 4s 373us/step\n",
            "10000/10000 [==============================] - 4s 378us/step\n",
            "10000/10000 [==============================] - 4s 379us/step\n",
            "0.8273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29cb550668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFPCAYAAAAfjmxyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n44QJniRJkiSNEyZ4kiRJkjRO/H9GdOpywORJPgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR4PM4STC5Q3",
        "colab_type": "code",
        "outputId": "1c17555a-8b9c-4221-8c66-7d639af288f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(max(accs[8:]))\n",
        "# for acc in accs:\n",
        "#   print(acc)\n",
        "pseudo_accs = accs\n",
        "print(pseudo_accs)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7316\n",
            "[0.8273, 0.8029, 0.8252, 0.7924, 0.7832, 0.8101, 0.8002, 0.7918, 0.7578, 0.7872, 0.6125, 0.6252, 0.6143, 0.7034, 0.7118, 0.6801, 0.5732, 0.6383, 0.629, 0.565, 0.6735, 0.6313, 0.703, 0.6141, 0.7316, 0.7199, 0.6201, 0.5918, 0.5861, 0.629, 0.7205, 0.6671, 0.593, 0.6148, 0.5729, 0.4076, 0.5092, 0.5492, 0.4577, 0.5631, 0.5576, 0.67, 0.701, 0.7258, 0.6478, 0.5608, 0.5918, 0.5512, 0.5747, 0.5967]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9jhBOIcqT-h",
        "colab_type": "text"
      },
      "source": [
        "# Mean Teacher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxPsJI6lMwsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "student = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "teacher = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "student.compile(loss='categorical_crossentropy', \n",
        "                metrics=['accuracy'], \n",
        "                optimizer=Adam())\n",
        "teacher.compile(loss='categorical_crossentropy', \n",
        "                metrics=['accuracy'], \n",
        "                optimizer=Adam())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anKFkigJMwpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_teacher_train(iterations, batch_size, save_interval, alpha, iter_epochs):\n",
        "\n",
        "    x_test, y_test = dataset.test_set()\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        # -------------------------\n",
        "        #  Train the model\n",
        "        # -------------------------\n",
        "\n",
        "        # Get labeled examples\n",
        "        imgs_labeled, labels = dataset.batch_labeled(batch_size)\n",
        "\n",
        "        # Get unlabeled examples\n",
        "        imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
        "\n",
        "        # Train on labeled examples\n",
        "        # loss_labeled_classification, acc_labeled_classification = student.train_on_batch(imgs_labeled, labels)\n",
        "        datagen.fit(imgs_labeled)\n",
        "        student.fit_generator(datagen.flow(imgs_labeled, labels, batch_size=batch_size),\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=iter_epochs, verbose=1, workers=4,\n",
        "                    callbacks=callbacks)\n",
        "        loss_labeled_classification, acc_labeled_classification = history.losses[-1], history.accs[-1]\n",
        "        pred_teacher_labeled = teacher.predict(imgs_labeled)\n",
        "        loss_labeled_consistency, acc_labeled_consistency = student.train_on_batch(imgs_labeled, pred_teacher_labeled)\n",
        "\n",
        "        # Train on unlabeled examples\n",
        "        pred_teacher_unlabeled = teacher.predict(imgs_unlabeled)\n",
        "        loss_unlabeled_consistency, acc_unlabeled_consistency = student.train_on_batch(imgs_unlabeled, pred_teacher_unlabeled)\n",
        "\n",
        "        # Update teacher model\n",
        "        teacher_weights_this = teacher.get_weights()\n",
        "        student_weights_this = student.get_weights()\n",
        "        for i in range(len(teacher_weights_this)):\n",
        "          teacher_weights_this[i] = alpha * teacher_weights_this[i] + (1-alpha) * student_weights_this[i]\n",
        "        # teacher_weights_this = alpha * teacher_weights_this + (1-alpha) * student_weights_this\n",
        "        teacher_weights_last = teacher_weights_this\n",
        "        teacher.set_weights(teacher_weights_this)\n",
        "\n",
        "        if (iteration + 1) % save_interval == 0:\n",
        "\n",
        "          # Save losses\n",
        "          supervised_losses.append(loss_labeled_classification)\n",
        "          unsupervised_losses.append(loss_labeled_consistency + loss_unlabeled_consistency)\n",
        "          labeled_consistency_costs.append(loss_labeled_consistency)\n",
        "          unlabeled_consistency_costs.append(loss_unlabeled_consistency)\n",
        "          accs_supervised.append(acc_labeled_classification)\n",
        "          accs_unsupervised.append((acc_labeled_consistency + acc_unlabeled_consistency)/2.0)\n",
        "          accs_labeled_consistency.append(acc_labeled_consistency)\n",
        "          accs_unlabeled_consistency.append(acc_unlabeled_consistency)\n",
        "\n",
        "          iteration_checkpoints.append(iteration + 1)\n",
        "\n",
        "          # Output training progress\n",
        "          print(\n",
        "              \"%d [supervised loss: %.4f, acc: %.2f%%] [unsupervised loss: %.4f, acc: %.2f%%] [labeled consistency loss: %.4f, acc:acc: %.2f%%] [unlabeled consistency loss: %.4f, acc: %.2f%%]\"\n",
        "              % (iteration + 1, loss_labeled_classification, 100 * acc_labeled_classification, \n",
        "                 loss_labeled_consistency + loss_unlabeled_consistency, 100 * ((acc_labeled_consistency + acc_unlabeled_consistency)/2.0), \n",
        "                 loss_labeled_consistency, 100 * acc_labeled_consistency, \n",
        "                  loss_unlabeled_consistency, 100 * acc_unlabeled_consistency))\n",
        "          \n",
        "          student.save(\"./models/models-label-\" + str(num_labeled) + \"/student-\" + str(iteration+1) + \".h5\")\n",
        "          teacher.save(\"./models/models-label-\" + str(num_labeled) + \"/teacher-\" + str(iteration+1) + \".h5\")\n",
        "          file1 = \"./losses/losses-label-\" + str(num_labeled) + \"/mt_supervised_losses.json\"\n",
        "          file2 = \"./losses/losses-label-\" + str(num_labeled) + \"/mt_unsupervised_losses.json\"\n",
        "          file3 = \"./losses/losses-label-\" + str(num_labeled) + \"/mt_labeled_consistency_costs.json\"\n",
        "          file4 = \"./losses/losses-label-\" + str(num_labeled) + \"/mt_unlabeled_consistency_costs.json\"\n",
        "          with open(file1, 'w') as json_file:\n",
        "                json.dump(str(supervised_losses), json_file)\n",
        "          with open(file2, 'w') as json_file:\n",
        "                json.dump(str(unsupervised_losses), json_file)\n",
        "          with open(file3, 'w') as json_file:\n",
        "                json.dump(str(labeled_consistency_costs), json_file)\n",
        "          with open(file4, 'w') as json_file:\n",
        "                json.dump(str(unlabeled_consistency_costs), json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS6N6-dRMwnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c22c532-3fb9-4e1c-910d-6547ad305479"
      },
      "source": [
        "# Set hyperparameters\n",
        "iterations = 50 # 30\n",
        "batch_size = 32\n",
        "save_interval = 1\n",
        "alpha = 0.5\n",
        "iter_epochs = 10\n",
        "\n",
        "supervised_losses = [] # classification cost\n",
        "unsupervised_losses = [] # consistency cost\n",
        "labeled_consistency_costs = []\n",
        "unlabeled_consistency_costs = []\n",
        "accs_supervised = []\n",
        "accs_unsupervised = []\n",
        "accs_labeled_consistency = []\n",
        "accs_unlabeled_consistency = []\n",
        "iteration_checkpoints = []\n",
        "\n",
        "discriminator_supervised.trainable = True\n",
        "student = load_model(\"./models/cifar10_model.035.h5\")\n",
        "\n",
        "starttime = time.clock()\n",
        "\n",
        "# Train the mean teacher for the specified number of iterations\n",
        "mean_teacher_train(iterations, batch_size, save_interval, alpha, iter_epochs)\n",
        "\n",
        "endtime = time.clock()\n",
        "print(\"Training time: %.4fs\" % (endtime - starttime))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 18s 18s/step - loss: 0.5530 - acc: 0.8750 - val_loss: 0.5810 - val_acc: 0.8712\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4614 - acc: 0.8750 - val_loss: 0.5774 - val_acc: 0.8732\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4881 - acc: 0.9062 - val_loss: 0.5801 - val_acc: 0.8728\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4688 - acc: 0.8438 - val_loss: 0.5856 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3834 - acc: 0.9375 - val_loss: 0.5928 - val_acc: 0.8678\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3644 - acc: 0.9062 - val_loss: 0.6017 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2773 - acc: 1.0000 - val_loss: 0.6083 - val_acc: 0.8652\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3204 - acc: 1.0000 - val_loss: 0.6171 - val_acc: 0.8630\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2536 - acc: 1.0000 - val_loss: 0.6274 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2426 - acc: 1.0000 - val_loss: 0.6351 - val_acc: 0.8585\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "1 [supervised loss: 0.2426, acc: 100.00%] [unsupervised loss: 2.2453, acc: 78.12%] [labeled consistency loss: 1.0675, acc:acc: 84.38%] [unlabeled consistency loss: 1.1779, acc: 71.88%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6215 - acc: 0.8438 - val_loss: 0.6413 - val_acc: 0.8558\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5501 - acc: 0.8750 - val_loss: 0.6416 - val_acc: 0.8559\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4999 - acc: 0.9062 - val_loss: 0.6418 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5947 - acc: 0.8750 - val_loss: 0.6399 - val_acc: 0.8569\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5007 - acc: 0.8750 - val_loss: 0.6394 - val_acc: 0.8576\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4700 - acc: 0.8750 - val_loss: 0.6393 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3356 - acc: 0.9688 - val_loss: 0.6394 - val_acc: 0.8593\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3012 - acc: 1.0000 - val_loss: 0.6413 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3049 - acc: 1.0000 - val_loss: 0.6441 - val_acc: 0.8568\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3064 - acc: 1.0000 - val_loss: 0.6471 - val_acc: 0.8548\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "2 [supervised loss: 0.3064, acc: 100.00%] [unsupervised loss: 1.4257, acc: 90.62%] [labeled consistency loss: 0.7864, acc:acc: 87.50%] [unlabeled consistency loss: 0.6393, acc: 93.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3947 - acc: 0.9375 - val_loss: 0.6381 - val_acc: 0.8570\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4469 - acc: 0.9375 - val_loss: 0.6329 - val_acc: 0.8580\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3692 - acc: 0.9375 - val_loss: 0.6268 - val_acc: 0.8595\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3660 - acc: 0.9688 - val_loss: 0.6229 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3015 - acc: 1.0000 - val_loss: 0.6211 - val_acc: 0.8607\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3179 - acc: 0.9375 - val_loss: 0.6214 - val_acc: 0.8603\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2870 - acc: 0.9688 - val_loss: 0.6231 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2586 - acc: 1.0000 - val_loss: 0.6264 - val_acc: 0.8589\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2515 - acc: 1.0000 - val_loss: 0.6310 - val_acc: 0.8579\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2479 - acc: 1.0000 - val_loss: 0.6358 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "3 [supervised loss: 0.2479, acc: 100.00%] [unsupervised loss: 1.5591, acc: 89.06%] [labeled consistency loss: 0.9137, acc:acc: 90.62%] [unlabeled consistency loss: 0.6454, acc: 87.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7424 - acc: 0.8438 - val_loss: 0.6363 - val_acc: 0.8557\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5879 - acc: 0.8750 - val_loss: 0.6435 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4716 - acc: 0.8750 - val_loss: 0.6536 - val_acc: 0.8499\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3690 - acc: 0.9375 - val_loss: 0.6674 - val_acc: 0.8464\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3554 - acc: 0.9688 - val_loss: 0.6823 - val_acc: 0.8429\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2587 - acc: 1.0000 - val_loss: 0.6987 - val_acc: 0.8381\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2806 - acc: 1.0000 - val_loss: 0.7167 - val_acc: 0.8334\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2887 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.8294\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2779 - acc: 1.0000 - val_loss: 0.7490 - val_acc: 0.8246\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2373 - acc: 1.0000 - val_loss: 0.7633 - val_acc: 0.8198\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "4 [supervised loss: 0.2373, acc: 100.00%] [unsupervised loss: 1.2433, acc: 93.75%] [labeled consistency loss: 0.7374, acc:acc: 93.75%] [unlabeled consistency loss: 0.5058, acc: 93.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7183 - acc: 0.8438 - val_loss: 0.7847 - val_acc: 0.8140\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8257 - acc: 0.8125 - val_loss: 0.7854 - val_acc: 0.8149\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6771 - acc: 0.7812 - val_loss: 0.7797 - val_acc: 0.8160\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5361 - acc: 0.9062 - val_loss: 0.7761 - val_acc: 0.8185\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4245 - acc: 0.9375 - val_loss: 0.7753 - val_acc: 0.8195\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3633 - acc: 0.9688 - val_loss: 0.7760 - val_acc: 0.8183\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2742 - acc: 1.0000 - val_loss: 0.7801 - val_acc: 0.8163\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2838 - acc: 1.0000 - val_loss: 0.7877 - val_acc: 0.8149\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2415 - acc: 1.0000 - val_loss: 0.7969 - val_acc: 0.8125\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2843 - acc: 1.0000 - val_loss: 0.8094 - val_acc: 0.8099\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "5 [supervised loss: 0.2843, acc: 100.00%] [unsupervised loss: 1.7024, acc: 90.62%] [labeled consistency loss: 1.0665, acc:acc: 87.50%] [unlabeled consistency loss: 0.6359, acc: 93.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5773 - acc: 0.8125 - val_loss: 0.7954 - val_acc: 0.8147\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6052 - acc: 0.8750 - val_loss: 0.7879 - val_acc: 0.8141\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6219 - acc: 0.8125 - val_loss: 0.7885 - val_acc: 0.8159\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4475 - acc: 0.9062 - val_loss: 0.7997 - val_acc: 0.8122\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3554 - acc: 0.9375 - val_loss: 0.8288 - val_acc: 0.8056\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3199 - acc: 0.9688 - val_loss: 0.8744 - val_acc: 0.7940\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3407 - acc: 0.9688 - val_loss: 0.9347 - val_acc: 0.7765\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2680 - acc: 1.0000 - val_loss: 1.0037 - val_acc: 0.7582\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2540 - acc: 1.0000 - val_loss: 1.0786 - val_acc: 0.7418\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2633 - acc: 0.9688 - val_loss: 1.1536 - val_acc: 0.7255\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "6 [supervised loss: 0.2633, acc: 96.88%] [unsupervised loss: 2.2730, acc: 82.81%] [labeled consistency loss: 1.4502, acc:acc: 81.25%] [unlabeled consistency loss: 0.8228, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.2288 - acc: 0.6562 - val_loss: 1.2021 - val_acc: 0.7148\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.1198 - acc: 0.7500 - val_loss: 1.1651 - val_acc: 0.7233\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9343 - acc: 0.7500 - val_loss: 1.1305 - val_acc: 0.7267\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7100 - acc: 0.8438 - val_loss: 1.1081 - val_acc: 0.7321\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6104 - acc: 0.9062 - val_loss: 1.1088 - val_acc: 0.7333\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4605 - acc: 0.9062 - val_loss: 1.1257 - val_acc: 0.7300\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3992 - acc: 0.9375 - val_loss: 1.1539 - val_acc: 0.7244\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3725 - acc: 0.9375 - val_loss: 1.1942 - val_acc: 0.7166\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2887 - acc: 0.9688 - val_loss: 1.2400 - val_acc: 0.7072\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2682 - acc: 1.0000 - val_loss: 1.2838 - val_acc: 0.6979\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "7 [supervised loss: 0.2682, acc: 100.00%] [unsupervised loss: 2.4052, acc: 78.12%] [labeled consistency loss: 1.5519, acc:acc: 81.25%] [unlabeled consistency loss: 0.8533, acc: 75.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9259 - acc: 0.6562 - val_loss: 1.3188 - val_acc: 0.6868\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5869 - acc: 0.8750 - val_loss: 1.3166 - val_acc: 0.6872\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5690 - acc: 0.8438 - val_loss: 1.2779 - val_acc: 0.6930\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6049 - acc: 0.8438 - val_loss: 1.2421 - val_acc: 0.7010\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3452 - acc: 1.0000 - val_loss: 1.2113 - val_acc: 0.7100\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4139 - acc: 0.9062 - val_loss: 1.1833 - val_acc: 0.7153\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2968 - acc: 1.0000 - val_loss: 1.1565 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2575 - acc: 1.0000 - val_loss: 1.1385 - val_acc: 0.7262\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2497 - acc: 1.0000 - val_loss: 1.1283 - val_acc: 0.7270\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3040 - acc: 0.9688 - val_loss: 1.1174 - val_acc: 0.7302\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "8 [supervised loss: 0.3040, acc: 96.88%] [unsupervised loss: 2.5277, acc: 82.81%] [labeled consistency loss: 1.5535, acc:acc: 84.38%] [unlabeled consistency loss: 0.9742, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.7650 - acc: 0.8438 - val_loss: 1.0837 - val_acc: 0.7385\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.9106 - acc: 0.7500 - val_loss: 1.0558 - val_acc: 0.7452\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.7062 - acc: 0.8438 - val_loss: 1.0332 - val_acc: 0.7493\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4510 - acc: 0.9375 - val_loss: 1.0155 - val_acc: 0.7528\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3855 - acc: 1.0000 - val_loss: 1.0016 - val_acc: 0.7523\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3997 - acc: 0.9688 - val_loss: 1.0002 - val_acc: 0.7504\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3275 - acc: 0.9688 - val_loss: 1.0144 - val_acc: 0.7465\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3019 - acc: 0.9688 - val_loss: 1.0335 - val_acc: 0.7401\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3376 - acc: 0.9688 - val_loss: 1.0602 - val_acc: 0.7316\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2605 - acc: 1.0000 - val_loss: 1.0934 - val_acc: 0.7238\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "9 [supervised loss: 0.2605, acc: 100.00%] [unsupervised loss: 2.7877, acc: 78.12%] [labeled consistency loss: 1.8818, acc:acc: 75.00%] [unlabeled consistency loss: 0.9059, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6408 - acc: 0.8750 - val_loss: 1.1623 - val_acc: 0.7065\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6776 - acc: 0.8438 - val_loss: 1.1525 - val_acc: 0.7126\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5645 - acc: 0.8750 - val_loss: 1.1395 - val_acc: 0.7201\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4472 - acc: 0.9062 - val_loss: 1.1296 - val_acc: 0.7222\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3090 - acc: 0.9688 - val_loss: 1.1298 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3910 - acc: 0.9375 - val_loss: 1.1362 - val_acc: 0.7298\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3246 - acc: 0.9688 - val_loss: 1.1484 - val_acc: 0.7309\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2440 - acc: 1.0000 - val_loss: 1.1657 - val_acc: 0.7310\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2326 - acc: 1.0000 - val_loss: 1.1872 - val_acc: 0.7290\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2216 - acc: 1.0000 - val_loss: 1.2090 - val_acc: 0.7270\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "10 [supervised loss: 0.2216, acc: 100.00%] [unsupervised loss: 1.7445, acc: 90.62%] [labeled consistency loss: 0.7875, acc:acc: 93.75%] [unlabeled consistency loss: 0.9570, acc: 87.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6828 - acc: 0.8438 - val_loss: 1.2318 - val_acc: 0.7227\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6910 - acc: 0.8750 - val_loss: 1.2102 - val_acc: 0.7245\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7095 - acc: 0.9062 - val_loss: 1.1764 - val_acc: 0.7269\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5298 - acc: 0.9375 - val_loss: 1.1433 - val_acc: 0.7306\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4734 - acc: 0.8750 - val_loss: 1.1152 - val_acc: 0.7353\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3696 - acc: 0.9688 - val_loss: 1.0958 - val_acc: 0.7384\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3187 - acc: 1.0000 - val_loss: 1.0859 - val_acc: 0.7406\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2936 - acc: 0.9688 - val_loss: 1.0866 - val_acc: 0.7426\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2734 - acc: 1.0000 - val_loss: 1.0955 - val_acc: 0.7397\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2851 - acc: 1.0000 - val_loss: 1.1096 - val_acc: 0.7382\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "11 [supervised loss: 0.2851, acc: 100.00%] [unsupervised loss: 2.3740, acc: 79.69%] [labeled consistency loss: 1.4213, acc:acc: 81.25%] [unlabeled consistency loss: 0.9527, acc: 78.12%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6547 - acc: 0.8438 - val_loss: 1.1585 - val_acc: 0.7308\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8306 - acc: 0.9062 - val_loss: 1.1686 - val_acc: 0.7272\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6705 - acc: 0.9062 - val_loss: 1.1716 - val_acc: 0.7268\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4742 - acc: 0.8750 - val_loss: 1.1742 - val_acc: 0.7257\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3987 - acc: 0.9062 - val_loss: 1.1819 - val_acc: 0.7239\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3372 - acc: 1.0000 - val_loss: 1.1891 - val_acc: 0.7213\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3760 - acc: 0.9688 - val_loss: 1.2001 - val_acc: 0.7177\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3278 - acc: 0.9688 - val_loss: 1.2103 - val_acc: 0.7151\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3163 - acc: 0.9688 - val_loss: 1.2226 - val_acc: 0.7129\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2921 - acc: 0.9688 - val_loss: 1.2357 - val_acc: 0.7107\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "12 [supervised loss: 0.2921, acc: 96.88%] [unsupervised loss: 1.7057, acc: 84.38%] [labeled consistency loss: 1.0627, acc:acc: 81.25%] [unlabeled consistency loss: 0.6430, acc: 87.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7865 - acc: 0.8125 - val_loss: 1.2405 - val_acc: 0.7092\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8162 - acc: 0.7812 - val_loss: 1.2336 - val_acc: 0.7114\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5281 - acc: 0.8750 - val_loss: 1.2146 - val_acc: 0.7148\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4929 - acc: 0.9375 - val_loss: 1.1839 - val_acc: 0.7226\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4006 - acc: 0.9375 - val_loss: 1.1599 - val_acc: 0.7287\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3088 - acc: 1.0000 - val_loss: 1.1393 - val_acc: 0.7344\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2714 - acc: 1.0000 - val_loss: 1.1237 - val_acc: 0.7396\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2796 - acc: 1.0000 - val_loss: 1.1113 - val_acc: 0.7432\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2698 - acc: 0.9688 - val_loss: 1.1006 - val_acc: 0.7457\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2614 - acc: 1.0000 - val_loss: 1.0921 - val_acc: 0.7484\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "13 [supervised loss: 0.2614, acc: 100.00%] [unsupervised loss: 2.6680, acc: 87.50%] [labeled consistency loss: 1.7463, acc:acc: 84.38%] [unlabeled consistency loss: 0.9217, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7848 - acc: 0.8125 - val_loss: 1.1208 - val_acc: 0.7390\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6871 - acc: 0.8125 - val_loss: 1.1262 - val_acc: 0.7396\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5731 - acc: 0.8438 - val_loss: 1.1373 - val_acc: 0.7350\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5815 - acc: 0.8750 - val_loss: 1.1484 - val_acc: 0.7310\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5388 - acc: 0.9062 - val_loss: 1.1584 - val_acc: 0.7287\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3162 - acc: 0.9688 - val_loss: 1.1708 - val_acc: 0.7269\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3572 - acc: 0.9688 - val_loss: 1.1894 - val_acc: 0.7222\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3063 - acc: 1.0000 - val_loss: 1.2097 - val_acc: 0.7186\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3343 - acc: 0.9688 - val_loss: 1.2274 - val_acc: 0.7142\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2751 - acc: 0.9688 - val_loss: 1.2441 - val_acc: 0.7076\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "14 [supervised loss: 0.2751, acc: 96.88%] [unsupervised loss: 2.5769, acc: 78.12%] [labeled consistency loss: 1.3368, acc:acc: 75.00%] [unlabeled consistency loss: 1.2401, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4514 - acc: 0.9375 - val_loss: 1.3929 - val_acc: 0.6790\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3059 - acc: 1.0000 - val_loss: 1.4262 - val_acc: 0.6729\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3378 - acc: 1.0000 - val_loss: 1.4515 - val_acc: 0.6700\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3230 - acc: 1.0000 - val_loss: 1.4701 - val_acc: 0.6683\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3373 - acc: 1.0000 - val_loss: 1.4822 - val_acc: 0.6669\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3235 - acc: 0.9688 - val_loss: 1.4874 - val_acc: 0.6672\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2960 - acc: 1.0000 - val_loss: 1.4965 - val_acc: 0.6666\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2687 - acc: 1.0000 - val_loss: 1.5064 - val_acc: 0.6682\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2630 - acc: 1.0000 - val_loss: 1.5151 - val_acc: 0.6701\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2409 - acc: 1.0000 - val_loss: 1.5184 - val_acc: 0.6721\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "15 [supervised loss: 0.2409, acc: 100.00%] [unsupervised loss: 1.5353, acc: 92.19%] [labeled consistency loss: 0.7510, acc:acc: 93.75%] [unlabeled consistency loss: 0.7843, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7346 - acc: 0.8125 - val_loss: 1.5563 - val_acc: 0.6679\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4741 - acc: 0.9375 - val_loss: 1.5449 - val_acc: 0.6694\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4207 - acc: 0.9375 - val_loss: 1.5246 - val_acc: 0.6752\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5319 - acc: 0.9062 - val_loss: 1.4952 - val_acc: 0.6785\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3834 - acc: 0.9375 - val_loss: 1.4782 - val_acc: 0.6833\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3374 - acc: 0.9375 - val_loss: 1.4606 - val_acc: 0.6871\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3016 - acc: 1.0000 - val_loss: 1.4387 - val_acc: 0.6902\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2397 - acc: 1.0000 - val_loss: 1.4210 - val_acc: 0.6939\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2431 - acc: 1.0000 - val_loss: 1.4055 - val_acc: 0.6959\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2388 - acc: 1.0000 - val_loss: 1.3941 - val_acc: 0.6989\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "16 [supervised loss: 0.2388, acc: 100.00%] [unsupervised loss: 2.5487, acc: 78.12%] [labeled consistency loss: 1.5880, acc:acc: 71.88%] [unlabeled consistency loss: 0.9607, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7674 - acc: 0.7812 - val_loss: 1.5077 - val_acc: 0.6823\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5739 - acc: 0.8750 - val_loss: 1.5181 - val_acc: 0.6823\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4566 - acc: 0.9375 - val_loss: 1.5075 - val_acc: 0.6844\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4037 - acc: 0.9375 - val_loss: 1.4950 - val_acc: 0.6831\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3726 - acc: 0.9688 - val_loss: 1.4758 - val_acc: 0.6864\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3874 - acc: 0.9688 - val_loss: 1.4457 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3079 - acc: 0.9688 - val_loss: 1.4057 - val_acc: 0.6953\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3082 - acc: 0.9688 - val_loss: 1.3674 - val_acc: 0.6980\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2844 - acc: 0.9688 - val_loss: 1.3329 - val_acc: 0.7001\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2887 - acc: 1.0000 - val_loss: 1.2966 - val_acc: 0.7039\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "17 [supervised loss: 0.2887, acc: 100.00%] [unsupervised loss: 3.0782, acc: 73.44%] [labeled consistency loss: 1.8946, acc:acc: 68.75%] [unlabeled consistency loss: 1.1836, acc: 78.12%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7222 - acc: 0.8438 - val_loss: 1.4577 - val_acc: 0.6763\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7094 - acc: 0.8438 - val_loss: 1.4596 - val_acc: 0.6731\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5641 - acc: 0.8438 - val_loss: 1.4456 - val_acc: 0.6770\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4464 - acc: 0.9062 - val_loss: 1.4277 - val_acc: 0.6790\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3452 - acc: 0.9688 - val_loss: 1.4106 - val_acc: 0.6828\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3006 - acc: 1.0000 - val_loss: 1.3800 - val_acc: 0.6853\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2678 - acc: 1.0000 - val_loss: 1.3522 - val_acc: 0.6884\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2301 - acc: 1.0000 - val_loss: 1.3332 - val_acc: 0.6917\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2364 - acc: 1.0000 - val_loss: 1.3168 - val_acc: 0.6924\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2401 - acc: 1.0000 - val_loss: 1.3078 - val_acc: 0.6900\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "18 [supervised loss: 0.2401, acc: 100.00%] [unsupervised loss: 2.8339, acc: 79.69%] [labeled consistency loss: 1.8745, acc:acc: 75.00%] [unlabeled consistency loss: 0.9594, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5871 - acc: 0.8438 - val_loss: 1.2775 - val_acc: 0.6943\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5207 - acc: 0.8438 - val_loss: 1.2413 - val_acc: 0.7007\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4808 - acc: 0.9375 - val_loss: 1.2242 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4769 - acc: 0.9062 - val_loss: 1.2071 - val_acc: 0.7094\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3146 - acc: 1.0000 - val_loss: 1.2012 - val_acc: 0.7132\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2872 - acc: 1.0000 - val_loss: 1.2017 - val_acc: 0.7108\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3021 - acc: 1.0000 - val_loss: 1.2102 - val_acc: 0.7096\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2595 - acc: 1.0000 - val_loss: 1.2219 - val_acc: 0.7071\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2555 - acc: 1.0000 - val_loss: 1.2346 - val_acc: 0.7050\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2506 - acc: 1.0000 - val_loss: 1.2494 - val_acc: 0.7021\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "19 [supervised loss: 0.2506, acc: 100.00%] [unsupervised loss: 2.5172, acc: 76.56%] [labeled consistency loss: 1.5900, acc:acc: 71.88%] [unlabeled consistency loss: 0.9272, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4723 - acc: 0.8750 - val_loss: 1.2759 - val_acc: 0.7002\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6425 - acc: 0.8125 - val_loss: 1.2858 - val_acc: 0.6979\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4862 - acc: 0.8750 - val_loss: 1.2919 - val_acc: 0.6962\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3673 - acc: 1.0000 - val_loss: 1.2925 - val_acc: 0.6966\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3694 - acc: 1.0000 - val_loss: 1.2957 - val_acc: 0.6948\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3580 - acc: 0.9375 - val_loss: 1.2938 - val_acc: 0.6940\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3355 - acc: 1.0000 - val_loss: 1.2881 - val_acc: 0.6947\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2774 - acc: 1.0000 - val_loss: 1.2815 - val_acc: 0.6949\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2767 - acc: 1.0000 - val_loss: 1.2728 - val_acc: 0.6957\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2918 - acc: 1.0000 - val_loss: 1.2615 - val_acc: 0.6969\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "20 [supervised loss: 0.2918, acc: 100.00%] [unsupervised loss: 1.9936, acc: 84.38%] [labeled consistency loss: 1.2430, acc:acc: 78.12%] [unlabeled consistency loss: 0.7507, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4541 - acc: 0.9375 - val_loss: 1.3627 - val_acc: 0.6762\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4241 - acc: 0.9375 - val_loss: 1.3649 - val_acc: 0.6760\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6381 - acc: 0.8438 - val_loss: 1.2996 - val_acc: 0.6882\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5622 - acc: 0.9062 - val_loss: 1.2048 - val_acc: 0.7050\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4096 - acc: 0.9375 - val_loss: 1.1076 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3703 - acc: 0.9375 - val_loss: 1.0271 - val_acc: 0.7471\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3170 - acc: 0.9688 - val_loss: 0.9665 - val_acc: 0.7647\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2996 - acc: 0.9688 - val_loss: 0.9237 - val_acc: 0.7739\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2963 - acc: 0.9688 - val_loss: 0.8959 - val_acc: 0.7815\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2404 - acc: 1.0000 - val_loss: 0.8800 - val_acc: 0.7861\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "21 [supervised loss: 0.2404, acc: 100.00%] [unsupervised loss: 2.0610, acc: 82.81%] [labeled consistency loss: 1.1775, acc:acc: 78.12%] [unlabeled consistency loss: 0.8834, acc: 87.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4290 - acc: 0.9375 - val_loss: 0.9064 - val_acc: 0.7775\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4913 - acc: 0.9062 - val_loss: 0.9158 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3661 - acc: 1.0000 - val_loss: 0.9231 - val_acc: 0.7708\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4296 - acc: 0.9375 - val_loss: 0.9278 - val_acc: 0.7692\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3288 - acc: 0.9688 - val_loss: 0.9312 - val_acc: 0.7692\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3690 - acc: 0.9688 - val_loss: 0.9348 - val_acc: 0.7679\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3055 - acc: 1.0000 - val_loss: 0.9368 - val_acc: 0.7665\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2695 - acc: 1.0000 - val_loss: 0.9393 - val_acc: 0.7649\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2410 - acc: 1.0000 - val_loss: 0.9426 - val_acc: 0.7648\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2871 - acc: 1.0000 - val_loss: 0.9464 - val_acc: 0.7626\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "22 [supervised loss: 0.2871, acc: 100.00%] [unsupervised loss: 1.7639, acc: 82.81%] [labeled consistency loss: 0.9042, acc:acc: 90.62%] [unlabeled consistency loss: 0.8597, acc: 75.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4738 - acc: 0.9062 - val_loss: 0.9650 - val_acc: 0.7594\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5323 - acc: 0.9062 - val_loss: 0.9591 - val_acc: 0.7613\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3845 - acc: 0.9688 - val_loss: 0.9463 - val_acc: 0.7612\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3301 - acc: 0.9688 - val_loss: 0.9326 - val_acc: 0.7650\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3419 - acc: 0.9688 - val_loss: 0.9247 - val_acc: 0.7651\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2980 - acc: 1.0000 - val_loss: 0.9207 - val_acc: 0.7641\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3223 - acc: 0.9688 - val_loss: 0.9210 - val_acc: 0.7654\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2575 - acc: 1.0000 - val_loss: 0.9275 - val_acc: 0.7659\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2586 - acc: 1.0000 - val_loss: 0.9394 - val_acc: 0.7662\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2382 - acc: 1.0000 - val_loss: 0.9549 - val_acc: 0.7640\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "23 [supervised loss: 0.2382, acc: 100.00%] [unsupervised loss: 1.8323, acc: 87.50%] [labeled consistency loss: 0.9685, acc:acc: 87.50%] [unlabeled consistency loss: 0.8637, acc: 87.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5061 - acc: 0.9375 - val_loss: 1.0111 - val_acc: 0.7509\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5879 - acc: 0.9375 - val_loss: 1.0271 - val_acc: 0.7474\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5546 - acc: 0.9062 - val_loss: 1.0356 - val_acc: 0.7465\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3991 - acc: 0.9062 - val_loss: 1.0410 - val_acc: 0.7456\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4492 - acc: 0.9062 - val_loss: 1.0415 - val_acc: 0.7463\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4126 - acc: 0.9688 - val_loss: 1.0348 - val_acc: 0.7483\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2960 - acc: 1.0000 - val_loss: 1.0269 - val_acc: 0.7504\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3001 - acc: 1.0000 - val_loss: 1.0185 - val_acc: 0.7535\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2785 - acc: 1.0000 - val_loss: 1.0083 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2649 - acc: 1.0000 - val_loss: 0.9984 - val_acc: 0.7590\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "24 [supervised loss: 0.2649, acc: 100.00%] [unsupervised loss: 1.8735, acc: 79.69%] [labeled consistency loss: 1.2039, acc:acc: 78.12%] [unlabeled consistency loss: 0.6695, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8153 - acc: 0.7812 - val_loss: 1.0336 - val_acc: 0.7485\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8303 - acc: 0.7812 - val_loss: 1.0287 - val_acc: 0.7499\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5596 - acc: 0.8750 - val_loss: 1.0108 - val_acc: 0.7507\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6196 - acc: 0.8750 - val_loss: 0.9897 - val_acc: 0.7544\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5573 - acc: 0.8750 - val_loss: 0.9703 - val_acc: 0.7565\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4028 - acc: 0.9688 - val_loss: 0.9511 - val_acc: 0.7606\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3933 - acc: 0.9375 - val_loss: 0.9443 - val_acc: 0.7624\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3245 - acc: 0.9688 - val_loss: 0.9469 - val_acc: 0.7624\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3102 - acc: 0.9688 - val_loss: 0.9568 - val_acc: 0.7613\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2644 - acc: 0.9688 - val_loss: 0.9721 - val_acc: 0.7586\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "25 [supervised loss: 0.2644, acc: 96.88%] [unsupervised loss: 2.8899, acc: 76.56%] [labeled consistency loss: 1.7998, acc:acc: 71.88%] [unlabeled consistency loss: 1.0901, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9788 - acc: 0.6562 - val_loss: 0.9707 - val_acc: 0.7567\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7466 - acc: 0.8125 - val_loss: 0.9501 - val_acc: 0.7611\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5326 - acc: 0.8750 - val_loss: 0.9318 - val_acc: 0.7648\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5912 - acc: 0.8750 - val_loss: 0.9213 - val_acc: 0.7672\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3902 - acc: 0.9688 - val_loss: 0.9135 - val_acc: 0.7697\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3445 - acc: 1.0000 - val_loss: 0.9115 - val_acc: 0.7731\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3160 - acc: 1.0000 - val_loss: 0.9126 - val_acc: 0.7734\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3237 - acc: 0.9688 - val_loss: 0.9204 - val_acc: 0.7719\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2625 - acc: 1.0000 - val_loss: 0.9310 - val_acc: 0.7701\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2668 - acc: 1.0000 - val_loss: 0.9453 - val_acc: 0.7664\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "26 [supervised loss: 0.2668, acc: 100.00%] [unsupervised loss: 2.5769, acc: 78.12%] [labeled consistency loss: 1.6141, acc:acc: 75.00%] [unlabeled consistency loss: 0.9628, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6286 - acc: 0.9062 - val_loss: 0.9763 - val_acc: 0.7571\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5524 - acc: 0.8750 - val_loss: 0.9789 - val_acc: 0.7554\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5333 - acc: 0.8750 - val_loss: 0.9793 - val_acc: 0.7557\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4133 - acc: 0.9062 - val_loss: 0.9800 - val_acc: 0.7553\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4361 - acc: 0.9062 - val_loss: 0.9839 - val_acc: 0.7540\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4431 - acc: 0.9688 - val_loss: 0.9930 - val_acc: 0.7540\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3229 - acc: 1.0000 - val_loss: 1.0038 - val_acc: 0.7533\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2826 - acc: 1.0000 - val_loss: 1.0168 - val_acc: 0.7489\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3166 - acc: 1.0000 - val_loss: 1.0355 - val_acc: 0.7462\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2497 - acc: 1.0000 - val_loss: 1.0581 - val_acc: 0.7418\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "27 [supervised loss: 0.2497, acc: 100.00%] [unsupervised loss: 2.3322, acc: 81.25%] [labeled consistency loss: 1.1180, acc:acc: 90.62%] [unlabeled consistency loss: 1.2142, acc: 71.88%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8482 - acc: 0.7500 - val_loss: 1.1825 - val_acc: 0.7162\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7803 - acc: 0.8125 - val_loss: 1.2187 - val_acc: 0.7096\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4012 - acc: 0.9375 - val_loss: 1.2561 - val_acc: 0.7045\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4121 - acc: 0.9375 - val_loss: 1.2936 - val_acc: 0.7006\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3171 - acc: 1.0000 - val_loss: 1.3249 - val_acc: 0.6964\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2831 - acc: 1.0000 - val_loss: 1.3503 - val_acc: 0.6938\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3358 - acc: 0.9688 - val_loss: 1.3775 - val_acc: 0.6901\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2722 - acc: 1.0000 - val_loss: 1.3961 - val_acc: 0.6883\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2427 - acc: 1.0000 - val_loss: 1.4108 - val_acc: 0.6865\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2563 - acc: 1.0000 - val_loss: 1.4217 - val_acc: 0.6841\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "28 [supervised loss: 0.2563, acc: 100.00%] [unsupervised loss: 2.9214, acc: 78.12%] [labeled consistency loss: 1.8658, acc:acc: 78.12%] [unlabeled consistency loss: 1.0556, acc: 78.12%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4302 - acc: 0.9062 - val_loss: 1.4682 - val_acc: 0.6785\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3645 - acc: 0.9375 - val_loss: 1.4791 - val_acc: 0.6769\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4030 - acc: 0.9375 - val_loss: 1.4878 - val_acc: 0.6776\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4253 - acc: 0.9062 - val_loss: 1.4910 - val_acc: 0.6781\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3251 - acc: 0.9688 - val_loss: 1.4976 - val_acc: 0.6787\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3153 - acc: 0.9688 - val_loss: 1.5047 - val_acc: 0.6793\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2645 - acc: 1.0000 - val_loss: 1.5112 - val_acc: 0.6793\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2766 - acc: 1.0000 - val_loss: 1.5194 - val_acc: 0.6810\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2914 - acc: 0.9688 - val_loss: 1.5324 - val_acc: 0.6801\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2327 - acc: 1.0000 - val_loss: 1.5476 - val_acc: 0.6784\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "29 [supervised loss: 0.2327, acc: 100.00%] [unsupervised loss: 2.5812, acc: 81.25%] [labeled consistency loss: 1.1230, acc:acc: 87.50%] [unlabeled consistency loss: 1.4582, acc: 75.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4771 - acc: 0.9062 - val_loss: 1.6808 - val_acc: 0.6618\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3458 - acc: 0.9375 - val_loss: 1.7262 - val_acc: 0.6527\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3867 - acc: 0.9375 - val_loss: 1.7577 - val_acc: 0.6469\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3628 - acc: 0.9375 - val_loss: 1.7840 - val_acc: 0.6431\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3453 - acc: 0.9375 - val_loss: 1.8030 - val_acc: 0.6386\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3245 - acc: 0.9688 - val_loss: 1.8152 - val_acc: 0.6352\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2994 - acc: 0.9688 - val_loss: 1.8337 - val_acc: 0.6319\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2753 - acc: 1.0000 - val_loss: 1.8490 - val_acc: 0.6302\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2475 - acc: 1.0000 - val_loss: 1.8627 - val_acc: 0.6281\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2634 - acc: 1.0000 - val_loss: 1.8723 - val_acc: 0.6274\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "30 [supervised loss: 0.2634, acc: 100.00%] [unsupervised loss: 2.1699, acc: 84.38%] [labeled consistency loss: 1.0977, acc:acc: 87.50%] [unlabeled consistency loss: 1.0722, acc: 81.25%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6579 - acc: 0.7812 - val_loss: 2.1209 - val_acc: 0.6008\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5217 - acc: 0.9062 - val_loss: 2.1571 - val_acc: 0.5978\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4476 - acc: 0.9062 - val_loss: 2.1658 - val_acc: 0.5976\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4457 - acc: 0.9375 - val_loss: 2.1742 - val_acc: 0.5967\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3547 - acc: 1.0000 - val_loss: 2.1771 - val_acc: 0.5956\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4155 - acc: 0.9375 - val_loss: 2.1672 - val_acc: 0.5992\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3541 - acc: 0.9375 - val_loss: 2.1310 - val_acc: 0.6039\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3310 - acc: 0.9688 - val_loss: 2.0992 - val_acc: 0.6094\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2894 - acc: 0.9688 - val_loss: 2.0785 - val_acc: 0.6109\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3207 - acc: 0.9375 - val_loss: 2.0652 - val_acc: 0.6116\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "31 [supervised loss: 0.3207, acc: 93.75%] [unsupervised loss: 2.6368, acc: 71.88%] [labeled consistency loss: 1.6184, acc:acc: 71.88%] [unlabeled consistency loss: 1.0184, acc: 71.88%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7678 - acc: 0.8125 - val_loss: 2.2643 - val_acc: 0.5837\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4974 - acc: 0.9375 - val_loss: 2.2086 - val_acc: 0.5890\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5717 - acc: 0.9062 - val_loss: 2.0632 - val_acc: 0.6052\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4274 - acc: 0.9062 - val_loss: 1.8743 - val_acc: 0.6282\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4329 - acc: 0.9375 - val_loss: 1.6878 - val_acc: 0.6526\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4319 - acc: 0.9375 - val_loss: 1.5335 - val_acc: 0.6733\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4221 - acc: 0.9375 - val_loss: 1.4158 - val_acc: 0.6939\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2720 - acc: 1.0000 - val_loss: 1.3305 - val_acc: 0.7098\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3047 - acc: 0.9688 - val_loss: 1.2604 - val_acc: 0.7237\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2470 - acc: 1.0000 - val_loss: 1.2134 - val_acc: 0.7304\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "32 [supervised loss: 0.2470, acc: 100.00%] [unsupervised loss: 3.1747, acc: 68.75%] [labeled consistency loss: 2.0498, acc:acc: 68.75%] [unlabeled consistency loss: 1.1249, acc: 68.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6588 - acc: 0.8125 - val_loss: 1.2898 - val_acc: 0.7141\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7005 - acc: 0.8438 - val_loss: 1.2866 - val_acc: 0.7176\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6904 - acc: 0.8750 - val_loss: 1.2700 - val_acc: 0.7211\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5228 - acc: 0.9062 - val_loss: 1.2482 - val_acc: 0.7241\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4221 - acc: 0.9375 - val_loss: 1.2247 - val_acc: 0.7269\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3056 - acc: 0.9688 - val_loss: 1.2104 - val_acc: 0.7285\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3028 - acc: 1.0000 - val_loss: 1.2001 - val_acc: 0.7299\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2825 - acc: 1.0000 - val_loss: 1.1928 - val_acc: 0.7301\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2489 - acc: 1.0000 - val_loss: 1.1893 - val_acc: 0.7306\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2659 - acc: 1.0000 - val_loss: 1.1853 - val_acc: 0.7283\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "33 [supervised loss: 0.2659, acc: 100.00%] [unsupervised loss: 2.2329, acc: 78.12%] [labeled consistency loss: 1.5188, acc:acc: 71.88%] [unlabeled consistency loss: 0.7141, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4652 - acc: 0.9688 - val_loss: 1.1612 - val_acc: 0.7308\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4401 - acc: 0.9375 - val_loss: 1.1244 - val_acc: 0.7361\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3396 - acc: 0.9688 - val_loss: 1.0885 - val_acc: 0.7448\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3769 - acc: 0.9375 - val_loss: 1.0561 - val_acc: 0.7488\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2942 - acc: 1.0000 - val_loss: 1.0227 - val_acc: 0.7549\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3020 - acc: 1.0000 - val_loss: 0.9955 - val_acc: 0.7599\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2848 - acc: 1.0000 - val_loss: 0.9739 - val_acc: 0.7644\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2772 - acc: 0.9688 - val_loss: 0.9560 - val_acc: 0.7699\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2647 - acc: 1.0000 - val_loss: 0.9425 - val_acc: 0.7735\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2393 - acc: 1.0000 - val_loss: 0.9330 - val_acc: 0.7740\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "34 [supervised loss: 0.2393, acc: 100.00%] [unsupervised loss: 1.8562, acc: 90.62%] [labeled consistency loss: 1.2401, acc:acc: 87.50%] [unlabeled consistency loss: 0.6161, acc: 93.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8959 - acc: 0.8438 - val_loss: 0.8953 - val_acc: 0.7847\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7226 - acc: 0.8438 - val_loss: 0.8689 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7221 - acc: 0.8438 - val_loss: 0.8524 - val_acc: 0.7955\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4839 - acc: 0.8750 - val_loss: 0.8485 - val_acc: 0.7952\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4928 - acc: 0.9062 - val_loss: 0.8660 - val_acc: 0.7909\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2951 - acc: 1.0000 - val_loss: 0.9013 - val_acc: 0.7785\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3353 - acc: 0.9688 - val_loss: 0.9535 - val_acc: 0.7640\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3634 - acc: 0.9688 - val_loss: 1.0205 - val_acc: 0.7504\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2576 - acc: 1.0000 - val_loss: 1.0932 - val_acc: 0.7361\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2309 - acc: 1.0000 - val_loss: 1.1652 - val_acc: 0.7231\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "35 [supervised loss: 0.2309, acc: 100.00%] [unsupervised loss: 2.8767, acc: 81.25%] [labeled consistency loss: 2.0398, acc:acc: 78.12%] [unlabeled consistency loss: 0.8369, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4806 - acc: 0.8750 - val_loss: 1.2581 - val_acc: 0.7117\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3907 - acc: 0.9688 - val_loss: 1.2779 - val_acc: 0.7098\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5083 - acc: 0.9062 - val_loss: 1.2933 - val_acc: 0.7092\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4043 - acc: 0.9375 - val_loss: 1.3071 - val_acc: 0.7097\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3416 - acc: 1.0000 - val_loss: 1.3207 - val_acc: 0.7093\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3063 - acc: 0.9688 - val_loss: 1.3346 - val_acc: 0.7084\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3145 - acc: 0.9688 - val_loss: 1.3457 - val_acc: 0.7060\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2569 - acc: 1.0000 - val_loss: 1.3568 - val_acc: 0.7040\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2665 - acc: 1.0000 - val_loss: 1.3702 - val_acc: 0.7023\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2387 - acc: 1.0000 - val_loss: 1.3826 - val_acc: 0.7006\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "36 [supervised loss: 0.2387, acc: 100.00%] [unsupervised loss: 1.7705, acc: 95.31%] [labeled consistency loss: 0.9646, acc:acc: 96.88%] [unlabeled consistency loss: 0.8058, acc: 93.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5692 - acc: 0.8750 - val_loss: 1.3485 - val_acc: 0.7014\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5857 - acc: 0.9062 - val_loss: 1.2980 - val_acc: 0.7058\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3916 - acc: 0.9375 - val_loss: 1.2615 - val_acc: 0.7063\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2760 - acc: 0.9688 - val_loss: 1.2381 - val_acc: 0.7078\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3053 - acc: 1.0000 - val_loss: 1.2264 - val_acc: 0.7064\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2730 - acc: 1.0000 - val_loss: 1.2208 - val_acc: 0.7057\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2601 - acc: 1.0000 - val_loss: 1.2168 - val_acc: 0.7060\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2659 - acc: 1.0000 - val_loss: 1.2119 - val_acc: 0.7084\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2450 - acc: 1.0000 - val_loss: 1.2074 - val_acc: 0.7087\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2410 - acc: 1.0000 - val_loss: 1.2031 - val_acc: 0.7105\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "37 [supervised loss: 0.2410, acc: 100.00%] [unsupervised loss: 2.0543, acc: 84.38%] [labeled consistency loss: 1.2705, acc:acc: 84.38%] [unlabeled consistency loss: 0.7838, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4824 - acc: 0.9375 - val_loss: 1.2709 - val_acc: 0.6926\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6465 - acc: 0.8750 - val_loss: 1.2548 - val_acc: 0.6956\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4015 - acc: 0.9688 - val_loss: 1.2331 - val_acc: 0.7004\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4312 - acc: 0.9375 - val_loss: 1.1950 - val_acc: 0.7084\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3629 - acc: 0.9688 - val_loss: 1.1497 - val_acc: 0.7184\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2840 - acc: 1.0000 - val_loss: 1.1048 - val_acc: 0.7292\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2971 - acc: 1.0000 - val_loss: 1.0707 - val_acc: 0.7380\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2732 - acc: 1.0000 - val_loss: 1.0388 - val_acc: 0.7448\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2462 - acc: 1.0000 - val_loss: 1.0169 - val_acc: 0.7468\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2767 - acc: 1.0000 - val_loss: 1.0014 - val_acc: 0.7512\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "38 [supervised loss: 0.2767, acc: 100.00%] [unsupervised loss: 2.5810, acc: 78.12%] [labeled consistency loss: 1.2113, acc:acc: 87.50%] [unlabeled consistency loss: 1.3697, acc: 68.75%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6720 - acc: 0.8438 - val_loss: 0.9936 - val_acc: 0.7513\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5133 - acc: 0.9062 - val_loss: 0.9535 - val_acc: 0.7586\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4895 - acc: 0.9062 - val_loss: 0.9184 - val_acc: 0.7683\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5111 - acc: 0.9375 - val_loss: 0.8877 - val_acc: 0.7784\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3217 - acc: 0.9688 - val_loss: 0.8726 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2917 - acc: 1.0000 - val_loss: 0.8662 - val_acc: 0.7804\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2544 - acc: 1.0000 - val_loss: 0.8672 - val_acc: 0.7786\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2561 - acc: 1.0000 - val_loss: 0.8718 - val_acc: 0.7785\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2393 - acc: 1.0000 - val_loss: 0.8800 - val_acc: 0.7760\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2481 - acc: 1.0000 - val_loss: 0.8901 - val_acc: 0.7734\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "39 [supervised loss: 0.2481, acc: 100.00%] [unsupervised loss: 2.5916, acc: 84.38%] [labeled consistency loss: 1.7481, acc:acc: 84.38%] [unlabeled consistency loss: 0.8435, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6245 - acc: 0.8750 - val_loss: 0.9083 - val_acc: 0.7657\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4102 - acc: 0.9375 - val_loss: 0.9056 - val_acc: 0.7659\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3980 - acc: 0.9062 - val_loss: 0.9023 - val_acc: 0.7644\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3856 - acc: 0.9375 - val_loss: 0.8994 - val_acc: 0.7673\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3477 - acc: 0.9375 - val_loss: 0.8971 - val_acc: 0.7680\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4416 - acc: 0.9688 - val_loss: 0.8998 - val_acc: 0.7648\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2584 - acc: 1.0000 - val_loss: 0.9072 - val_acc: 0.7632\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2584 - acc: 1.0000 - val_loss: 0.9171 - val_acc: 0.7619\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2889 - acc: 0.9688 - val_loss: 0.9290 - val_acc: 0.7600\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2442 - acc: 1.0000 - val_loss: 0.9402 - val_acc: 0.7584\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "40 [supervised loss: 0.2442, acc: 100.00%] [unsupervised loss: 1.9541, acc: 90.62%] [labeled consistency loss: 1.1113, acc:acc: 90.62%] [unlabeled consistency loss: 0.8428, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3500 - acc: 0.9688 - val_loss: 0.9409 - val_acc: 0.7597\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4626 - acc: 0.8750 - val_loss: 0.9382 - val_acc: 0.7607\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3714 - acc: 0.9375 - val_loss: 0.9323 - val_acc: 0.7611\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2789 - acc: 0.9688 - val_loss: 0.9253 - val_acc: 0.7624\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3036 - acc: 0.9688 - val_loss: 0.9200 - val_acc: 0.7644\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2954 - acc: 0.9688 - val_loss: 0.9149 - val_acc: 0.7658\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2762 - acc: 1.0000 - val_loss: 0.9111 - val_acc: 0.7685\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2506 - acc: 1.0000 - val_loss: 0.9074 - val_acc: 0.7688\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2647 - acc: 1.0000 - val_loss: 0.9025 - val_acc: 0.7694\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2444 - acc: 1.0000 - val_loss: 0.8977 - val_acc: 0.7709\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "41 [supervised loss: 0.2444, acc: 100.00%] [unsupervised loss: 1.5466, acc: 85.94%] [labeled consistency loss: 0.8221, acc:acc: 84.38%] [unlabeled consistency loss: 0.7245, acc: 87.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3686 - acc: 0.9688 - val_loss: 0.9001 - val_acc: 0.7702\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4216 - acc: 0.9062 - val_loss: 0.9025 - val_acc: 0.7701\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4036 - acc: 0.9375 - val_loss: 0.9073 - val_acc: 0.7696\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3509 - acc: 0.9688 - val_loss: 0.9131 - val_acc: 0.7683\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3393 - acc: 0.9688 - val_loss: 0.9180 - val_acc: 0.7676\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3517 - acc: 0.9688 - val_loss: 0.9232 - val_acc: 0.7660\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3091 - acc: 1.0000 - val_loss: 0.9297 - val_acc: 0.7636\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2738 - acc: 1.0000 - val_loss: 0.9400 - val_acc: 0.7624\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2405 - acc: 1.0000 - val_loss: 0.9509 - val_acc: 0.7612\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2269 - acc: 1.0000 - val_loss: 0.9631 - val_acc: 0.7593\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "42 [supervised loss: 0.2269, acc: 100.00%] [unsupervised loss: 1.8921, acc: 87.50%] [labeled consistency loss: 1.1383, acc:acc: 90.62%] [unlabeled consistency loss: 0.7538, acc: 84.38%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5358 - acc: 0.9062 - val_loss: 0.9990 - val_acc: 0.7536\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4580 - acc: 0.8750 - val_loss: 0.9988 - val_acc: 0.7538\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5705 - acc: 0.8750 - val_loss: 0.9965 - val_acc: 0.7545\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4569 - acc: 0.8750 - val_loss: 0.9935 - val_acc: 0.7553\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4224 - acc: 0.9375 - val_loss: 0.9886 - val_acc: 0.7580\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3393 - acc: 0.9375 - val_loss: 0.9845 - val_acc: 0.7584\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2984 - acc: 0.9688 - val_loss: 0.9810 - val_acc: 0.7604\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2682 - acc: 1.0000 - val_loss: 0.9800 - val_acc: 0.7627\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2627 - acc: 1.0000 - val_loss: 0.9796 - val_acc: 0.7638\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2314 - acc: 1.0000 - val_loss: 0.9808 - val_acc: 0.7630\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "43 [supervised loss: 0.2314, acc: 100.00%] [unsupervised loss: 2.1519, acc: 89.06%] [labeled consistency loss: 1.2983, acc:acc: 87.50%] [unlabeled consistency loss: 0.8535, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8227 - acc: 0.7812 - val_loss: 0.9881 - val_acc: 0.7630\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8723 - acc: 0.7500 - val_loss: 0.9863 - val_acc: 0.7616\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6147 - acc: 0.8750 - val_loss: 1.0014 - val_acc: 0.7554\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5214 - acc: 0.9375 - val_loss: 1.0376 - val_acc: 0.7470\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4728 - acc: 0.9375 - val_loss: 1.0886 - val_acc: 0.7340\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3640 - acc: 0.9688 - val_loss: 1.1538 - val_acc: 0.7183\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2657 - acc: 1.0000 - val_loss: 1.2232 - val_acc: 0.7033\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3106 - acc: 1.0000 - val_loss: 1.2909 - val_acc: 0.6898\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2741 - acc: 0.9688 - val_loss: 1.3528 - val_acc: 0.6780\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2730 - acc: 1.0000 - val_loss: 1.4078 - val_acc: 0.6678\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "44 [supervised loss: 0.2730, acc: 100.00%] [unsupervised loss: 3.4478, acc: 73.44%] [labeled consistency loss: 1.9075, acc:acc: 68.75%] [unlabeled consistency loss: 1.5402, acc: 78.12%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.9220 - acc: 0.7812 - val_loss: 1.5149 - val_acc: 0.6461\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8544 - acc: 0.8125 - val_loss: 1.4458 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5370 - acc: 0.8438 - val_loss: 1.3662 - val_acc: 0.6732\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5063 - acc: 0.9688 - val_loss: 1.2957 - val_acc: 0.6861\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4803 - acc: 0.9375 - val_loss: 1.2475 - val_acc: 0.6968\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3109 - acc: 1.0000 - val_loss: 1.2272 - val_acc: 0.7018\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2523 - acc: 1.0000 - val_loss: 1.2274 - val_acc: 0.7019\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2592 - acc: 1.0000 - val_loss: 1.2421 - val_acc: 0.7018\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2695 - acc: 1.0000 - val_loss: 1.2663 - val_acc: 0.6995\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2492 - acc: 1.0000 - val_loss: 1.2965 - val_acc: 0.6959\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "45 [supervised loss: 0.2492, acc: 100.00%] [unsupervised loss: 3.5308, acc: 75.00%] [labeled consistency loss: 2.4300, acc:acc: 75.00%] [unlabeled consistency loss: 1.1008, acc: 75.00%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.7833 - acc: 0.8125 - val_loss: 1.4118 - val_acc: 0.6721\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5814 - acc: 0.8125 - val_loss: 1.4421 - val_acc: 0.6684\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5155 - acc: 0.9062 - val_loss: 1.4562 - val_acc: 0.6659\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6519 - acc: 0.8750 - val_loss: 1.4535 - val_acc: 0.6687\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5082 - acc: 0.9062 - val_loss: 1.4481 - val_acc: 0.6704\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4366 - acc: 0.9375 - val_loss: 1.4477 - val_acc: 0.6701\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3002 - acc: 0.9688 - val_loss: 1.4621 - val_acc: 0.6669\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2816 - acc: 1.0000 - val_loss: 1.4821 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3074 - acc: 0.9688 - val_loss: 1.5068 - val_acc: 0.6589\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2808 - acc: 1.0000 - val_loss: 1.5317 - val_acc: 0.6553\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "46 [supervised loss: 0.2808, acc: 100.00%] [unsupervised loss: 2.7360, acc: 79.69%] [labeled consistency loss: 1.7494, acc:acc: 68.75%] [unlabeled consistency loss: 0.9866, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7585 - acc: 0.8750 - val_loss: 1.5623 - val_acc: 0.6504\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6739 - acc: 0.8438 - val_loss: 1.5715 - val_acc: 0.6506\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5202 - acc: 0.8750 - val_loss: 1.5846 - val_acc: 0.6500\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4526 - acc: 0.9375 - val_loss: 1.6064 - val_acc: 0.6476\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4265 - acc: 0.9375 - val_loss: 1.6235 - val_acc: 0.6450\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3634 - acc: 0.9688 - val_loss: 1.6444 - val_acc: 0.6410\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3322 - acc: 0.9688 - val_loss: 1.6660 - val_acc: 0.6375\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2759 - acc: 1.0000 - val_loss: 1.6852 - val_acc: 0.6333\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3034 - acc: 1.0000 - val_loss: 1.7029 - val_acc: 0.6304\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2388 - acc: 1.0000 - val_loss: 1.7211 - val_acc: 0.6265\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "47 [supervised loss: 0.2388, acc: 100.00%] [unsupervised loss: 2.8995, acc: 68.75%] [labeled consistency loss: 1.5443, acc:acc: 75.00%] [unlabeled consistency loss: 1.3552, acc: 62.50%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8608 - acc: 0.8125 - val_loss: 1.7715 - val_acc: 0.6194\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.8177 - acc: 0.8125 - val_loss: 1.7366 - val_acc: 0.6245\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6243 - acc: 0.8750 - val_loss: 1.6846 - val_acc: 0.6336\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6117 - acc: 0.8750 - val_loss: 1.6296 - val_acc: 0.6435\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4806 - acc: 0.9375 - val_loss: 1.5791 - val_acc: 0.6522\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4653 - acc: 0.9062 - val_loss: 1.5106 - val_acc: 0.6607\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3311 - acc: 0.9688 - val_loss: 1.4583 - val_acc: 0.6683\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3366 - acc: 0.9688 - val_loss: 1.4159 - val_acc: 0.6723\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2829 - acc: 0.9688 - val_loss: 1.3831 - val_acc: 0.6797\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2437 - acc: 1.0000 - val_loss: 1.3596 - val_acc: 0.6847\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "48 [supervised loss: 0.2437, acc: 100.00%] [unsupervised loss: 2.4258, acc: 82.81%] [labeled consistency loss: 1.5432, acc:acc: 75.00%] [unlabeled consistency loss: 0.8826, acc: 90.62%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.7678 - acc: 0.7500 - val_loss: 1.3997 - val_acc: 0.6776\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6453 - acc: 0.8125 - val_loss: 1.3686 - val_acc: 0.6833\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5375 - acc: 0.8750 - val_loss: 1.3298 - val_acc: 0.6909\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4744 - acc: 0.8438 - val_loss: 1.2860 - val_acc: 0.7029\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4006 - acc: 0.9688 - val_loss: 1.2446 - val_acc: 0.7124\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3371 - acc: 1.0000 - val_loss: 1.2091 - val_acc: 0.7184\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3605 - acc: 0.9688 - val_loss: 1.1793 - val_acc: 0.7259\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3045 - acc: 1.0000 - val_loss: 1.1577 - val_acc: 0.7332\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2759 - acc: 0.9688 - val_loss: 1.1467 - val_acc: 0.7348\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2756 - acc: 1.0000 - val_loss: 1.1430 - val_acc: 0.7355\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "49 [supervised loss: 0.2756, acc: 100.00%] [unsupervised loss: 2.6853, acc: 68.75%] [labeled consistency loss: 1.5684, acc:acc: 65.62%] [unlabeled consistency loss: 1.1169, acc: 71.88%]\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5341 - acc: 0.9062 - val_loss: 1.1586 - val_acc: 0.7273\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.87680\n",
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.5965 - acc: 0.8750 - val_loss: 1.1416 - val_acc: 0.7286\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.87680\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3493 - acc: 1.0000 - val_loss: 1.1326 - val_acc: 0.7279\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.87680\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.4723 - acc: 0.9375 - val_loss: 1.1201 - val_acc: 0.7303\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.87680\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3971 - acc: 0.9375 - val_loss: 1.1113 - val_acc: 0.7318\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.87680\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3275 - acc: 1.0000 - val_loss: 1.1105 - val_acc: 0.7305\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.87680\n",
            "Epoch 7/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2710 - acc: 1.0000 - val_loss: 1.1168 - val_acc: 0.7292\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87680\n",
            "Epoch 8/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2482 - acc: 1.0000 - val_loss: 1.1258 - val_acc: 0.7274\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87680\n",
            "Epoch 9/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2548 - acc: 1.0000 - val_loss: 1.1363 - val_acc: 0.7267\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87680\n",
            "Epoch 10/10\n",
            "Learning rate:  0.001\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2314 - acc: 1.0000 - val_loss: 1.1479 - val_acc: 0.7241\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.87680\n",
            "50 [supervised loss: 0.2314, acc: 100.00%] [unsupervised loss: 2.4065, acc: 79.69%] [labeled consistency loss: 1.4233, acc:acc: 84.38%] [unlabeled consistency loss: 0.9832, acc: 75.00%]\n",
            "Training time: 1695.3057s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ndAup4NMwkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "a381e832-f7a1-47a1-9f74-d7776856c765"
      },
      "source": [
        "plot_supervised_losses = np.array(supervised_losses)\n",
        "plot_unsupervised_losses = np.array(unsupervised_losses)\n",
        "plot_labeled_consistency_costs = np.array(labeled_consistency_costs)\n",
        "plot_unlabeled_consistency_costs = np.array(unlabeled_consistency_costs)\n",
        "plot_all_losses = np.array(supervised_losses)+np.array(unsupervised_losses)\n",
        "\n",
        "# Plot losses\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(iteration_checkpoints, plot_all_losses, label=\"All loss\", color='black')\n",
        "plt.plot(iteration_checkpoints, plot_supervised_losses, label=\"Supervised loss\", color='tab:blue')\n",
        "plt.plot(iteration_checkpoints, plot_unsupervised_losses, label=\"Unsupervised loss\", color='tab:green')\n",
        "plt.plot(iteration_checkpoints, plot_labeled_consistency_costs, label=\"Labeled consistency loss\", color='tab:red', linestyle='dashed')\n",
        "plt.plot(iteration_checkpoints, plot_unlabeled_consistency_costs, label=\"Unlabeled consistency loss\", color='tab:orange', linestyle='dashed')\n",
        "\n",
        "plt.xticks(iteration_checkpoints, rotation=90)\n",
        "\n",
        "plt.title(\"Mean Teacher's Supervised and Unsupervised Loss, num_labeled=%d\" % num_labeled)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29c6540d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFPCAYAAAAfjmxyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd1xWZf/A8c8FDsStuEdqbhABBQeI\nOzV83CtTM6tH6ynrsWWZaUMfTR8zrV9mjys1R0PNsDRz4l44cJOQK0UQBBFkXL8/zrnpZgrKDYjf\n9+vF6wVnXd9z7nNuzvdc4yitNUIIIYQQQgghHn52+R2AEEIIIYQQQojcIQmeEEIIIYQQQhQSkuAJ\nIYQQQgghRCEhCZ4QQgghhBBCFBKS4AkhhBBCCCFEISEJnhBCCCGEEEIUEpLgCSEKLaXUNKXU//I7\njoeFUmqLUmpwLm9zjFJqc25uM4uy9iqlhuVFWQWRUqqhUirSBtt9pI9rdimluiulzmdz2fu+LvJr\nXSHEw0MSPCEKKaVUiFLqrlLKKc30I0oprZSqk4exPK2UijF/7iilkq3+jsmrOB6UmTCOv4/1Biil\njimlbimlwpRSm5VSNW0R44PQWnfSWq/K7zhsQSm1Uin1XpppjZVSifkVU27TWp/VWpfLyzLlIcqj\nQSk1XSl1QimVlPY70ExsU32nWz8oUkpVUkqtV0rdVkpdUEoNSLP+M0qpP831vldKlc2r/RKisJIE\nT4jC7QLwlOUPpVQzwDGvg9BaL9dal9JalwJ6AFcsf5vTCjylVJH7XK8p8D/gZaAs8DgwH0jOveiy\nFcd9xS8KDvkMRT46A7wO/JbJ/D+sv9PTPCiaD9wEKgPPAQuVUg0AlFLuwBxgMFANUMBnNtoHIR4Z\nkuAJUbgtBUZY/f0M8I31Akqp4kqpmeYT1GtKqXlKqRLmvPJKqZ/NWqeb5u81rdbdppT6SCm1SykV\nrZTalLbGMLuUUrWUUuuUUjeUUn8opcZYzfNWSu1TSkUqpa4opT61vtlVSjU3mxfeVEr9pZR63WrT\nJZRSK8z4jiml3LJZ5jSl1LdKqVVKqWhgSJp4qyqlfjVjCldKbclk1zyA01rrHdpwS2u9Wmt9xdxO\nqpqltM28zP15Syl1WikVoZSar5QqbjW/r7lfkUqpnWZCab3uG0qpIOCWUmqSUmpZmv34Sin1ifl7\nSlM8s3YrQCkVZX7+31it42J1vE8ppfpYzauslNpg1lbuAR7L5LiglCqilPrBPO8ilVJblVKNrOav\nVErNVkptND+/XUqpx6zm+ymlzpnrzsqsnOwyj9e/lVFTEaWUWq6UKmbOy/DzVko5KKNG3Pq6SPlM\nLZ+nUuoD8/O7oJQaaLVsCXMfL5rlz7V8vlbrTlRKXQO+NM/TLlbrO5gxNVVpaiSVUi8ooyY/2lzP\nutzRSqkzZkz+SqkauX1clVLNzHMy0jxHe1jN622e09Hmvo/N6jhnoyzLsXrXPF8vK6Wetpqfqpmp\nsmqqaPUZjlFKBZvn7ntKqUZKqf1W50KOEmyl1Pvm5x1tnlN+aRaxU8b1d0spdVIp5Wu1bgWl1Dfm\nOXFRGdduhvdsKpeux6xorRdqrTcCOWpxoZQqD/wDmKi1vq213gJsBCyfzXDgB631Hq11NPA+MFgp\n5XA/cQohDJLgCVG47QXKKKWaKKXsMZKUZWmWmQY0BNyA+kANjH+yYHxHLMK4KagN3AE+T7P+UOBZ\njKezxYA3chqkGdsGYDdQHegOvKuUam8ukoBRA1YRaIdxw/C8uW55YDPwI1DV3JcdVpvvCywEygG/\nA7OzWSZAf2AJRs3bD1rr8Vrraea8tzGeajthPHmenMnuHQTclVIzlFIdlFIlc3JsTE8BnYBGgDvw\nprkPrYH/wzj+FTES+rVpbkQHA13N+SuA3urvBL4oMAD4NoMy/wOsxThutYGvzHXKYDzFX2Du+wiM\nJ/L1zfXmAxFAFeBFYNQ99m0dRq1mVeA0xvG2NhR4B6gAXAU+MOOoBqzGqFWoBIQBLe9RVnYMADpj\nXAutzPIh+593RupgXBtVgReAJUqpuua8WUBNoBnG59sQGJ9m3aJALWAssBKrWnnADwjRWp+0LtC8\nLmYAnbXWpQEf4IQ5bzDwGsZ1VAU4gvm9kFvH1bxB98c4hyphnLPfWe33QmCEGZsbsNOc/iDH+TGM\nGqDqGN8X85RSOWkh0BloDrQHJmHULA0E6gJeGN8HOXEGaIvx/TEdWKlSPwDzBY5iXJvTMK7dMua8\n5UAUUM8suw9GMpTKg16PZpIfmclPTpL7Wkqp6+aDhBmW7xigMRCttQ61WvYo4Gz+7mz+DYDWOggo\ngvGdIIS4T5LgCVH4WWrxugKngMuWGUopBfwT+LfWOsJ8gjoVs7ZKax2utf5Bax1rzpuCcfNjbZHZ\n9+cOxo2hGznnAzhoradrre9qrc9iJJaWOPZrrQ9orZO01sEYTR4tcfQBzmutP9dax5s1ZAestr1F\na/2b1jrJPBZu2SnTtF1rvUFrnWzun7UEjBvJ2ub6O8iA1vo0xo1jPeB74IZS6n9WN0DZ8ZnW+orW\nOgwj8bLc4I8GPtdaHzKPzXygONDCat1PzXXvmPt4BuPGHoyk9prWOjCDMhMwkouq5rq7zOl9gRNm\ns9sk81ivB/qbN/W9gPfMdQIxblQzpLVO1Fp/o7WO0VrHYSRvXmme3q/WWh/WWidgJKKWz+8fwAGt\n9U/mvE8wbmQf1Kda62vmsd5gVV62Pu9MJAIfmOttxnggMcBMxJ8DXtVaR2qtozBu9K3PwXjgI3Pd\nOxjHoJ8yaxYxEtCMEnQLF6WUg3kOnDKnjQE+Nq/bBIzj7qOUqkLuHdd2gAZmaa0TzNqf3zAeOAAk\nAc5KqdLm98wRc/qDHOdY4D9meWvM8uvfYx1r08xz8QhwFtigtQ7VWkcAmzAermSb1nqV1vqq+f2x\nFOO71/ravKi1/j8z3m+AS0A3ZdRS+wLjzO/eqxjJ5pB0hTzg9ai1bqS1LpfJz7hs7uoxjMS4KvAE\nxner5UFYKYxE1VoUUDqL+bes5gsh7oMkeEIUfksxbgJHkqZ5JsaTdUfgkOWpLfCrOR2llKPZhChU\nKXULo2asnFn7ZfGX1e+xGP+wc+oxoI7102NgHMYNA8pofvaLMpry3cKoYbQ8Ca8FBGex7cziy7JM\n08UstjsFuAJsNZuGZXozpLUO0Fr311o7YdTEdQPeymLbaVnHEYpxA2zZh3fT7EMljFrYzPbhW/5O\nEIeSeQL2b4xz44gymtdZmrc9BvimKbM/Rm1LVYwalLTxZkgZTTT/az71v4VRg6cwajQsMvv8qluX\nYybwl8lcIkZNmLWiGAmFtczKy/bnnYEwM4G1sHyG1c0YgqyO5VqM2vCUeMxECwCt9QmM/e5h1t70\nwKiZTUVrfROjGdxY4C+l1E9WtTqPYdRuWcoMwzg+Ncn5cc1MdeBPrbVOs9+Wc7M3xnnzp9m80NOc\n/qDH2bpva06/j65Z/X4ng79z9N2mlHpO/d18OhIj2bSuwbuUZhXLefEY4ACEWa37GUYtXFq5dj3e\nL/PhwWkzkT2PUeNuGUglBiiTZpUyQHQW80tbzRdC3AdJ8IQo5MymMReAJzGaMVq7gXHj4mz11Las\n/nvgk9cxmo210lqXwXiqDMZNQ266iNFPzfrpcWmtdV9z/tfAYeBxM44PrWK4yP0157lXmWDUAGRI\nax2ltX5Va/0Yxg3Ve0op73sVqrXeg9Es0cWcdJvUA99UTbeSkcRa1Ma4Abbsw/tp9sFRa239Oafd\nh1UYtQQ1MGprMqz90Vpf1lqPwrhRHIvR7Ku2WeamNGWW0lq/hpEc6QzizcyzGDXLHTGasTU2p2fn\n/LpqXY7ZP6lG5ovzJ0aNpLW6ZPOGN4vP+y5GkpjVZ+iUplbS8hlexUisHk9z/VknuBmdgyswkvT+\nGLVtGT6I0Fr7a607YyZbwJfmrIvAyDSfYQmt9SFyflwzc4X0n31tzGRRG32uemIkLZswz8P7va6y\nITvXWa5RSjUE5mK0kKigjdFNz5P63E47kq7lvLiIkfiUt/p8ymitPTIo6oGuR2X0OYzJ5Gf2fe6+\nttrP0xjdBKzLbQ4Emb8HmX9b4mmKUbub1UM7IcQ9SIInxKPhOaCT1vq29UTzaffXwKdKqcoASqka\nSqlu5iKlMRLASKVUBYx+KbYQYJb9mjIGPCiilHJVSlluaEoDUVrrGKWUM0Y/Jou1QH2l1ItKqWJK\nqTJWtQEPUmaWlFK9lFL1zGauURg3JelGxlRKdVRKjVJKWWpFnTH6Te01FwkEeiqlyplJ1ysZFDdW\nKVVNGf13xmMkaWD0r3lFKdVSGUqZcWU6UqrW+jKwD1gMHNdaX8hk/wYrpaqbNTCWd6slYRxvd3N+\nUfOYt1ZKNTRrqdYDHyhj8BBX/h5MISOlgTggHCgJfJzFsmn9BHgqpXoqoy/hmxj99DLzHUbTxk5K\nKTulVC3gXYw+bfeU2edtXkPHgaeVUvZKqV5AmzSrFwUmmseqE0ZS+4NZM7cQ+Ewp5WR+hrWUUl3v\nEc4KoCdGP9QME3TzOvYzz4V4jITBcn7Ow0icGpnLlldKWfqX5fS4Atib15DlpxhGnzo78/oqYu7T\nE8BqpVRJpdQQswYyAaO2JtmMJdPrShmD18y7RyyZCcRoFuuglGqM0aLBlkphxB2GcRzGkL65aC1l\nDOxSRBk15LUwkrULGN8PnyilSpvnawOllE8G5TzQ9ai1flynHv3S+uc1y3Lmth0w7huLmMfRzpzX\nSZmDDCmjeelUjIdYlprkn4EPldEipANG03BLy4FlGM1JWymjv+QHwKo0Nd5CiBySBE+IR4DWOlhr\nfTCT2W9jPFneq4xmcpsxau3AGJCkBEZN316M5pu2iC8Bo4axLUaNShhGbYOlJvHfwPPKeGfeF/yd\n4FhuILpi9E+5jtHHLKMboZyWeS9NgK0YN6c7gJlm7VxaNzGaKwWZ8a/HuLmxPB1fiHH8/8S4EUrX\n3A4jCdkKnMNIJj4x92EXRu3aVxhJ2FmMZpeZ1jyavgW6kHXfrTYYTXdjMJKjf5q1ejcxmpg+i1Hb\ncwUjMbM0fxyNUStzzYxrURZlLMA47n+Z+xVwj7hTmP2ShmAcxzCzzMzOcbTRr+oZjEFNIjESkK0Y\nfRqzI6vP+2WMvmU3MfqE/pxm3RCMmrq/MD7vZ7XWf5jzXsM4hgcxEppfuUe/Ma11CMbAFJ4Yn01G\n7DEeBvyFkUB7mnGitV6BMVjSj+Y1H4hxDeX4uJpGYjwIsvycNG/Qe2Kc++EYx32w1X6PwrjuojD6\nCFtG+83qONcCLH1Bc+oTjME7wjAejKQdbCpXaa0PYyTSBzGuk7qkP447MPr1RQATgH7a6IcJRg1t\nOYwasAiM77x0TTRz+XrMylKMz7Yv8JH5+yBzXitgv1IqFuO62kfqwbZewGiaegPjwdJzWutzZvyH\nMa6BH8wY7YBX7zNGIYRJpW4eL4QQoiBRSv0FDNBaZzv5EQWHUqo7xkA4ORnsQ6Rh1kQeAFzNfoFC\nCCEyIS9NFUIIIUSBprWO5e+h9YUQQmRBmmgKIYQQQmSDMl5Yn9GAJGvyOzYhhLCQJppCCCGEEEII\nUUhIDZ4QQgghhBBCFBIPXR88JycnXadOnfwOQwghhBBCCCHyxaFDh25orStlNO+hS/Dq1KnDwYP3\nGrFZCCGEEEIIIQonpVRoZvOkiaYQQgghhBBCFBKS4AkhhBBCCCFEISEJnhBCCCGEEEIUEg9dH7yM\nJCQkcOnSJeLi4vI7FCEy5eDgQM2aNSlatGh+hyKEEEIIIQqpQpHgXbp0idKlS1OnTh2UUvkdjhDp\naK0JDw/n0qVL1K1bN7/DEUIIIYQQhVShaKIZFxdHxYoVJbkTBZZSiooVK0otsxBCCCGEsKlCkeAB\nktyJAk/OUSGEEEIIYWuFJsETQgghhBBCiEedJHi5aO3atSilOH36dMq0kJAQXFxcANi2bRs9e/ZM\nt15m04UQQgghhBAiJyTBy0UrVqzAx8eHFStW5HcoQgghhBBCAH8P9iYeDZLg5ZKYmBgCAgJYsGAB\nK1euvO/tRERE0KdPH1xdXWndujXHjh0DYPv27bi5ueHm5oa7uzvR0dFcvXoVX19f3NzccHFxYefO\nnbm1O0IIIYQQ4iF28eJFFi9ezLBhw6hevTpOTk7s3r07v8MSeaBQvCbB2muvvUZgYGCubtPNzY3Z\ns2dnucy6devo3r07DRs2pGLFihw6dIgWLVrkuKxJkybh7u7O2rVr2bJlCyNGjCAwMJCZM2fyxRdf\n4O3tTUxMDA4ODsyfP59u3boxYcIEkpKSiI2Nvd9dFEIIIYQQD7GbN2+ybds2Nm/ezObNmzl79iwA\nlStXpnPnzvz44498//33tG3bNp8jFbZW6BK8/LJixQpeffVVAIYMGcKKFSvuK8ELCAjghx9+AKBT\np06Eh4dz69YtvL29GTduHE8//TT9+vWjZs2aeHp6MmrUKBISEujTpw9ubm65uk9CCCGEEKJgiouL\nY/fu3fz+++9s3ryZgwcPkpycTMmSJWnfvj1jxoyhS5cuuLi4oJSie/fu+Pv7M2vWrPwOXdhYoUvw\n7lXTZgsRERFs2bKF48ePo5QiKSkJpRQzZszItTLGjx+Pn58fGzZswNvbm40bN+Lr68uOHTvw9/dn\n5MiRjBs3jhEjRuRamUIIIYQQomBITk4mMDAwpYZu586dxMXFYW9vT+vWrZk4cSKdO3emVatWFCtW\nLN36fn5+jB07lvPnz1O/fv182AORV6QPXi74/vvvGT58OKGhoYSEhHDx4kXq1q17X33i2rVrx/Ll\nywFjdE0nJyfKlClDcHAwzZo14+2338bT05PTp08TGhpKlSpVeOGFF3j++ec5fPhwbu+aEEIIIYQo\nAJ566ilatGjB22+/zZUrVxg9ejTr168nIiKCgIAAJk+eTLt27TJM7sBI8AD8/f3zMmyRDyTBywUr\nVqygb9++qab179//vkbTnDx5MocOHcLV1ZXx48ezZMkSwKiZdHFxwdXVlaJFi9KjRw+2bdtG8+bN\ncXd3Z9WqVSlNRIUQQgghROGydetW/Pz8uHLlCidOnGD27Nn07NmTMmXKZGv9evXq0bhxY0nwHgFK\na53fMeRIy5Yt9cGDB1NNO3XqFE2aNMmniITIPjlXhRBCCJFTYWFhVK5cmf/+97+MGzfuvrfzxhtv\nMHfuXMLDwylVqlQuRijymlLqkNa6ZUbzpAZPCCGEEEKIAuzkyZMAODs7P9B2/Pz8uHv3Lps3b86N\nsEQBJQmeEEIIIYQQBVhQUBDw4Amej48PZcqUkWaahZwkeEIIIYQQQhRgQUFBlClThho1ajzQdooW\nLcoTTzzBhg0beNi6aYnskwRPCCGEEEKIAiwoKAhnZ2eUUg+8LctALYGBgbkQmSiIJMETQgghhBCi\nADt58iRNmzbNlW316NEDkNclFGaS4AkhhBBCCFFAhYWFERYW9sD97yyqVKmCp6enJHiFmCR4uWTK\nlCk4Ozvj6uqKm5sb+/bty7dY2rZt+8Db2LZtGz179sz2dCGEEEIIkftya4AVa35+fuzbt4+wsLBc\n26YoOCTBywV79uzh559/5vDhwxw7dozNmzdTq1Ytm5WntSY5OTnT+bt377ZZ2UIIIYQQIu/YKsHT\nWvPrr7/m2jZFwSEJXi64evUqTk5OFC9eHAAnJyeqV68OQJ06dbhx4wYABw8epEOHDgBMnjyZ4cOH\n06ZNGxo0aMDXX3+dsr0ZM2bg6emJq6srkyZNAiAkJIRGjRoxYsQIXFxc+Oijj3jzzTdT1lm8eDEv\nv/wyQMqLK69evYqvry9ubm64uLiwc+dOADZt2kSbNm3w8PBg4MCBxMTEAPDrr7/SuHFjPDw8+PHH\nH++53xEREfTp0wdXV1dat27NsWPHANi+fTtubm64ubnh7u5OdHR0prEIIYQQQojMBQUFUbZs2ZR7\ny9zg4eFBlSpVpJlmIVUkvwPIbR+sD+LklVu5us2m1csw6R+ZPzV54okn+PDDD2nYsCFdunRh8ODB\ntG/f/p7bPXbsGHv37uX27du4u7vj5+fHiRMnOHfuHPv370drTa9evdixYwe1a9fm3LlzLFmyhNat\nWxMWFkabNm2YMWMGAKtWrWLChAmptv/tt9/SrVs3JkyYQFJSErGxsdy4cYOPP/6YzZs3U7JkSaZP\nn86sWbN46623eOGFF9iyZQv169dn8ODB94x/0qRJuLu7s3btWrZs2cKIESMIDAxk5syZfPHFF3h7\nexMTE4ODgwPz589PF4sQQgghhMiaZYCV3BhB08LOzo4nn3ySNWvWkJiYSJEihS4leKTZrAZPKeWg\nlNqvlDqqlApSSn2QwTIjlVJhSqlA8+d5W8VjS6VKleLQoUPMnz+fSpUqMXjwYBYvXnzP9Xr37k2J\nEiVwcnKiY8eO7N+/n02bNrFp0ybc3d3x8PDg9OnTnDt3DoDHHnuM1q1bA1CpUiXq1avH3r17CQ8P\n5/Tp03h7e6favqenJ4sWLWLy5MkcP36c0qVLs3fvXk6ePIm3tzdubm4sWbKE0NBQTp8+Td26dWnQ\noAFKKYYNG3bP+AMCAhg+fDgAnTp1Ijw8nFu3buHt7c24ceOYM2cOkZGRFClSJMNYhBBCCCFE1iyv\nSLhfIVEhzDk8h5G/juRqzNWU6X5+fkRGRkrXnkLIlul6PNBJax2jlCoKBCilftFa702z3Cqt9cu5\nVWhWNW22ZG9vT4cOHejQoQPNmjVjyZIljBw5kiJFiqT0l4uLi0u1TtonMUoptNa88847jB49OtW8\nkJAQSpYsmWrakCFDWL16NY0bN6Zv377ptufr68uOHTvw9/dn5MiRjBs3jvLly9O1a1dWrFiRatnc\nfBfK+PHj8fPzY8OGDXh7e7Nx48YMYxkxYkSulSmEEEIIUdhcv36dGzdu5DjBi4qPYmPIRtYFr+NY\n2DHslB3JOplfQ37lWZdnAejatStFixbF398fX19fW4Qv8onNavC0Icb8s6j5o21VXn46c+ZMSi0b\nGMnSY489Bhh98A4dOgTADz/8kGq9devWERcXR3h4ONu2bcPT05Nu3bqxcOHClH5xly9f5vr16xmW\n27dvX9atW8eKFSsYMmRIuvmhoaFUqVKFF154geeff57Dhw/TunVrdu3axfnz5wG4ffs2Z8+epXHj\nxoSEhBAcHAyQLgHMSLt27Vi+fDlgjK7p5OREmTJlCA4OplmzZrz99tt4enpy+vTpDGMRQgghhBCZ\ny8kAK4nJiey4tIPXt71Op9Wd+GjvR8QmxPJ6i9fZPGAz9cvVZ9flXSnLlylThnbt2kk/vELIpg1u\nlVL2wCGgPvCF1jqjdwf0V0r5AmeBf2utL2awnX8C/wSoXbu2DSO+PzExMbzyyispzRHr16/P/Pnz\nAaOf2nPPPcfEiRNTBlixcHV1pWPHjty4cYOJEydSvXp1qlevzqlTp2jTpg1gNP9ctmwZ9vb26cot\nX748TZo04eTJk3h5eaWbv23bNmbMmEHRokUpVaoU33zzDZUqVWLx4sU89dRTxMfHA/Dxxx/TsGFD\n5s+fj5+fH46OjrRr147o6Ogs93vy5MmMGjUKV1dXHB0dWbJkCQCzZ89m69at2NnZ4ezsTI8ePVi5\ncmW6WIQQQgghROayk+CdvXmWn87/hP8Ff27cuUG54uUY0HAAvev3pkmFJiktvHxq+LDs1DJiE2Jx\nLOoIGM00X3/9dUJDQ1MqJ8TDT2lt+0o1pVQ5YA3witb6hNX0ikCM1jpeKTUaGKy17pTVtlq2bKkP\nHjyYatqpU6do0qSJDSK3ncmTJ1OqVCneeOON/A5F5KGH8VwVQgghRP546aWXWLFiBREREam64kTE\nRbDhjw38FPwTpyJOUUQVwbemL73q98K3hi9F7Yum29beq3t5YdMLzO00lw61OgBGK7TGjRvzxRdf\n8NJLL+XVbolcoJQ6pLVumdG8PBkyR2sdqZTaCnQHTlhND7da7H/AJ3kRjxBCCCGEEAVdUFBQygia\nCUkJbL+0nXXB6wi4FECiTqRpxaaM9xrPk3WfpLxD+Sy35VHZgxJFShBwOSAlwWvYsCGPP/44/v7+\nkuAVIjZL8JRSlYAEM7krAXQFpqdZpprW2jKcTy/glK3iKWgmT56c3yEIIYQQQogCSmtNUFAQ/fr1\nA2BCwAR+CfkFpxJODGs6jF6P96JB+QbZ3l4x+2J4VfUi4HIAWmuUUiil8PPzY/78+cTGxuLo6Gir\n3RF5yJYvOq8GbFVKHQMOAL9prX9WSn2olOplLjPWfIXCUWAsMNKG8QghhBCiEDpz5gyJiYn5HYYQ\nuer69euEh4fj7OyM1prdV3fTvU53fhvwG6+3fD1HyZ2Fdw1vLsdc5s/oP1Om+fn5ERcXx9atW3Mz\nfJGPbDmK5jGttbvW2lVr7aK1/tCc/r7W+ifz93e01s5a6+Za645a69O2ikcIIYQQhc+BAwdo0qRJ\ntt4/K8TDxHqAlRt3bhAVH4VbZTeK2N1/Azyf6j4ABFwOSJnWvn17SpYsKaNpFiK2rMETQgghhLCp\njz/+GK01mzdvzu9QhMhVJ0+eBIwE71yk8TquBuVyXmtnrVaZWtQuXTvV6xKKFy9Oly5d8Pf3Jy8G\nXxS2JwmeEEIIIR5Kx48f56effqJ48eLs2LFDbk5FoRIUFES5cuWoWrUq528a7y+uX77+A2/Xu4Y3\nB/46QHxSfMo0Pz8//vzzz5RaQ/FwkwQvF4SEhODi4pJq2uTJk5k5c2Y+RZQzBw8eZOzYsQ+8ncz2\n+WE6FkJkZOPGjdy4cSO/wxBCpDF16lRKlSrF+++/z9WrVwkODs7vkITINUFBQTg7O6OU4nzkeSo4\nVKCCQ4UH3q5PDR/ikuI4dO1QyrQnn3wSQJppFhKS4D0isup83rJlS+bMmZOH0Qjx8Dh27Bjdu3en\nZ8+e3L17N7/DEUKYzp49y6pVq/jXv/5Fnz59ANixY0c+RyVE7rCMoGl5wfm5m+ceuHmmRcsqLSlq\nVzRVM80aNWrg5uYmCV4hIQleHujQoQNvv/02Xl5eNGzYkJ07dwLGkxkvLy/c3NxwdXXl3Llz6WoD\nZ86cmfJKhQ4dOvDqq6/i5pJBacAAACAASURBVOaGi4sL+/fvB+D27duMGjUKLy8v3N3dWbduHQCL\nFy+mV69edOrUic6dOzNkyJBUF+7IkSP5/vvv2bZtGz179gRg+/btuLm54ebmhru7O9HR0QDMmDED\nT09PXF1dmTRpUso2pkyZQsOGDfHx8eHMmTP3PBaBgYG0bt0aV1dX+vbty82bNwGYM2cOTZs2xdXV\nlSFDhmQZixB5acGCBdjb27Nv3z7efPPN/A5HCGGaNm0axYsX59///jdNmjTByclJEjxRaFy7do2I\niAicnZ1J1skERwXnSvNMAMeijrSo0iJVggdGM83du3en3JuJh1eevOg8L03fP53TEbk7GGfjCo15\n2+vtB9pGYmIi+/fvZ8OGDXzwwQds3ryZefPm8eqrr/L0009z9+5dkpKSuHbtWpbbiY2NJTAwkB07\ndjBq1ChOnDjBlClT6NSpEwsXLiQyMhIvLy+6dOkCwOHDhzl27BgVKlRgzZo1rF69Gj8/P+7evcvv\nv//Ol19+yb59+1K2P3PmTL744gu8vb2JiYnBwcGBTZs2ce7cOfbv34/Wml69erFjxw5KlizJypUr\nCQwMJDExEQ8PD1q0aJFl/CNGjGDu3Lm0b9+e999/nw8++IDZs2czbdo0Lly4QPHixYmMjMw0FiHy\nUnx8PMuWLWPAgAFUq1aN2bNn4+Pjw8CBA/M7NCEeaaGhoSxdupQXX3yRKlWqANCuXTtJ8EShYT2C\n5uWYy9xJvJNrNXhgNNOceXAmV2OuUq1UNcBI8KZMmcLGjRtTHraLh5PU4OUCpdQ9p1teUtmiRQtC\nQkIAaNOmDVOnTmX69OmEhoZSokSJe5b11FNPAeDr68utW7eIjIxk06ZNTJs2DTc3Nzp06EBcXBx/\n/mm836Rr165UqGC01+7Rowdbt24lPj6eX375BV9f33Rlent7M27cOObMmUNkZCRFihRh06ZNbNq0\nCXd3dzw8PDh9+jTnzp1j586d9O3bF0dHR8qUKUOvXr3ISlRUFJGRkbRv3x6AZ555JuWfsaurK08/\n/TTLli2jSJEimcYiRF5au3YtERERjBo1iunTp9O6dWtGjRqVrdpqIYTtzJgxA6VUqlr19u3bc+HC\nBS5evJiPkQmROywjaDZt2jRXB1ix8KlhvC5h15W/a/G8vLxwcnKSZpqFQKG7Y37Qmrb7UbFixXTV\n2REREdStWzfl7+LFiwNgb2+f0h9u6NChtGrVCn9/f5588km++uorGjZsSHJycsp6cXFxqbabNplU\nSqG15ocffqBRo0ap5u3bt4+SJUum/O3g4ECHDh3YuHEjq1atyvDpzPjx4/Hz82PDhg14e3uzceNG\ntNa88847jB49OtWys2fPvuexyS5/f3927NjB+vXrmTJlCsePH88wlsaNG+damULcy8KFC6lduzZd\nunTBzs6O1atX4+7uzoABA9i3bx+Ojo75HaIQj5yrV6/yv//9j2eeeYZatWqlTPf19QVg586dDB06\nNL/CEyJXBAUFUb58eapWrcrPx38G4PGyj+fa9uuVrUfVklXZdXkXAxoOAIx71O7du/PLL7+QlJSE\nvb19rpUn8pbU4OWCUqVKUa1aNbZs2QIYyd2vv/6Kj49Pluv98ccf1KtXj7Fjx9K7d2+OHTtGlSpV\nuH79OuHh4cTHx/Pzzz+nWmfVqlUABAQEULZsWcqWLUu3bt2YO3duyvDQR44cybTMwYMHs2jRInbu\n3En37t3TzQ8ODqZZs2a8/fbbeHp6cvr0abp168bChQuJiYkB4PLly1y/fh1fX1/Wrl3LnTt3iI6O\nZv369Vnub9myZSlfvnxKH8SlS5fSvn17kpOTuXjxIh07dmT69OlERUURExOTYSxC5JXQ0FB+++03\nnn32WezsjK/KWrVqsXz5coKCgnjppZdkSHYh8sGsWbNISEjg7bdTP9B1dXWlTJky0kxTFArWI2ie\nizxH9ZLVKVWsVK5tXymFd3Vv9l7dS0JyQsp0Pz8/wsPDU8Z5EA+nQleDl1+++eYb/vWvfzFu3DgA\nJk2axOOPZ/2kZfXq1SxdupSiRYtStWpV3n33XYoWLcr777+Pl5cXNWrUSFdj5eDggLu7OwkJCSxc\nuBCAiRMn8tprr+Hq6kpycjJ169ZNlxhaPPHEEwwfPpzevXtTrFixdPNnz57N1q1bsbOzw9nZmR49\nelC8eHFOnTpFmzZtACOhXbZsGR4eHgwePJjmzZtTuXJlPD0973mclixZwpgxY4iNjaVevXosWrSI\npKQkhg0bRlRUFFprxo4dS7ly5Zg4cWK6WITIK4sXLwbg2WefTTW9W7duTJw4kQ8//JB27drx3HPP\n5UN0QjyawsPD+fLLLxkyZAj166durmZvb4+Pj48keOKhZxlBc9CgQYAxgmZuNs+08Knhww/nfuBY\n2DFaVDHGUOjWrRv29vb4+/un3PeJh4962J5At2zZUh88eDDVtFOnTtGkSZN8iijvdOjQgZkzZ9Ky\nZcv8DkXcp0flXH3YJScnU69ePRo2bMimTZvSzU9KSqJ79+4EBASwZ88e3Nzc8iFKIR4977//Ph99\n9BEnTpxIGT7e2vTp0xk/fjzXrl2jcuXK+RChEA/u6tWrVK9enTlz5jDmpTF4LffiGedneK3Fa7la\nTvTdaNqtbMcol1GM9fj7fci+vr5ER0dn2SJM5D+l1CGtdYZJgTTRFEKINH7//XdCQ0MzrZ2zt7dn\n+fLlVKhQgQEDBhAVFZXHEQrx6Ll16xZz586lb9++GSZ38Hc/vICAgLwMTYhcZT3ASuitUBJ1ok1q\n8EoXK03zSs0JuJz6evHz8yMwMJDLly/nepkib0iC9xDZtm2b1N4JkQcWLlxI+fLl6d27d6bLVK5c\nmVWrVhESEsKoUaOkP54QNvZ///d/REZGMmHChEyXadGiBSVKlJBmmuKhZv2KhPORxgiaufmKBGs+\nNXw4FXGKG3dupEzz8/MDYMOGDTYpU9ieJHhCCGElIiKCNWvWMGzYsHu+e9HHx4fp06fz448/5uqo\nskKI1GJjY5k1axbdu3fP8n2rxYoVo02bNpLgiYdaUFAQFSpUoEqVKpyLPIe9sqdO2To2Kcu7hjcA\ne67sSZnm7OxM7dq15XUJDzFJ8IQQwsry5cuJj4/P9uAp48aNo0+fPrz11lvs3r3bxtEJ8Wj6+uuv\nCQsLy7L2zsLX15fAwEBpOi0eWtYjaJ6/eZ7aZWpT3L64TcpqXKExFRwqpGqmqZTCz8+PzZs3Ex8f\nb5NyhW1JgieEECatNQsWLKBFixY0b948W+sopVi0aBG1a9dm0KBBhIWF2ThKITKmtWbXrl2p3qVa\nGMTHxzNjxgx8fX0zff1QXGJcSjNpX1/flGMhxMPGMoKmpZ/puchz1C+X+/3vLOyUHd7Vvdl9ZTdJ\nyUkp0/38/Lh9+zbbt2+3WdnCdiTBE0II0+HDhzl69GiOX31Qrlw5vv/+e27cuMGwYcNISkq690pC\n5LL169fj4+PDp59+mt+h5KolS5Zw+fJl3nvvvQznX4q+hO8qX37/83cAWrVqRdGiRaWZpngo/fXX\nX0RGRtK0aVNiE2K5FH2JBuVt0//OwruGN5HxkZyKOJUyrWPHjjg4OEgzzYeUJHi5pFSp7L98cvLk\nycycOdNm27/fMh7UTz/9xLRp0zKdHxgYmG8ddhcvXszLL7+cL2WLh8eCBQtwcHDgqaeeyvG67u7u\nzJ07l02bNvHxxx/bIDqRV7788kuWL1+e32Hk2KJFiwDjPawXL17M52hyR2JiItOnT8fT05MuXbpk\nuMzqs6u5k3iHHZeMhM7R0RFPT09J8MRDyXqAlQtRF9Bomw2wYtGmehsUKlUzTUdHRzp16oS/v78M\nIvYQkgRP5JpevXoxfvz4TOfnZ4InxL3cuXOHb7/9lv79+1OuXLn72sbzzz/P8OHD+eCDD/jtt99y\nOUKRF5KTk5kwYQIjR44k7TtXC7KwsDB+/vlnBg0aRHJyMq+9lrvvy8ovK1eu5I8//mDChAkopdLN\nj0+KZ825NQAcvn44Zbqvry8HDhwgNjY2z2IVIjdYJ3jnIs8B2LSJJkAFhwo4V3Rm1+XUzZr9/PwI\nDg7m7NmzD7T94OBgPvjgA8LDwx9oOyL7JMGzofXr19OqVSvc3d3p0qUL165dS5l39OhR2rRpQ4MG\nDfj6669Tps+YMQNPT09cXV2ZNGlShtvNbJkpU6bQsGFDfHx8OHPmTIbrXrt2jb59+9K8eXOaN2+e\nMijErFmzcHFxwcXFJWU0wJCQEJo0acILL7yAs7MzTzzxBHfu3AFgzpw5NG3aFFdXV4YMGQKkriX7\n7rvvcHFxoXnz5vj6+nL37l3ef/99Vq1ahZubG6tWreL27duMGjUKLy8v3N3dWbduXcp2+vXrR/fu\n3WnQoAFvvfVWSvy//vorHh4eNG/enM6dO5OcnEyDBg1S+j0lJydTv379LPtBhYSE0KlTJ1xdXenc\nuTN//vlnhjGD8UXr5eWFm5sbrq6unDt3LtPtiofbjz/+SFRUVI6bZ1pTSvHll1/StGlThg4dyqVL\nl3IxQpEXzp07x82bN0lKSmLo0KHExMTkd0jZ8u2335KYmMj777/PxIkT+fHHHx/6plXJyclMnTqV\nZs2a8Y9//CPDZTaGbCQyPhKfGj6E3gpNGerd19eXxMRE9u7dm5chC/HAgoKCqFixIpUrV+b8zfMU\nsytGrdK1bF6udw1vjt04RlT834MTWV6XcL/fJWFhYYwdO5YmTZowefJkad2Sl7TWD9VPixYtdFon\nT55M9XfIsOHpfsKXL9daa50UG5vh/Js//Ki11johIiLdvOwoWbJkumkRERE6OTlZa631119/rceN\nG6e11nrSpEna1dVVx8bG6rCwMF2zZk19+fJlvXHjRv3CCy/o5ORknZSUpP38/PT27dtTbT+zZQ4e\nPKhdXFz07du3dVRUlH788cf1jBkz0sU0aNAg/emnn2qttU5MTNSRkZEp68bExOjo6GjdtGlTffjw\nYX3hwgVtb2+vjxw5orXWeuDAgXrp0qVaa62rVaum4+LitNZa37x5U2ut9aJFi/S//vUvrbXWLi4u\n+tKlS5nO11rrd955J2V7N2/e1A0aNNAxMTF60aJFum7dujoyMlLfuXNH165dW//555/6+vXrumbN\nmvqPP/7QWmsdHh6utdZ68uTJKfu0ceNG3a9fv3T7bV12z5499eLFi7XWWi9YsED37t0705hffvll\nvWzZMq211vHx8To2NjbdtnMi7bkqCo6OHTvqevXq6aSkpAfe1qlTp3SpUqV027Zt9d27d3MhOpFX\nFi9erAH95ZdfaqWUfvbZZ/M7pGxxc3PTnp6eWmvju6pJkya6Tp06+vbt2/kc2f37/vvvNaBXrFiR\n6TJP/fyU/seaf+gj145ol8UuelPIJq211pGRkdrOzk5PmjQpj6K9P1euXNG//fZbfochCpC2bdtq\nX19frbXW/9z0Tz3wp4F5Uq7lGvr1wq+ppjs7O+tOnTrlaFsxMTH6o48+0qVLl9b29vZ69OjRum/f\nvtrR0VFfv349N8N+pAEHdSb5ktTg2dClS5fo1q0bzZo1Y8aMGSnV7gC9e/emRIkSODk50bFjR/bv\n38+mTZvYtGkT7u7ueHh4cPr06XQ1Rpkts3PnTvr27YujoyNlypShV69eGca0ZcsWXnzxRQDs7e0p\nW7YsAQEB9O3bl5IlS1KqVCn69evHzp07Aahbty5ubm6A8QLZkJAQAFxdXXn66adZtmwZRYoUSVeO\nt7c3I0eO5Ouvv850wIlNmzYxbdo03Nzc6NChA3FxcSm1aZ07d6Zs2bI4ODjQtGlTQkND2bt3L76+\nvtStWxeAChUqADBq1Ci++eYbwHhB9bPPPpvl57Jnzx6GDh0KwPDhwwkICMg05jZt2jB16lSmT59O\naGgoJUqUyHLb4uEUHBzM1q1bGTVqFHZ2D/612LhxY77++mt2796dZbNlUfDs2bOHMmXK8M9//pMJ\nEyawaNEiVq1ald9hZSkwMJDAwEBGjhwJGO+C+/LLLwkJCWHKlCn5G9x90lozZcoUGjRowMCBAzNc\nJuhGEMdvHGdwo8E4V3TGwd6Bw9eMZpply5bFzc2twPfD++ijj+jevTu3b9/O71BEAaC15uTJkzRt\n2hSA8zfP23yAFQsXJxdKFyudYTPNHTt2cOvWrXtuIzExkfnz59OgQQMmTpxIly5dOHHiBPPmzWPK\nlCncuXOHOXPm2GoXhJX0d+aFwGNLv8l0nl2JElnOL1K+fJbzc+KVV15h3Lhx9OrVi23btjF58uSU\neWn7Eiil0FrzzjvvMHr06Ey3mdkytnrJcvHif793xd7ePqWJpr+/Pzt27GD9+vVMmTKF48ePp1pv\n3rx57Nu3D39/f1q0aMGhQ4fSbVtrzQ8//ECjRo1STd+3b1+6chMTEzONsVatWlSpUoUtW7awf//+\n+x4cIaOYhw4dSqtWrfD39+fJJ5/kq6++olOnTve1fVFwLVq0CDs7O5555pkM5x/86yANyjegbPGy\n2d7mkCFDCAgIYNasWXh7e9OvX7/cClfY0N69e2nVqhV2dnZMmjSJ33//ndGjR9OqVSvq1KmT3+Fl\naPHixRQrViyluTxA+/btGTFiBDNmzGDYsGE0adIkHyPMuV9++YUjR46wYMEC7O3tM1xm5ZmVlChS\ngl6P96KofVGaVWrGoWt//6/x9fVl3rx53L17l2LFiuVV6Dmye/dukpKSCAwMxNvbO7/DEfns6tWr\nREZG4uzsTFR8FNfvXLd5/zuLInZFaFOtDbsu70JrnXKf6ufnxyeffMJvv/1G//79M1xXa826det4\n5513OH36NG3btuW7775LdU43adKEvn37MnfuXN58803KlCmTJ/v1qJIaPBuKioqiRo0agDHMs7V1\n69YRFxdHeHg427Ztw9PTk27durFw4cKUPh+XL1/m+vXrqdbLbBlfX1/Wrl3LnTt3iI6OZv369RnG\n1LlzZ7788ksAkpKSiIqKol27dqxdu5bY2Fhu377NmjVraNeuXab7lZyczMWLF+nYsSPTp08nKioq\nXT+V4OBgWrVqxYcffkilSpW4ePEipUuXJjo6OtW+zJ07N2V0piNHjmR5PFu3bs2OHTu4cOECABER\nESnznn/+eYYNG8bAgQMzvRmwaNu2LStXrgSMl1pb9jWjmP/44w/q1avH2LFj6d27N8eOHcty2+Lh\nk5SUxOLFi+nWrRs1a9ZMN/9MxBme3fgsz218jui70RlsIXP//e9/8fT05Nlnn005b0XBFR0dzfHj\nx2nTpg0ARYoUYfny5SQnJzNs2LAsHzTll7t377J8+XJ69+6d0qrBYsaMGZQqVYqXXnrpoRoFz1J7\nV7t2bYYNG5bhMlHxUfxy4Rd61utJ6WKlAfCo7MGZm2eIuWv8P/L19SUuLq7ADpYTExOT8nC0oMYo\n8pb1ACvnI88Dth9gxZpPDR+u37meMrgLGPdM5cqVy7Qf3u7du2nXrh19+/ZFa82aNWsICAjI8IHF\nu+++S1RUVMp9qLAdSfBySWxsLDVr1kz5mTVrFpMnT2bgwIG0aNECJyenVMu7urrSsWNHWrduzcSJ\nE6levTpPPPEEQ4cOpU2bNjRr1owBAwakSoiATJfx8PBg8ODBNG/enB49euDp6ZlhnJ999hlbt26l\nWbNmtGjRgpMnT+Lh4cHIkSPx8vKiVatWPP/887i7u2e6r0lJSQwbNoxmzZrh7u7O2LFj0406+Oab\nb9KsWTNcXFxo27YtzZs3p2PHjpw8eTJlkJWJEyeSkJCAq6srzs7OTJw4MctjXKlSJebPn0+/fv1o\n3rw5gwcPTpnXq1cvYmJi7tk8E2Du3LksWrQIV1dXli5dymeffZZpzKtXr8bFxQU3NzdOnDjBiBEj\n0FrLyGyFyKZNm7h8+XKmg6usOL2CYnbFCI4K5pUtrxCXGJftbRcvXjyled9TTz1FQkJCrsQsbOPg\nwYMkJyfTunXrlGl169Zl3rx57Nq1q0AOELBhwwZu3LiR0jzTWuXKlZk2bRrbtm1j2bJleR/cfdq+\nfTu7d+/mrbfeyrTmbe35tcQnxTO40d//BzyqeJCskzkWZjyIs7wUvaA20zxw4EDKS+klwROQJsG7\naSR4edVEE6Bt9bYAqZppFilShO7du7Nhw4aU8xXgzJkz9OvXD29vb4KDg5k3bx4nTpygT58+GY54\nC0ZXn27dujFr1qyUFmHCRjLrnFdQf7IzyIp49Bw4cED7+PjYvJykpCR9/vx5feDAAX3r1q0cry/n\nasHTv39/XalSJR0fH59uXmRcpG65tKWetGuS9g/2180WN9Ov/P6KTkhKyFEZq1at0oAeP358boUt\nbGDq1KkaSBnAydqIESO0nZ2d3rlzZz5ElrnevXvrqlWr6oSEjM/JpKQk3bp1a12pUqUM96sg6tKl\ni65SpUqmg1olJSfpHj/00CM2jEg1PeZujG6+pLmec3hOyrSmTZvqHj162DTe+zVlyhQN6Hbt2unG\njRvndziiAHj++ee1k5OT1lrrj/Z8pFsvb50yWF9e6buur37u1+dSTVu6dKkG9IEDB/SVK1f06NGj\ntb29vS5VqpT+8MMPdUxMTLa3v337dg3ouXPn5nbojxzyY5AVpZSDUmq/UuqoUipIKfVBBssUV0qt\nUkqdV0rtU0rVsVU8ovCaNm0a/fv35z//+Y9Ny0lOTiY4OJibN28CPDTDp4vMhYWF8dNPPzF8+PAM\nawrWnl9LXFIcQxoP4cl6TzLeazxbL27lwz0f5qjJ26BBg3j++eeZPn06mzdvzs1dELloz549NGrU\nKF1TR4DPP/+cOnXq8PTTTxMZGZkP0aV3/fp1/P39GT58eIaDXQHY2dkxb948IiIiePfdd/M4wpzb\nt28fmzdv5o033sh0UKs9V/ZwMfpiqto7gJJFS9KoQqOUgVbAaKYZEBCQ6WBf+Wnv3r00btyYrl27\ncubMmWwNYiEKN+sBVs7dPEf9cvUzrQ2zFZ/qPhy6fojYhL9bKnXv3h2lFC+//DL169dnwYIFvPji\niwQHBzNx4kRKliyZ7e23a9cOb29vPvnkE+7evWuLXRDYtolmPNBJa90ccAO6K6Vap1nmOeCm1ro+\n8Ckw3YbxiEJq/PjxhIaGpjTHsYWkpCTOnz9PVFQUtWvXpnjx4tJMsxBYunQpCQkJjBo1Kt28ZJ3M\nytMr8ajsQeMKjQEY2mQoY5qPYc35Ncw+nLOBjT777DMaN27M8OHD0/WtFflPa83evXtTNc+0Vrp0\naVasWMGVK1cYPXp0gejTZnn3XWaDA1k0b96csWPH8tVXXxX498JNmTKFChUqMGbMmEyXWXl6JRUc\nKtD1sa7p5nlU9uD4jePcTTJuHH19fYmOjubo0aM2i/l+aK3Zs2cPbdq0oWXLlmitOXz48L1XFIWW\n1pqgoCCcnZ3RWnM+Mu9G0LTmXcObxORE9v+1P2Wak5MT3t7e7Nu3Dz8/P06dOsXcuXOpXLlyjrev\nlOLdd9/l4sWLfPvtt7kZurBiswTPrD20VHEUNX/S/kfsDVhGH/ke6Kzy+lGFEPdgSe5u3bpFnTp1\nqFy5Mo6OjjKs9UNOa82CBQto1aoVzs7O6eYHXA7gUswlnmryVKrpLzV/iUENB7HwxEKWBC1Jt15m\nHB0dWbVqFTdv3uSZZ55J1ZdB5L8LFy4QFhaWaYIH4OXlxUcffcTq1atZvHhx3gWXicWLF+Pp6Znh\n+ZvWBx98QI0aNRgzZkyBHCwG4OjRo6xfv55XX32VUqVKZbjM5ZjLbL+0nf4N+lPUvmi6+S2qtCA+\nKZ6T4ScBUgbRKmj98P744w9u3LhB69atadmyJSD98B51V65cISoqCmdnZ8LuhHHr7q08HWDFwr2y\nOyWKlCDgckCq6d9++y3Hjx9n9erV1K//YHH16NGD5s2bM23atAJZu14Y2HSQFaWUvVIqELgO/Ka1\n3pdmkRrARQCtdSIQBVTMYDv/VEodVEodDAsLs2XIQqSSmJjIuXPniI6Opm7duimD5ZQsWZK7d+/K\noBkPsX379nHy5MksB1epVKISnWt3TjVdKcW7rd7liceeYObBmfwU/FO2y2zWrBmzZs3i119/5dNP\nP32g+EXu2rNnD0DKCJqZefPNN+nYsSOvvPIKZ8+ezYvQMhQYGMjRo0czHFwlI6VLl+azzz7j6NGj\nfP7557YN7j5NnTqV0qVL88orr2S6zHdnvkMpxaBGgzKc717ZGCDs8HWjNqxmzZrUq1evwCV41udb\npUqVeOyxxyTBe8Tl9wArFsXsi9GqaisCLgekaqlQq1YtXFxccqUMSy3emTNnWLNmTa5sU6Rm0wRP\na52ktXYDagJeSqn7OjO01vO11i211i0rVaqUu0EKkQlLcnf79m3q1atHxYp/P3uwtDeXWryH18KF\nC3F0dEw1GqtF6K1QAi4HMLDRQIrapa8lsLez5z/t/kOraq14f9f7bL+4Pdvlvvjii/Tt25d33nlH\nbugKkL1791KyZMl71obZ29uzdOlSihcvztChQ/OtD0lG7767l379+tGjRw8mTpzIpUuXbBhdzp05\nc4bvvvuOf/3rX5QvXz7DZe4m3eXHcz/SoWYHqpasmuEyFUtUpE6ZOun64e3YsaNANKu12Lt3L6VL\nl07pb9WyZUv5PnjEWSd4ltcUPF7u8XyJxbuGN5djLhN6K9RmZfTv35+GDRsydepUm1+b58+ff+Ra\nzeTJaxK01pHAVqB7mlmXgVoASqkiQFkgPC9iEiIrCQkJnD17ltjYWB5//PF0gy44OjoCSD+8h9Tt\n27dZuXIlgwYNyvBlqytPr6SIXREGNhyY6TaK2Rfjs46f0bhCY17f/nqqG8qsKKX43//+R9WqVRky\nZIgMrFBA7N27Fy8vr0wHK7FWo0YNFixYwKFDh3jvvffyILrUsnr3XVaUUnz++eckJiby73//24YR\n5twnn3yCg4NDlnFtVwVLPAAAIABJREFUDNnIzfibDG6c/qGMNY8qHhy5foRkbdzQ+fr6Eh4ezqlT\np3I15gexZ88evLy8Ut7b2rJly1SDeIlHz8mTJ6lUqRKVKlXifOR5KjpUpIJD9q/v3ORdw3iH3a4r\nu+6x5P2zt7dn/PjxHDlyhI0bN9qsnNWrV9OgQQPefPNNm5VRENlyFM1KSqly5u8lgK7A6TSL/QRY\neocPALbogvSILZtCQkLSVVtPnjyZmTNnZrnetm3b6NmzZ5bLLF68mJdffjlH8dSpU4cbN25ke/n7\nKeNBHTx4kLFjx2Y6PyQkJN86327evJkuXbpw584d6tevn+4df2B8MTk4ODxyNXiFpa38d999R3R0\ndIbNM2MTYll3fh1dH+uKUwmnDNb+W8miJfm/Lv9HtZLVeHnLy5y9mb0mexUqVGD58uVcuHDhoXsJ\ndWF0584dAgMDs+x/l1afPn0YM2YMM2bM4LfffrNhdOlZ3n2Xnfd+plWvXj3ee+89vv/+e3755Rcb\nRJdzN27cYPny5YwYMSLLQRtWnVlFnTJ1aF0t68/Jo7IHt+7eSnlRtK+vL2C8X68guH37NkePHk3V\nHNjSD+/QoUP5FZbIZ0FBQalG0MyP5pkWtUrX4rEyj6Xrh5fbnn76aWrVqsXUqVNtsv3Tp0/z3HPP\n4ejoyKeffsq2bdtsUk5BZMsavGrAVqXUMeAARh+8n5VSHyqlepnLLAAqKqXOA+OA8TaMRxQgLVu2\nZM6cOZnOz68E7+7du1y8eJHk5GQaNGhA2bJlM122ZMmS3L59+5G5Of/zzz8pVaoUbm5uTJ8+nZCQ\nkPwO6b4tWLCAhg0b4u3tnW7ez3/8THRCNEMbD83Wtio4VOCrrl9Rwr4EY34bw6Xo7DV9a9euHZMm\nTWL58uV88803OYpf5K5Dhw6RmJiYowQP4L///S9NmzZlxIgR5GX/8MWLF1OtWjW6dk09iuTdpLss\nP7Wc2wlZP3h64403aNSoES+//HKBeNnw119/TXx8fJZ9706Fn+Jo2FEGNRqEncr61sWjyv+zd95x\nTZ3fH/9cAmEjyhZwIyuEjQNRFK111S2CtmpdtYq2jjrrqNaf66tVnHXhpKgoKo6qiAoKDrYgyBBk\nyt4zyfP7I00KkkCAhGF5v168Xpr73OechMvNPc9zzudYAQDCPoUB4Aa13bt3bzd1eCEhIWCz2XWu\nN2trawCdQiv/VWoraHIIB4mFiW0isFIb++72eJP1BpWsSonZoNPpWLNmDQICAhAQECDWucvKyjBt\n2jTIy8sjLCwM/fr1w5w5c1BUVCRWO+0VSapoRhJCLAkhTEIIgxDy2z+vbyaE3Prn35WEkOmEkH6E\nEDtCSJKk/GlLHB0dsXbtWtjZ2aF///4CL+JXr15h0KBBsLS0xODBgxEXF8c/lpqaCkdHRxgYGGDb\ntn/bCV68eBF2dnawsLDA4sWLBe6uCBtz9uxZ9O/fH3Z2dnj+XPAWfGlpKebNmwczMzMwmUx4e3sD\nADw9PWFmZgYGg4G1a9fyxyspKWHjxo0wNzfHwIED8enTJwDc3RIGgwFzc3P+Smrt3cunT5/CwsIC\nFhYWsLS0RElJCdatW4eAgABYWFjgwIEDYLPZWLNmDWxtbcFkMnHixAn+PI6Ojpg2bRqMjIwwa9Ys\nfsD1+vVrDB48GObm5rCzs0NJSQmGDh2K8PBwvs9Dhgzhy2dXVVUhLi4ONTU1UFRUhIqKCvLz8zFp\n0iQwmUwMHDgQkZGRfJ8nTJiAGTNm8H3OzMzE0KFDYWFhAQaDIfabVVvz8OFDVFZyb/Tr1q1D7969\nMXjwYBw6dAhZWVlt7J3oxMXFITAwEN9//329/kKEEHjGesK4mzHMNcxFnrO7UnecGHUCVewqLH64\nGHkVomWab9y4EcOGDcPSpUvbVLDjvw6vdUBTAzwFBQV4enqioKAA33//fass9jTU++524m3serUL\n+940nD0iKyuLo0ePIikpSWIr56LCYrFw7NgxjBgxosH6R684L8jR5DCx38RG59RT0oOmvCZCsrm7\nYRRFtas6PJ7ASu3rrWvXrujbty9ev37dVm510oakp6ejuLgYpqamSC9JRyW7sk138ABummYlu1Lk\n8oPmMn/+fGhoaIi1lzEhBIsXL0ZMTAwuX76M/v374/z580hLS8OKFSvEZqddI6wDenv9sba2rtfJ\nPSYmpu4LZ8bW/3n5J/dYVZng46EX/2nskFv/WCN8+PCBmJqa1nlty5YtZO/evYQQQoYNG0ZWrlxJ\nCCHkzp07xMnJiRBCiL+/Pxk3bhwhhJCioiJSU1NDCCHk4cOHZMqUKYQQQs6ePUu0tbVJbm4uKS8v\nJ6ampuT169ckJiaGjB8/nlRXVxNCCFmyZAk5d+4cIYSQnj17kpycHKFjMjIyiL6+PsnOziZVVVVk\n8ODBZOnSpfXe1y+//EJWrFjB/39+fj5JT0/nn1tTU0OGDx9Obty4QQghBAC5desWIYSQNWvWkO3b\ntxNCCGEwGCQtLY0QQkhBQUG99z5+/HgSGBhICCGkpKSE1NTU1DlOCCEnTpzgz1dZWUmsra1JUlIS\n8ff3JyoqKiQ1NZWw2WwycOBAEhAQQKqqqkjv3r3Jq1ev6ny+Hh4e/PcUFxdHeNdTRUUFiYiIIKGh\noeTu3bt828uWLSNbt24lhBDi5+dHzM3N+T4/fPiQvH79mnz8+JHU1NSQffv2kR07dhBCCGGxWKS4\nuLjeZ1rvWu1AzJkzh6irqxMOh0OSkpLI//3f/xEmk0kAECkpKTJixAhy8uRJkpeX19auNsgvv/xC\naDQayczMrHfsVeYrwvBgkOvvrzdr7rBPYcTmgg2Zfms6KakqEemc1NRU0q1bN2JpaUkqKyubZbeT\nljFlyhTSp08f/v+Ti5JJVmmWyOcfPHiQACDu7u6ScK8OBw4cIABIdHR0vWOz78wmZh5mhOHBIEEZ\nQY3ONXv2bCIjI0PevXsnCVdF4tq1awQA/3tEEEVVRcTmgg3Z8nyLyPOufrKaOF1xIhwOhxBCyNGj\nRwkAkpCQ0FKXW8ykSZOIgYFBvdednZ1Jjx492sCjTtqa+/fvEwDkyZMnxC/FjzA8GCQiO6JNfSqr\nLiNW563I7le7WzQPh8MhXrFeZLjXcPIq85XAMTt37iQASEhISIts8Th+/DgBwH9u5PHrr78SAMTb\n21ssdtoaAG+IkHipVURWvnSEte6r/fqUKVMAcNMwBKW2FRUVYfr06WAwGPj555/5akoAMGrUKKip\nqUFeXh5TpkxBYGAg/Pz8EBISAltbW1hYWMDPzw9JSXU3QIWNefnyJRwdHaGhoQE6nS5QRRDg1qIt\nXbqU//+uXbvi9evX/HOlpaUxa9YsftoLnU7n78rVfp/29vaYO3cuTp48KXCX0d7eHitXrsShQ4dQ\nWFgoUOTgwYMHOH/+PCwsLDBgwADk5eUhPp6rMmVnZwc9PT1ISUnBwsICycnJiIuLg46ODmxtbQEA\nKioqkJaWxvTp0+Hr64uamhqcOXMGc+fORUVFBeLi4sDhcGBoaAh5eXm+3cDAQHz77bcAgBEjRiAv\nLw/FxcWwt7fHxo0b4eXlhaysLEhLS8PW1hZnz57F1q1bERUVBWVlZYGfa0fl2bNncHBwAEVR6N27\nN9atW4eIiAhER0dj48aN+PjxIxYuXAhtbW1MmDABly9fRmlpaeMTtyI1NTU4d+4cxo0bB23t+ip8\nnrGe6CLbBWN6j2nW/BaaFtjvuB/xBfFY4b8CVeyqRs/R09PD2bNnERYWVmdHvJPWgfzTcLr2borb\nYzfMuT8HpdWiXb9ubm4YO3YsVq9ejaioKEm5CoCbnmlnZ8ev1eHxoegDwnPCscRiCXqp9MLWF1tR\nXtOwCNS+ffugqKjYpnWg7u7u6NmzJyZMmCB0zM2Em6hkV2KmkeiKoZaalvhU/gkZZRkA/q3Da+s0\nTd71xqu/y6/MR8gn7k6jra0tPn78iOzs7LZ0sZM2oE6LhH9qR9tKQZOHgowCrLWs8Ty9+UIrRVVF\nWPV0FbYHb0deZR6OhB8ROO7HH3+EioqKWHbxeBoPY8aMwYYNG+oc+/XXX2FtbY1FixZ1qMyj5vBl\nBnjz7tT/sVvIPUZXEHzcchb3uKJa/WONoKamVk/5Kj8/n98zDeCmxABccQ5BTWZ//fVXDB8+HG/f\nvsXt27f5qXBA/QCSoigQQjBnzhyEh4cjPDwccXFx2Lp1a51xoowRJzIyMnxfa7/P48ePY8eOHUhN\nTYW1tTXy8uqmr61btw6nTp1CRUUF7O3tERv7uRYP9724u7vz38uHDx/w1VdfAfj3s/3criAUFBQw\natQo3Lx5E1euXMHkyZMRFxcHQggMDQ356piNwfOZzWZj0qRJiI2N5acA6erqYu7cuV9UXVVaWho+\nfPjAbxpcGxMTE/z22294//493rx5gxUrViA8PByzZs2CpqYmnJ2dcePGjTrXdFtx7949fPr0SaC4\nSlZZFh5/fIwpBlMgJy3XbBsOeg7YPmQ7XmW9wrpn68DmNC5M880338DNzQ0HDx6Er69vs2130nTS\n0tKQmZnJf+AuqCzAh6IPSC9Nx86XoqUvUhSFs2fPQlVVFS4uLhKrawsLCxPa++5mwk3QKBqmGUzD\nb/a/IaM0AwdDDzY4n5aWFnbu3Al/f/82qXmOjIzE06dPsXTpUr6a5OdwCAdecV4w1zCHUTcjkee2\n1uLWtPHSy4yNjaGmptbmAV5ycjI+ffrEX1A4HnEcCx4sQAWrosMJrVRUVKC4uLhdpL12dHgKmurq\n6kgoSICuki4UZRTb2i0M0R2CpKIkZJRmNPncsOwwTL89Hf4f/bHKehVWWa9CyKcQhGeH1xvbpUsX\nLFu2DN7e3gKfAUUlPz8f06ZNg7a2Ni5cuAApqbphjoyMDC5cuICysjIsWLDgi752v8wAr5VRUlKC\njo4OHj9+DIB7gd2/fx9DhgwReY6ioiLo6uoC4K7Q1ubhw4fIz89HRUUFfHx8YG9vDycnJ1y7do2/\n0pefn4+UlLr9SoSNGTBgAJ4+fYq8vDzU1NTg6tWrAn0aNWoUjhz5d7WloKAAdnZ2ePr0KXJzc8Fm\ns+Hp6Ylhw4Y1+N4SExMxYMAA/Pbbb9DQ0EBqamq942ZmZli7di1sbW0RGxsLZWVllJSU8MeMHj0a\nx44d4zcWf//+fYMKloaGhsjMzOTXM5SUlPADvwULFmD58uWwtLRETk4OKIqqt3PHw8HBAZcuXQLA\nrfdTV1eHiooK3+cVK1bA2NgY7969Q0pKCrS0tLBw4UIsWLAAoaGSzVtvTXj1hLxVcEFQFAVra2vs\n3bsXKSkpCAgIwLx58+Dv748pU6ZAS0sLe/bsaS2XBXL69GloaWlhzJj6O3RX4q6AQzhwNmxYgl0U\nxvcZj7W2a/Ho4yNsD94u0pfInj17YG5ujrlz5yI9Pb3FPnQiGp/XQ0Xlcnfg7Lvb43bSbdxNuivS\nPJqamjh37hyio6OxevVqifgqrPcdi8PC7cTbsNe1h4aCBiw1LeFq7IrLsZf5u0PCWLRoEezs7LBy\n5cpWl+h3d3eHvLy8wAUXHsGZwUgpTmny32U/1X5QllHmNzyXkpKCg4NDmwd4vHpP3oJCeHY4WBwW\n4vLjYGlpCYqiOoTQSlVVFfr3748uXbpATk4Oenp6sLCwwKhRo+Dq6orly5dj+/btOH78OK5du4an\nT58iJiYG2dnZX4waszjhCawAQHxhPAxU27b+jscQXe5zbFPaJbA5bJyIOIF59+eBRtFwYewFzGXM\nxbT+06Aqq4rTUacFnvfTTz9BTk4Ou3fvbpavHA4H3333HTIyMnD16tU6vYtrY2xsjF27duHOnTs4\ndepUs2x1BDoDPDFx/vx5bN++HRYWFhgxYgS2bNmCvn1F317/5ZdfsH79elhaWtbbgbKzs8PUqVPB\nZDIxdepU2NjYwMTEBDt27MBXX30FJpOJUaNGITMzs855wsbo6Ohg69atGDRoEOzt7WFsbCzQp02b\nNqGgoIAvkOLv7w8dHR3s2rULw4cPh7m5OaytrTFxYsNF72vWrOGLsvBET2rzxx9/gMFggMlkQkZG\nBmPGjAGTyQSNRoO5uTkOHDiABQsWwMTEBFZWVmAwGFi8eHGDO3V0Oh1eXl5wc3ODubk5Ro0axd9B\nsra2hpKSEoYPHw4pKSmhwR3AbXcREhICJpOJdevW4dy5c3V8HjNmDGg0GkaMGIEnT57A3NwclpaW\n8PLy+qIKeQMCAqCkpFTvdycMKSkpDBkyBEeOHEFGRgb+/vtvMJlMbNmyhR+ktzaZmZm4c+cO5syZ\nAxmZus3Lq9nV8I73xjD9YdBV0hWLvdkms7HQbCG8473hHube6Hg5OTl4eXmhoqICs2fP7nwIaiWC\ng4MhJycHJpMJgPvATaNo2DdsHyw0LLA9eDvSS0ULuEePHo2VK1fi6NGjYt8R4/W+mzRpUr1G4C8y\nXiC7IhuT+k3iv7bccjl0lXSx5cUWVLCE7yjSaDQcP34cubm52Lhxo1h9boj8/HxcunQJs2bNarCX\nn1esF7rKdsXoXqObND9NigYLTYs6AhHDhg1DUlJSmzZ5DwoKgqKiIhgMBipYFfzWKtF50VBRUYGh\noWGHCPB8fHz4ghU//fQTRo8ejR49eqC0tBSvXr3C+fPnsXnzZixZsgTTp0+Ho6MjTE1NoaWlBRkZ\nGairq2PIkCGdvWTBzVCKiYmBqakpatg1SC5KRr+ubaugyaN3l97QUdQROU0zuzwbix4uwuHwwxjd\nazSuTrgKhjq3jZiCjAJcjV3xJO0J4gvi652roaGBRYsW4eLFi/U2LERh9+7duHPnDg4cOAA7O7sG\nx7q5ucHJyQk///wzEhMTm2yrQyCsOK+9/ogkstJJJ0LgcDgkPDyc9OjRg4SHh7dY1KKsrIy8fv2a\n5ObmijS+o16rDAaDjB49ukVzXL58mQAgoaGhYvKqaezatYsAILGxsfWO3Uq4RRgeDPI8/blYbXI4\nHLL5+WbC8GCQJx+fiHTOmTNnBBaHdyIZBg4cSIYMGcL///y/55Ppt6YTQghJLU4lAy8NJN/e/ZbU\nsGtEmq+qqooMGzaM0Ol0EhAQIDY/r1+/TgCQu3fv1jv2s//PxMHTgVSzquu8HpwRTBgeDLLv9b5G\n51++fDmhKIq8fPlSbD43xJ49ewgAEhEhXEgiszSTMM8xyYE3B5pl42TkScLwYJD8inxCCCEhISEE\nALl8+XKz5hMHtra2xNHRkRBCyJusN4ThwSAMDwbZELCBEMIVvunevXub+ScqI0aMIL169SJsNlvo\nmKqqKpKenk4iIiLIo0ePiKenJ3F3dyebN28ms2bNIgCIp6dnK3rdPvn48SMBQI4ePUre578nDA8G\n8U30bWu3+Gx9sZUMuDSAVLOrGxz3NPUpcfB0ILYXbcmN+Bt8gaPaFFYWEruLdmTts7UC5/j48SOR\nkZEhy5Yta5KPjx8/JlJSUsTFxUWgXWG2unTpQgYPHkxYLFaT7LUX0IDISpsHbE396QzwOmkuVVVV\nZPfu3URTU5McOnSIry7aEjgcDgkJCSEpKSkije+I12pubi4BwFcIbS4JCQkEADlx4oSYPBMdDodD\n+vfvX+dBvjauvq5k/PXxhM0R/rDSXKpYVWTKzSlk6F9DSU55TqPjORwOcXFxITQaja8u24lkqKys\nJHQ6naxevZoQQgiLzSIDLg0g24P+Da5vJ94mDA8GORp+VOR5c3NziYGBAVFTUxObauM333xDdHR0\n+GrLPAoqCojleUuy6+Uugedte7GNMM8xG1XkKyoqIjo6OsTKykriDzssFov06tWLDBs2rMFxB0MO\nEjMPM5Jekt4sOyFZIYThwSCPUh7x7SorK5MffvihWfO1lPLyciItLU3Wr19PCCHkTNQZwvBgEFdf\nVzLJZxIhhJA//viDACDp6c17z61BfHx8i78TWCwW6d69O/nmm2/E6FnH5N69ewQAefr0KbmbdJcw\nPBgkNq/+QmRb8Sj5EWF4MMjrzNcCj1exqsiul7sIw4NBpt6cShILExucb++rvcT8nDlJLU4VeHz+\n/PlETk6OZGWJpmScnp5ONDU1ibGxMSkpEU29msfFixcJALJz584mnddeaCjA60zR7OQ/QUFBAWJi\nYjBy5Ei8ffsWy5Ytq5emJyqEEFSxuOqIFEVBQUGhwXrAjg6vT2JD9Xei0KdPH3Tr1q1N+jw9f/4c\n79+/F1jr8zb3LSJzIzHTaGajDZSbA51Gx26H3SitLsWWF1sarcejKArHjx9Hz5494erq2up1Uf8l\nwsPDUV1dza+/SypKQllNWZ0eiOP7jMe4PuNwIuKEQHEAQaipqeHOnTsghGDcuHEt/h1++vRJaO+7\nOx/uoIZTUyc9szYrrVdCQ14Dm59vRjW7WqgNFRUV/O9//0NoaCjOnDnTIn8bw9fXF8nJyQ02Nq9h\n13DTpvWGobtS92bZYagzQJei8xue02g0DBkypM3q8EJDQ8FisfjXW0ROBPSV9flCFuU15Xyhlfac\npnnq1CnQaDTMmzev2XPQaDQ4Ozvj3r17//l7XExMDABuWU18QTxoFA29u/RuY6/+xU7HDtKUtMA6\nvOSiZMy+OxsX312Eq5ErLo27hD5d+jQ437cm34KiKHhEewg8vnbtWlRXV+OPP/5o1Leamho4Ozuj\nrKwM3t7eUFJSEuk98XB1dcX06dOxZcuWOj2SvwS+mACvsYemTv6bsNlsJCcnIzExEXQ6HSYmJtDQ\n0BDa2kIUcipykFCYwJcgV1RURHl5OTgcToPnddRr9NmzZ6DT6fyWE82FoijY2Ni0SYDn6ekJRUVF\nTJ8+vf6xWE8oSCtgYt/GGyg3l35d+2GlzUo8S3uGK3FXGh2voqICT09PZGRkfPFKX20JT2CFJ3gR\nkRMBAPWa3G8csBHaitpYF7BO5NYJBgYG8PHxQVJSEqZOnYrqauHBVWNcvnwZbDYbc+bMqXfsZsJN\nGHczhmE3Q4HnKtGVsHXwViQWJeJ4xPEG7cycORMODg7YsGGDRB+6Dx06BH19/Qbrtx+mPER+ZX6T\nWiN8Dp1GB0OdwRdaAbgLVTExMcjJyWn2vM2ltqAPIQQRORFgajBhomYCDuEgNj8WFhYWkJKSarcB\nXnV1Nc6ePYsJEyage/fmBd48XFxcUFNTg+vXr4vJu45JdHQ0NDU1oa6ujvjCePRS6QU6jd7WbvFR\npivDXNO8Xh3ercRbmOE7AxllGTg0/BDWD1gPWZqskFn+RUtRCxP7TsSN+BvIrcitd9zAwADTp0/H\nkSNHUFhY2OBcGzZsQGBgIE6ePClUT6IhKIrCsWPHoK6ujtmzZ7cLtW9x8UUEeHJycsjLy+t8COqk\nDqWlpYiJiUFubi60tbVhZGQEObnmy98DQGFlIXLKuQ8G5SxugKegoABCSIM3BkII8vLyWmy/LQgI\nCMCAAQPE4rutrS3evn3b6oX1L168wKBBg6CoWFd2Or8yH/c/3Mc3fb+BEr1pK39NxdXIFfbd7bHv\nzT4kFSU1Ot7Ozg47d+7E9evX+eI+nYiX4OBg6Ovr8x9UI3MioSqrCn1l/TrjlOnK2OWwC5llmSK3\nTgC4KrxnzpyBv78/fvjhh2Z9RxFCcPbsWYG97+Ly4/Au/x0m9mt4cWKI7hBM7DsRZ96ewbu8d0LH\nURQFd3d35OfnY8uWLU32VRSio6Px+PFjLFmyRGDPUx5ecV7QV9bHoO6DWmTPWssa7/Le8RfkeJkI\ngYGBLZq3OQQFBaFPnz7Q1NREVlkWcityYa5hDhM17u81Ji8GioqKMDU1bbcB3q1bt5CdnY1Fixa1\neC4bGxv069evTVp0tCdqK2gmFCS0G4GV2gzRHYJ3+e+QW5GLspoyrA9Yj42BG2GiZoJrE65heI/h\nTZpvHmMeWISFCzEXBB5fv349SkpK6ii5f86NGzewb98+LF26FC4uLk2yXxs1NTWcPn2a39P3S0H4\n3bUDoaenh7S0tDZZkeuk/UEIQVFREYqKikCj0aCuro6SkhLExcW1aN4qdhXyK/JBp9HBIiwUShUi\nRy4HNTU1yM3Nxdu3bxtsbs6Tku5IlJaWIiQkRGwNuO3s7MBmsxEWFgZ7e3uxzNkYpaWliIyMFHjj\nvh5/HdWcargYNf/LQVQoisJ2++2Yemsq1j1bh0tjL0GG1nCa8KpVq3D16lVs374ds2fPbvCBuJOm\nExwczN+9A7gBHlODKXCH30LTAouZi3Es4hiG6A7B2D5jRbIxe/ZsxMfH47fffoOBgQHWr1/fJB/D\nw8MRFRWFo0eP1jvmk+ADGSkZjOs9rtF51tiuwfOM5/j1+a/wHO8JGSnB1565uTl++OEHHD16FAsX\nLoSZmVmT/G2Mw4cPQ1ZWFgsXLhQ6Ji4/DqHZoVhts7rFadNWWlY4GXUSkbmRGKgzEDY2NpCTk8Oz\nZ88wefLkFs3dFMg/Dc5HjBgBAIjI5e4WMzWY0FDQgKaCJqLzuM2ubWxs4OvrC0JIi7JNJMGff/6J\nHj168PvQtgSKouDi4oIdO3bwFb7/a5B/FDTnzJmD8ppypJWmNbpg0xbYd7fHwdCD8HjrAf9Uf6SV\npuFHix+xyGwRaFKCe1g2RE+VnhjVcxSuxF3BArMFUKbXfXYyNzfHuHHj8Mcff+Cnn36qtzibkJCA\nuXPnwtbWFv/73/9a9N4AYMyYMViyZAkOHDiACRMmwNHRscVztjnCivPa648gkZVOOuGRlJREBg8e\nTAAQV1dXUlBQIJZ5EwsSyaDLg8jEGxNJcVUxWfNkDRl5dSQhhCuKoaqqShYtWiQWW+2Jhw8fEgDk\n3r17YpkvIyODACAHDjRPFa85PH78WKD6YA27hoy8OpLM/3t+q/lCCCGPUrgF66IqA3p7exMAxMvL\nS8Ke/bfgXYv79+8nhBBSVFVEGB4MciJCuAhQDbuGzL4zmwy8NJCklaSJbIsnnAOAXLlypUl+Ll++\nnNDpdJKfn18Ky7YIAAAgAElEQVTn9WpWNRniOYSs9F8p8lx+KX6E4cEgx8KPNTguNzeXdOvWjTg6\nOoqsSCcKBQUFREFBgcybN6/BcdtebCPWF6xJYWVhi20WVxUTMw8zciTsCP+14cOHEysrqxbP3RRS\nUlIIAHL48GFCCCG7X+0m1hes+cqEbn5uZMKNCYQQQo4cOUIAiCze1VokJSURAGTbtm1imzMmJoYA\nIH/88YfY5uxI8K6LY8eOkaicKK4oUPKjtnarHmwOmwz7axhheDCI0xUnoYIrTSEmN4YwPBjkZORJ\ngcefP38u8NooLy8n5ubmpFu3biQ5ObnFfvAoLS0lBgYGpEePHqSwsOX3ntYAnSIrnXzpEEJw/vx5\nmJub4+3bt7h48SIuXboEVVXVFs+dV5GHH/1+BF2KjiMjj0CZrgwzDTNklWUhpzynTWvLJM2zZ88g\nJSWFwYMHi2U+HR0d6OrqtupnxWssPGDAgDqvP019iqyyrFbZvauNUw8nTDWYijNvz+B1VuOfw8SJ\nE2FgYIDdu3d3pqGLEd51wRO8eJvzFgB3R0UY0lLS+D+H/wMArA9YDxZHeC/O2lAUhTNnzmDw4MH4\n7rvv+LYbo6Hed0/SnqCwqlCouIogRvQYgTG9xuBE5AmBfah4qKmpYceOHXjy5AmuXbsm8vyNcebM\nGZSXlzcorlJSXQLfJF+M6T0GXWS7tNimMl0Zht0M69XhhYeHo6ioqMXzi8rn11tkTiRM1Uz5O6km\naiZILkpGWU1ZuxVaOXXqFKSkpPD999+LbU5jY2OYm5vD09NTbHN2JD4XWAHQLlM0pSgpfM/4HhP7\nTsS1Cddgo23T4jmN1Yxhr2uPCzEXUMmqX+IyePBgODo6Yu/evaiqquK/vmzZMkRERODixYvo2bNn\ni/3goaioiPPnz/P7O3Z0OgO8Tjo8BQUFmDlzJubMmQMLCwtERERg1qxZYpm7klWJ5f7LkVeRB/cR\n7vwm2Gbq3LSlyNxIANzasqioqC+qQBfg1t9ZWFhARUVFbHPa2tq2aoAXFBQEQ0PDes2UPWM9oaOo\ng2F6w1rNFx6/2P4CfWV9bAjcgOLq4gbH0mg0rFmzBqGhofDz82slD798goODQafTYWVlBYCbMkeB\nAkON0eB5esp62DhwI8Kyw3Ay6qTI9uTk5ODj44Pu3btj4sSJSE5ObvScO3fuIC8vD3Pnzq13zCfB\nB5rymhjcvWmLL+sHrIcKXQWbn29uMEBdtGgRzM3NsWrVKrGoBLPZbBw5cgT29vawtLQUOu5W4i1U\nsCpaJK7yOVaaVojMiUQNpwYAN8DjcDh48eKF2Gw0RlBQEOTl5cFkMlHNrsa7vHd1FhNM1UxBQLiv\nM5mQlpZuVwFeTU0Nzpw5g3Hjxom91MDV1RUvX778chtON0B0NDct19TUFAmFCZCjyUFPqX2Wcnxn\n+h12DNkBVbmWL5zzmM+Yj/zKfNxIuCHw+IYNG5Ceno4LF7i1emfOnMGZM2ewadMmjBkzRmx+8Bg4\ncCA2bNiAc+fOdXjxn84Ar5MOjb+/P5hMJq5fv47ff/8d/v7+6NWrl1jm5hAONgZuRFROFHY57IKZ\nxr+1KEbdjCBNSeNtLnfV38bGBiwW64uS2a2qqkJwcHCL2yN8jq2tLeLj41tFGpsQguDgYP6qOY/E\nwkS8zHqJGYYzIC3V+nVtCjIK2OWwCznlOdgRvKPR8d9++y20tbWxZ8+eVvDuv0FQUBAsLS0hK8tV\nfYvIiUBf1b4iie00p3UCAGhoaODOnTuorq7GuHHjGt1B8vDwgI6ODkaNGlXn9ZzyHASmB2JC3wlN\nrn/pKtcV6wesx9u8t0IFDgDuwoK7uztSU1Oxe/fuJtkQxL1795CUlNTg7h0hBF5xXjBTN4OpmmmL\nbfKw0rJCBasCsXmxALgPcdLS0q3aLiE4OBg2NjaQkZFBXH4cqjnVdQI8ntBKdF405OTkYGZm1q6y\nQnx9fZGVlSUWcZXPmTmTG8z/9ddfYp+7vRMdHQ0tLS2oqakhviAefVT7NKumraNio2UDcw1zeLz1\n4C/A1GbkyJGwsbHBrl27EBISgqVLl8LJyQlbt25tkp0KVoXIYzdv3gwrKyssWrQIWVlZTbLTnugM\n8DrpkFRVVWHt2rVwcnKCvLw8Xrx4gQ0bNoBGE9+N8VDoITxIeYBVNqvg1NOpzjE5aTn079YfUTlR\nAMBvIdCevpBbSkhICCorK+Hg4CDWee3s7AC0TvpRUlIScnJy6ghpANzdO7oUHVMMpkjcB2GYaZhh\nifkS3PtwD75Jvg2OlZOTw08//YSHDx8iNDS0wbGdNE5NTQ3evHnDD/w5hIOonKh67REaojmtEwDA\nyMgI3t7eeP/+PaZPn46amvoPNUDDve9uJ90Gh3CalJ5Zm9E9R8OphxMOhx3Gh6IPQsc5ODjA1dUV\ne/bsQVJS48qvDeHu7o7u3btjyhThf3Ovsl7hQ9EHse7eAdwdPAD8NE0FBQXY2tq2WoBXVVWF0NBQ\n/n2Il/nBVP83wFOTV4OOok4doZU3b960m7TsP//8E7q6uvj666/FPnePHj1gb2//n0zTrKOgWZiA\nfqrtLz1TklAUhQVmC5BRloH7H+4LPL5hwwYkJibC0dERampquHz5cpOe9QLTA2HvaY8/I/8UabyM\njAwuXLiAsrKyDt2mqDPA66TD4efnByaTiT179mDhwoUICwtrcY+2z/F+743Tb09jRv8Z+M7kO4Fj\nzNTN8DbvLdgcNvT09KClpdUqAV5ISEir3HACAgIAgB/gFVQWYOqtqdgUuAmROZHN9oFXX9Ian9Xn\nfc4Abo3PrcRb+Lr31+gm103Yqa3CArMFsNS0xO/BvyO9NL3BsYsXL4aysnLnLp4YiIqKQkVFBf+6\nSClOQXF1cZMCPF7rhKyyLPz+8vcm2R8xYgROnDiBhw8fws3NTeDfkrDed4QQ+CT4wELDAr269GqS\nXR4URWHTwE2Qk5bD5uebweawhY7ds2cPpKWlsWrVqmbZAoDY2Fg8ePAAS5YsgYyMcOVYrzgvdJHt\ngtG9RjfbliA0FDSgr6yP0E916/Bev37dKi1bQkNDUV1d/W+D8+wIaCloQUtRq844EzUTxORxa7Js\nbGxQWFjY4sBaHKSkpODvv//G/PnzJabk6+LigujoaERFRUlk/vYI+UdB09TUlNuCqSIHBqoGbe1W\nqzNUbyj6qfbD6ajT4JD6/YQnTpwIY2NjVFZWwsvLC5qamiLPHZcfh1VPVkGKkoJ7mDv8P/qLdJ6J\niQl27dqFO3fu4NSpUyLba090BniddBiysrLg6uqKkSNHgs1m4/79+zhx4kQ9+dyW8iLjBbYHb4e9\nrj3WD1gvVKaaqcFEWU0ZPhR9AEVRrVJb5ufnBxsbG7EKHwjj2bNnMDIygoaGBgDgZeZLvC94j7sf\n7mLW3Vlw9nXG1fdX+f2lREVVVRUGBgatEuAFBwdDSUmJv0IK/Fvj42rsKnH7jUGTomHnkJ0gINgQ\nsKHBB21VVVX88MMPuHr1art46OvI1G44Dfzb4LwhgRVB8Fon+Cb54k7SnSad+/3332PdunU4ceIE\n9u/fX+cYaaD3XUROBD4UfcBkg5ZJ/KvLq2Od3TqE54TjrzjhqXG6urrYtGkTfHx88ODBg2bZOnz4\nMOh0eoPpfVllWXj88TGm9JsiUrPkpmKlaYWw7DB+MD106FDU1NTg5cuXYrf1OTyBldo7eIKuNVM1\nU6QUp6CkuoS/aNke6vBOnz4NAJg/f77EbEyfPh00Gu0/1RMvNTUVpaWlMDExQUJhAoD2KbAiaaQo\nKcw3m4/EokQ8TX1a/7iUFG7evInHjx83qb1Sdnk2lvothRJdCde/uQ4TNROsD1wvUh9aAHBzc4OT\nkxN+/vnnDlkf2hngddLuYbPZOHz4MAwNDeHt7Y3NmzcjKioKo0eLd5UXAOIL4rHqySr0Ue2DfUP3\nNVifxRNaicr9N00zLi4OxcUNi2a0hCtXrgCAxFNZ2Gw2nj9/Xic9MzQ7FPLS8vCf4Y9NAzaBRVj4\nLeg3jLg6AjuCdyAuX/Q+g60ltBIUFAQ7Ozt+OgeHcPBX7F9gajDFWuPTEvSU9bBhwAaEZofibPTZ\nBsf+9NNPkJaWFkvfn/8ywcHB0NbWRo8ePQBwFQ2VZZTRu0vvJs+1kLkQlpqW2BG8A2klaU069/ff\nf8e0adOwZs0a+Pj48F8PCwtDVFQU5s2bV+8cnwQfyEvLi2WXa3yf8XDQdcDB0INILUkVOu7nn39G\n3759sXz5clRXVzfJRnFxMc6dOwdnZ+cGV96vvb8GDuFguuH0Js0vKtZa1iioKuCnpNrb24OiqFZJ\n0wwKCkKvXr2gra2N3IpcpJemC9wt5t2T3uW9g6mpKWRlZds8wGOxWDh9+jTGjBnD/3uRBJqamhg5\nciT++uuvDpsS11Q+F1gB8J9L0eTxda+voauki1NvTwn8/RsYGDSpXKS8phzL/JahpLoER52OoodK\nD/zh+AdkabJY8XgFSqpLGp1DSkoKZ8+ehbS0NL777juw2cIXYNsjnQFeJ+2aN2/eYMCAAXBzc4Od\nnR2ioqKwbds2yMvLi91WbkUulvothby0PI46HW1UbKGnSk8o05XrKGkSQhASEiJ23wBu0OXj4wOK\nonD37l2JBpJRUVEoKiqqI7ASnh0OpgYTXWS7wNnIGd4TvHFhzAWM0B+BG/E3MO32NMy+Oxu3E2+j\nil3VwOzczyo9PR0ZGRkSew/l5eWIiIiok54ZnBGM5OLkVm+N0BgT+kzA6F6jcSTsCKJzo4WO6969\nO7799lucOXMG2dnZrejhlwWvwTlvdz4yJxJmGmbNaqrd3NYJAPcB4vz587C1tcWsWbP49w4PDw/I\nysrC2dm5zvgKVgXuJ9/HqJ6joCjT8swFiqKwedBm0Cgatr7YKjA9CgBkZWXxxx9/IC4uDocPH26S\nDQ8PD5SWljYorlJeU46/4v7CMP1h0FfWb9L8omKlxa3DC8nmfsZdunSBhYVFqwR4tYWeInO43xeC\nArzaQit0Oh3m5uZtHuDdvXsXGRkZEhFX+RwXFxckJyeL3Eako/N5gKdMV4aWglYjZ32ZSEtJY57p\nPETmROLNp5Zd82wOG2uerUFcQRz2DtsLw26GAAAdJR3sG7YPaSVp2BCwQej9rjb6+vo4cuQImEym\n0Hrp9kpngNdJu6SwsBBLly6FnZ0d0tPT4enpiQcPHqB///4SsVfBqsAyv2UorCrEYafD0FbUbvQc\nKUoKZupm9YRWJPWF/Pz5c2RnZ2P58uWoqqrC7du3JWIHqF9/V1ZThriCOFhq/itvTlEULDQtsNNh\nJ/ym+2G1zWoUVhViQ+AGOF11wt7Xe5FclCxwfp7QiiR38d68eQM2m11HQdMz1hPd5Lrhq55fScxu\nc6AoCr8O/BVq8mpYF7CuwbTX1atXo6qqqskP2p1wycnJQUJCAv+6KKspQ3xhfJPTM2ujq6SLTQM3\nITwnHCcjRW+dAADy8vK4desWNDQ0MGHCBCQmJgrtffco5RHKasqaLa4iCG1FbayyWYVXWa9w7b3w\n1O/x48dj7Nix2Lp1q8jKchwOB4cPH8bAgQMbrJO+EncFRVVFWGi2sMn+i0oP5R7oJtetXh1eUFBQ\nk3clm0J6ejpSU1P/Tc/MiYS0lDSMuhnVG6sqpwpdJd06QishISHgcBp/EJUUf/75J3R0dDBu3DiJ\n25o8eTJkZWX/M2Ir0dHR0NbWRrdu3RBfEA8DVQOhJSH/BSb2m4huct1wKqr5NW+EEOx+vRvP0p5h\ng90GDNWrqwJuq22L1bar8STtCY5HHBdpzlmzZuHYsWOQk5Nrtl9tQWeA10m7ghCCS5cuwcjICMeP\nH8eyZcsQGxuLmTNnSuzGx+awsT5gPWLyYrBn6B7+KqooMNQZiC+MR3lNOdTV1dGrVy+JBS3e3t6Q\nlZXFb7/9Bj09PXh5eUnEDsCtv+vRowe/iWhETgQ4hFMnwKuNqpwq5pjOwe1Jt3Hyq5Ow07bD5XeX\nMcFnAhY8WIAHyQ/qSCBbWFiARqNJNMD7vM4qrSQNT9OeYlr/aaDT6BKz21y6yHbBziE7kVKcgn1v\n9gkdZ2RkhIkTJ+Lw4cMoLRVdvbETLryaK951EZ0bDQ7hNElgRRDj+ozD+D7jcTzyeJNaJwCAlpYW\nfH19UVZWBjs7O+Tn5wvsfXcz4SZ0lXRhrWXdIl8/Z6rBVAzQGYD9IfuRWZopdNyBAwdQWVmJ9evX\nizTvgwcPEB8f3+DuXRW7CudizmGAzoAWBdmNQVEUrLWsEZYdxn9t6NChqKiokFjWBSCgwXluJIy6\nGkFOWvDD4udCKyUlJXj//r3E/GuI1NRU3Lt3D99//32j4io1nBoUVRUhqywLSYVJiMqJwsvMl/D/\n6I87SXdw9f1VnIs+h2MRx7D/zX7sCN6Bg6EH69Qdq6ioYPz48fDy8gKLJfpOeEeFp6BJCEF8Yfx/\nNj2Th5y0HL41+RYvMl7wFzmaysV3F+EZ64k5JnPgbOQscIyrkSsm9p2IYxHH4Pfxy+0t2xngddJu\niI2NxciRIzF79mz06NEDr1+/xqFDh9ClSxeJ2j0QcgB+H/2w1m4tHPUdm3QuU50JDuHwv5AlVVtG\nCMH169cxevRoqKioYMaMGfj7779RWFgoEVsBAQF18t3DssMgRUk1+hBMURQG6gzEfsf9eDDtAdws\n3fCx+CNWPV2Fr659hRvx3GamCgoKYDAYEg3wgoOD0a9fP6irqwPg7hJIUVKY3l8yNT7iwE7HDnNN\n5+Lq+6t4kvpE6Li1a9eioKCgw6p7tSVBQUGg0Wh8NVdeijWvprYlbBywETqKOlgXsA5FVQ33uPsc\nBoOBK1euoKioCN27d6/X+y69NB0vs15iYr+JzUolbQiKorB1EDdFc8dL4X0Z+/fvj5UrV8LDw0Ok\nNLpDhw5BW1sb06ZNEzrGJ94HuRW5Et2942GlaYX00nRklXF3IHn3OEmmaQYFBUFWVhYWFhZgcVh4\nm/u2wUDWVM0UqSWpKKoq4l+jbZWmeebMGRBCBIqrcAgHPzz8AUP+GgKrC1awumCFIX8NwahrozDx\n5kS43nXFggcLsNx/OdYFrMNvQb9h35t9OBp+FJ6xnrj74S5ORZ3C6091vwNcXFyQnZ0Nf3/R1A47\nKjwFTRMTE2SXZ6OkuuQ/KbDyOc6GzlCSUcLpqNNNPvfxx8fY+3ovnHo4YaXNSqHjKIrCr4N+BUON\ngQ0BG5BU+GWKlnUGeJ20ORUVFdi0aROYTCZCQkJw9OhRBAUFwcrKSuK2vWK9cC7mHFyNXDHLeFaT\nz+c1P+c1PLe1tUVycjJycnLE6ufr16+RlpaGqVOnAgBmzJiB6upq3Lx5U6x2ACA+Ph6fPn2qU38X\nlh0Gw66GTar70VDQwCLmItybcg+HRxyGhrwGdr3axV+x5QXDkiioJ4QgKCiInxZVwaqAd7w3RvQY\nIVL6bVuyzHIZjLoZYcuLLcityBU4ZuDAgXBwcMD+/fs7XF1AWxMcHAxzc3MoKCgA4ErW91LphS6y\nLV9IUqIrYffQ3cguz4bbY7cmNdcFgNGjR+P+/fvw9PSs1+fpZsJNUKAwse/EFvspCD1lPSwxX4Jn\nac/wMlO4suTGjRuho6MDNze3BlMH4+Pjce/ePSxevBh0uuAd8xpODc5GnwVTgwk7bbsWv4fG4NXh\n8dI0NTQ0YGxsLPEAz9raGnQ6HYmFiahgVTQY4PEySGLyYmBsbAx5efk2CfDYbDZOnTqFr776Cr17\n1xcfepHxAs8znsNO2w7fmXwHN0s3rLVdi22Dt2Hv0L044nQEZ0afwV/j/8KtSbfwaNojvHB5gfBv\nw/F69ms8nv4YijKKuJt0t868Y8eOhbKy8hefpvnx40eUlZV1Cqx8hjJdGTONZuJRyqMGe3R+TnRu\nNNYFrANDnYH/c/i/RhfBZGmyODD8AOSk5bDCXzTRlY5GZ4DXSZty9+5dmJqa4vfff4ezszPi4uKw\nZMkSsTYsF0ZAWgB2vtqJYXrD8IvtL82ao5tcN+gq6dYRWgHEv+Lq7e0NaWlpTJgwAQC3hq1Xr14S\nSdP8vP6OxWEhMicSFpoWzZqPJkXDMP1h+NbkW5SzypFYxJUbtrOzQ0FBgUTkh5OTk/Hp0yd+gHfv\nwz0UVxe3O3EVQdBpdOxy2IWymjJsfr5ZaAC8du1apKam4q+/hEvcd1IXNpuNV69e8dPlCCGIzI1s\ncXpmbcw1zLHLYRfCs8Ox+unqOqnJojBy5Mg6iysAd7fkZsJNDNAZgO5K3cXm6+e4GrtCR1EH+0P2\nCxUg4PVifPPmDTw8PITOdeTIEcjIyGDx4sVCx9z7cA/ppelYZLaoVWqP+nftD0UZRX7Dc4CbphkY\nGCgRhbzq6mqEhITw70OitOOoLbQiLS0NS0vLNgnw7t+/j7S0NKHiKpffXYaanBp2O+zGT9Y/YRFz\nEWabzMYUgyn4uvfXGKo3FLbatjBVM0XvLr2hpagFZboyaFLc73Y5aTk49XDCo5RHdUS55OXlMWXK\nFFy/fh2VlZWt8l7bAkEKmv/FHniCmG08G3QaHR7RHiKNzyjNwFK/pegq2xWHRhyCvLRoInzaitrY\n77gfaSVpWBewTiTRlY6ExAI8iqL0KYrypygqhqKoaIqiVggY40hRVBFFUeH//GyWlD+dtD9+/PFH\njBs3DrKysnj8+DEuXLgALa3WUZCKy4/D6qerYdjVEHuG7uF/6TQHpjqT3yrBysoKFEWJNfWQl545\nYsQIvugCRVGYMWMGHj58iPz8fLHZArjpSurq6jAy4ooAxBXEoYJVIbT+TlT4bSU+E6WRRJrm53Uv\nz9KeQVdJFzZaNmK3JQn6qvbFSuuVCEgPENqjbOzYsWAwGNizZ89/Rla8pURHR6O0tJT/wJ1Wmob8\nynyx13591esrbBq4Cc/SnjWoTikqr7NeI6MsQ6ziKoKQpcnCzdINMXkx+Dv5b6HjZs2ahcGDB2Pd\nunUC08RLSkpw9uxZTJ8+HTo6OgLn4BAOTkWdQv+u/esJIUgKaSlpmGuY1wvwiouLERkZKXZ74eHh\nqKqqqhPgdZPrBj0lPaHndJHtAn1l/Tp1eGFhYa1ek3by5EloaWnxFxVr87H4IwLTAzHdcDpkaMIb\n1zfGuN7jUFJTgsC0wDqvu7i4oKioCPfu3Wv23O2d2gFefEE8NOQ1oCqn2sZetQ/U5NUwud9k3Eq8\nxU+nFkZJdQmW+i1FNbsaR0cehbq8epNsWWtZY63dWjxLe4Yj4Uda4na7Q5I7eCwAqwghJgAGAlhK\nUZQg9YoAQojFPz+/SdCfTtoR8fHxOHbsGBYuXIiIiAgMHz68VeyW15TjaPhRfHvvWyjRleA+wh0K\nMgotmtNMwwxZZVnIKc+BiooKDA0NxRq0REVFISEhgZ+eyWPGjBlgsVi4ceOG2GwB4Nff8VbUwz5x\nRQlaGuD1VOkJFboKPxg2NTWFnJycRAK8oKAgKCoqwszMDIQQROREwFLTskMplLkYuWCI7hD8783/\nBNYIUBSFX375BW/fvv2iH4TEyeeBP29HRZw7eDxmGM7AUouluJV4CwdCDrRoLp8EHyjLKMOph5OY\nvBPOuD7jYNjVEAdDD6KaLVhdkqIouLu7Izc3F9u2bat3/Pz58yguLm5QXMXvox8+FH3AQrOFrfp3\naaVphYSCBH6NpCTr8OoJrOREgqnObPT9mqqZ1qnrLi8vR2xsrNj9E0Z6ejp8fX0xb948yMjUD+D+\nivsLNIrW4npmOx07dJPrhjsf7tR53cnJCRoaGl90mmZ0dDR0dHTQtWvXToEVAcxlzAUhBOdjzgsd\nU8OpwconK5FclIz9w/ejr2rfZtlyNnTG5H6T8Wfkn3iU8qi5Lrc7JBbgEUIyCSGh//y7BMA7ALqS\nstdJx+LPP/+EtLQ0tm3bJrQ+Q5ywOCxcibuCsdfH4ljEMTjoOuD8mPPQUmz5jiFvZ6p2mqY4a8u8\nvb1BURQmTqxbe2NlZYW+ffvym5+Lg7S0NHz48KGewIqOok6La9coioKZuhn/c5KRkYGlpaXEdvBs\nbW0hLS2NzLJM5FbkSuQhXpJQFIXt9ttBp9FxOFxwS4SZM2dCX18fu3fvbmXvOibBwcFQV1dH377c\nB4HInEjIS8tL7OFqMXMxXIxc4BHtgbNvG25iL4yS6hI8SnmEr3t/LVR5UZxIUVL42fpnpJem40qc\n8HuLlZUVFi1aBHd3d/5uBMDNODh8+DBsbGwwYMAAgecSQnAy8iR6qvTEqJ6jBI6RFFZaViAgfKVT\nfX199O7dWyIBXlBQEPT19aGrq4uiqiIkFyfDXLPx+5CJmgnSS9NRUFnQJkIrZ8+eBZvNxoIFC+od\nK68ph0+8D0b1HAVNBeGN60VBWkoao3uNxrO0Zyit/lcRWFpaGjNmzMDt27dRUvLl1UYB3ADPxMQE\nbA4bSYVJnQIrn6GrpIsxvcfg2vtrKKysnyVACMGO4B0IzgzG5kGbMVBnoIBZRIOiKGwcuBFMdSY2\nBm5EQkFCS1xvN7RKDR5FUb0AWAIQVLk9iKKoCIqi7lEUZSrk/EUURb2hKOqNuMUrxEFYWBjc3d3b\n2o0OQ2VlJc6ePYtJkyYJTd8RF4QQPP74GJNvTsb24O3oqdITl8Zewv8c/wddJfGsNxirGUOakq6T\nevjp0yekpaWJZf7r16/DwcGhXvoqL03Tz89PbKIuvPo7Xg0QIQRh2WEt3r3jYaZhhsTCRH6fN1tb\nW4SEhIg1/aiiogJhYWH1dmkkKcEuKdTl1THNYBoef3wsMFVFRkYGK1euxLNnz/4zzYFbQlBQEAYO\nHFi3wbm6WYtStBuCoiiss1uHMb3GYH/Ifr6KbFP4O/lvVLIrJZ6eWZvB3QdjgM4AnIg80aD4wI4d\nO6CiooIVK1bwF7QePXqE2NhYuLm5Cd2pCkwPxLv8d5jPmC+xz14YZupmkJaS5jc8B4Bhw4bBz89P\n7KrEtUHJ3xsAACAASURBVBuc8zIXmOqN34dM1biPQjF5Mejfvz+UlJRaLcDjiauMHDmSvxBSG98k\nX5TUlMDFWDz1zGN7j0UVuwqPUx/Xed3FxQWVlZXw8fERi532BIfDwbt372Bqaor00nRUsis76+8E\nMJ8xHxWsClyOvVzv2Om3p3E9/joWmi3EZIPJLbYlS5PFfsf9UJBRwAr/FU1WQW6PSDzAoyhKCYA3\ngJ8IIcWfHQ4F0JMQYg7AHYDAv2RCyJ+EEBtCiI2GhoZkHW4Gvr6+WLFiBbKzs9valQ7BtWvXkJeX\nhx9++EGidiJyIjD3/lys8F8BiqJwaPgheHztIfYHfVmaLPp368//Ahdnbdn79+/x9u3beumZPJyd\nncFms3H9+vUW2wK4AZ6SkhLMzbmrzOml6cipyBFfgKduBg7h8Hvc2NnZoaKiAjExMWKZHwA/YKzd\nWFiOJof+XfuLzUZr4mzkDAICrzjBgjoLFixA165dsWfPnlb2rGNRUFCA2NhY/gN3JasScflxEg/8\npSgp/D7kdwzuPhjbgrbB/2PT5N9vJNxAny59xNLGQVQoisLP1j+jsKqwwZ1HdXV1bN++HX5+fvxU\ncXd3d2hqasLZWXAPKgA4FXUK2oraGN9nvNh9bww5aTkw1Bh1Gp6vWLECxcXF2Llzp9jsZGVlITk5\nuc59SIqSgqm6wHXsOhirGQPgBnhSUlKwtraWaEuZ2jx8+BApKSkCxVUIIfCM9YRxN2NYaDRPdOtz\nzDXMoaukW09Nc9CgQejRo8cXmaZZW0EzvjAeQKeCpiD6de0HR31HXHp3ib8oDAD3P9zHwdCDGNN7\nDNwshaeBNxUtRS3sd9yPjLIMrAtYV6dHY0dEogEeRVEy4AZ3lwgh9Z5ACSHFhJDSf/59F4AMRVFN\nq5BsB4wfPx6EkM46GBE5fvw4DAwMJFZ3l1KcgpVPVmL23dlIKU7BrwN/xfVvrmN4j+ESq/UwUzfD\n29y3YHPYsLCwgLS0tFhWXHmB2+TJgleomEwmDA0NxZam+ezZM9jb2/Ob2vKaAoszwAO4DzuAZIRW\nBNVZmaqbQlqq4Ua97RVdJV046jnC+713HbU5HkpKSli2bBl8fHwQFxfXBh52DF69egUA/AfumLwY\nsAirVVJ3ZWgyOOB4ACZqJljzbA1CPonWWDupMAmROZGY3G9yq9ePmqqZYmzvsbgQcwGfyj4JHbd4\n8WKYmZlh5cqViI6Ohq+vLxYtWgRZWVmB499kvUFodijmms5tkUBHS7DUskR0XjQqWVyVRgsLC8yZ\nMwcHDx5EcnKyWGwEBQUBqFt/10+1n0itZpTpyuil0ou/EGZjY4OIiAhUVwuuiRQnJ0+ehIaGRr2S\nAIAr9pNQmAAXIxexXY8URWFs77EIzgyu0xZGSkoKM2fOxMOHD5GbK7hdTEeljoLmP+mAza0f+9JZ\nYLYAxdXFuPr+KgDuM8nGwI2w1LTEdvvtYr8vWmpaYr3degSmB3Z40RVJqmhSAE4DeEcI2S9kjPY/\n40BRlN0//uRJyidJYWFhge7du8PX17etXWn3REVF4fnz51i8eDGkpMR7+eVX5uP/Xv4fJvlMQmB6\nIH40/xF3p9zFDMMZEn+4Z2owUc4qR1JREuTk5GBmZiaWoMXb2xt2dnbQ19cXeJyXpvnkyRN8+iT8\nIUwU8vLyEB0dXa/+TklGSWyri13lukJfWZ+/29mvXz906dJFrAFeUFAQ+vTpA01NTVSxq/Au/12H\nq7/7HFdjVxRUFeDeB8GLSMuWLYOsrCz27t3byp51HIKCgkBRFH9RgbfI0Fo7YwoyCjjidAQ6ijpw\n83NDXH7jwbhPog9oFA3j+7b+ThcAuFm6gU3YOBZxTOgYaWlpuLu7IyUlBaNGjQKNRmswO+NU1Cl0\nk+uGqQaCsxJaA2tNa7A4LP59CAC2b98OGo2GDRs2iMVGcHAw6HQ6rKyswCEcROZGNmm32FjNuE6A\nV1VVVafWURJkZmbi1q1bmDt3rsDa+Muxl6Eqq4oxvceI1e7Y3mPBJmw8SH5Q53VXV1ewWCxcu3ZN\nrPbamjoKmoXx0FPSa7HY25eKuYY5bLVtcT76PBILE7H88XJoK2rj4PCDkKUJXkRqKTMMZ2CqwVSc\njDpZ75rsSEhyB88ewLcARtRqgzCWoqgfKIri3f2nAXhLUVQEgEMAZpIOqPdNURTGjRuHv//+u1VW\n2DoyJ06cgKysLObOnSu2OStYFTgZeRJjr4+FV5wXJhtMxp3Jd7DEYkmr3TR5D4m1G56/efOmRUIr\nKSkpePPmjdD0TB7Ozs7gcDjw9vZuti0ACAzkSlV/3uDcXNNcrHUyZupm/HpFKSkp2NjYiC3A+7zB\n+bu8d2BxWB2y/q42dtp26KfaD5ffXRZ4TWlqauL777/HhQsXkJGR0QYetn+Cg4PBYDCgrKwMgLuz\nq6ekBzV5tVbzoatcV/w56k/Iy8hjyaMlSCsRXqfL4rBwO/E2HHQdmiz9LS70lPXgbOiMGwk3kFgo\nvF/lsGHD4OzsjMzMTEyZMgW6uoLrm6Nzo/E84zm+M/muVQRjhGGhaQEKVJ00TT09PaxatQqenp78\n3d6WEBQUBCsrK8jKyiK5OBkl1SUi1d/xMFUzRVZZFvIq8lpNaMXDwwMsFkuguEpmaSb8U/0xxWCK\n2H93/br2g0FXA9z9UDdNk8lkwtjYGJcv16/B6shER0eje/fuUFVVRUJBQqsJrBA2GyWPH4NIoOej\nJFnAWIDsimy43HEBAcHRkUfRVa6rRG1uGLAB5hrm2PR8E+IL4iVqS1JIUkUzkBBCEUKYtdog3CWE\nHCeEHP9nzGFCiCkhxJwQMpAQ8kJS/kia8ePHo6SkhP+Q3El9SktLcf78ecyYMQNqai1/qGJz2LgR\nfwPjr4/HobBDsNO2w/VvrmPzoM3QUGjdWs2eKj2hTFeuo6RZWFiIhITmqzHxalqmTJnS4DhTU1OY\nmJi0uOl5QEAA6HQ6f4ejqKoICYUJsNQQT3omD6YGE9kV2XzREFtbW0RGRoqlqW1qaioyMzNbRQa/\nNaEoCi5GLniX/w7hOeECx6xatQqs/2fvzOOiKtv//z4zrLKvKiiyuKGCivuKS4op7oppuZSVLY+V\nlZlly/Mr7Vta+Wg+j2VWtmiuuURumQsamIqCAioIKCqy7+swc35/4IyMM8AAM2zyfr14veqc+5z7\nBsbDue7ruj6fsjL+85//1PPqGj8KhYKzZ8+qAn+ldYYuiob6pq1lW74Z8w0l8hIWHV1ERpH2opW/\n7/5NelF6vYqraON53+dpZdSKtRfWVjluzZo1DB48mOXLl1c6ZtPlTViZWDGrS+X9efWBjakNHe06\nqvnhAbz11ls4Ozvz5ptv1mlzTiaTcf78+QfPodSaP4cqCq14eXlha2tr0ABPoVCwadMmRo4cSefO\nmv3Kyh5gQ/3uxnuMJyItQm3TQxAEZs+eTUhICElJSQaZtyGIjo6mW7dulMpLuZl7s94EVoqvXOH2\nSy+Traee/fpikMsgvO29KVOUsW7kOjpYdzD4nCZSE74Y8QWWxpZNVnSlXlQ0HwVGjx6NqalpS5lm\nFWzbto28vDy9iKuEJYcx48AM3v/7fdpYtOGHcT+wbtQ6PG099bDSmiMRJGqZKX30lu3evRtfX186\ndqx+d2/WrFmEhITUKXtz6tQpBgwYgJlZ+e6sMjjya+1X63tqQ2V4fr88qn///pSVlXHpkvbApSYo\n+14qGgu7Wro2WAZEnwR6BmJlYsXWGO272Z6ensycOZONGzeSk9P0/hgZkmvXrpGdna164U4pTCGt\nKK1GGRV94mXrxYbRG0grSuPFP19Uk4hXsjduL3amdvVmAl4ZdmZ2LPRZyInbJ6rsHWzXrh1nzpyh\nVy/t4hs3sm9w7NYx5nSdg6WJpaGWqzN+zn5cSr1EmeKBgq+VlRX/7//9P0JCQti3b1+t7x0ZGUlR\nUdEDgZX0yPK+Oht3ne/h7eCNgEBURhSCINC3b1+DBnjHjh0jISFBq7hKcVkxu2N3M6LdCFwsXQwy\nv7Ls81DiIbXjs2eXq3XWdQOzsaBQKIiOjqZ79+4k5iZSJpbVm8CKmY8PUidHCgxgCWJIBEFg/aj1\n/Br4q97fR6rCuZUzX4z4guSCZJadWtbkRFdaAjw9YWFhwciRI1sCvEoQRZH//e9/+Pj4qP7o1Ya7\n+Xd5/cTrPHfkOYrKiljjv4afx/9Mn9Z99Lja2uHj6ENsdiyFssI6m3jfu3ePM2fOVJu9UxIUFIQo\nirXuVcjPzyc8PFyj/85IMKKHY49a3bMyutp3xVhirNdgWElYWBjm5ub4+pa/uEem1azvpTHTyrgV\n0zpO4+jNo5WKXixbtozc3Fw2btxYz6tr3DwsvKPMgjZkZreXcy8+9/+c2KxYXj3+qpqATlZxFseT\njjPBc0KDCZFU5EnvJ8tfdi58UevM1reXv8XcyJynvJ/S8+pqh5+zH4VlhVzPuq52fOHChXh7e/PW\nW28hk8lqde/KDM4lgu6vXBbGFrjbqAutXL58WS+VDtrYtGkTDg4OWgW9DiUeIrskmznecwwyN5SL\nSfV27k1wvLrpeceOHenXr1+zUdO8efMmhYWFagIrnewMn8GTpaYilpRgPTaA/FMhKAoKDD6nPmlt\n0bpBlLB7Offi3QHvYmFsgUxRu+dBQ9ES4OmRwMBAYmNjuX79evWDHzHOnz/PxYsXeeGFF2qlelQi\nL2FjxEYm751MyO0QFvdezL4p+whwD6h3dbnK8HXyRSEqiM6IxsjIqE4m3nv37kUURY3+O5lCxo5r\nO1Tqb0q6du2Kr69vrXc5Q0NDkcvlagFeeEo43g7emBuZ1+qelWEiNaGrfVdVOaurqytt2rTRS4AX\nGhpK3759MTY25l7BPVIKU5p8eWZFZnWdhUJUsOO6dtXU3r17M2bMGNauXUtJiabi5qNKWFgYtra2\ndOnSBSh/4TaVmja4dcawdsP4aOhH/HPvH5aHLFftEAfHB1OmKNOLv5M+MDcy51+9/kVkWiR/3vqz\nxtcn5SVxMOEgMzvPxNbM1gArrDnKTEDFPjwoF41ZvXo1sbGxfP3117W6d2hoKC4uLrRv354CWQFx\n2XG12mjq7tCd6PRyC5m+ffsik8m4fPlyNVfVnJSUFH777Tfmz5+voX4qiiJbY7biZeNF/zb99T53\nRcZ7jCcuO04j6J49ezbh4eHNQiVYGaj6+PgQlx2HkWCEu7W7wedN/b//I37yFKzGjEEsKSG/iWXx\nGpIZnWewxn9Ng/YN14aWAE+PTJgwAYDg4OBqRj56bNy4EQsLC556qma7t6IocvzWcSbvncyGSxsY\n3m44+6fs53nf5w2moFRblJmuin544eHhtTLx3r17N507d6Z7d3XPpEMJh/go7CP2xmlaRs6aNYu/\n//67Vr0KISEhSCQSBg8eDECpvJSojCh6OevH6+hhfBx9ymXqFWUqZcO6ChuUlJRw8eJFNd8paPr9\ndxVpb9Ue/3b+7Lq+i1K5dkGnZcuWce/ePX766ad6Xl3jJTQ0lAEDBqiUeyPTIunu0L1RZMcCPQNZ\n1m8ZR28eZeXZlYiiyN64vXRz6NbgAWhFJnlNoqNtR/4T/p8a72R/f+V7JIKE+d3nG2h1NaeNRRtc\nLV01+vAAxo8fz6hRo/jwww9rVe4cGhrKwIEDEQSBqPQoFKKi1gFealEqaYVpKqEVQ/jhbdmyhbKy\nMp577jmNcxFpEcRkxujVGqEyxrqPRSpINTzxZs2ahSAITT6Lt2/fPlasWMGMGTPo378/sVmxuNu4\nG/w5JEtJIffIUaxGjaJVv75IHR3JPdJ01SEbgsaSSKgJLQGeHnF3d6dHjx4tZZoPkZ2dzbZt23jy\nySextrbW+brEnERePPYirxx/BTOpGd+O/ZbPR3xOW8u2Blxt7bE3s8fV0lUtwKuNiXdmZibHjx9n\n2rRpGg8VpcrYkZuaD+egoCAAdu7cWeO1h4SE0KtXL9XvJzojmhJ5CX7Ohql393HyoaisSKXM169f\nP65du1an3rHw8HBKS0vVBFZMpaZ0seuilzU3FuZ4zyGzOFOjV0XJqFGj8PPzY/Xq1cibmFqaIcjL\ny+PKlSuqz0WpvJTojOhGVbr7VLeneM7nOXZe38myU8u4lnWtwcVVHkYqkfKa32vczL3J7uu6K/am\nFKSwN24vUzpOwbmVswFXWHP8nP0ITwnXKDsVBIE1a9aQmZnJJ598UqN7pqamEh8fr9Z/B7Wz41Ca\nokdnROPm5oajo6Pe+/CU4irDhw+na9euGue3Xt2KlbEVE70m6nVebdib2TPQZSAHEw6q/U5cXFwY\nMWIE27Ztq5P4TUNy8eJF5syZQ9++fdmyZQsSiYTY7Nh66b/L+vVXkMuxe3IOglRK+w1f0fbf/zb4\nvC00LC0Bnp6ZMGECp06dahE5qMCPP/5IUVGRzuIqhbJCvrzwJVP3TyUiNYK3+r3Fzkk7GdB2gIFX\nWnd8HX3rbOK9f/9+5HK5RnlmRlEGoXdDsTax5vy982qmsFDeq+Dn51dj0/OSkhLCwsLU7BEupZb3\nKBkqg6cUt6gotAJw4YJuBtDaeFhgJTItkm4O3RpFlkafDGw7EE8bz0otEwRBYNmyZVy/fp39+/c3\nwAobF+fOnUMURdXn4mrmVWQKWaMK8KDcc256p+kcTDyIscSY8R7jG3pJGgxvN5y+rfvyv4j/USDT\nrYfnx+gfUYgKnunxjIFXV3P8WvuRUZzBrbxbGud69+7N3LlzWbt2LTdv3tT5ng/330WkReBu7Y6N\nqU2N19fFrgsSQWJQoZUTJ04QFxenVVwlrTCNo4lHmdxxcr1ZDk3wmMDdgrsqkS8ls2fP5vr161y8\neLFe1qFP7ty5w8SJE3FwcGDfvn20atWKQlkhd/LvGDzAU5SUkL19B5YjR2Jy30/XvGdPpDXYbG+h\nadIS4OmZwMBAysrKONKS/gbKSyw3btxI//796d27arl9URQJjg9m4m8T+e7Kd0zwmMCBqQeY220u\nxpKm8ZLu4+RDSmEKqYWpdOrUCWtr6xr/Qd69ezdubm706aMuHHM48TByUc57A99DROTPm5q9MLNm\nzeLs2bMkJibqPN+FCxcoLi5W779LDcfNys1g6pPtrdpja2qrCvD0UX4UFhaGu7s7bdq0QSaXlWdp\nGkgl0ZAoLROiMqJU2YGHmT59Ol5eXnz66adNdsdbXygDf+UmQmMt3RUEgRUDVxDUOYhnejxTq4DA\n0AiCwOt9XiezOJMtUVuqHZ9VnMXO6zsZ7zGedlbt6mGFNUNZofBwH56Sjz/+GEEQePfdd3W+Z1hY\nGEZGRvTp0wdRFOsk9NTKuBWeNp5qQitRUVEUFhbW6n7a2LRpE3Z2dlr9Vnde30mZWMYTXZ/Q23zV\nMcptFKZSUw2xlenTp2NsbNzkPPEKCgqYNGkSOTk5HDhwgLZtyyuQlNUrhvbAKwgJQZ6Zif1TT6od\nz961i7QNGww6dwsNS0uAp2cGDhyIvb19Sx/efUJCQoiJiak2e3ct8xpPH36at0PexrGVIz+P/5mP\nh37c5OTtK1oA1MbEOy8vjyNHjmgtzwxOCKazXWfGeYzD08aTw4mHNa6fOXMmQI2yeKfuN1srAzxR\nFLmUeslg2Tsof1Hs4dhD9bLt4OCAp6dnnQI8Zd8LlGdpShWlDeJzVh9M8pqEpbElv8T8ovW8VCrl\nzTff5OzZs6rfb1WUlJRw9+5drly5wqlTp9i7dy+bN2/miy++4MaNyg2umwJhYWF4e3tjZ1dujBuR\nFkEbizaNrlwQwEhixHuD3uNfvf/V0EupFB8nH8Z2GMsPUT9oVBE8zM8xP1NUVsRCn4X1tLqa4WHj\ngZ2pXaX2D+3bt2fJkiX88ssvOm/UhYaG0rt3b8zNzbmTf4fM4sw6bSZ0c+hGdEY0oijSt29fFAqF\nXixlANLS0tizZw/z5s1T2eMokcll7Ly+k6GuQ+vFd0yJhbEFI9qP4MjNI2q9nvb29gQEBLB9+3YU\nCkW9racuKBQK5s6dy8WLF9m2bRs9ez74HMRllytodrY1bJ+t5ejRuO/cQauH1MuLIiLJ3PwdCgOp\nsrbQ8LQEeHrGyMiIxx9/nD/++KOl/4VycRVbW1tmzdJujppTksOqs6sI+j2IG9k3+GDQB2wdv7XR\n7a7rireDN0YSIzULgMjISJ0VDYODgyktLdXYTU3KTSIyLZIJnuVCPgHuAVxIuUBaYZraOA8PD/r3\n71+jAC8kJISuXbvi5FRuDp+Ym0hWSZbB+u+U+Dr6ciP7hqrUqy5CK7dv3+b27dtq/nfKOZojrYxb\nMaXjFI4mHiW1MFXrmPnz5+Ps7Mzy5ctZvXo1b7/9Ns8//zwzZsxg1KhR9OzZk/bt22NhYYGZmRmu\nrq74+Pjg7+/P1KlTefbZZ3njjTcYOnRojTLCjQlRFAkLC1MF/vBAsr6F2vOq36vI5DI2RlRux5Ff\nms+2mG085vYYXrZe9bg63REEgd7OvbUKrSh5++23cXJy0sn8vKysjHPnzqmVZwJ1Kgfu7tCd9KJ0\nUgtTVWX/+irTXL16NaWlpVrFVY7ePEp6UTpzuhrOGqEyxnuMJ7M4k7PJZ9WOz5kzh9u3b3P69Ol6\nX1NteOedd/jtt9/4/PPPCQwMVDsXmx2LmdQMVytXg65BEATMfXw0NoytAgJQFBZScOaMQedvoeFo\nCfAMwIQJE0hLSzOI2lVTIjU1lV27djF//nxatdKs3z+UeIiJv01k+7XtBHUO4vepvzOj8wykEmkD\nrFY/KEU9KgqtyGQyIiIiqrmynN27d9O6dWsNr8DghGAEBFVfztgOY8vLNLVIlgcFBXHhwgXi4uKq\nnU8ul3P69Gm18kxl/11v56pLauuKj5MPIiJR6eXlR/379ycpKYmUFO0eb1WhzXeqjUUbWlu01t+C\nGxmzu85GLsrZeV27qI65uTlvvPEGoaGhvPXWW3zxxRccOHCAmJgYZDIZ7u7ujBkzhhdffJGVK1fy\nv//9j+3bt/Pnn38SHh5OYmKiqnx33LhxZGRk1PN3WHdu3LhBenq66nORVpjG3YK7TXYDqbHgZu3G\njM4z2HV9Fwk5CVrH/HrtV/JkeTzr+2w9r65m+LX2IykvSWOzTIm1tTUffvghJ0+e5MCBA1Xe68qV\nKxQUFKj1AZsbmdepz6qbQzcAojKicHFxoW3btnoJ8Pbt28fq1at57rnnNNSaoVxcxc3KjSGuQ+o8\nV00Z6joUKxMrDiYcVDs+adIkWrVq1STUNL///ns+/fRTFi1axGuvvaZxPjYrFi9brxp5I9aUu+++\nS8rq1VrPWQzoj8TGhtzDmpVALTQPWgI8AxAQEIBUKn3k1TS///57ZDIZixYt0jiXV5rHe6ffo61l\nW3YE7uDdge82yp6T2uDj6MOV9CvIFfIaCa0UFRXxxx9/MHXqVKTSB0GusjexT+s+tLFoA5TX7XvZ\neFVZpqmLmubly5fJzc1VE1gJTw3H1tQWDxuPaq+vC8pyVmUfWV0Mz0NDQzEzM6NXr/Ky0oi0iGaf\npXGzdmNYu2HsvLYTmVy7bP3SpUu5c+cOeXl5lJSUkJycTFRUFCEhIezbt4/vvvuONWvW8M477/DC\nCy8QFBTE6NGj6d27Nx06dMDPz48DBw6QmJhIYGCgXnt/6gNl4P+wdUZjE1hpirzQ8wVMpaasC1+n\nca6orIifon9iiMsQujtoBg+NiT6ty3udq8riPffcc3Tp0qVa83Nlv2fFjaYejj0wkhjVen1d7Lsg\nFaRqfXh13TyOjY1l3rx59O3bl3XrNH9/URlRRKRF8ETXJwwagFSGidSEMR3G8OfNP9U8Xy0sLJg0\naRI7d+6stQl9fXDixAmef/55xowZw/r167VK7MdlxxlUYEWWkkrOvv0g117OKhgbYzV6NPl/HUdR\nqt1yp4WmTUuApwdO3T7Fx2Efq/7f3t6eIUOGPNJ9eAqFgq+//hp/f3+8vb01zv8R/wfF8mLeH/g+\nXeybl4y9j5MPhWWFxOfE0759e5ydnXX6g3z48GEKCws1yjOjM6NJzE1UlWcqCXAPIDwlXGPn2c3N\njUGDBulkev5w/x2UZ/B6OfUyuO+LjakNHaw7qMpZ/fz8kEgktXp5CQsLo0+fPpiYmDxSWZo5XeeQ\nUZzB4Zvad2EFQcDFxQVLS8ta/z6HDh3K1q1bOXv2LLNnz66Vr2NDERoaiqWlJd26lWdBItIjMJIY\n4e2g+UxqoWY4mDvwdI+n+fPWn6qsv5I9sXvILM7kOV/N0r/GRhf7LpgbmVcqtAJgbGzMZ599xrVr\n19i0aVOl48LCwmjdujXu7u4UlxVzNfNqnTeazI3M8bL1IjrjgeH5tWvXyM3NrdX9CgoKmDZtGsbG\nxuzatUuj9w5gW8w2zI3Mmdxxcp3WXhfGe4ynsKyQk7dPqh2fM2cOGRkZHD16tIFWVjWxsbFMnz6d\njh07smPHDoyNNQXisoqzSC9Kp5NdJ4OtI3v7A2uEyrB+fBxm3bsjT6+6l7aFpklLgKcHEnIS2H5t\nO8n5yapjgYGBXLp0idu3bzfgyhqOo0ePkpCQUKm4yu7Y3XSx66IqP2lOVBRaUZp46xK07NmzBzs7\nO/z9/dWOB8cHYywxZkyHMWrHx7qXl2kevan5h27WrFlERERw7dq1KucMCQnBzc2NDh3Km+gzijJI\nzE2kd2vDlmcq8XH04XL6ZURRxMLCgm7dutU4wCstLeXChQtqu+bwaGRpBrkMwt3ana0xhlWWmzZt\nGuvXr2f//v28/PLLTUaZMywsjP79+6sy4pFpkXSz74ap1LSBV9Y8mNdtHo7mjnx54UvVZ0Iml/H9\nle/xc/ZTZccaM8YSY3ydfDmXcq7Kz/XEiRPx9/fngw8+qNQGqaLB+dXMq5SJZXp5DnV36K4mtCKK\nYq3sAkRR5PnnnycqKopt27apnvsVySzO5GDCQSZ6TsTapOGk9Pu27ouTuZOG6XlAQAB2dnaNskwz\nUmW94wAAIABJREFUMzOTCRMmIAgCv//+O7a2tlrHKQVWOtkaJsBTlJaStX0HliNGqKwRtGE5bBgd\ntvyAsYuLQdbRQsPSEuDpgcEugwEITQ5VHZswoTzb8qhm8TZu3IiTkxPTpk3TOBedEU1MZgzTO083\neJaoIehg3QErEys1P7yYmBjy8vIqvaa0tJT9+/czefJktR0/uULOoYRDDHMdplHC6mXrRUfbjlrL\nNGfMmIEgCFWKrYiiyKlTp9Szd2n103+nxMfRh7SiNFIKy/vulEIrNQkgLl68SElJyQOBlfQIjCXG\nzXLz4GEkgoTZXWdzOf2yKhNqKF5++WWWL1/ON998w0cffWTQufRBYWEhERERqs+FTCEjKj3qkQj8\n64tWxq14seeLhKeGcyLpBAC/x/9OSmFKk8jeKXnM7TFis2I5nnS80jFK8/P09HQ+/fRTjfMZGRnE\nxsZqCj3p4fPWzaEbmcWZ3Cu4p7LPqU0f3ldffcXWrVv5+OOPGTNmjNYxe2L3UKooZXbX2XVac12R\nSqSM8xhHyJ0QckoeBNQmJiZMnz6dvXv3NqqS8dLSUmbMmMHNmzfZu3cvXl6VCwspAzxDWSTkHTyI\nPCMDu4esESqjLCsLsRGXvLZQO1oCPD3Q0bYjTuZO/H33b9Uxb29vPDw8Hsk+vNu3b3PgwAEWLlyI\niYmJxvk9sXswlZo2SiNffSARJKrMFKDacQ0Pr7wE6K+//iInJ0ejPPOfe/+QVpSmUZ6pZKz7WC6m\nXtRQUnR1dWXo0KFVlmnGxsaSmpqq1n93MeUiJhKTeuubUb78KIPh/v37k5GRUSPVxof7rCJSI/C2\n98ZEqvnZa45M7jgZC2MLtl41vD/UypUrmTdvHh988AGbN282+Hx14fz588jlclVmNzYrlmJ5cUuA\np2emdZqGu7U7a8PXUiovZfOVzXjbezPEpf7FOWrLjM4z6Gjbkc/OfabW8/Uwffv25cknn+TLL78k\nKSlJ7Zy2fk9XS1e9WP0on8dRGVG0bt2a9u3b1zjAO3PmDK+//jqTJk3i7bff1jqmTFHG9mvbGdBm\ngMH92XRhvMd4ZAoZx24dUzs+e/Zs8vPzG837lSiKvPTSSxw/fpzNmzczdOjQKsfHZcVhbWKNk7mT\nQdZj5uuL40svYTF4cLVjC8MvEjt0GAVhZ6sd20LToiXA0wOCIDDIZRBhyWHIFXLVscDAQI4dO0ZR\nUVEDr7B+2bx5MwqFQqv0clFZEcHxwYzpMKbZiKpow8fRh7jsOAplhTqJh+zZswdLS0see+wxtePB\n8cFYGlvi395f63UBHQKqLNOMiooiKipK67UhISGAev/dxbSLdHfsXm/BURe7LphITNRUR6FmQiuh\noaG0b98eFxcXZIr7BueP0Eu8hbEFk70mcyjxULW+ZHVFEAS+/fZbAgICWLRoUaOuUFC+cA8YMABo\nvAbnTR0jiRGv9XmN+Jx4lpxYws3cmzzn+1yTqs4wkhjxzoB3uJN/h++vfF/l2JUrVyKKIitWrFA7\nHhYWhlQqVWXYItP1Z8fR2b4zRoKRWh9eTQK8e/fuMXPmTNzd3dmyZQsSifZXvxNJJ7hXcK/Bs3dK\nujt0x83KjT8S1Ms0/f39cXV1Zf369Y2iXHzNmjVs3ryZFStW8NRTT1U7PjY7lo62HQ32b8TUwwOn\nVxbrdH+z7t2QmJmRd6RFTbO50RLg6YnBLoPJKckhJjNGdSwwMJCioiKOH6+87KO5UVZWxqZNmwgI\nCMDT01Pj/NGbR8mX5TO903QtVzcffJ18UYgKojOicXZ2xs3NrdKgRS6Xs3fvXgIDA9Ua3ovLivnz\n1p881uGxSnuGPG096WTXiSOJRzTOTZ8+HYlEUmmZ5qlTp3B0dKRr166q+aIzouutPBPAWGpMV4eu\nqpdvHx8fTExMahTghYWFqXbNr2ddp1he/Mi9xM/uOpsyRVmllgn6RCnO0KtXL2bOnMnZs41z5zcs\nLIyOHTuq/B0j0iJwNHekrUXbBl5Z82NU+1H0curFqdun8LDxYLTb6IZeUo3p16Yfj7s/zuYrm7md\nV3nvfIcOHXjttdf46aef1KoyQkND6dmzJxYWFqQUpHCv4J7eNppMpaZ0suukUtLs168fcXFxZGVl\nVXutTCZj1qxZZGdns2fPnkr7wqDcGqGtRdtKNxTrG0EQGO85nn+S/1ETE5NKpaxYsYLTp09Xa11h\naPbu3cuyZcuYOXMm//73v6sdL4oicVlxBhNYyfzpZ4ouXap+4H0kpqZYjhxJ3tE/EZuQgFYL1dMS\n4OmJgW3Ly4BC7z7ow/P398fCwqLRlBHUB7///jt37typXFzl+m46WHdoEs33daGHYw8AtcxUZTuu\nISEhpKWlaZRnnrx9kgJZQaXlmUrGdhhLeGo4KQXq/nFt2rTB39+fHTt2aN3lDAkJYdiwYapdvivp\nVyhTlNVrgAfl2c6YzBjKFGWYmJjQq1cvnQO85ORkbt68qSGw8qgFeO427gxxHVKlZYI+sbS0JDg4\nmLZt2xIYGMj169cNPmdNEEVRJXihRGlw3pQyS00FQRB4o+8bSAUpL/i+0CDS+vrg9b6vIxEkrD6n\n3TtMyfLly7G3t1eZn8vlcs6ePfvgOZSuf6Gnbg7diMqIUgmtAFWW/St5++23OXXqFJs2bcLHx6fS\ncbFZsZy7d45ZXWbVydZB3zzu8TgiIocSD6kdf/bZZ+nSpQvLli1rMGXf8PBwnnzySfr161dlZrQi\nKYUp5MnyDGKRIEtJJeXTT8k9eKj6wRWwChiLPDubwkfcu7m50TSfwo0QB3MHvO291frwTE1NGTNm\nDL///nujKCOoDzZu3Ei7du1UIjMVic+JJzw1nGmdpjX7lyx7M3vaWbZTC/Di4+O1mkXv2bMHMzMz\nxo0bp3Y8OD4YJ3Mn+rXuV+VcY93HAmg1PZ81axZXr17l8mV1AY7bt2+TkJCgXp6ZWq7K1suplw7f\nof7wcfShqKxI1XiuDIblcnm11yp9pyoKGziZO6n8Ah8l5nSdQ1pRmtZyXUPQunVrDh0qf5EYN24c\n9+7dq5d5deHWrVvcu3dP9cKdVZzFrbxb9HR+tAL/+qSXcy9OBJ1gvGfT7a1uY9GGRb6L+CvpL07f\nOV3pOBsbGz788EOOHz/OH3/8QXR0NPn5+Wr9d8YSY7rad9Xb2ro5dCOnJIc7+XdUZaDVbYTt2LGD\nL774gsWLF/Pkk1ULbmy7ug0TiQnTOmkKozUknjaeeNt7a6hpGhkZ8emnn3L16lW+/fbbel/XnTt3\nmDhxIo6Ojuzbtw9zc3OdrlM+nzvbddb7mrK3b6/WGkEblsOGIbRq1WJ63sxoCfD0yECXgVxKu0SB\nrEB1LDAwkKSkJI0X7OZIfHw8hw8f5rnnnsPISHMH8LfY3zASjJjkNakBVlf/+Dj6qClpgqbymUKh\nYM+ePYwbNw5LS0vV8ZySHELuhPC4x+NIJVKqwtPGk852nbWqaU6bNg2pVKohtqLsv1MTWEm9iKeN\nJ7ZmlZfwGAJln0pFoZWCggKuXr1a7bVhYWGYmJjQu3dv1T16OvVs9hsI2hjqOhQ3K7d6EVtR0qlT\nJ4KDg0lJSWHChAlVKsUamoKCAvbt28ezzz6r6rtTbmCorDP01BPVgnbq+9lhCOZ2m4u7tTv/98//\nUSqv3AB60aJFdOrUiaVLl6qepxUrCbo5dNNrL3N3x3KhleiMaOzt7fH09KyyDy86OppnnnmGwYMH\ns2bNmirvnVOSw+/xvzPeczx2ZnZ6W7O+mOA5gSsZV7iZe1Pt+KRJkxg2bBgffPBBvT57CgoKmDRp\nErm5uRw4cIA2bXTbUDx95zSfn/+cYa7D9F5lUm6NsB1Lf39M3NxqdK3EzAzXNatxePZZva6phYal\nJcDTI4NdBlOmKOP8vQcP3fHjy3czG7MYgb745ptvkEqlLFy4UOOcTC5j/439jGg/Qi+qYk0BHycf\nUgpTSC1MrXTH9dy5c9y5c0fDTuLIzSOUKcqqLc9UMrZDuZrmvQL1LIqTkxOjRo3SKNM8deoUlpaW\n9OxZ/kdGISq4lHap3sszAdpZtcPO1K5WQiuhoaH4+flhampKRlEGSXlJj5TASkWUlgkRaRFEpWsX\n1jEE/fv3Z+fOnURERDB9+nRKSyt/KdY3ycnJbNq0SbWTPmXKFHbt2sXIkSPZv38/vr7ln4WItAik\ngvSRsM5ooW6YSE14u//b3My9yU/RP1U6Tml+HhMTw4cffoijoyNeXl7ldhwZ+rfj6GTbCWOJsaoP\nryqhldzcXKZNm4alpSU7d+7UqmZdkX1x+ygqK2o04ioPE+AegIDAwYSDascFQWD16tWkpqZWG8Tq\nC1EUWbBgAZcuXeLXX39VPWOq41rmNd48+Sad7Dqx2n91tRu3NeWBNUL1Ii/asBo1CpN27fS6phYa\nFp0CPEEQvARBML3/3yMEQXhFEISmv1WnZ3o798ZMaqZWptm2bVv69OnT7PvwSkpK2Lx5M5MmTcLV\n1VXj/PGk42QWZza68g9DojI8T7uMjY0NXbp00Qhadu/ejbGxMRMnTlQ7HhwfjIeNB9723jrNpSrT\nvKlZphkUFERcXJyaMW5ISAhDhgxRZVpvZN8grzSvQQI8QRDo4dhD5ePWpUsXrKysqg3wZDIZ58+f\nV5VFKQPER63/riKTO07G3Mi8XrN4UL6RtWnTJo4ePcrChQsNVpIuiiIRERF8/PHH9O/fHxcXF5Vx\n86JFizh27BhpaWls27ZN7d9UZHokne0608q4lUHW1ULzYojrEEa1H8XXkV9rbJpVZPLkyQwbNoy0\ntDQGDRqEIAhcz7pOibxE7wGeidRETWilb9++3Lx5k7S0NLVxoijy9NNPExcXx/bt23GpxsRaISr4\n9dqv9HLq1Wg3QNpYtKFP6z4ExwdrPFsGDBhAUFAQa9asITk52eBr+fHHH9m1axerVq3S2oqijdTC\nVF4+9jIWxhZ8NeorLIwt9L4uRUkJ5n37YDGkemuEysg9fISsnYYX6mqhftA1g7cbkAuC0BH4BmgP\n1O8bRBPAVGpKnzZ91AI8KC/TDA0NJT3dsBLmDcmePXtIT0+vVFxlT+we2li0UZnCPwp4O3hjJDFS\nNdz369dPLWgRRZHdu3czevRoNWWz5PxkLqRcYILHBJ1LDT1sPOhi16XSMk0jIyOVmmZGRgZRUVFa\n++/8nP1q/o3qAR8nH+Jz4skvzUcikdCnTx/++eefKq+JiIiguLhYrf/OSDBqtC8p9YGViRWTvSZz\nMOEgGUWa/Z6G5Omnn+ajjz7i559/Zvny5Xq7b2lpKUeOHGHx4sW4u7vTq1cv3n//faRSKatWreLy\n5cvcuHGDtWvXMmrUKIyNjdWulyvkXE67/MhmdluoHUv7LUUhKvji/BeVjlGanwMq7zOV0JOj/jea\nujt0JzojWk1o5cKFC2pj1qxZw549e/jss8/w969eDfP0ndMk5SUxx7tmfVv1zXjP8STmJnI1U7N0\nf9WqVchkMj744AODriEpKYlXXnmFYcOG8eabb+p0TaGskH8d+xe5pblsGL2B1hatDbI2u6AgOvz0\nU53aE3KDg0lbtw5RodDjylpoKHQN8BSiKJYBU4H1oiguBVq0prUwuO1gEnMTSc5/sJMUGBiIKIoc\nPHiwiiubNhs3bsTLy0vDxw3gTv4d/r77N1M7TtV7WUJjxlRqShe7Lmqlh8nJydy5cweAyMhI4uPj\nNcozlZ4/NRUrGOs+lktplzR2nO3t7RkzZgzbt29HFEVOny4XD3i4/87BzIF2Vg1TouHr6IuIyJWM\nK0D5zyoiIoKSkpJKr1EKrFTse+li3wUzI7NKr3kUmO09G5lCxu7Y3fU+97vvvsuiRYv49NNPWb9+\nvc7XiaJIdnY2165dIyQkhN27d7NhwwaCgoJwdHQkICCAzZs307t3b7799lvu3r1LaGgoy5cvp0eP\nHlW+1NzIuUFhWeEjndltoea0s2rHwh4LOZh4kHP3Kq8m6N+/PxcvXmTx4sVA+XPIUEJP3R26k1ea\nx+282/j5lW/GVSzT/Ouvv3j77bcJCgpiyZIlOt1z69WtOJk78Zib5t/uxsQYtzEYSYw0PPEAvLy8\neOmll9i8eTPR0dEGmV+hUPDMM88gl8v5/vvvkUqrf5eRK+QsO7WMa1nXWOO/Rq+iOxUpjo5GVCjq\n3HtuFTAWeVo6RRWqfVpouuga4MkEQZgNzAeUtYbGVYx/ZFFmqEKTH9gl+Pn50aZNm2bbhxcdHc2p\nU6dYtGiRVpngvXF7AZjScUp9L63B8XH0ISo9CrlCrtFbtnv3biQSCVOmqP9cghOC6enUk/ZW7Ws0\n19gO5WWa2lQUg4KCSExM5Pz585w6dQoTExPVeqA8wPNr7ddg4iQqW4n7ZZr9+/dHJpMRGRlZ6TVh\nYWG4urrSvn17yhRlXE5vydJAuejOoLaD2H51OzJF7SwTkvOT2XZ1G4uPLSY4XvfnliAIbNiwgcmT\nJ/Pqq6+yZcsWLl68yKFDh/jxxx9Zs2YNS5cuZf78+Tz++OP06dOHdu3aYWpqip2dHV27dmX48OHM\nmDGDf/3rX5w+fZonnniCAwcOkJGRwd69e1m4cKHOogZQQWCl5bPRQg15usfTuFq6sursqir/LfXq\n1UulohiZFomvk2HsOJTVCVEZUaqyf2WAl5SUxBNPPEGXLl3YvHmzTvMn5iRy5s4ZZnaeibG0cb/S\n2ZrZMtRlKAcTDqIQNTNMK1aswNLSkmXLlhlk/o0bN/Lnn3+yZs0avLy8dLpm9fnVnLh9guX9lzO8\n3fDqL6gFspRUEoJmkb7hv3W+l6X/CAQTE3IPtahpNgd0DfCeBgYBK0VRTBAEwQOovPv4EcbL1gtn\nc2e1Mk2JRML48eM5dOgQMpnhParqm6+//hoTExMWLFigcU6ukPNb7G8Mdh2Mi2XVvQDNEV8nXwrL\nConPiadnz55IpVK1AG/48OEqI2YoN+qOzYrVWVylIu427nS176q1THPKlCkYGxuzfft2QkJCGDBg\ngMpUPaUghTv5d+rdHqEiNqY2uFu7q5WzQtVCKxV9zm5k36CorKglS3OfJ72fJLUolWO3juk0XiEq\niEyLZF34Oqbvn87Y3WNZdXYV/9z7h/fPvE9MRozOc0ulUrZu3crAgQNZsGABfn5+PP7448yfP5+l\nS5eyfv16Tpw4QXp6Om3btmXs2LG8/vrrfP755/z8888cOXKES5cucffuXW7fvs0333xDYGCgzjLk\nDxORFoGtqS1uVjVTlmuh6SBLTibWfwR5x4/r9b5mRma81e8t4rLj2H51e7XjM4szuZV3q0abCYqC\nAkriE3Qa29G2IyYSE7U+vHPnzlFSUsLMmTMpLi5mz549aorMlSFXyPm/f/4PE4kJM7vM1Hm9Dcnj\nHo+TUphCeIqm/5+joyPvvPMOv//+OydOnNDrvHFxcSxdupSxY8eyaNEina75JeYXfon5hbnd5vJE\n1yf0up6KKK0RbCZNrH5wNUgtLbAYNoy8I0dayjSbATq5WYqiGA28AiAIgh1gJYrip1VdIwhCe+BH\noDUgAt+Iovifh8YIwH+A8UAhsEAUxeqdOxsxgiAw0GUgJ2+fRK6Qq0oSAwMD+e677zhz5gwjRoxo\n2EXqkcLCQrZs2cKMGTPUAhUlZ+6eIaUwhWX9DbOr1thRCa2kX6ZTp0706NGDc+fOcfXqVaKjozV6\nFoPjg5EKUgLcA2o139gOY1l3cR33Cu6plQjZ2toSEBDA1q1bSU1NVdvlvJh2v/+udcP03ynxcfTh\n77t/I4oibm5uODk5VRrgpaSkkJCQwMsvvwyUv8RDS5ZGyVDXobSzbMe2mG2Mcx+ndUyhrJDQ5FBO\nJp3k1O1TZBRnIBWk9HLuxRt93sC/vT82pjbMPDCTN0++yfbA7ViaVP/iCNCqVSsOHjzI/v37sbKy\nwtnZWfVlZWVVr5liQ2ZUWmgcFF+9SllKCimf/B9WI0fq9d4j249kiOsQNlzawDiPcVWqQCsrEGpi\nx5H00ssUnj1Ll8gIJNWoXRpLjeli30UtwPvll1946qmnOHv2LLt376ZrV93KADdc2sCZu2f4YNAH\nTUbZekT7EZgbmfNHwh/0bdNX4/wrr7zChg0bWLp0KWfPntXJeLw65HI58+fPx9jYWOfM6PFbx/n0\nn08Z1X4Ub/R5o85rqAxFaSlZO3ZgOXw4Jh066OWe1gFjKU1IoCwtDePWhukXbKF+0FVF84QgCNaC\nINgD4cAmQRAq7zwupwx4QxTFbsBA4GVBEB5WP3gc6HT/63ngfzVafSNlsMtgckpyiMl8sOv92GOP\nYWJi0uzUNH/99VdycnKqFFexN7NnRLsR9buwRoKbtRtWJlZqfnjnz59n9+7y/qipU6eqxipEBX8k\n/MFgl8HYm9nXaj6lmuaRxCMa52bNmkVycjJyuVxNYOVS6iXMjczpYt+lVnPqCx8nHzKKM0guSEYQ\nBPr161ep0EpYWBigbnCuNJdvAaQSKU90fYLw1HC17Nu9gnvsuLaDl/58iWG/DuO146/x580/6dem\nH58M+4STs07yw7gfWNBjAR42Htib2bN6+Gru5N/hw9APa6SOaWNjw9y5c5kyZQqDBw+mY8eOWFtb\n12uglVuaS3xOfIv/XTPHauRInN54HdmtWxTruQdLEATe7vc2xfJi1l5YW+XY2thxFJ49C4BYVKTT\n+G4O3YjJiEEhKlRCK7t27eKtt97S6OeujL9u/cWmy5uY1mkaMzrP0HmtDU0r41aMbD+SIzePIJNr\nVkOZm5vz8ccfc/78eQ3v19ry+eef8/fff/PVV1/RTgcbgaiMKJaFLKObQzc+GfaJQXUH8g4dQp6e\njt3cuXq7p3VgIF5/BLcEd80AXbc3bERRzAWmAT+KojgAqLIjVxTFZGU2ThTFPCAGeFg/f/L9+4mi\nKIYBtoIgNHnxloFty8vGKpZpWllZMWLEiGbXh7dx40a6d++uUhCrSHpROieTTjLZa3Kjr+83FBJB\ngo+jj5rQSlZWFhs2bGDAgAFqfzDCU8K5V3CvVuWZSjpYd8Db3pvDNzXLNCdNmoSpqSkSiYTBgx+o\nmYanhOPj6IOxpGF/RyrD8/QHhucxMTFaDWxDQ0MxNjZWCQ20ZGk0mdppKuZG5vw34r9suLSBoANB\njNk1ho/CPiIxN5GgLkF8O/ZbTj5xktX+qwn0DMTG1EbjPn6t/VjcezGHEw+z/Zp+XprqC2VGpadz\nS+luc6UoMhJRocAuKAjB3JzMrfoX+Ha3cWd+t/nsu7GPS6mXKh1XUzuO0lu3AGj97rtIbTT/7Wmj\nu0N38mX53Mq9Re/evTExMWHkyJGsXLlSp+sTchJ45/Q7dHfozjsD3tHpmsbEBM8J5JTkaKiVK3nq\nqafo2bMn77zzTpUiXbpw5coV3nvvPaZOncqTTz5Z7fh7BfdYfGwxtqa2fDX6K4PbsuQdPYqJhwcW\ngwfp7Z7C/aynorTUYHY3LdQPugZ4RvcDryAeiKzojCAI7kBv4OxDp1yBpAr/fxvNIBBBEJ4XBOG8\nIAjnH/Z8aYw4mDvgbe9N6N1QteMTJkzg6tWrxMXFNdDK9MuFCxc4d+4cL7zwgtYX631x+ygTy5ja\naaqWqx8dfBx9iMuOo1BWqOotS05OZvr06WrjghOCMTcyZ2T7upUYjXUfS2RapJqSK4C1tTVBQUGM\nGDECa2trAApkBVzLukYv54brv1PS2a4zJhIT1Ut5v379EEWR8HDNqu2wsDB69+6NmZkZ2cXZJOYm\ntvTfPYS1iTUTPSdyIukE30R+g7mROUv6LGHf5H0ETw1mWf9lDGg7QKfA/ukeTzPMdRifnftMVR7W\nFIhMi0RAoIdDj4ZeSgsGoCQ2lsRZT5C55UekNjbYTJ6EoqDAIC+mz/s+j3MrZ1adXYVcIdc4L1fI\nuZJ+pUZl4vn3FY1bDehP6e07Ol1TUWjFwsKCf/75h/3796s8TauiQFbAkuNLMJGY8OWILzGVmuq8\n1sbCIJdB2JraEpygfbNcIpGwevVqEhMT2bBhQ63nKS0tZd68edjY2LBx48ZqNw/zS/N56dhLFJUV\nsWH0hnope3Vdu5b2mzapgjJ9UXj+PLGDh1B85Ype79tC/aLrp+L/AYeBG6IonhMEwROI1eVCQRAs\nKffRe+1+FrDGiKL4jSiKfUVR7Kutz6sxMshlEJfSLlEgK1AdU5piNpcs3rp167CwsOCpp57SOCeK\nInti9+Dn7IeHjUcDrK7x4Ovki0JUEJURRY8ePVTiJhXLaWRyGUcSjzCy/cg67/op1TSP3NQs0/z+\n++85fPhBdi8yLRKFqGgw/7uKGEuN8XbwVst2gqbQSllZGefOnXtgj3A/49cS4Gnyap9XWTtiLSeC\nTrDl8S080+MZPG09a5zplAgSVg5dib2ZPW+eeJO8Us2samMkIj0CL1svnXsHW2hapK1bj6RVK2ym\nTAagzfvv0+7LLw2SyW9l3IqlfZcSkxmj1YIkPieeAllBjZ5DEvNWWPr7k7b2PyS9oJt4h5etF6ZS\nU9VGS8+ePXUSVRFFkffOvEdCbgKr/VfT1rJpFksZS4wZ02EMJ5JOUCgr1DpmzJgxBAQE8PHHH5OV\nlVWreVauXMnFixf5+uuvcXZ2rnKsTCHjzZNvEp8dz+cjPqeTXadazVkTRIUCQSrFpJ1GTqTOmHbq\nhKK4mLzDLWqaTRmdAjxRFHeKougriuKL9/8/XhTF6dVdJwiCMeXB3S+iKO7RMuQO5abpStrdP9bk\nGewymDJFGefvPfCo8fLywtvbu1n04SUnJ7Nt2zaefvppNZNuJedTznMr71aTqu83FCoLgPTLGBsb\n079/f/z8/NSklk/fOU1uaW6dyjOVuFm74W3vrbUPTyqVqu30Xkq9hIDQaMRJfBx9iMmIQaaQ4eTk\nRIcOHTQCvMjISAoLC1X9d5FpkUgECd0dujfEkhs11ibWjO4wGjszuzrfy87MjjX+a7hXcI+c+Jk7\nAAAgAElEQVQP/v6g0ZfvKEQFl9MutwT+zZSiK1HkHT2K/YIFGNmVf76VmYzS27cR5ZpZtroS4B5A\nvzb9WHdxHdnF2WrnamPHYTt1Cu2/3ohZ926U3ohHnl9Q7TVGEiO62nclOqNmvYY/RP3A0ZtHec3v\nNQa0HVCjaxsb4z3GU1RWxImkE5WO+eyzz8jOzmbVqlU1vv+5c+dYuXIlc+fOVeuT14Yoinxy9hPO\n3D3DewPfU1llGRJZaipxo0aTf+qUQe4vtbHBYtAgcg8fafTP+RYqR1eRlXaCIPwmCELq/a/dgiBU\n2W16XyFzMxAjimJlgiz7gXlCOQOBHFEUkysZ26To7dwbM6mZRp14YGAgJ0+e1NpX1JT473//S1lZ\nGa+++qrW87tjd2NlbMVjHRq3eWp9oBT/UJYebtu2jQMHDqiNCU4Ixs7UjkEu+qmlD3APIDI9krv5\nd6scF54aTme7zliZWOll3rri6+RLsbyYuKzyMmZtQivaBFZq0vfSQu3p5dyLV/1e5ejNo2y9qv9e\nJ32SmJtIbmluS4DXTElb9x+kNjbYP71A7XjhuXPcGDOW/JAQvc8pCALL+y8nvzSf9RfXq52LTI/E\nxtRGZzsOeV4eYmkpAOY+PiCKFEfpVv6sFFrRViqqjbPJZ1kbvpYxHcawoPsCna5pzPi19sPFwoVf\nYn6pNADx9fVl/vz5rFu3jsTERJ3vXVRUxPz582nTpg3r1q2rdvwPUT+w8/pOFvZYyPTO1eY99EL2\n9h2UpaToTTlTG9YBY5ElJVESo7tFTguNC11LNL+nPBhzuf914P6xqhgCzAVGCYJw6f7XeEEQXhAE\nQSm5+AcQD8QBm4CXavoNNFZMpCb0adNHI8CbMGECMpmMo0c1zaibCkVFRWzcuJFJkybRsWNHjfM5\nJTkcTTzKeM/xmBvVzruqueHj9EBoxcXFBReXB56A+aX5nEg6QYB7gN6ETpRqmtpMz5WUKcqITIts\nFP13SiraSkC50EpiYiIVe29DQ0Np06YNbm5uyBVyLqe3ZGnqk3nd5+Hfzp8159dwJb3x9mi0GJw3\nX+Q5OZTGJ+Dw3LNIHypPNO/VCyNHR7J+McwGRCe7TszuOpud13eqZdEiUiPwddRd6Cnjm2+IHTYc\nRWkpZj7lz73iK5d1ura7Q3cKywq5mXuz2rHJ+cksPbkUD2sPPhryUbMQopIIEl7o+QKR6ZFaWxGU\nfPTRR0gkElasWKHzvVesWEFMTAzfffed1uqkihxJPMIXF74gwD2AV/xe0XmOuiCWlpK1fTsWw4cZ\nNMCzHD0apFJyD1f+822hcaNrgOckiuL3oiiW3f/6AaiyGU4UxdOiKAr3Szt73f/6QxTFjaIobrw/\nRhRF8WVRFL1EUfQRRfF8VfdsagxuO5jE3EQ1sYvBgwdja2vbpMs0f/75Z9LT01myZInW87/H/06p\norSlPLMCvo6+pBSmkFqYqnHu2K1jlMhL9FKeqaS9VXu6OXTTanqu5HrWdQrLChtF/50SV0tX7M3s\n1WwlAM6ff/BoCAsLY9CgQQiCoOp7aXmJrz+U/XhO5k68efJNckpyGnpJWolMi8TK2OqR7wFujkht\nbPD6I1irPLxgbIztE7MoCAmhtAaZm5rwUq+XsDOzY9XZVShEBbmludzIuVFDgZUzmHbujMTEBCM7\nO4xdXSm6rNuGibIcvTrBoxJ5CUtOLKFUUcqXI7/EwthC5/U1diZ5TaKTXSf+E/4frZYJAO3atWPJ\nkiX88ssvXLhwodp7njp1ii+//JIXX3yRsWPHVjk2Mi2Sd06/Q0+nnnw85GMkgn6FTioj9/Bh5Onp\n2D+lP2sEbRjZ2dFmxbtYB1T9c2ih8aLrJzJDEISnBEGQ3v96Csgw5MKaA8pa7NDkB2qaxsbGjBs3\njuDgYBQKRUMtrdaIosjatWvp3bs3w4cP13p+d+xuujl0o6u9boarjwKqPrw0zR3a4Phg2lm203sW\nKsA9gMvpl7mTr72t9WJqucF5b+feep23LgiCoGYr0adPHwRBUPXhpaWlERcXp9Z/B/UnsCLPz2/p\nSQBsTG1Y7b+alIIU3j/zfqP8mUSkReDj5FNvL14t1A+lt2+jKC5GMDFBYqpdBdIuKAiMjcnats0g\na7AyseL1Pq8TkRbBgRsHVJlsXQM8WWoqJTExWFTwI239znIcFszX6XoPGw/Mjcyr7cNbdXYVURlR\nrBy6stltdEglUl7v8zpJeUnsuL6j0nHLli3D0dGRpUuXVvmcysvLY8GCBXh4ePDZZ59VOfftvNss\n/msxTuZOrBu1DjMjs1p/HzUla+s2TNzdsRhi+F4/u9mzMeumu6djC40LXf/yPUO5RcI9IBmYASww\n0JqaDV62XjibO2vtw0tNTdVpR6mxceTIEaKjo1myZInWUo+ojChis2KZ3ql+atGbCt4O3hhJjFSK\nj0rSi9I5e+8s4z3H6710RqmmeTRRe5nmxdSLtLFo0+jU1HwcfUjISSCvNA8rKyu6du2q6sNT9t8p\nFTQj0iKwNbXVue+lNlQUa7gxZixXfXsS6z+ChGnTufX882T9+qvqfO7BgxSEhlJ8/TplmZmITXAT\nR1d6OvVkSZ8l/JX0Fz/H/NzQy1GjQFZAXHZcS2a3mSGKIndef4Nb8xdUOc7IyQnrsWPJOfA7okx7\ndqeuTPSaSE+nnnxx4Qv+vvM3AoKqxLw6Cs6UvxNYDnvgH2s1ejTmvXQrl5dKpHS171plBm/X9V3s\nid3Dcz7PMdpttE73bWoMcRnCgLYD2BixsVJlXxsbG95//32OHz/OwYMHK73X0qVLSUxMZMuWLVWq\nksrkMl49/iplijI2PLYBezP7On8fNcHp1VdovfxtvVsjVEbB2X/IO368XuZqQb/oqqJ5UxTFSaIo\nOomi6CyK4hSg5Q2+GgRBYJDLIMKSw9SaoceNG4dEImmSZZpffvklbdu2ZdasWVrP77q+C3Mjc8Z7\njK/nldUfJQkJNb7GVGpKF7suqsyUkoMJB1GICr2WZyppZ9WO7g7dtZZpiqLIxZSL9HZqPNk7JT5O\nPoiIql3xfv36ce7cOURRJCwsDCMjI/r06QOUB3iGNDiX5+aSMGUqeX/+CYDjiy/gsGA+FoMHI3V0\nQJ6eQVlaOgCKkhLuLHmdW08/Q8KkycQOHsJVH1/S1q2vaoomzdxucxnZfiRfnP9ClU1tKPJK87iQ\ncoGtMVt5/8z7KETFI9mbWXr7dkMvwWDkHz9OcWQkNjOqf/1wWrIEz/37EIz109f8MBJBwjsD3iGr\nOIufYn7Cy9ZLZ7GqgtOnkTo6Ytqli+qYorSUvOPHKYnX7e9Ld4fuXM28SpmiTONcZFokq86uYojL\nEF7u9bJu31ATRBAE3ujzBtkl2Wy+vLnScYsWLaJjx4689dZbyLWoqx46dIivv/6aN954g6FDh2q5\nwwO+vfIt17Ous3LoSjxtPOv8PdQUi4EDsfT3r7f50v/7X1LXfF5v87WgP+qyBfC63lbRjBnkMoic\nkhxiMh8oETk4ODBo0KAmF+BFRUVx+PBhXn75ZUxMTDTOF8oKOZhwkLEdxjZb36miK1HET5xE1q+/\nIs/Pr9G1Po4+RKVHqQX7wfHBeNt7G+wPRYB7AFcyrmiUad4tuEtqUWqjElhRUtFWAsqFVlJTU0lK\nSiI0NJSePXvSqlUrcktzic+Jx9fRMFkaURRJfu99ShISMLrvv2k/bx7Ob7yByyercPvmGzz27MZp\n8b8AEIyM8Az+HbctW3D94nNav/MODs8+i3nv8p+xPN8wBswNiSAIfDTkI1pbtK63fjyFqCApL4lj\nN4/x30v/5ZW/XmHc7nEM3jaYBYcW8Mk/n3Du3jn82/k3qv7S+iD/9BluPDamWQojiAoFaf9Zh3EH\nN2ynTKl2vEk7V4wcDWs23c2hGzM7z0QhKmqULbafN5c2K1aoZWHEUhm3X3qZ3D/+0HnuorIiEnLU\nA8L0onSWnFiCcytnPh3+KVKJVOd1NUW8HbwJ9Azk55ifuVdwT+sYExMTPvnkE6Kiovjhhx/UzmVl\nZbFw4UK6devGRx99VOVccVlxfBP5DY+7P86I9iP09B3ohqhQkLb+K503APSFVcBYSm/coCQurl7n\nbaHu1CXAa/pSTPXAwLblpWTayjTDw8O5e7dqGfvGxNq1azEzM2PRIu2GrIcTD1NYVthsxVUUJSUk\nL38bI3t7MjZ9S/K7uitzQXl/RmFZITdybgCQmJNIVEaUQbJ3SsZ0GAOg4Ymn7L/za934XoCtTazx\nsPFQ9SsqhVbCwsL4559/VP13yvM9nQ2TpcneuZO8w4dxevUVzHtWP4cglWLq5YXFgP5Yjx+P/by5\nOC95Dcthw5ClpJIwZQpZPzWuUkZ9YGNqw+rhq0krSmPF6RV6DWKLyoq4nHaZXdd3sTJsJfMOzmPw\ntsGM3zOe1068xteRX5OYm4iPow+v+r3Kf0f/l2Mzj3Fy1km+Gv3VI2edkX/iBIAq49ycyDt0iJJr\n13D612Kds3KlSUkkPvkUhQ95aeqTxb0X423vzWNuulsCmffsifW4ALVjUksLTLw8Kb6so5KmY7nQ\nSsU+vDJFGW+deouckhy+HPElNqY2Oq+pKbO492JEUdSwrqjI9OnTGThwIO+//z4FBQ/8BhcvXkxq\naio//vgjZmaV99LJFXI++PsDLI0tWdZ/mV7XrwtFFy6QvmGDzkqr+sLqscdAEMhtMT1vctQlwGte\nW9EGwsHcAW97b60BHsAfOu7WNTRpaWn89NNPzJs3D8dKdkV3xe7C08az2ZZFpa1bR0lsHG0//ggz\nXx+Kr9RMIl5lAXA/MAlOCEZA4HGPx/W+ViXtrNrRw6GHRpnmxZSLWBhb0Mm2k8Hmrgs+jj5Epkci\niiI9e/bE2NiY77//noKCAjWBFQGBHg499D5/SVwcKas+wWLwYBwWLqzz/YycHDHt3JmUzz6jsAn2\n3laHj5MPb/R5gxO3T/Bj9I+1vo9CVHAl/QrrL65nxv4ZDNw6kDl/zOHfof/mQPwBBAQmek7kg0Ef\nsG3CNsLmhLF/yn5W+6/mWZ9nGdZuGM6tnJuFFHxtcF76JsaurhSePdvsssX5J09h2qkj1uN1f14a\nOTpSEhdHpoEsEwBszWzZMXEHw9oNq34wkH/mDPlnzmg9Z+7jS9Hlyzr97tyt3Wll1EqtD2/thbWc\nu3eODwZ9gLeDt27fQDPAxdKFJ72f5MCNA1zLvKZ1jCAIrFmzhrt37/Lll18CsHv3bn755RdWrFih\nKvuvjG1XtxGZHsmy/stwMHfQ+/dQHdn79iFp1ao84KpHjJ2dMe/jR14zrApo7lQZ4AmCkCcIQq6W\nrzzK/fBa0IFBLoOISIugQPZg16h79+506NChzmWacrmcrKysui6xWjZu3EhJSQmvvfaa1vOxWbFE\npkUyrdO0ZvlyVRgeTuZ332MbFITl8OGY9+iB7M4dyjIzdb5HB+sOWJtYczm9/A94cHww/dv2x7mV\nswFXXl6mGZURxe28B705F9Mu0tOpZ6Mt3/F19CWzOJO7BXcxNTXF19eXQ4cOAeoCKx3tOhqkHDjv\n/7N33uFNVW8c/9ykTdM06V60QKHIpmyQVZYIKtvJ8MdUQUQFnIAgKDJUUHADsjfILsgQkI3svcss\npYO26Uyz7u+PQAXpSNqbpi39PA8P2px7zlva3Nz3nPf9fv/agczNjaApkyVpZhdkMoKmTEYRHMzt\nYcMwxD5ul1Hc6V29N+3Kt+P7o99zIvaE1ddlmjLZfXs3Xxz4gmdXPkvPiJ7MPj0bjULDoNqD+L71\n92x+cTMHeh5g/vPzGd1kNC9XeZlavrVKfTb/g8zFBd93h2KMjUV3NneFxeJGmcmTKD9/PoLc+nuW\nzNUVz5deImXbNgwxMXaMznrif/qZuO+nZ/uaMqwWpoQEjFZU9sgEGdV9qmcleH9e+5P55+bTo2oP\nOlfqLGnMxYGBYQPRKDRMOzotxzHNmzene/fuTJkyhTNnzjB48GAaNGjAqFGjcp37dsptZhyfQXhw\nOB0r2q/iJifMOh0pf25B06EDMlXhVyW4t++AMS4OYyE8a5YiHbk+uYiiqBFF0T2bPxpRFJ0KK8ji\nTrOgZhjNRo7c/dfLSxAEOnbsyLZt29DpdDbNZzKZ2LVrF++88w7BwcEEBwdzxsbTJFvIzMzkp59+\n4rnnnqN69ex3BVdfXo2TzIkulbrYLQ5HYkpMRFm9Ov4ffwyAsqbl1Eh3Nncfood52ALgdPxpbqXc\nKpQPi2cr3C/TvG8Im6xP5krilSLZf/eAML9HTzsflGn6+/tTsWJFzKKZU/Gn7NZ/5zvoLULXr8vq\nvZMCuUZD8A8zMKemETVsOKJeL9ncRQFBEBjffDwBbgF8tPsjknRJOY5N0CWw9spahu0cRviycN75\n6x0iIiOo41+HiS0m8verfzP3ubkMqTuEZ0KeoaymbKFuHGk3bEC7oXj1SGs3bCD2++9Rt2pF+Xnz\nUFat4uiQJEHU6zHGxyMIAk7etisWevXsAWYzSctzltIvLExaLRknTjyinvkwrvcNzzOsLdP0qcnF\nhItcSLjA2P1jqetXl48bfSxZvMUJDxcPBtUexP47+9kftT/HcZMmTSIjI4MmTZqQkpLC/Pnzcc6l\n5FcURcYfGI+AwJgmYxyygZ26Ywfm1FQ8unYt9LUBPF97lcp7duPk5eWQ9UvJH6UGQYVAPf96KOXK\nbMs009PT2XW/byI3TCYTu3fvZujQoQQHB9OmTRvmzp1Ly5YtUavV9OnTB72dHhiXLVtGTEwMI0Zk\nr6uTacpkQ+QGnin/DF7KknkD0DzzDBVWrUSuthjFKmtavGFsLdOs5VuLK0lXWHVpFQqZgnYh9i+3\nCFYHE+YbllWmeTL2JCJikRagqOxVGRe5S5atROPGjQGyDM6va6+Tok+RvBw4dc9edOcsJx9OPtKX\n4SirVCHoqwkIcjnm9HTJ53c07gp3praeyr2Me4zeNxqz+K9NxDXtNeaemUvfzX1ps6INY/aN4XT8\nabpU6sKv7X5lT489TGs9jc6VOuOp9HTY9yCazdyd8BV3PvqIuxO+QjQ+rlJYFElasZLUXX/j5OWF\nW5On7aYeWdgkrlrFlWfbo79xI1/XK8qVQ92yJYkrVjh8UyXtwEEwm3HLQalRWbUqoRvWo3n2Wavm\nq+lTk0xTJm9ufRM3Zzemtp6Ks7xk/NzzQ49qPQhWBzPt6LRHxMwepmrVqgwaNIi0tDQmTJhAzZo1\nc51z3dV1HIw+yPAGwx1mKWSMi0PxVCVUjRs5ZH2ZiwuCk1OJK/su6ZQmeIWAQq6gYWDDxxK8Nm3a\noFKpiIiIyPY6s9nMnj17ePfddylXrhytWrVizpw5hIeHs2LFCuLi4lixYgUzZ87k+PHjeSpA5QdR\nFPnuu++oVasW7XKo/d5xcwfaTC0vVn5R8vUdTdr+/SQsXoxoNj9SqifXaPD/6CNU98sFraW2X23M\nopl1V9fRqlwrq2W1C0qHCh04d+8ct1JucTz2OHJBbrVnkyNwljlTw6dG1gnegwTv4fJMkNbg3HDn\nDlEffmh5qLfjB5n7Cy9Qfv485J6OS2LsSU2fmnzY8EN2397Nt0e+ZeqRqXRe05kua7sw7eg00o3p\nDKo9iOWdlrP95e181uQzmgc3RyF/XJnXEQgyGVX278OrVy8SFy3i1luDMGntrw5aEExaLenHjqFu\nbZFPN0RFEfP1N0WmLDG/mDMyuPfLryhr1sC5fP69Ln3efAPfQYMc/oCatm8vMo0G19rZVx4ICgUu\nlStbXYZaw8ey0ZiqT2Vqq6l2L/cv6ijkCt6v/z4XEy8ScS375yqAKVOmsGrVKoYPH57rfPEZ8Xx9\n+Gvq+9fn1aqvSh2u1Xj37Uvo+vWF5n2XHemHD3O13bPob950WAyl2EZpgldINC3TlOvJ17mT+m9t\nvVKppF27dmzcuDHrg8dsNrN3717ef/99ypUrR8uWLZk9ezbNmjVj+fLlxMbGsnLlSl555RXc3Cyn\nSd26daNv375MmjSJQ4cOSRr3rl27OHnyJMOGDcuxNOGPS38QrA7OUgwtKZiSk7kzajSJi5dku/Pr\nM3AAqnq2+cg9sACwl/ddTjyspnk89jjVvKsVeYXBMN8wziecx2A2UKNGDRYtWsTgwYMBS4KnUWio\n4FFBkrVEo5Gojz4Gg4GgSRPtXoYjyGQYExK4NWgwuvPn876gmNGzWk/ah7Rn4bmFLDq/iCB1EKOe\nHsXWl7aysvNKhtQdQg2fGkWyX9es0yHI5QSOHUOZryaQdvgwN9940+HJQW6k7tkLJhOaNm0AS2KU\nMGcOqcXcoDhxyVKMcXH4v/9+gX5XVA0b4v2/15G5uEgYne1knDmLW9OmCE45d7ikHzvO3S8nIJrN\nOY55QHn38jQt05QxTccUSUXkvLDHe6pDhQ7U9KnJD8d/QGfMvv1FrVbz0ksvIc8jkZ54aCKZxkzG\nNRuHTHDM4/KDzSVHJncAzkFBGKKiStU0ixGlCV4h0SyoGQAH7hx45OsdO3bk+vXrLFq0iGHDhlG+\nfHnCw8OZOXMmTz/9NEuXLiUuLo5Vq1bx6quvolZnLygxffp0goKC6NOnD+kSln599913+Pn50bt3\n72xfv5V8i0N3D9H9qe4OuwHai5iJkzDGxRE0eRKybOSTzTod6UePYkpJsXpOb6U3ZdVl0Sg0hAdb\np7omBUHqIGr71ibiWgSn409Tz992g3NjfDyRXbqSfuRI3oMlIMw3jExTJpcSLyEIAr1798bz/qnX\ng/47qX7n4n/5lYyjRwkcPw5FSIgkc+aJ2YzuwgVuv/sepqSc+9WKI4IgMKHFBH5+5md2v7ab3579\njZ7VejqsxMla9Nevc6lZc1Lul817vvQSIXPn4FfABMPepO7cidzHB+X9Hi5FpUo4lytHSjFO8Eyp\nqdybNQu35s1RNSp4aZpZpyNxxQp0ly5JEF3+qLhqJYHjx+U6Rn/9OomLF6O/lrffmUyQMbP9zGJZ\nPZO0Zi0X69azSajMGmSCjA8afsDdtLssPr843/Nsv7GdbTe28Xbdt6noUVHCCG3jRt9+RH3s+L5K\n5+BglHVqk7hwEZmRkY4OpxQrKFlP5EWYSp6V8Hf1f6xMs2NHyylOnz59+PXXX2nUqBFLliwhNjaW\n1atX06NHjxyTuofx8PBg7ty5XLp0iZEjR0oS86VLl9iwYQNvv/12jv4wa66sQSbI6PqUY5p/7UXK\nX3+hXbsWn7fezLGcRnfuHDfy4bE0tN5QPm38aaGXpLWv0J7LiZfJNGXmK8FL/nMLmZcucferiVbt\nLheU/wqtPCBVn8qVxCuSlWdmnD5N/C+/4NG1Kx6dC099zsnXl7LTv8cQE0PUxx8Xyr9pYeLq5Ep4\n2fBCK0OWgqS1axF1OpTVa2R9TdWwIeoWzQFIWLCAhMX5f2i0F4LSBffnn8/a5RcEAXWb1qQfOFhs\nez3T9u3HpNXiN+x9SeYT9XpiJk0mYUH+bTwKiiCX5ylU4Vr7vtDKqcL1OytMRFEketQoxMxMDFHS\newE3CmxEq7KtmH16Nok625UftZlavjr0FdW8q9G3Zl/J47MW3YULZF64gGvtomE9VWb8eESTiRu9\nepNx6pSjwyklD0oTvEJCEASaBjXl0N1DjzT/BgcHM3fuXBYtWkRsbCxr1qyhZ8+eaDS2PxQ988wz\nvPvuu8yYMYMdO3YUOObp06ejUCgYMmRItq8bzUbWXllLeHA4gW6BBV6vqGDW6YgeNw6X6tXxe/vt\nHMcpq1UDmcxmoZWOoR0dojbaPqR91n/nJ8FL2bIFwcUFfWQkmRez9xqSkiC3ILyV3pyOf/RB58y9\nM4iI1PaTRkFTWa0a/h+MIGDMGEnmswXXunUJHD2KtN17iP/xp0Jfv5R/EU0mtGvX4daiOc4Bj/cy\niaJI2j//EPPlBKLHj0c0GBwQZfYEffUVgZ+NfuRrmjZtEPV60g4cyOGqoo17h/ZU2rYtS1myoMjd\n3fHo3JnkDRsdcmJ+57PPiJ85K89xiooVkalUVhueF0cyjh8HUSRw/Hhcw6T3MQUY3mA46cZ0Zp6a\nafO1U49MJVGXyPhm43GWOU60RrtuPTg54d7xBYfF8DDKatWosGQxMo0G3bmS11pQ0ihN8AqRZkHN\n0GZqOZ/w6BujX79+9O7dG3d39wKvMXnyZKpUqUK/fv3QFkAYICEhgXnz5tGrVy8CAgKyHfP3rb+J\ny4grluUhuSFTKgn+5huLB5oi51M2mUqFS6VKZNjRokJKyqjLUNevLuU15fFT2Sb/LxoMiKIZn4ED\nqbR1K8oc7DKkRBAEavvW5lTcozuFJ2MtAisPTvjyiyiKmFJSEJyd8Rk4MEshtbDxfO01PLp3R7t+\nPea0tLwvKMUupB08iPHuXTy7d8/2dUEQKDt9Oj5vDCRp6TJuvvlWkSitzel3RtWgAU5BZTDGxRdy\nRAXngd+WomywpPN69e6FmJlJ0h+rJZ03L8wZGSSv34DJinJEQS5HWbNmsflcyQ+JS5Yi02jw6NwJ\nc2amXe57lTwr0f2p7iy7uIxbybesvu5g9EHWXFlDv5r9skRsHIFoNKLduAF1q1ZFyp5AERJC6Lq1\nePV4DaDUG68IU5rgFSJNgiwiJP8t05QSlUrFggULiIqKytGU3BpmzZpFenp6jnOIosjvZ34nWB1M\neNnC6yWzNw/66dyaNEFZJW8fKWVYGLozZ4u0AMPDTG45mRltZ9h8neDsTIVFi/B9dyjOAf6Ioogh\nKsoOET5KmF8Y15Ovo838d7PiVPwpQj1CcVcUbEMkcckSIjt1xmCFqbA9EQSBwM/HUmHlCmRujkky\nSwHtmrXI3N1Rt22b4xhBLsf/ww8pM2kSGUePcr1HT8yZmYUY5eNce+VVoseNe+zrgkLBU3/9lfUg\nVlww3rvH1XbP2qUUVlm1KqqGDUlctgzRlL2Mvj1IP3wYUa/P0R7hvyjDwjCnppa4stcjWAEAACAA\nSURBVG2wPDuYdRl4vvgiotHI5fCWJCxeYpe13qn7Ds4yZ6Yfz95Y/r+kG9IZt38cIe4hDK4z2C4x\nWUvagQOY4uLx6Fr0vIUfmK3rLlzgartnSVy61MERlZIdpQleIeKt9Ka6d3W7JngATz/9NCNHjmTe\nvHmsW7fO5usNBgM//PADbdu2pU6d7Gu/D9w5wOn40wwMG+jQEgYpMcTEcrV9BxJXWG+Iq6xVE1NC\nAsboaDtGJh3B6mAqeVay+TpzRgZAltBE3PTpRHZ/0e4nGA+sHM7GWwzlRVHkVNypAvff6S5cIHbK\n17hUq4pTGccLf8iUSpy8vBD1euJ/m1ls+6aKMz5vvkmZL7+0SmnRs3s3ys+fj3ffPg5VZtRfv44+\nMhKXpypn+/qD92tx8fIDuDdzJmadDrdmzewyv9frvZF7e2GMv2eX+bMjdc9eBKUSVaOGVo33/2AE\nlTZFOFw50R4IgkC5H3/E/5OPkbu741KpEskbN9plLT+VH31r9mXL9S2PVYJkx48nfiQqNYpxTceh\ndMped6CwUDVoQNDXU1C3bu3QOHJDERKCqlEj7o7/griffio2G91PCiXv7lHEaRrUlJOxJ0kz2LcU\na+zYsdStW5c333yT2NhYm65dtWoVUVFROXrEiKLIb6d+I0AVQNdKJUNcRRRFosd8hjkjA7f7nmvW\noGnXjpAlS3Dy9bVjdI7FmJjIpWbNSVq9Jutr7s8/jzklhfjfbO9vsIVavrUQELIMz2+m3CQpM6lA\n/Xfm9HSiRnyAzMOdoIn2t0SwhYwzZ4n7/nuix4wt/bAsZJRVq+DeoX3eA++jql8Pr549AUjdu4+E\nBQsK/WeWsnMXQI4PgaLBQGTnzsT9VDz6Ow1375K4dBke3briUtE+yoWaDh2ouHx5tn2W9iJt715U\njRpZvRlgrQ9ecUM0GrMqPx4kr+6dOpJ56RK6i/ZRN+1Xsx8+Sh+mHpma6/vzVNwpFp9fzGtVX6Nh\noHWJuD2RqVR4dOmCLJc2EUcjc3Wl7A8z8OjalfgffiRmwlcl8tS5uFKa4BUyzYKaYRSNHL5rm/Ki\nrSgUChYuXIhWq2Xw4MFWP3g8MDavUqUKL7yQfWPvkZgjHIs9Rv9a/YuMOXFBSVq1irTde/D/8EMU\nFSpYfZ2zvz+q+vVy7dUr7qTu2IGYkYFL1X9LVpVVq+LRrRuJixahv22/Uk2NQkNFj4pZQitSGJzf\nnTgR/bVrBH/9NU4+PpLEKRWq+vXwe/99kiMiSFy40NHhPDHE/fQTGSdO5Pv65IgIYiZO4u7Ysdl6\nZtqL1F27cKlcOcdeNcHZGZmHB6k7ioddQvzPvyCKIr5vZy/sJQUPNnRMSUkY79n/FM+s1+Napw7u\nzz1n03XRY8YQO3WqnaJyDKm7dnHl2fakHzue9TX3554DuZzkiJyNyQuCm7MbQ+oO4VjsMXbd2pXt\nGIPJwOf7P8fP1Y9h9fPf2iIVKTt2cm/O3CIl5JQTgrMzZSZNxLt/fxIXLybpjz8cHVIp9ylN8AqZ\nev71UMqVj/nh2YNatWrx5ZdfsmbNGhYtWmTVNfv37+fw4cMMGzYMWQ7lIb+d+g0fpQ8vVX5JynAd\nhv72bWInTUbVpAlevXrafH3awUMkrlxph8iKBslbtuBctizKGo82nPu99y7IZMTNsK6/Ib+E+YZx\nOu50Vnmmm7MboR6h+ZpL1Osxxsbi8+abuDVtKnGk0uDz1puo2z1DzJSvbbbgKMV2Mq9dI/6HH0k/\nejTfc5T5agI+gweRtHIVNwcMLBThAVNyMulHj6K+b26eE5o2bcm8eLFQemYLgik1leRNm/B65RXJ\nxVX+izk9nSvtnuXeTPtWIADIFAqCJk/C8yXbxMgMMTGk7vrbTlE5hsQlS3AKCMiyggBw8vHBrWlT\nkjdutNsJ+IuVX6SCewW+O/YdRvPj5cqzT8/mStIVxjYdi1qRty2VvUmYN4+k5cvBycnRoViFIJPh\n//FHBE+fnqNIVSmFT2mCV8go5AoaBja0ex/eAz744AOaN2/Ou+++y61beStJfffdd3h5edGnT59s\nXz8Re4JD0YfoV7Ofw2vUpUJ36hSCiwtBE7/KV89D8ubNxH7zbYksqTNptaQdOIimQ/vHShmdy5TB\nu08f0g8essns3VZq+9UmMTOR26m3ORl3kjDfMOSy/JUwCQoF5X791ZKcFlEEmYygyZNRlCvHnVGj\ni1X/VHFEu3YdyGS4F8ADUZDJ8B82jKBvviHj1Cmuv/Kq5AbOj63p5ESZ8ePx6JJ73A8SwAfm7UUV\nuVpNpc2b8B36jt3XkqlUqFu1Imn1Grv3uxpiYvL12eBaK4zMq1dLTD9uZuQ10vYfwOu1VxH+k7j4\nvfcuwd9Ns9vaTjInhjcYzjXtNVZfflRB9UriFWaenskLFV+gZdmWdovBWgxRUaT/8w8e3boWqfaB\nvBAEAfcO7RGcnDDExBI1YkSpwqaDKU3wHECzoGZcT77OnVT7q/fJ5XLmz5+P0WhkwIABmHOpj752\n7Rpr1qxh0KBBuOWg5jfz1Ew8XTx5teqr9gq50HF/4QWe2r4N56CgfF2vrFUTc3Iyhps3JY7M8aTs\n3AkGA+7ts+9N8h08iEp/bkaeD99Ga3kgtPJP9D9cSryUr/470WDg7pcTMNy5gyCTPfaAUdSQq9WU\n/elHyv74Y5GPtTgjmkxo163DLbwFzv4F78ny6NyJ8nPn4PnyywjO9hWfkqlUeL70Ii5PPZXrOJfQ\niihCQki9369XFHmgaOnk54eTt3ehrOnVuxfmlBS0G+wj8AH3eyBf6Ejst9/afK0yrBaYzejOnbND\nZIVP4rKl4OyM58svP/aaa+3auNapY9eEpk25NtT3r8/PJ37O0kAwmU18vv9zNM4aPmn8id3WtgXt\nhg0AeHQpeuqZ1pJ5+TIp2//ixv/+h+HuXUeH88RSmuA5gGZBFnWwwijTBKhUqRJTp05l+/bt/PLL\nLzmOmzFjBjKZjKFDh2b7+tl7Z9kTtYc+NfqgclbZK9xCIzMykpTt2wEKJE/vWsti1FoSfYtUDRvh\n/8knKGtnn1TJ3NyQqVSIBoPd7AYqe1VGKVey7OIyzKI5X/13CfPnk7h4MRmn8lZSKyq4VKqE8n7f\nY+blyw6OpmSSl/ddflA1aIDv4EF23fQQjUYSly3DYKWAlu/Qd2wuESxM7s2axfWevTDrdIW2pmu9\nerhUr07i4sV2q77IOHECc1oaqnr1bL72gcF7xuni/7kiGgwkb4zAvX37HAXJdJcuETNpkt0qFgRB\n4IOGH3BPd4/5Z+cDsOTCEk7Fn+LTxp/irSycjYXcEEUR7dp1qBo3xjnYvmXK9kTdojnlZs3CGH2X\n6716kRl5zdEhPZGUJngOINQjFH9X/0Ir0wR46623eO655/joo4+4dOlxtark5GR+//13Xn31VYJz\nuLHMPDkTjUJDj2o97B2u3RGNRu58OpLo0Z8VuLzQ5amnEBQKdGfOShRd0UFRNhif/v3y3Fm99fYQ\nbg15xy4KWk4yJ2r41OBCwgUAavvafoKXvHVbvoQOigKJy5YR2bVbiXjQK2qYEpNQVKqUZx+brYii\niDYiguRt2ySd9wEZx49zd9x4Mh4Sq8gNj86dcX/+ebvEUlBEg8FifK1SIVMWXtm/IAh49+5F5qVL\nZF68aJc1UvfsBScnVE2a2Hytk68v6rZtkbsXzO+zKCA4OxO6bi1+w3MWMDHcvEnC/AWkHThotzhq\n+9WmfUh75p2dx4nYE/xw/Adalm3J8xWLxnvDnJyMc1AZPEpAH5vb040JWbgAMVPPjd690dnpPZYd\notGI4c4d0o8dQxsR4XCvUkdRWvvjAARBoGlQU3be2onJbMp3P5E2U8tPJ37iROwJfmn3Cz6uOSsC\nCoLA7NmzqVWrFn379mXPnj04PVT69fvvv5OSkpKjNcKlxEvsuLWDwXUGo1HYb2faWgzR0aTs3GlR\nrDOL+AzoD0Dqnj3ozp4DREuyYRYRnOT4DraYliZv2oTu/Hn012+gO3WK4GlTC7zTLjg741K9GpmR\nVwv6bRUp0o8dwxgXj+aZtnmWCXp078adDz4kecMGPLpKb50R5hvGsdhjVHCvgKfS06ZrTVotujNn\nsn4HihvuL7xA/E8/E/3ZZ1RctdLupX9PEh6dOuLe8QW7lIYlzF+ASZuEpm1byWXvU3btAmdn3Fo0\nt/oa/c2b6G/cRB1undl2YZGybRvG2FgCvxhf6Gu7d+yIa/0GuITax5Ihbe9eVHXrIlfnT7ij3M/F\nw97CGpz8/HJ93a1lS2QaDckbN9r1d3RY/WHsuLWDAVsGoJArGNNkTJHpdZN7eFB+zhxHhyEZyho1\nqLB4ETGTJuMcECDJnKLJhDE+HuPduxii72K4G41Hx444+fmRvGkTMZOnYIyPh4c2m0M3ReASGkrc\nzz+D0YTP4EFF2n5CKkoTPAfRLKgZ666u43zCeWr51rLpWrNoZu2VtXx/9Hu0ei0yQcbY/WP5se2P\nud6ogoOD+fnnn+nVqxfffPMNI0eOBMBkMjFjxgxatGhBw4bZ+7/MOjULlZOK16u/blOsUpMZGUn8\nr7+SvGkzPFTK4X3/lCll+18W9amHEFxdsx7uU//eTfLmzSAIePXqiXsOVhC2Uv6335B5eEgyV1Eh\nYe48Mk6cQPNsuzzHuj//PAlz5hL7/XQ0zz0nuflzmJ+lXCk//Xdphw6B2Yxbc/sYJ9sbubs7gZ+P\n5fbQd7n3+xx8Bw9ydEglAkNsLE4+PnbxHBMEAZ8B/YkaNpzUnTvRtMv7PWQLqTt34daooU2JQ9z0\nGaQdOEDlPbuLlM9awsJFOJcvj7pl4QtcyFxds5I7URQlfdA3xsejO3cOvxw2Ta1FNBpBFIvtxk76\nsWPEffc9ZSZ+haJcuRzHyRQKNB3ak7JpM+bx4+x2mlvOvRyvVX2NxecX82njTwl0C7TLOrYi6vUY\nk5Ly7gU+tx5kcqjWsXACKyCKChUo99uvgOX57UbfvggIIAggk4EgEPDxR7g//zwZZ88SNWw4CILl\nvXj/T8CoUajDW5C6eze3hrzzyLMfgEvlyqj9/HAKCMCteXOcywTiFBiIc6Dlb0XZsoiiiCEqCu0f\nq0neuoWgCRNwrVvXEf8khYbdEjxBEOYAnYBYURQfy2AEQWgNrAMeFOeuFkXxC3vFU9RoEmQp2dh/\nZ79NCd7Z+LNMPDSRU/GnqO9fn1FPj+Lw3cNMOTyFFRdX8Fq113K9vkePHqxZs4bPP/+cF154gTp1\n6rB27VquX7/O1Bw8dyK1kWy5voUBtQbg4VL4SYwoiogGAzKFAv31G6Rs/wvv3r3w7NHD4mP2kPJl\n4GejCRg9ynJzkMlAJnvkQztoymSCpkyWPEa5p22nSkUdc3o6qXv24Pnii1YpiwoyGf4ffcTNfv1I\nXLQIn4EDJY2nrl9dnGRONA603oT+AaLBgEv16rjm0EdYHNC0a4emQwfif/4ZTfv2djtxeJKIeu99\nZCoV5ef8bpf5Ne3a4RwczL258yRN8PQ3bqCPjMSrh22l8uo2bUiOiCDj1Kl89YTZg4zTZ8g4fpyA\nUSPzpWAsBaLJRNQHH+JS+Sn83pFOwVOmVhM8YzrK6tXzPUfGmbPceP11yv4wA3V4uGSxFSaJS5ai\nu3DBKs9Rj06d0K76g9Rdu+xaTj+s/jCaBTWjRXDROc1O+ftvot4fRoVlS3P+rDIZYVV/CP+w2CR4\nDyNzc0PTug0gWvpezSKIIk73k1q5m5sl6RLF+3/MiKKI3N1SZaWoUAGfgQP/TeDKlME5ICBrc13V\noAGqBg1yXD/oq69wb9+e6HHjud6zF959/off+5bPgRKJKIp2+QO0BOoDZ3J4vTWw0dZ5GzRoIJYU\nXln/ith3c1+rxiZmJIrj948Xw+aFia2WtRLXX1kvms1mURRF0WQ2iYO2DhIbLmwoXk26mudccXFx\nYmBgoBgWFibqdDqxefPmYsWKFUWj0Zjt+FF7RokNFzYU49Pjrf7epMCs14tJa9eKV7t0FWOmfWf5\nmskkGpOSCjUOazAmJ4tRI0eJyTt2ODoUSdBu/lM8V7WamHrwkE3X3XjrLfH6//pk/W5KSXRqtGgy\nmySft7hgiI0Vr3R4TkzZu9fRoRR7dFcjxXNVq4nxs2fbdZ178+eL56pWE9NPnJBszqT1G8Rz1aqL\nmTdv2nSdMSlJPFejphgzdZpksRQUU2qqmLB0qWhMTnZoHDcHDRYvNn5a1N++7dA4/osxJUU8V626\nGPvjj44OJV8Y4uLEc7XCxOivvrJqvNloFK927iImLFtu58iKHjffeUe82KKFaDYYch4U+bcofu4u\nimfXFl5gJRBjSooYPX68eL5WmJhx4YKjwykQwBExh3zJbltmoijuBuxrBFTMaRbUjJOxJ7Mke7PD\nZDax4uIKOq3txOrLq+ldvTcbum+gc6XOWSdTMkHGl82/xNXJlU93f4rBZMh1XV9fX2bPns3p06d5\n+eWX2bdvH++99x7ybMp2bqXcIiIygleqvpJrj5+UmFJTuff7HK482547n3yKaDJmqQkKMhnyIlgK\nKVOpSP7zT9L27nN0KJKQsnULcm9vVA1z3g3LjuApUyg/d45dehoC3QKRCbbdskS93i7CL47Ayc+P\n0IiNqJtb33dVSvZo164tsPedNXi8+BKudepgTsv5Hm/znJ07UXn/vlzL3bJD7uGBqmFDUnfulCyW\ngiJzc8OrRw+7Ko5ag//HHyOaTNx+9z1JlDxFs5l7c+eht8J7NjfkajWK0FB0xVRgKWnVH2Aw4NWj\np1XjBbmciuvW4vVaybFhsgZjYiKpf+/Go1Pn3Pvdz60DJ1fwqggr+0FafKHFWJKQq9UEjh1Lpa1b\nUFatCkDSH6sxJSc7ODJpcbSKZlNBEE4KgrBZEISaOQ0SBOEtQRCOCIJwJC4urjDjsytNg5piFI0c\nvns429dPxp2k16ZefHnwSyp7VmZl55V80viTbEVO/FR+jGs2jvMJ5/nhxA95rt2xY0feeOMNNm7c\niLu7OwMGDMh23O+nf0cuyOlXs59N31tBuPvFF8R+8w2KkBDK/fYroevXS9YrZy8EuRxljeroSoBV\ngiiKZF6NRPPsszb36sg9PRHkckxaLcYi8F7Vrl/P5abNMMTEODoUSRDkckSTiYQFC0r9hfKJ1N53\nuSFXu1Fh+TLcmknb/+nk5ZWv69RtWpMZGVkk3ptJq1aRuGyZ3SwKbMEltCJB33yN7vx5oseOLXBM\nurPniJ0yhYzj1qmc5oZrrVpknDlTJP6dbEE0Gklcvhy3Zk1tKikXBAFRFJ8ok+zkTZvAYMCjWy4C\nZWYznN8AlduBk4sl2ds3vfCCLIE4lykDWMreo8eOJbJjpyzrrJKAIxO8Y0CIKIp1gB+AtTkNFEVx\npiiKDUVRbOiXhxJTcaKefz2UcuVjdgkJugTG7hvL65teJz49ninhU5jTYQ6VvSrnOl/b8m15ucrL\nzDszL8ek8WGmTZtG/fr1GTlyJO7ZSDFHp0az7uo6ulfujr/Kfg9CuosXufPJp2RetahQ+g4aRIWV\nKwmZPw91q1YO682wFddaYeguXEA05H6CWtQRBIGKa9cQ8Gn+jF/Nej2RXboSM+VriSOznbT9+xEU\niqwa/5KAMSaG2O++5+74L4rdQ19RIP3QIYwxMZJ63+WFOS2N9MN535PzImX7dm6+8aZFJS4feL74\nIlX27c1T0dDeiAYDcdNnkPLXjiKjYKhp0wa/994lbf8BjFb6C+ZE2r69ALhJcNquDAvDdF81sDgh\nms349O+Hzxtv2HztrYEDiRoxwg5RFU2S12/ApVq1rNOkbLn9D6TGQI1u4FcVwl6Bf2ZBasF+V0sB\nRUgIFZYvR+7jw+2h73J72PB832OLEg57chZFMVkUxdT7/70JcBYEIXsHzBKKQq6gYWDDLMNzo9nI\nkvNL6LSmExuubqB/zf6s776eF0Ktl/H+qOFHhLiHMHLPSLSZ2lzHajQajhw5wqeffprt63POWOR6\nB9aSVjDjARknTnBz4Btc69qN5G3bsryIXCpVwjXMNmXRooCyVi3EzMysRLW4It5Xk5O5uubreplC\ngUe3biRv3EiGA70BRbOZtAMHcWvWtMg8REqBc1AQfu+9R+rOnaRs3uzocIodqsaNKTfzN8m973Ij\nZsrX3Bw0GJM293tyXqRs24bu9Ol8izrJ3d1zv/avL+DPUfmMznqSt27FGBeH9/8cq8r8X3wGDSJ0\n/boCS7qn7tmLsmZNq4RF8sKtWVN833u32KloyhQKvPv0ydfptWvdeqQfPIShgIl2cSF4+veUycsm\npGwj6L8ZqnSw/H+rT8Ckh73f2z/AJwDXWjWpuHIFfsOGkfrXX1zv0dOiYFuMcViCJwhCoHD/qUsQ\nhMb3Y7nnqHgcRbOgZlxPvs7ma5vpsbEHk/6ZRA2fGvzR5Q9GNByBm7ObTfOpnFVMDp/MvYx7fHnw\nyzx3+HN68I1Lj2P15dV0rdSVMuoyNsVgDYaYWG4OGIju4kX8hg+n8s4dRb4MMy9cw2qhqFgRU1LB\nHuIciVmv52r7DiStXlOgeXzeGIjcy4vYb7912ClT5sWLmBITJS+PKwp49/kfyrAw7k746okqZZIC\nwckJdcuWklt55IZXr56I6ekkLl+R7zlEk4nUv3fj1qplnr6UuZF+5Ag3BwzElJr66At3TsCeqaC2\n/2l34sJFKEJCcGtRdFQMwdLj7eTtjWgyEffzz+hvR9k8hyklhYwTJ3CTyMvNJTQUvyFDcPItPvvf\n+hs3SFq1Kt/9jO6dOoIoPjEbWM6BgXmrPMvkENIMXO636PhUgjo94MjvkBxt/yCfAARnZ3wHD6Li\nurUEjBqF4ORksVeIKZ4bDXZL8ARBWAocAKoKgnBbEISBgiAMFgThgdvwy8AZQRBOAjOAHuITWG/U\nLMjy8Pnx7o/R6rVMbTWVWc/OItQzNN9z1vStyZC6Q9hyfQsbIjfka455Z+dhEk12O71L+Ws7otFI\nhSWL8R30VpEUTrEVRUgIlTZvwq3J03ZbQxRF0vbvt9vOUtr+/Rhu3cLJt2A7z3KNBt+33yb94EHS\n9u6VKDrbSNtvKX1WNWnqkPXtiSCXU2bCl5iSk4mdLL3tR0lFGxFB7NSpmPX6Ql1XWa0abs2akbhw\nIWI+1844eRJTUhKa1q0LHE/a/v2PCkKJImz9DFy9oWF/MJsgD7Gu/JJx+jQZJ07g9frrRbb83hgT\nQ8LcedweOhRzRoZN1+rOnweZDLWEyatJqyWjGAmtJCxeTPT4LzD/dxPBSlxCQ1HWqIF2Y4TEkRUt\nRLOZO598Qtqhf3IfGH0KNn8CKf/pJW/5ETR9B5zzV21TSva4hIaiaWup8EhauZKrzz9PajEU0LOn\nimZPURTLiKLoLIpiWVEUfxdF8VdRFH+9//qPoijWFEWxjiiKTURR3J/XnCWRUI9QulTqwpthb7Ku\n6zraV2gvSTnZgFoDqO9fn4mHJnI75bZN1yboElh5aSUvVHyBcu62KbVZi3evXlT6czOK8uXtMn9J\nJXXnLm4OGMi9WbPsMn/Klq3INBrcmjQp8FxePV7DuXx50vYfkCAy21E1bozfiBE4B5Sc/ruHUVat\nSsCokXi+8oqjQyk2JC5cROquXQ4pd/Pu3x9jXBzaiE35uj515y5wcirwqZdr3brIPTweVdO8tAWu\n74HWI0GQwaw2cODHAq2TE6LRiFuzpnh072aX+aXAOSiI4G+/IfPiRaJHf2ZTFYJb48ZUPXhAUhPl\n2O++42b//sVCEdicno52zVrc27cv0Kmje6dO6E6fRn/jhoTRFS3S/zmMdt16jPF5iB6dWQWHZ4OT\n4tGve1eEZ8aCa8ny4S1KqJs3R9OmDcqaNRwdis0Uze2zJwhBEPiqxVe8V/89VM7SmS3KZXImhU9C\nhoyRe0ZiNFt/4rPg7AJ0Rh1v1La9OTovRLOZzGsWb3vnoCDJ53c0SX+s5nLrNnY7IdBuWA9A/C+/\nYoiyvXwoN0SDgZQdO9C0bYOgUOR9QR4ICgUVV64g4JOPJYjOdlzDwvB9602HrF1YePfqhaphQ4BS\nwZU8yIy8RsaJE3h06+6Qnky3Fs1xqVyZjGNH83W9okKIxVIgG0EsWxCcnHBr1ZLUv/9GNJks5snb\nxoB3JcvpnYsG3INh97eQIr2wh6pePcrPmYNcrZZ8bilRt2qF3/vvk7xpEwlz5tp0rczNrUBltP/F\nNSwMc2oq+utFP9nRbtyIOSUFr969CjSPR+dOlP3xB5zKSN8iUlTQrluHTK1G88wzOQ8SRYtiZsVW\n4JqDeu6lrbBvhn2CfMJxDg4meOq3+VYudiSlCV4JJkgdxOgmozkRd4LZp2dbdY02U8vSC0tpX6E9\noR75LxPNcf41a4js1LlYlZvYgkytxnj3bpZgjJSYUtNI3bETTfv2BH4xHieJE+S0Q/9g1mrRdOgg\n2ZwPSm/1N25I4i9lLfobN0g/cqTYN0lbgyiKxEyaTOzkKY4OpUijXbsW5HLcO3dyyPqCIBCyeBFl\nvvwyX9d7vvQSgZ+NliQWTZs2mJKSyDhxwtLb0/Yz6PgtyO+fbLafYBFw2J6H8IONpB85gjGh+Njj\n+gx6C0379sT98INVqnqZkZFc79mLjLPSikspa4UBoDtzWtJ5pUYURRKXLMWlalVc69Ur0FxOfn5o\n2rVDJsFmY1HEnJ5OypYtaJ7rgEypzHng3dOQeB1q5GKhcOlPi0BSYtHfACil8ChN8Eo4HUM70jG0\nI7+e/JWTcSfzHL/4/GLSjem8VfstyWMxpaQQO+07XGvXRlkrR9vDYo3r/e/LHn54oi4Dz5dexOeN\ngXh262bxC5IwgXEuE4hXn/9JIu39MPpbt7jasRMJCxdKOm9uJK36gxv9+mPWZRbamo5CEAREg4GE\nBQtIl8B3qyTywPtO3cL+3ne58eD0zVZDXf2tW5Kapbu1aIGqcWPLCZ4gWB4etlqEpgAAIABJREFU\nK7X9d4BPJWgyBE4ugdtHJFlT1Ou5PWw40aM/k2S+wkAQBIImTSRk4UKryg3T9uwh4/hx5B7Slsy5\nVApFcHUtWhujogibPoKL/wqhmLVaBLkcr169JDklNyYmEvfDj+guXirwXEWNlL/+wpyejmfXXBI3\ngPPrLWXT1TrmPCb8A8uY3d9IG2QpxZrSBO8JYPTTowlQBTByz0jSDDk/JKTqU1l0fhFty7WlilcV\nyeOI//kXTAkJBIweXaJk6x/GKSgIuZcXGXZI8Jx8fQkcOzZLbSt5y1auvtARU1KSJPO7VKpE4KhR\nkqsLKsqVQx0ezr3fZhaa4mPagQO41qmDXG2bCm1xxW/ECJwCA4keM6bQBUSKA+aUFFQNGuD5quP7\nFVN27eJyi3B0Npzy3/18HNd79ZYsBrlGQ8iC+bhl7rE8FGZX3tvyQ1AHwMFfJFkzecsWTPHxePXq\nKcl8hYXMzS3Ltidlx07M6ek5jk3dsxdFaCiKssGSxiA4OaGsUQPd6SJ0gmfIgH9mwtIeFhNuQO7p\nSYVVK/F85WVJlhAEgfiZMy2n7yUMwVmBW3g4rg0a5DFQBtU6gVsuGwwewZby6hNLICFS2kBLKbaU\nJnhPABqFhonhE4lKjWLKPzmXcS29sJQUfQpv1ZH+9C4z8hoJCxfi+fJLWadcJRFBEFDWqoVOYv83\nY2Ii6ceOP9JnpQgpjyEqitipUws8f2bkNdKPHbNbE7//ByMwp6cT/4s0D4u5YUpKQnf2LG7NSp56\nZk7I1W6UGfc5+itXuffbTEeHU+SQe3oSPG1q7r0uhYSqbl2Qy0mYO8+q8abUNNIOH5b8ZB1tFOKu\nKZijz1pO8f6Liwb+txa6SfOeTVi0CEWFCtJ/H4WE/vp1bg8dyp3Ro7PtdzXrdKQfPoxbC/t8f/4f\nfkDguM/tMne+UKig+/17TeROTCkpmLRaBEGQTB1V7umJukULkiMiLKfNJQj35zpQftbMvP+t2oyC\n16yofmkx3FJi/ffX0gRoD44thK1jHB3FE0NpgveE0CCgAQNrDWTNlTVsu7HtsdfTDeksOLeAFsEt\nqOkjfQKmO30KuYcHfsOGST53UcP9uedQh7eQVPQiOWITN3r1Qv+QibqyWjW8+/UlaeUq0o8UrIwq\ncdFCbg58AzHTPiWNLk89hUfXriStWIkpJcUuazwg7eAhEEXcmpY8/7vcULdqhXunTiTMn29zCWBJ\nxpSaSuaVK44OIwu5pyeeL76INiLCKn+ltH37wGBA3bqVpHGYN3+GqM8kOaVOzoMCaliU+zJTQZ//\nEtGMkyfRnTxVpK0R8kJRoQL+I4aTsvlP7s1+vKc9/fARxMxM1OHhdllfVa8eymrV7DK3zRh0EHcR\nanYDNz/4ZyaJi5dwuXUbyXss3Tt1xBgbS/qR/IkTFUUyI69ZZ7+RnpD96Xp2aAKh9adQvuAK2JJz\n44DFYzPmjEWdN+GaoyN6Iiied9pS8sXbdd+mpk9Nxu0fR0zao34qKy+tJCkziUG1B9llbY+uXXlq\n+zacfArmr1Yc8HzpRfw//FDSMtTkjRtxqVoVl6eeeuTrfu+8g3NQENHjxuXbX0s0mUjets1i/uxq\nPz8dr549EE0mMk6dstsaAOn/HHqkrOpJImDUSCqsXFFgpcWSRPLGCCI7dUZ3qej08Xj37QMmE4mL\nF+c5NnXXLmTu7qjq15cugOiTyC6sQRtbFu3ePN6POi382MiiqplP0o8cRabR4NGt6FojWIP3wIG4\nv/A8cdO+I3XPnkdeE1wUqFu3zlK1lRrRaES7fj3px4pAn+2FjfBTY4s/W4P+iJe2kLJuAap6dXHy\n9pZ0KU2bNggqFckbN0o6r6MQRZGo99/n1pAheQ+e3xn+sMGLuMVwaNAv37HZBZMBIkbAkbnQ+C2Q\nOcH+UsXPwqA0wXuCcJY5Mzl8MgazgdH7RmMWLeV4OqOOuWfm8nTg09T1l867B8Cs15N2wOKDZs/k\noahh1usl28nU37pFxokTuHd6vMlaplIRMOYz9Feu5tuIM+P4cUxx8bh3aF/QUHNFGRZG5d1/o7Zz\niVbAp58SsnSJQ7zOHI2TtzcuFSsiiiL6W7ccHU6RQLtmDS6Vn8KlcmVHh5KFonx5NO3akbRiRa49\nk6LJROrff6MOD5dUdp+tY8DVC2PlXqQfOZL7qbrSAyqGF2jn3WfgAJ7avq3Y98QKgkCZCRNwqVKF\nqA8+fKSn2K1xY8r9+ov9PufkcmImTkK7ZrV95reF44vAoxwEN4CGA9BX6I3+djyePaXvr5SpVLg/\n/1yJKdFMjthE5uXLuOelVn3vquXEK9jGDQNjpsUzL056Je98ceg3iD0Hz0+xiDfV7WX5/bGDBUsp\nj1Ka4D1hVPCowMeNPuZQ9CEWnrPUda++vJp7unsMqiP96V3C/Pnc7D+gaKl/FQKRz79AzOTJksyV\nHBEBgEfH7FW0NG3aUHH9OjRt2+Rv/i1bERQK3FpKWwL2XwRByPKSseeHtaBQoKwivUhQceLerNlE\ndu0muVdicSMzMpKMkycd5n2XG37Dh1Fh2dLcZeBlMsrPnYPPIIn7otuNgy4/4Nb2eTAaSfvPaVS2\n42XOsNV2BcwHoiQPLFOKOzKVirI//Ujg6FFZ9zNTairGe/fsuq4gCCjDwsg45WChlaRbELkL6vYG\nmQzcyxCzOwOZTxCaNvn7DMqLMhMmEDTxK7vMXViY09OJHvs5dz78EGWtWrh3ysOu5dw6y9/VO9u2\nUGYqbPscdk3KX6BSknzHEkflDlD1BcvXmr8PZiMc+MmxsT0BlCZ4TyAvVX6JtuXaMv3YdM7En2HO\nmTnU969PwwBpS0sMsbHc++VX1G3aPHHlci5Vq0omtJL6925cGzbI1Rj+QUKTGXnN5t6/9IMHcQsP\nL5TdddFk4kbffsROm2aX+VO2byfm628w26mXsLjg0akjAhD9+bgn2gBdu8bifefRxcaHpELApWJF\nFBUq5DpGEASUVatKv2ERXB+qd7IozXp5kbJjZ+7j3YMgfISlNC9yl9XLmPV6rj73PPG//laweIsY\nirJl8bgvb6+/fp3kiE1cbhGO/uZNu67rGlaLzCtXclXytAXthg1Edu5C9OfjrN8MOrkUEKGu5bTO\nEB1N2v79BHapjHBlqyRx/ZcHmzOFpcJsD+JnzSJp5Up83nyDCksWI1erc7/g/HrLCalnOdsWcvOB\npwfD2TVw18Eb61tGW5K556f8K+TkHQqtR0LFlo6N7QmgNMF7AhEEgXHNxuHp4smALQOISY/hrdpv\nSb7DHTd1GqLBQMCnn0g6b3FAWasm+mvXMKWmFniu8vPnETwlbxPr9KNHiezUieSITTbNX/GPVQR+\nPja/4dmEIJcj06jRrluPaDBIPr92YwTJEREIJdQc11qcg4LwGzGCtL17SV6/3tHhOARRFEnZuhV1\neDhOfn6ODidbjImJ3HpnKMlbsn8wjp0+vcACSo9wZC6se8cicY/l/Rg0eRK+1vQDNR0KniH/nixY\nQcqff2KMjUVZq2Ru8GVevUpk127ETp2KU2AgzuVsfBi3EWWtMDCZ0J0/X+C5Mq9eJXrMWExpqZb+\ntvslwMlbthLzzTek7t2XvRDImT8sD+deFQBwLlOG0I0bUStOwY4vrRcFsZF7s2dz5Zl2kvpB2hvR\nbMYQaxFS8n3zTUIWzMf/gw/y/nxKugl3jkP1LvlbuNlQcHF3/Cle06HQcSp4V3z0660+hsrPOiam\nJ4jSBO8JxUvpxYTmE8gwZlDLpxbNgqRVHMw4eRLtunV49+uLIiRE0rmLA65hYSCK6M6eK/BcMoUC\n5+C8fZVc69ZFWbMmMZMnY9JqrZ5fUCgKx/z5xFL46ws8X3wJU3z8YyIFBUU0m0k/cAC3pk2LXDme\nI/Dq1RPXevWI/nwcSWtKno9UXgiCQIVVKwn4bLSjQ8kRubs7mZcvc2/O74+dtBqiorj3y6/SleTp\nkmHnV3AvEpyUWV9Wt2qFS2jFXC68j7MSBm6DjtadvouiSMKChShCQ3FrXjIVbRWhoWiefRZzcjLq\nFs3tft95UAlji4didpgzM4ka8QEylYoKy5ZR5dBBnAMCLHNfOE/CgoXceuMNLjV+mht9+hL/28x/\nfz8HbIGO3z0yn8tTTyE0G2Lptbq+t0Cx5YRrvXqI6el5nzYXEQwxMdwcOJCb/fpjzsxEplKhatTI\nuovd/OCVeRCWTz9BVy9o+o7lxP3OifzNURAe/K6UbQD1Xs9+TNo92DUF9NKcRpfyOKUJ3hNMs+Bm\n/PTMT3zd6mvJP5iM8fG4VK2Kz6DBks5bXFDWtFhN6ApgeC6azdzo0xftxgirxgtyOWXGj8OUkEDs\ntO/yHC+KIjcHDEBbGCc8MWdh/VDYMxV1qBK5ny9Jf0grFqA7dx6TVltiHyZtRZDJCJ42FfeOL6Ao\nbzlZSD92jGuvvUbczz+TcfZsiS/flGs0KMqWdXQYOSLI5Xj364vu5Ckyjj+qjpiyaxcA6tatpVls\n33RIi4MOEx7zvUvestW6+4wmwHKtNsoi4Z4LupMn0Z05g9frvUvshosgCJT58gs8e7yGlx0ERv6L\nk58fT+3+G+9evQo0T+aVKxjv3iVo8iSc/f0fEfDxf/99qh46SLlZM/F6/XVMKSmkbN2a9TOMm7OY\nhD8PkRkZSdIfq7k9bLjlVC3sFUti8Y99fDhd69XDKahMsVDTTNm+nWtdupJx4iTe/fraXlHi7Ao1\nu4NHAe5dTd6G0NaWEsnCZu802PA+mHJZO/4S7JoIx63w+CslX0goy1VKcaRlWfvUQWueeQZ127Yl\n9oM9L5y8vQkY8xmqhlbu2GVD+pEjpP/zD56vvmr1NcoaNfDu04eEefPw6NYVVb16OY7VnTlL2v4D\nuHfMo9lbCnyrQNsxsG86wr5peHTpQsL8BRjj43Hy9ZVkibQD+wFwa1IEfYAchHOZMgR99a84gZiZ\nCSLE//Aj8TN+wMnPD7dWLfH/4IMswYiSgCk5mVuDBuM3fBhujRs7Opxc8ezenfjpM7g3Zw6q2jVh\n+eugT0N3yBNFSIh1p2t5oY2yqGCGvWLp6/kPSStWYIiKwiMbpd7HyEiEn56GOj2gY87WCQmLFiNT\nq/G836tWUpG5ulJm3LhCW0+KagvXmjWp9Nf2HPvAZCoV6vDwLE8/s14PumTEJa9i2JtO/PE4y0BB\nwKVqVQSVypL41+8D+38E7e2CJSfZIMhkeHTsyL258zAmJhbJ+5VZpyNm0mSSli9HWaMGQd9+a/v7\nN+UunFgM9f4H6gL8rJUe0Mf6cmrJSLxuMVuv0gHkuaQYIU2hfFPYNwMa9Lf4bZYiKaUneKVIiik1\nlcSVKxFNpic2uXuAd+/eKKvmXxwheWMEgkplszqm37tDUYSE5GnunLJ1Kzg5oXmmbb5jtAp9Osid\nocUwS9nI5a14t6lJwKiRCEoJJcWNRlSNGhXZfquigFvTplRcsZzKe/dQZvIkXBs2IG3/fuRuFoGd\npFWruDdvHpnXiq8RrWgycfeLL8k4fhyZW9GX5Ze5uuLZswepf+3AtOZDuLwVMfokAT6b8A33lqan\nadckyzxtx2T7srpNG/TXr1v3c3f1siR3R363nMzngP/HHxH83bRi8TMoTmScOkXUiBGYkpJsvtYQ\nHU3CgoWIZnPeIh8PIVMo4OxqhJsHCPrmOypt20rgF+Nx79yJgI8/+vezvtEb4F/DbhL47p06gdFI\nypYtdpm/oAhyOZkXLuA9cAAVli3N3+bMufXw1xeWjRQpSE+AYwukmcsaNn8Kghw6WNH/12IEJN+G\n0yvtH9cTiFDcSnQaNmwoHpGy6bwUSYn5+hsS5syh4prVKKtXd3Q4DsWUkkL6kSOoGjWy6cMUQNTr\nuRTeEnXLlgR/87XNa4t6fa5lIaIocvW551CULUf532fbPL/VXNoKG96D/60B/+qWPqCID6DlR+D3\nZFsZFBVEUcx6QLs1dCip2/8CwDmkPOqWrfDu26dIlzk+jCiK3B37OUkrV+I3bBi+g6W3frEHxrg4\nEpctx+ul53GKP4rOGIB5QS9Unqnw5o5sT91sQhsFt/+xlH1lgyEqiivPtMP/44/xGdA/7/nSE2BG\nPShTG/qsf6zksxT7kXbgADf7D6Dc7NmoW1jvKSoajdzo24/M8+cJjdiIc5kyti08u51Fgn/IAYf9\nvEVRJHnjRtxatCgyJ3ii2UzismW4P/88Tl5eeX725sm8TpZS6ncOSRPgvumwbSwM2Arln5Zmzpy4\nuBmW9oBnv4Tm7+U9XhTh13AwZcKQQxbbjVJsQhCEo6IoZiuBX/qvKQV3TsAvLSA+9xOTkk7mtWsk\nLFyIx0svPvHJHVj6726/PYSMkydtvjZ1717MWq11JVPZ8OADJmXHjmwNrzMvXsRw4yYae5qbp8Vb\nFPtcvcDr/k6m0h1emgV+VTBnZJC4fEWBBQPA8vBiF7S34doeywfRpo/g+GL7rONAHj5pL/fjj1Ta\nvo2AMZ+hCAkhaflyYiYWAT8lKxBFkdgpX9+XIn+z2CR3AE5JJ/B7+y2cgipB7VdR1m+F69QbiL1W\n/ZvcafPhaSiKlj8ewTkmdwDOwcG4VKlC6k4rBSxU3tD2M7i22yLk8BBmvZ5bQ4eSfuyY7fGWkif/\n9nfbJr4T//MvZBw9SuD4cbYnd3EX4fZhi2CGNcldZirEXbJtDSsQBAGPzp2LTHJniI3l1ptvEfPF\nl2hXW3rKC5TcpcbBjX35V8/MjkZvWERbdtrZR1AUYft48Ktu6f+zBkGAlh9YWjh0tp9Il5I7pQme\nFGjKQNwFS8nKE0zM5MnIXFzwHz7c0aEUCbI+iPNh8u7k7Y17l864Ncu/YIgxMZE7H37E3S++fFxM\nQxDQdOiApl27fM+fK6II69+z3LRfnGVR4HuY+MtweDYxkyaRuGRpgZeLmz6dyM5dpDVQ196GeR3h\nj4Gg08K9K5aE9cQS6dYogijKlsW7d2/Kz5xJxdV/5OsE2SGYTBiio/Hq3Ru/EcXoHnR6FSx+GfZP\nJ3nbNpLWrkU0mxHkTghV7kuJ3zkBM+rC1jFg1Fs/9+WtsKALpMTkOVTdpg3Ge/esty9p0B/8a8Ld\nRxON5E2bSN3+F6JOZ32cpViN3N0dRYUKZNjwuZJ26B/if/kFj+7d8eicD0/I44tA5gS1X7Nu/MLu\nsPoNu1gmiKJI4rLlJG+yzQ5IalJ27ORa126kHz1K4LhxeA8YUPBJL2wE0Qw1JEzwFG7QYjhc+9tu\nCqeAJVnrvQJenGlpybCWmt2hx2LLplEpklKa4EmBJsDyhjy+GPTFx6NFSlL//pu0v3fjO2SIZKIZ\nxR25uzuKkBB0Z21P8Fzr1iX4668RnG24Uf4HJy8v/Ia9T9qePaT8+ecjrymrVqXs9O9x8rbTTfX4\nQrgYAc98DoHZeGCdXIZsx2d4P9eI5IiI7P2WbCBt337kHh4IcnmB5sniQXKXngA9loCrp+Xv0Naw\ndkiJT/Ie4PLUU8jc3DCnp5O0eo2jw8kRs16P4ORE8NRvCRg9qvj0/17bDWvfhvLNoOm7JK1cyd3P\nx3E5vCXpD6tq+laGur1h/wyY/X/2zju8qXJ/4J+TpGm6N9DNFGSDXBEQ3Av33tvrwnW9zqs/97zO\nq7hwK24RAfcWB6gsEZBZSkv3TNukmef9/fEmaYHSmTRteT/Pc55zctb7Jjnj/e5DpEWlLbweKRBa\ni9o1eEqbdSWDP/2k/c8co0m6jx70n8AqIQQ1b87FPGQI0VOmtO88ig5jGTMGx1/ts+DpLhfFt9yC\neeBABnS2ZEjGBJh2HcS2M7553OlQ8qe0+gUZTdOwzp9P5ZwXg37u9lL5why2X3klpgEDGDTvQ5LO\nOD04z5y6IkgbAf2DXDdy0kUQOwC+fyA0dQqd9fK8iTnSbbszVG4Of2H2PoYS8ILFP/4JTqssAroH\nYoiJIfaQQ0g+5+xwd6VHYRk9msY1u09E0BKODRtbdKvsDElnn41l1ChKH3gAb309ION9XAUFQTn/\nbsn7QRbD3W83BZSnzIKIGJIHlaM3NFD/9dedbspTU4Pj77+JnhqkAWVtYZNwd+7HkOVzb4+IgjPf\naSbkdd3y2Fuoee99Sv7zH2reez/cXdmFmnffY+tJJ+GpqkIzmdB6SxxH2Vp492xIHgxnvg0RFlIu\nvBDhdOKtqcE8cGDTvuYYOPZJqWSoK4IXDoBlr7R+/hWvQ+UGOOyedmnUNbMZTdOofO45Kp55htp5\nH2H79VeceVt3r4DxW+aLlkNdCY0rV+FYu5bkc8/pPiFb12ViipKOu8L3VqImjMeYkoK3oW2FssFs\nJuPBB8l8/LHOJ7wZfRIc0nKCnhYZewZEJsBvL3SuvTaIP+YYnOvX49y0KSTnb4vEU06m3y03M/C9\nd4kcMiR4Jz74drj8l+DHOEZEwfR/y3AJd5DrzgkhM/9+cEHnz6F74Y3j4YtbgtatXaje2nrZhj5I\nL3kT9gJy9pPuKr+/GBoNSQ8netIksp+Z3TX/8z6IZfRoPCUleCor231M+WOPUnDBhUGpUaYZjQy4\n+268VdVUPCFr49W8/z5bjjgST3Xrday6xMkvy8Ho7gbb0cmw7z8xlvxA9PC0LlmH7EuXghDEdsGd\ndQeWvwr2Gp9wt1NyC7+Qt9cRe5RLSfJ55xIzfTql996LvQclubIuXEjp3XdjzszCGBcX7u60H12H\nDy+SgtvZH8qBFxC9335YxowhevK+LccZjTgarvgVcqdCQ/nuz++ok5kzc6bKYzpA3WefU/n0bEpu\nu42Ciy4mb+ZMim+6KbC96MabKLn7bipfmIN14UJsP3+DeOUo+OYuaua+iSEujoTjguhitju8bqlk\neXYyvH9u2wJvHyL5rLMYPP8jjLGtC2zucnmNxOw3ufNx8Rs+b7Pm4S5ExsKEs2HdxyHJqBl/1JFg\nMFD74YdBP3dreK1WhMeDKSWFlAsukNlFg3Zyn/DRWmmBrrDvP6UrpDnIWW3XzpcK3dz2J/zZBYNR\nxu3l/wSFwbf6suxV6eI+5wDY9mvwz99DUVk0g8n6T6Wpesxpe0w2IE9FBdVvziXl0n92OFPknoCn\nogKv1Yp50KB2uQ96qqrYNOMAUi6+mH5BjCOqmP0M5uwsEo4/nrzjjscQF8fAt+YG7fwB/nxX1rZJ\nym1734YKeHIMDtPelK4aQM7rr2GIjOxwkyX/dwd1X3zBXkt+3aFgb6fRdajZCimtaGaFaNKy1hZI\n15Q+jreujvzTTsdbV8egD94nIjMzrP2p+/priq77l1QuvfA8Boul7YPaS8VG0AyQOjR459wZvzvS\nTi7M3oYGQGt98K7rgJADoy3fy2LGww5r2v7jI/D9fXDJd7sqKdqB7nTiKSvDXVKKp7QEY0oqsftP\nQ3i9bD35FNwlJehWa2D/7LNyiNWXYs26EY8hs32ZOLvCqrfh+wfBWgD9x8D062Hk8TJEwrod+o8M\nbfu9AMe6deSfeRbp993bubg7kEqEx0ZIj4vD7+3YsVVb4Ol9pOV5nws6134rFN9+O9Z5H5E9Zw6x\n0/cP+vl3Rug6BRdfjGYwkv3Si8G3UL99Bpij4ZQQKyqKVsg6dQf9p/PulH6c9TD7HzKJy6U/yOdR\np8/VAE+OluOHM4PoHfPXhzDvEnlea6GczvoA9gphgrlupLUsmqrQeTDpoKa0L1D++BNYP/mExJNO\nVAJeC5jS0jpUl63uiy/A6yW+k9kzd0faVbMAmenUuXEj/f9za1DPD8D2ZdJ1ccI5cNxTbe8fmwZT\nriTS1cjAmx/otFtK7EEHEjlsaNeEu5ptMoHKCc9KYa014Q6a+rr5W3j7NDj+GVkbrA9jjI8n69ln\nyT/tNIpvv53cV18NW19sS5dSdP2/iRo9muxnnwmucAfw59vw8xMw6WI5EIoJUlyx2wF/L4Ixp7Qc\nmwrte442VyD+8j/I+x72vVS6Y0ZESW146rBOCXcAhshIzDk5mHN2VFxoRiODP5bWdt1ux11aJgXA\nhCj4/AwS9G/hom871WabOOqk9cFglEqV+HQ4+jEp2Prvx3fPgrpimWK+I4keeiEld96Ft7qarKd3\nfdbqNhtF1/8bY0ICMft3QfhZ/R4Ir3ymd5SUIXDNCumCHAIG3HYb3tpaTGndE/Nf/drr2JcsZcA9\ndwdfuHPUwZZvZahPqKnJh4Jf4YXpsPexcOB/Oq8Q+eEhqC+B097smnAH0uq772Xw40NQti54SprU\nYVL5c+LzMoHNsldgiK+2cMUGSB4SOqtpmNkzzEzdgH3FCnSHQxan/OUpmSK+j9O4ahXW+fNJOf+8\nHeNFFDtQ/803VL/VvvT6dYs+IXKvvbDsFfwacUIICs47H4C4ww5rY+8O4myAj/4J8Rkd0/Qecgfa\nUQ+CpuGtrUXoeoebjjv4YJLPO6/DxwWo2SZrD5WuBntVx47NmSJdU+ZfLq2XfZzIwYPImj2b9Hs7\nqM0PMubBg4k/4giy57wQmkLaU6+R6cWXvwZPTYRfZ3cse2VL6DrMv1RmFyxZFZRuAnDmuzD5Cvh9\nDsw5EEpWy8HSqBOC10YLGKKjiRw8iJipU7GMmgCH3Q3FK+CVI5p2qs7retyLrRK+u09q9/0lGabf\nABd9KbXwzQfbU66C6i3yf+vrCIHtt99adOUvve9+XNu2kfHII50vKSCEzJ6ZtS+kDe/cOfzCXSee\n621hiIoie/ZsLCNGAHTq3dFeHOvXU/HEE8QecgiJp54a/AY2fgleV3CzZ+6O0SfBtavhgJthyw/w\n3FRYdG3Hz+NuhHULYOJ5kP2P4PRt8mUQlRyceNqafDlPHwenvS4VX+YYmHq1VP64bPD6sVLQzf+l\n6+31QJSAFwTcRUVsO+98Su64A1FfCl//n8wi2IfRHQ6K/3MbpgEDSLm8nTVP9lDqv/6GyueebzOm\nzlNVRePatcQfe0xI+qFpGlETJxIzY3rH6yC1xZf/kUHMJ74AloQOH+62ywnsAAAgAElEQVT4+lW2\nHjFNxtN15LiNG3Hmbe18vKJfuHNa4bwFMltcRzBHywH2oOk+Ie+9zvWjFxGz32TMWVkIXe/2eDxX\nfj7C4yGiXz8yH30EY0LHr7VWaaiAbUtkfOXRj8miztn7wle3dS0BgBDyHlm3AA6/r+PXWWtEWOCo\nh+Ccj6Qw9ML08GSjG3u6jL31u+PpOrx4MDycC2+eBIsfkQMpdzvLJ1i3w+e3wBOjYfGjMOgASPG5\nzBpNLVv89zpCKlx+fFi6j/VhLGNGo9fV4d62bYf11kWLsM6fT+oVVxAzed/ON1C0XJZ/mtDFxGnf\n3SdLdYQIIQQld9xJaYiUTrrDQdENN2BITCD9vntDkzzo7wUyy2VWF/6vjhCVKD0TrlstSygkDZTr\nhZDvxPYQESXjgQ8L4u8enQzXr4PxZ3btPPk/wzP7wR+tlC6LiIajH5fK6ddmwrx/hiReNJwoAS8I\nRGRmknrlFdQtXETNF8tg4HT44xWZGaiPUvH007jy8ki//742A733dCxjxuCtrMRT1notKlNKCsMW\n/0jSaaeFrC+ZTz5Bzpw5wT3pxq9kxr79r4OBnQi0bignculNpI5qoHbeRx06tHL2MxRcfHHH2wTp\n5vXaMeCs65xw58ccDWe+5xPyLtulLlhfpeadd9h2zrnUf/NNt7Tn2LiR/NPPoOzBh0LXyOJH4PVj\npJsfSMvFOR/COfNkHBJIRUbJ6o6dd8ls+O05mVV2ylXB7bOfoYfArN/hyIebBmzdiaZJ11O/QCC8\nMPNR6bpcXyIH+q/NbCq47HHC5m9aFsSEkELh73NknaxZv8Hpb0L/UW334bB7wVYhra59mKgxYwB2\nqYen2+zETJ1C6pVdVLxu+1UOgked1LXzRCXL5BnFK9vetxNomoYxPo7ad97FumBB0M/vKS8Ht4eM\nBx4MTYF1lw02fSPdJbs7d0N0Mhx6pxTyQFrIn5oAC66S78fdUbZOejRY4qWwGEwiouTcb4HrKNuX\nwdunyzwAI1vxYtA02PsY+WyZcZNUvj09ST7f+wpCiJBMwCtAObBmN9s14ClgM7AamNie8+6zzz6i\nJ6J7vaLgylli3chRovHj/wpxZ7wQ6z8Pd7dChnPrVlH1+uvh7kavwL5ypVg3fISwfvVVuLsSGhx1\nQnz/kBBuZ+fPseg6od+ZKDbtO1J4amvbdYju8Yj1+04WRf/5T+fatFcL8frxQhSt7NzxO+O0CbFi\nrhC6Hpzz9XC8jY0i75RTxfoJE0Xjhg0hbcu5davYMG1/sXH6DOEsLAxNI9Vbhbg7RYiF17a+37x/\nCnFnghALrhKivqzt81ZuFuKuJCHeO08IrzcoXe2V2KqE+PtTIcrWyc/5v8r35F2JQjw/Q4jPbxHi\n41nyPvJvr87vXFvvnSfEu2f36XtRd7vF3+PGi5L77991W7Cus4bKrp+jsVaI+9KFmH9F18+1G3S3\nW+Sfc674e9x40bg++M8i3eUK+jkDOOqFWPpC8N5DXaGuVIjPbhLinlT5LFz0LyGsRTvuY68W4r9D\nhJh3aej6sfgxIe7t177na3OK/xTiwWwhnhwnhLW4Y8dWbhbi+webnhm12zt2fJgAlondyEuhVBe8\nBhzZyvajgGG+6VLguRD2JeRoBgMZDz+EOSeHgv/OR8T0gz9eCne3go5wuxFCYB44sGtxT3sQkSNG\ngMmEo5V6eI7168k/55yw1fXpFEJId6vIODjwZjB1IWX0/v8CTSN5SA11n33WrkMc69ahW63ETOlg\neQTrdtnvqCQ472PIGN+JDreAOVpaLzRNWvH+6t4U3t2NwWIha/bTGGJi2H7lLDw1NSFpx11UxLYL\nLwKvl5xXX8GclRWSdvj+QZko4ICbW9/vqIelJW7V2zI+76fHW3c7TBkC586X7st7SHblFolOhhEz\noZ8vXX/6OFmKZPoN8hmy7BVY+3GTBTy3ndl4W+LEF+D0ucGvJ9aD0Ewmks44IxCvXTH7Geq++FJu\n6+p15o9ni0np2nlAuuyPO0M+D0OUm0Azmch8/DGMcXEUXXNNoOZrV/DU1FD+2OPoDgdaRAgT9kTG\nwuRLg/ce6gpx/eXz7ZpVMPFcWPEGvH7cjqW/vrtPxqr7PRpCwd7HSQv/0mfbf4yzHuaeDOY4OH+h\nTMLUEVKGwIG3yGdGzTaZAfbDi5q8OXohIXvbCCEWA60VTzkeeMMnhC4FEjVNC3JgUPdijI0l65nZ\npFxyKUy6SGbs8brD3a2gUnr//RRd96+QBjT3NQwWC5HDhuEu2f2Dou6TT2hc9SfG1O7JCBYUlr0s\n68o0VHT9XIk5MP4sEoc2Ur+gfSmSbb/IejYxU/ZrfzvVW+GVI2FhiNzk/Cx+RCadWf1BaNsJMxH9\n+5M1+2k85eUU33BjUGo3NkcIQeHVV6M3NJDz8kvBLSrcnLK1MmPg5MvbHhhEJcGRD8CVv0m33G/v\nlhk3d6Z0jXRBBBh8QFNRcIXEHC2z2R18G1zwCdxSADduhpzJXT+3/7euLWjd1ayX0/+Wm0k85RQa\nFi+mcvZs7L//HpwTv3UKfN6GoqMj7HspeJ3SlT9EmNLSyHzyCTy1tTg3buzSuYQQlNz+f1S/9hqu\nghBeP24HrHxLJufrSSRkwjFPwNXL4dj/SaHH7ZDXxB8vy/+zqyUWWiN1qMx8+cfL4LC2vT9IJdFR\nD8lwi66WLYrtB9Ouhb8/kWUgfvlf15NshYFw5gbNBAqbfd7uW1ey846apl2KtPKRk9Oz601FDh5M\n5ODBIASe6mqMBhN9RYfY8NPP1L77HskXXth1DWG4qdwkNUT9R3WLlnfgO2/vNpW70HWsn35G7LRp\nofHxDwUVG+HL22XMXZBSyGvTr0es+4wB17QvqN+2ZAmRI0ZgSmmnlrl6q4y5c9tklsRQcsJzsjjw\n/Evl57EhyLzWQ4gaN470Bx/AlJoW9AQEmqaRfuedCF3HMjKEtc2q8+SgYP/r2n9M6lBZr2nL903a\n96Llsn5edKocJBsj4KplYOp4fcc9jmD/Rm6HzCqaM0UWeO6juPLz2X7NtUQOH06/m29q+4C2qMmX\nKftzpnT9XH76jZDxmEMPCd45WyB6n30Y+u23Xc4LUPv+BzR8+y39br45JBmtA2z5DhZcCXEfhfy3\n6RRJuU1W9G0/y5jYmDSZoCXUTL8e1n0sPeGm/3v3+1mLoGoTDD4QRp8cnLYjouCgW6Xl+Ytb4es7\nZIKnXlYKLaSFzjVNGwh8IoTYpeCPpmmfAA8JIX72ff4WuFkI0Wpath5d6LwZzryt5J9xBv2vvoDE\nMy7s9dpbb10deccehyE2lkEfzetUQeoeQU0+fHc//PW+/JyQLa2t06/vvj44G6CxGgwRYEnA/uda\ntp17LhkPP0TCccf3fLcijwtePhRqC2WWwbgBwTu319PumjTe2lrcZeVYhrfjBVydB68dK4W78xaG\nVvvox2WTwd7bfoHjn+16ZrBegrukpNNZWnWXC/sff2BbvBjhdjPgjjuC3LvWGvd2vZbTGydA3g8Q\nnSK9Ny76vO3EIIrQ8eN/ZVKXi74KjmWwh+EuKmLzIYcCMPjTT4Jj4f7+Afm7/WsNJITIHTrECCGo\neecdLMOGEf2PjqXwd27dytaTTiZ6wniyX3optMrsjy6DjV9Iy3VvqNtYnScVWN2VxGnuyTKk4sql\nLY+LGsrh1aOgsVZmBDWHKOHftiWQs1+PHJv11ELnRUB2s89ZvnV9AvPAXOL/MZCETbfg/LSGyBO6\nQeMRQsrufwBPZSUDZ8/uvcIdwE+PyULD+18PyYNgwxfg8cXPeN2w8BoYcrAsnhvE7FCe7ZtxPH0W\nUWlujLZ86b4LcORDWD8vI7KfiYSV58NKQDPKh73R7MtCd7qsC/P+eVIojE6GY54MXiHQjvLjQ7I/\np70ZXOEOwGiicfWf1L8zm7S7n0Ez7z6uz5iYiDGxHf+RrsO7Z4PbDucvggFjgtjhVjDHwFnvwVun\nySxy48+UsQwvHgTxmfL6Sx4iff/7jQxeMe0wYv30U0puuZWcV18helKL75wWqf/mG2rnfYRt6VJE\nYyOa2UzsATMQQoQmLbkfIWDT1zD00K4LdyDrLf30GPw1D059TQl34WbKLGkB+Pr/ZN28HjhA6wqm\njAziDjuU+KOOCo5wp+sytnTIQaER7gqWyvvtkP8L/rmbIRwOat6ci7ehnkHz5hHRr1+7jy298y4M\nZjPpDz4YWuHO44INn8tMjr1BuIOQFa3fLcf+T7rEt3Tf2qulQq2uWMY4h0q4AxkP3AsJpwXvaOAq\nYCYwGXhKCNFmEZDeYsED8FqteO8fjtcNpltWE9G//Q+ZnoSnspK8444n6YwzSLvm6nB3p2O4bLD0\nOSm0ZU6UGh/dIwty70zlJnh1JtjKwWCC3KkwfKZMEx3Xv33ted0ySUDh71C4FNLHw/7XIex16Pfm\n4onKIXL/0yAxW+6bsx+1v2zEU7yJ1LGatGB5XaC75fKYUyBrElRtgR8ekuu3/iSFgX9+L+NYuhOv\nWxYyTtsbTngmJE24Xj4PU95CbFNfIu7oU1rcp/bDD9Ht9tYT/eg6IOTAvWi5fFF09wsK5G9WXyr/\nc5dN1tup3iJdRr1Ouc+MG+Hg26UmcsEs2c+UIT4BcGjHA8bDhLeujvzTTsdbV8egD94nIjNzl32E\ny4V9xQoafvqJtFmzMERHUzH7Gazz5xN7wAHEzJhOzOTJGKKiQt/hjV/C26fBSS/C2NCVJ1GEkWWv\nwifXwelvycG0Yvds+R7ePAFOeSV47m7N+flJ+OZOWT8txMoP56ZNbD3tdCwjR5L72qvtTpTiys/H\nXVxMzNQOJu/qKJu+lm7cZ74Hw1vLR6hA90plnN+7x1EHbxwvY6fPfl+6Z+6htGbBC5mAp2naO8CB\nQCpQBtwJRAAIIZ7XpFp2NjLTph24sC33TOhdAh6Ae9F9RCx/hOL8qaTPWdCqRaIzCCEQdjuGmNDW\novNUV2OMjQ16/0OG1wOr5srMeA2lcOCtMkNSW+i6FAY2fCa1axV/wwWfyVizqi0yGDpjYlM2PI+z\nKXbkvXNlUgW3XX5OyIYJ5wTa3XraaRgsUeS+0cVA8y3fwZsnwrTr4LC7u3auzuB1SyE0RBozUboW\nnptKvW0k8Y8uaXGfvBNPwhgXt/vf0lEHH18BqcPg0LtC0s8uo3uhrki6vcRnyr5WbYF3zpDCn94s\nQdMRD4Q2a1kQceZtJf/004nIymLgW3MxREfjqamh/uuvaVi8GPuvS9DtdoiIIPf114meOAHhckFE\nRGitdTuj6/D8/vJ+veqP3qNFV3QMr0cWfx99klSkKHZPXbFM+jH16tCEldir4fG9ZWzTsf8L/vl3\nwrroE4pvvJHkCy+kfxvxiZ7KSowpKd33DPr+Aal8vnGzitFtjbpiGTs/48amMIdfn4Zv7pJKmz1c\nOA6LgBcqepuAh8OK+O8w7K6BRN2+eLeJNjpD459/UvbgQzjWrWPAnXeSeHIXC5LuhBCC+m++Ie7g\ng9GMQXBf6i42fglf3Q6VGyF7Mhx6d+dN7NV5kJAjNUdf/AeWPgMx/aQ/dqUvU9es3+T8y9ukdTB7\nspwSdrRelN5zD9YFC9nrj98Drh+2pUuxjByJMT6+Y/1a/b50K4tO7tz36ii6V6aD3/cSaQkLMY77\npxJhX4d+2R9E5AzbYZunqopN0/Yn7brrSL38sl0PLl8P750thaQjHoD9Lg95f4OO7gVrobz+Sv6E\nSRfLorJC9Ao3s4bFiym87HJSLrmYfv/+N41r15J/8imYMtKJnT6D2ANmSCtdiBVTrfLnezIJzskv\nS0u5ou/SXBGnCC8LroI18+D6dd3yLim99z5q3n6bwYsWEjl0aIv7eOvr2Xr8CcQdfjj9bwli9tC2\nsFUFpxRFX0YIeG6aHFtduVQq13UdSlf3jNISYaY1Aa+Xp0LsBVgS0CacRUx0EQaDHrTyAlWvvEr+\n6Wfg2r4dy6hRlNx2G9WvBzcFcd2nn1F09TVYFywM6nlDTsmfcn76WzLuoiv+08mDm9wCZtwgXbkG\nToPildJCN+bUphoxR9wva8iMPmkX4Q7AMmo0us2GK38bAN4GG4WXX0H5Ey2kWG+LsadJ4c7rllrR\nUPP9A/D9fdKq2Q0Yj7oLY4TA9cGusau2pUsBiJnawv+6bgG8dIhMrXz+ot4p3IF0K00aKF2L9/+X\nFO7cjfDa0TKGtLvopAIwdsYM+t18E15rHQCWvfdm8KKFDP32W9Lvvou4gw8Or3DnccnrecBY6YKt\n6Nv4hbvCP2SSK8WubPpaPltCrfSffJm0mq/snsym/W++iZzXX9utcAdQes+9uMvKiD+qm61BSrhr\nG02T78DKDTD3JKn0NBiUcNcOwplkZc9hxo0w40ZcZVVsv+Za0u++i6ixHc/ip9vt6E4npqQkYqZN\nI+XSS0m59FIMlkgq58wh7qijgtZld1k5pffeS9S4cSQcf1zQzhsSytfLWlRjT4dRJ8j6Jftf3+5s\njO0mOlkKVp2M1YkaOwbLuLHoNjnAaPjuW4TDQcIxnYwLEUI+8HRdFvYMRpKIlli3AH56FCaeB+O6\nJxNkxMTDaZyXS6R78y5WK9uSJRji47GM2imGo65Exrelj4XT3mg5zrI346yXCYHeO0de3wffHrr/\nXAj46wPpBuOwQly6VF4MPUTWFdv4pVwXnw5xGbJu0E59SbnggoBCSzMYiBw2rIWGwoS1UMbZHnrn\nnl18fE+icrPM/nvQbXBAEMoJ9DW+v1+6s44IcZzigDEw6kSZir4b0MxmYvaV6R3sK1ZiGTEcQ3RT\n7Lr1k0+pW7SI1KuvImrcuG7pE1/dLq13Jz7XPe31dkadKBVyed9D/s/hiaXvhSgXzW7EU1ND/imn\nIjweBs37EFM7i1oLXafuk08of+xxoidNIvOxR3e/r9dL8S23knjqKYGHWkcRQlB4+eXYf/udQfM/\nInLQoE6dJ+RYi+CHB2TWL3OstKBNbCXpRg+j4NJLcW7ezNBvvul8tq6Vb8k6OgffHpr4krJ18NKh\nMmPnBZ92r5uTvRosCbsIDkU33Ai6Tubjj8kVLntTspltS2Qynb7qjuVxwmc3yoLBgw+SyRCC7abr\nssv01AW/QsYEyN4P6otlzGfmRFj7MXxw/o7HaEZ5feROgYLfpAtWfLqsByd0GU845lT5fxb+Dlt/\nlINJ3SO36V4ZJxsZK60I6z8D4ZWDzZEhUjB5PfLa6gUur4og8d45MpHINasgNi3cvek5lK6B56fB\nkQ/BfleEuzchwV1ayubDDif+qCPJePhhNE3DXVRE3gknEjl0KLlvvoFm6gabh+6VcYjZk+H0N0Pf\nXl+heKUsmbD3seHuSY+ip5ZJ2LOwFmFaNIuc284m7/qn2H7ddeS+2nZmJ/vKlTLObvVqLKNHk3RW\n6xYUT1UVjjVrKPjsM/rdeAPJ55/f4aBh67x52H5cTP/bbgu/cKd75U1ds1XWXZtwjhyQfXuPDLQF\nmHyFLITZS9wdhK7jra3F9suvpFx0UddSMY8/Sxal/f5BGHQAZHdOqN8tn90gB92nvdn9QlN0MsLt\nxrlmJZYRIwNCXOajjxBQTBWvlMltDrlTFhPvpemM240pEo57CjL3kf/Nx1fIUgzBwOuWiUbM0ZA2\nXAa0jz9nVwvX3sfBvzdKoa+uxDcvbqqNVL0F/nwXnNYdjxt8kBTwCpbAd/fJdZpRWtKMEdLyHhkr\nYyfzf5LC7Or34KDbpXt0sASxgqXSihDKtNqKnskhd0nlwY8Pw9G7V5Tucax6S5bgGdONmWS9HqkI\nSswGNN/9rcGA0fLerC+T3gKB+14DDeg/Wj4HG8rlfu28jyMGDCBt1pVUPPk/oidMIOnMM3EXF2NM\nSiLjvw93j3BXuRl+eQIaymDk8aFvry+RMUFOinajLHjdhccJT4yCzElY486h+MYbSTr3XAbctvv6\neLUffkjJ7f+HKS2NtH9fT8Jxx7VLGPA2NFB8yy00fPMt8TNnkn7fvTu4JLSFfeVKaufNI/2ee0Jb\nB8aPu1EWIK/eKuvvRETByrkyqUdtwY7ZBG/aKi0Wq9+XsXb7XgpJuaHvY5Cofv11Kp9/gf633kLx\nTTczaMGC9hXqbg2HVWYDBLj8ZzmIDhb1pXIKk797+X23kWx7FsNht2I4+KYd66KtnAufXA8xaVIT\nmjkxLH0MG9uXy1qNKUO6VqRb130ZZx+QReDTung9+nE2gL1K9ssQIYt/G01yYIfwCXetPF88Tlh4\ntRTygmWhtlXBU+OlFviEZ7t+PkXv45PrpQV81u/y3gk3qz+Qz+y9DoeGCqncSB4s62QG81m+Ozwu\neHwEDNxfurZ3F0uegS9bGP9c/osU8n6bA5+3cM9f+6dUJv30uDzHjBth0oXtUkAKXWf7FVfS8Ouv\nDHxrLlFjxyI8nu4R7jZ/Kz0jjBEw/mzp8t5XPU0U3Yay4PUETJEw8Xz46TESrn0Yx/nnY1++HL2x\ncYd6T7rNhqemBnNWFrEHHUTqVVeRcuEFHUpIYIyNJeupp6h68SUqnnwSr62BnBdeaPfx0RMmED0h\nxJoSZ710Ncv7AepLmtZf9pOMobIkyof83sfKF13SQEgaJNdDl2LhwokxORlvTQ2Rw0cw5KsvMefk\ndP2klgQ46SVZ68lWGZxBwaavZYKPuAHBL2beAWJnnozjhReJ/uUp2P8qim6+DU0TZB6swbJXpNXy\nlFf6RJHwDpO1j5wLAfMukb/B4feDqQOlTIqWw6c3QPEK6YpJEBV+kbFy2pn2xsaaIuHEF6TGfsyp\nwenTz4+Dq0GmgVfsmRx4i0wWVf53+AW85a/BomvhhOfl5+1/wIcXNm2PTpHvvaMfk0q2umLp0ZI0\nSN7vwbBq1xZAZDxMOLfr5+oI+14K6eOk5wCiKbmLX2E7/Ej57gffNt/2GF894WGHy5JBX9wsBb2D\nbpVx+K0oujSDgYyHH2LLsceyfdZVDP3h+9AJd143rJ0v+zP6ZMidBgffJseBsb2zJrKid6EseN1J\nbSH8byxMuxZx4O0IrxdDpNTgCF3HumAhFY8/TkRmJrnvvB2UeiwNP/+CMSGeqDFjdrR+tED1W2/h\n2ppP/5tvandR0E6T/4us5TbyeFn/K2mQfJj3H9VtwdfhwJm3lbyZM0m///6gl7VA14OTMGLNR3KQ\nceTDYc9CKYSg+NT9yRy9BnHYfWy87k3SjtyLZOMi6dJ38B3BT6bT29C98PUdsGQ25EyBU19rWygX\nAj79txSSY/vBYfdKhUlPjkfzf8/9roCErI4fb90OT02UJRGU9W7Pxu+OHE7+eBk+vR6GHganz5V1\n59yNshZmzVaZLbDaNz/mCSmM/v6idM0GGXeePMgnAD4uYworN8namrEDIK6/VIi2554WPgGrtyUc\nEkIm3vjmbihZJWPwj3u6zcMcGzZQ/cYb9L/pJowJQbaSNtZIwf23OdJ9feihcM684LahUPhQdfB6\nEu+cBYVL4fq/wRSJt66O8kcexbFuHY61a7GMG0v/W24JiQWt7OH/YoiJIfXKK3ZxvXTl55N3wolE\nT96X7OefD12xz4byJu1VXYlMxLAHIXSd9SNl9scRa/4KvvbQZfMNgq/snHa6dA28fJiMUTr/k45Z\ng0JE5YsvErXiP0QP0NnwfhoZjzxO/IQsaelVNPHXh9KlMTJeulrlTN51n+ZKgG/ulgXrD7hZlmHo\n6ZSvl9dmRDSc/b7U/neEBbOka/fVyyExCJZzRe9G1yHvOxhySPcrNvyC2rAjpHt5e1316stkaEJ1\nnpz8guAl30p37W/ugp+bld0xWeT7dtbvUnG6/lNpuYwbIIXAyDgZbxuVGJKv2W0IIbM9Jw2Ulk5r\nEVRthsEHdG8/fn8Rvr4T3DbpXTLlKing9TbBWdFrUC6aPYlp18D2KVIbDbi3b8e6cKEM9H3kv8Qf\nfXRI4t6EruOtqaH61VdxrFlDxn8fDhTX9mfe1CIjSb/n3tAJd6vegU/+BWfMlQ+9PUy4A1+6+L33\nxltbGxrXkMZaOdAvWg4XfdUxAc1eDe+eJV08T3ujRwh3AAnHHU/x3IfJ7V9BVIqL6ClTICn0BXJ7\nHWNOgX57y0yB758rY1WaW8O3LZFu0UfcB4MPlCUCehP9Rsi6lm+dCq/OlJbKYYe171ivR3pQ/OMS\nJdwpJGs/gnkXw5nvwvDglRhqE49TWu+G+67hjsRhxfWHuMN3v33fy+S71R873VAK9pqm58DGL2DF\nTnF2lgT5rOiGouMhQ9NkiSQ/S5+VHg2DD4JD7ghdfLYQMmlTyhApSCfmyKy/U2ZJJalCEUaUBa8H\n4C4rw5iQgMFiCWk7Qghq3nmHsgceJCIjg6ynn8YyfC+qXnqJ8kcfI+PRR0k45ujgN6zr8N09UrM4\naAac+nrwU7v3InSXC4QIuOcGnXUL5QB/2rVw2D3tP+7tM2RGzgs/h6wWFUJhw7FhA7WP/IvGWhOD\nPlwY7u70bBprZSbLzH3kvWctkAlUVr8H8Vlw3P/kILC3UlcCb58GZWvh+Nkyk2x7EEK65vUQxYUi\nzHjd8Ox+Movr5b90j6u334Juq5LWs3Bci+5Gn/BXJueRsb37edASbgf88RL89Bg0VstQkINuD14C\nKa9bWgyXPCPjlw+8VcZ2KhTdjHLR7Gl4nDLOKWOC1Ep3M/YVKyi69jpZj2/Bx+QdcywxU6aQ+eQT\nwbfeORtg/mWw/hPY50KY+Uj4Yx/2BBZdB8tfhXM/lplJ20PRchnzMeaU0Patk1TPfQtDVFTwYxf7\nMosfkSUJjGaYeg1Mv75vlAdwNsj6j1OvaVsZUblZln7oa4XvFV3Hrww79inY5/y29+8Kvzwlk6ic\n8op6B3YXjjophC2ZLS18xz/T/mOd9VCzDWq3yc8jfMrv14+TtTw9jZA8BKZcCePO7BvPVUWvQwl4\nPY3GGnhsb5nU4LinwtIFd3k5zvXriZ0xA+fWrRgTEjAlh8CqtlKxHDwAACAASURBVOptGfty5EMy\na1ZPTuLQl3DZ4cWDpCvwrN9bjwGoLfTVIlL0OTZ+BesXySLl4c4YGErWzIPhR8tEFc0RAl4/Vg7U\nrl3V+VISir6JEPDy4WAthKtXBGptBp2fn5DxcaNOgpPmKAGvu7FVgtClG2XRCvm8mHqNFNJq8qUg\nOPI4ue+Cq2DDZ7LEi59+I+HKJXL523vB45BlJYYdoeLrFGFFCXg9kQWzpBXv+r97f4BzS7hsUqMl\nhAzq7j8y3D3a8yhfLwe8/gLULVGyWg5wjrhPxicpFL2NsnXw3FTIngxnvA0xKU3bNn8Lc0+Co/4L\nky8LXx8VPZdtS6SXyZnvhuY9tfhR+O5eWerjhOdV1t9ws+RZ+Oo2KfD5iUyAWwvk8k+PS6tdYq6v\nPJNv2oPDShQ9FyXg9USKV8GcA3pEKvqgs/oD+PJWmYUxDC6oip0QAsrXyRIUzbFVwYsHygQUl/2o\navMoei9r58NHl8nyCWd/4Cv+rsvru7EGrlqmigordo/XIwWv6jypGNvryOBYZn5+Er65U9ZnO+E5\nZUHuKZSvl2Ejsf19AlwuJGQrDyNFr6M1AU/ZlsNFxnjInCQDgXuZkL1bdF26L3x0CaQOVwJDT+Hn\nJ2DOQbIEgh+vBz68QKbdPn2u+q8UvZtRJ8L5i6Qw99KhUPAbrPtYppQ/6DYl3Clax29VW/46vHsm\nzN4HfntBxmF1hdxp0jNCCXc9i34jYMYNMPFcGDRdZr9Uwp2ij6EEvHDyj0tknZqG8nD3pOu4bPDB\nefDTo7LY6LnzlUtDT2HiedINeN7FMjYPpFZ562I45nHI2ie8/VMogkHOZLjkG5nuvSbf5xo+RrrG\nKRTt4eDb4ZRXIToVPr8JHh8plZYdQQjp9gmQ/Q84+jEl3CkUim5HuWiGE12XWqO+oDn64WH48SE4\n/D5ZZLsvfKe+xJbv4M0TYdJFcMwTsuBz6V9weAcHLwpFT8ftaEq20nxZoegI25fJempRSVJIAyhe\nCenjd/9+EwK+vVt6TZw7H4Yc3H39VSgUexwqBq+nY6+WU4RFllDwumTx0fgMmQUx73tZd8W/zeOU\nweCZ+0jL2V8fyDS94XBD0r1SO+lxyjT7uVO7vw+K9vHV/8GvT8EZ78CImeHujUKhUPR8hJACXeEf\n8PKhUsDb70rpFty8jp0Q8PUd8hk76SKY+ZjKsKhQKEJKawKeSucUbhxWeHIMuBp2XP+Pf8LRj0oB\nau7Jux437Top4HmcsOha+HW2tMwMmt49/fa44Pc5sgzCBZ9Id0wl3PVsDv4/KYR7neHuiUKhUPQO\n/Na6/iPh6Mfht+dh/qVSmNv3Eph8OZhj4cvbYOkz8t098xHlxaJQKMKKsuD1BDZ+CbUFshixKVLO\nU4ZA+jipFSz8rdm2SKk1tCSCJV5u3/wtfPZvGXcy/mw47N4dU4UHm01fwxe3QtUmGHa4TP0cyvYU\nwcPjlNbgyNhw90ShUCh6H7ouXd6XPgvFK+Bfa6W7+ytHSGHvyIeUcKdQKLoF5aK5J+BuhMWPwC//\nk2l/Z/0e/MBuZwN8eBFs+hKSh8CRD8JeRwS3DYVCoVAoegP26qZkYtuWQM5+SrhTKBTdhnLR3BOI\niIJD7pAZ42oLpHCne2XBzuTBXTu3P87OHCPnh90rNZXN4w8UCoVCodiTaJ4pOndK+PqhUCgUO6Ei\ngPsa/fZusqotfw2emQzfPyCzyXUUXYeVb8HT+4C1SGomz3gbpl2jhDuFQqFQKBQKhaIHogS8vsze\nx8LIE+DHh+G5qZD3Y/uP3b5MZgxbcCXEpMpsnaDcTxQKhUKhUCgUih6MEvD6MrH94OQXZT0eocMb\nx8F397V+jK7D/CvgpUOk1e7EF+CiryBtr+7ps0KhUCgUCoVCoeg0IRXwNE07UtO0DZqmbdY07ZYW\ntl+gaVqFpmmrfNMloezPHsuQg+HKJTD9BhjoK6PgcUlhzo/ulXODQcbz7X89XL0Mxp2havkoFAqF\nQqFQKBS9hJAlWdE0zQg8AxwGbAf+0DRtoRBi3U67vieEuCpU/VD4iIiCQ/6v6fN390o3zGOfhKot\n8NXtcMrLkDEBjn5MuWIqFAqFQqFQKBS9kFBm0dwX2CyEyAPQNO1d4HhgZwFPEQ7ShsOKN2QSFgSk\nDgevR25Twp1CoVAoFAqFQtErCaWAlwkUNvu8HZjcwn4na5o2A9gI/EsIUbjzDpqmXQpcCpCTkxOC\nru6BTDgHhh0Bi/8ra9r942IwRoS7VwqFQqFQKBQKhaILhDu4ahEwUAgxFvgaeL2lnYQQc4QQk4QQ\nk9LS0rq1g32a2DSY+Qjsd7kS7hQKhUKhUCgUij5AKAW8IiC72ecs37oAQogqIYTT9/ElYJ8Q9keh\nUCgUCoVCoVAo+jShFPD+AIZpmjZI0zQzcAawsPkOmqalN/t4HPB3CPujUCgUCoVCoVAoFH2akMXg\nCSE8mqZdBXwJGIFXhBBrNU27B1gmhFgIXKNp2nGAB6gGLghVfxQKhUKhUCgUCoWir6MJIcLdhw4x\nadIksWzZsnB3Q6FQKBQKhUKhUCjCgqZpy4UQk1raFu4kKwqFQqFQKBQKhUKhCBJKwFMoFAqFQqFQ\nKBSKPoIS8BQKhUKhUCgUCoWij6AEPIVCoVAoFAqFQqHoIygBT6FQKBQKhUKhUCj6CErAUygUCoVC\noVAoFIo+Qsjq4CkUCoVCoVDsjjqHm9/zqlmSV8WvW6pwe3UOH9mfmWPSGZURj6Zp4e6iQqFQ9EqU\ngBcmrI1uft5UyQ8byvl1SxWpcZFMG5LCtKGp7JObhCXCGO4u9imqbS42lzcEpi0VDUSaDIzOTGBU\nRjyjMxPoFxepBhQKhUIRIuwuD8vya/h1SxVLtlTyV5EVXUCkycA+uUkYNI0XFufx7A9byEmO5qgx\nAzh6TDpjMhPUs1mhUCg6gCp03k0IIVhXUscPGyr4cUMFywtq8OqCeIuJqUNSqWhwsqqwFq8uMJsM\nTMpNYtrQVKYOSWFMZgImY8/ypq13uPmryEpBlZ2kGDNpcZGkxUaSFhcZNuFUCEGx1bGjIFfewOaK\nBqptrsB+lggDQ9JiaXR72Vppw38LpMZGMjozXgp8GQmMzkwgKymqxwwsdF2wptjK71urqXd4cHp0\nnB6vnLubLXt0nO5myx6vb7tctkQYyU2OJiclmtzkGHJTon1TDEnRET3m+4abRpeX1dtrWVFQy5oi\nK/3iIxmfncjEnKQedV00x2p3s66kjnUldfztm2psLsZkJTApN5l9BiYxOiMBsyl0zxO7y8Oaojr+\nLKylxOpgZEY8E3ISGZQSg8HQ834zRehwuL2sLKhlSZ4U6FYV1uL2CkwGjQk5iUwZnMKUIalMyEkM\nvDdqbC6+WlfKZ3+V8svmSjy6IDMxipljBjBzTDrjsxN75L2nUPRlhBCU1zsxaBppcZHh7o7CR2uF\nzpWAF0KaW+l+3FhBeb0TgFEZ8Rw4PI0Dh/djQnZiQHhrcHr4fWsVv2yu4pfNlawvrQcgLtLE5MEp\nTBsqLXzD+sV26wvO5dFZXyoHbH9ut/JnYS2bKxrY3aUTbzFJgS8ukrQ4S0DwC0y+z8kxZoy+AZ9X\nF7i9um8SeLw6rp2WPV4R2O726ticHvIqbTtY5ewub6AfidERDE2LZWg/OQ3pF8vQtFgyE6MCA02b\n08PfJXWsKbKypljON5U34NVF4LuMykhgdGZ8wNo3KDU20O9QU21z8dOmCn7YUMHijRVUNRNUzUYD\nkSYDkREGIk1GIk0GzCYDkRFy2eKby8no28+AzelhW5Wdgmo7JVbHDu3FRZqk4JcSTc5Owt+AeMsO\n39urCxocHuocbjk1yuV6h4e6Rvcuy3WNHkxGjcGpMQxOi2Vwmpynx1vCPvAXQrC9ppEVBTWs2FbD\nioJa/i6pw+O7DrKSoqhscOJw6wCkxpoZn53EhJxEJmQnMjY7kdjI7nOI0HXBtmp7QIhbVyznxc3+\nz9RYM3unx5MUbWZVYS0F1XZAWkvGZSUyMTeJSblJ7JObRFKMuVP9cHt1NpTWs6qwltXba1m93crG\nsnp8PxtmkwGXR/5mCVERjM9OZEJOopxnJ5EQHdG1H2I3CCGod3oCzyhNA/8V5n92Nn0Gzfdp58eq\nVxd4hUDXBV5doAvQhVz26gIhwCv820Rgm//7JseYiYow7jECidurs3q7lSVbKlmSV8Wy/BqcHh2D\nBmMyE5gyJJUpQ1KYlJtETDvul1q7i6/XlfH5mlJ+2lSB2yvISLBw5Oh0jh47gAnZSV1+dnh1QY3d\nhVcXpMZGdtuzvbdR73CzpcIWeNduLm8gr6IBS4SRrKQospOiyU6OJjtZLmclRRNlVp5IwcDt1dlS\n0RB4zjs9Ov3jLQyIt5CeYKF/glxuzz3VGrouKK1zkF9lY1uVnfwqG/mVcnlblZ1GtxxfpcZGMjIj\nnpHp8YH5oNSYHnHvCCGosrnIr7SRX2X3zW0U1TaSlRTNmMBYLoGEqNC8f7oTJeB1E0II1hbX8ePG\nCn7YUM6KgtqAlW76XmkcuFcaBwxPo1+cpV3nq2xwsmRLFb9uqeTXLVVsq5IDtLS4SKYOSWHakFSm\nDk0hKyk6aN9B1wVbq2xSmPMJdOuK63B55SAtJcbMuOxExmUlMi47gSFpsVgb3VTUO+XU4KS8zkFF\ng7NpXb0TWzPBy49BA5PRgNur71ZYbA8ZCRYpvPknn1CXEts5LZPD7WVjWT1riupYU2xlbZGVv0vr\nAwPVqAgje6fHMSI9nuH94xg+II7h/eM6PUhujlcXrN5eyw8bKvhhYwWrt9ciBCRFRzBjrzQOHJ7G\ntKGppMQEZyDicHvZXmMnv9LOtmo7BVU239xOYY0dt7fpjzEbDaQnWnB7dOodHuqdnjbPH2M2Eh8V\nQZzFRLwlAqdHZ2uljYZmx0ZFGBmUGhMQ+IakxTA4VQqAXX1htfa9/yqysnxbk0BX2SAVMNFmo08A\nkta6CTlJJMeYA8LMysJaVhbUsKqglrxKGyAFg736xTUJLzlJDO3XdUWAx6tjc3rZXNHQJMyV1LGh\ntD6gzDAapNA8MiOevdP9U9wuz5nyOgfLt9WwzDetLbIGBNghaTEBC98+uUkMTo3ZRSjxPxtWb6/l\nz0Irf26vZW1xXeC+SIqOYGxWIuOyEhiXncjYrERSYsxsqWhgZUEtKwtrWFlQy4ay+sD9Pjgthgl+\nQTknkeH949rlreDy6JTVOdhe00hxbSNFtU1z/7JfGA83ZpOB5GgzidFS4EuKMZMUHeFbZ95hXVK0\nXDYbDQGLvKuZJd6/7GpmmXd5fRZ8r7Tce3VBcoyZAb5BX/8EC3GRpqAJmR6vTlFtoxz0+Z8ZPoVR\nfpUt8LuPGBDHVJ9At++g5C4PpqyNbr79u4zP/ipl8aYKXB6dAfEWjhwtLXv75CZhNGjouqDO4abK\n5qKqwUVVg7Np2eZfdlLV4KLa5qLa7gpcjxFGjQEJFjISoshMiiIzUU4ZvikzMapPCy1CCCoanAHv\nF79At7m8gdK6JuWRyaAxMDWGIWkxOD06hdV2ttc04vTseM+lxprJ8gt+SVFkJ0cHhMGMxKiQehL0\nVqyN7oDSzu+JsamsITAG8ytt6xy7vn/jIk3yvk+wBATA/gkW0uOb1iVFR1BidQQEuG1VNrZW2tnm\ne/e7mv2HZqOB7OQoBqbEkJsSw6DUaNxewd8ldawtrmNTeX1gjGCJMDBiQPwOgt+IAXFEm4P/DvcL\ncf6++4W4/Cob2yrtO4xNjAaNrKQo0hMsFFbL94Of3JRoRmcmMDojgTGZUpGfGN31cVx3ogS8ELM0\nr4p5y7fvYKUbnRnPgXv148DhaYxvZqXrCttr7Py6uYpftlTyy+aqwIC0f3wkCVERRJtNxEQa5dxs\nJDrSN2++PrDdRHSkkagIIwXVdv4slNr3P7fXUu97cESbjYzJTNhBoMtM7Jxrms3podIn9JU3E/w8\nuiDCqBFhNGAyapiNhsByhNEQ2NZ82WQwYDZp0tUwJaZbLCd+DdqaImnlW1dcx/rSuh0esv3iIgPC\n3vABchrWL67NAUFFvTNgpftpUwU1djeaBuOyEgOW3jGZCd2uHfPqguLaRgqq7b7BnI3iWgeRJgPx\nFp/QFhVBvMVEnCWC+CgpxMX7lmMjTS1e90IIKuqdbK5oIK/CJqdKuVxYY99B2B8Qb/EJfjEMSo0l\n2mzEqGlomnxwGzQNg0HDoOFb71tuYVulzcWKbTWsLKhhbXGTdW5gSrQU5HKTmNgBIQOkhWFVYS2r\nCmtZWSDn1kY3ALGRJsZmJTAhJ5HBqbE4PF7sTi82lwe7y4vNudPc5dll+84DpjiLib3TfS9QnzA3\nrH9sp9yiHW4vfxbWsmxbDct9k7/vyTFmJuYkMTE3kXqHJ2Cda/5sGJ2RwLjsBJ9Ql0h2cvueDQ1O\neb6VBf7frIbKBmmZjoowMjYrgfE50sIXYdQorm1ke20jxbUOimrsFNc6KKt37KIUSo2NJDPRQmZS\nFBkJUfT3WYabv+P8iwIR+Cxa2CYE8vppdi0ZDTteTwaD5psT2O5fL4SgrtFDtd1Fjc1Fjd1Ftc1N\njV0u19hc1Da6u6TY6gjRZqMc7MU3H/xF+gaDUQyIt5Aaaw5c93aXp+m+bybAbauyU1TbGLBSghRg\nc5ObLP375CYxeVBypxVs7aHe4ea79eV89lcJP2yowOnRSY4xYzJoVNtcgXt7Z/xCdmqM9CBJiTWT\nEhtJSowZg0Fea8W1jRT5FAeldQ52PlVyjNkn9FnITIz2zaOIj4rAEiE9JywR8t0a5VuONBm6ZGkU\nQgRc8R0eLw63F4dbx+Fzxfd4dXSfNVnXmyzJ0qrMThZmmvYR0gvDb5HbXN6wwzstxmyU3i9psTso\nUXOSo4nY6RnpFw4LqxvZXmMPCH2FNXYKq+Xv2fx/MWiQEhuJ2fe+Nxo0IgwGjAYNk1HDZNAwGZpt\nMxp8cw2jwUCEoZlZHppu5JY/svNY12DQSIwykxwTQVKMmWSfciU5xiwVLdERIQ2NEUJQWN3IuhIr\n60rqA9a55gKI3wsjIDT5LGUmowG7y0Op1UFpnYOyOgelVqdv7qCkzkGZVSravbu5F/xEmgw+AS6a\ngam+ue9zekJUq+MOl0dnc3mDDAsorpPfpbhpXKRpMCg1JiDw+d+tnmbeWm6fd5b00vKt03XcHoFH\n39F7q9rmkoJppa1FIW5gSgwDfd9jYEoMA1NjyEqK2uFarWpwsra4jr+KrD7PLSuF1U2/eVZSlE/Y\nk9OYzASSg6C8DxVKwAsxz/+4hWe/38z0vdI4aHg/ZuyV2m4rXWcRQrCpvIFfNleytrgOu8tDg9OL\n3enB5vJid3mwOeXc3oL1bGdMBo0R6XFSkMtKZFx2YlAsEH0ZIQRldU7Wl9axsaye9aX1bCyrZ1NZ\nQ2BgrmmQmxzdTPCLZ/iAOGrtLp+lt4K/iqyAfJjPGCatvDOGpQXFItjbcLi9bKuyk1fRQF6ljS0B\nIbChRY1lR/ELEBNzk3zWuURSgzgQFUKwtdIWsFitKqzl75L6XV6ylggDMWYTMZEmos3GprlP8bLD\n3CwVGXunx3VawdIedF2wpaJhB4Fva6UNk0Fj7/R4xmYlhOTZ0Nw9Vv5utawrtrZoPfZbVjISo8jy\nW1V82tnelpjKqwvqGt1U213U+gVAn0XJ7dGxRBily3UzN2yzsdlywP3a55rtc8M2aBpVDc6WB3++\nAWB5vWOH3xfkgDstLhJdSKVTcxKiInxu2z5BLjkm4MrdPy68LtY2p4fv1pfzw4YKzCZNCm4xkVJ4\nC8zl4H1noaQtPF6d0jqHVC7USuWC32rstxi35/0KBIQ/v9Anl+U6o0ELxE47diPEhZLU2EiG9osJ\neMD4hbkB8ZagWn7L6p0UVkvhr7CmkQrfdejx6nh0gccr5FzXA2Ebci52+OzxLe/Mzl3V0Ha73eMV\nWBvdO3iT7Ey8xRSwsPsFwJQYaXmPMGq+PvtCSXS/IOITWvSmEBO3bz+PV+DWBQ0ON5vKGgJCisEv\nCGUk+BR3cYzMiO/yONKrCyqbPQtKrQ6qbS7SEyw+i1wM/eIig3r/CiEoqm0MWCD98+01jW0fvBMG\njR0U/PFREe0S4jpKrd0VEPr+KpJeW/k+jzmQXmLjcxJ55qyJPc7dXgl4IabR5SXCqPW4RCh+dF3Q\n6JaWAZtzV4vBgAQLozLie90Aqafi1QXbqmxsKK1nQ1l9YJ5fadtBG2zQYGJOEgfsJa10ozLiwx6L\n1lMRQlBjd+P0eGUc1A5aagLaaV1nh1iowDZdEGsxdcg6FywaXV5K6xxEm42+ydRrFCc1NhdRZmO3\nPxscbi9/l9QhgKzEKFJjgzsI2dPRdUG13UWp1REQ/Mp8g0AhCFjj/MJcqGIleztCSCGhqLYRm9NL\no9svmHlpdPnmbn2X9Y3NhLdGtxePLgJx0xb/vJk10OKLrQ6sNzUtR5qMASuXQWuyJksLdLP1fgvz\nTlbnKLOReMue+/86PV5q7W6qba6AgqXG1mRxrw5Y4OX6KpurRYHbaJBWR78wYjJKK6PJ75Hks0aa\njAaiIgwM6xcXsM4N79+2p09vx9roZnN5AyB28MQyGQxEmHweWr5lUzOLbTj7u7bYytoiKfjZXV5e\nOr9FOSqsKAFPoegBONxeNpc3sKG0HkuEkf2HpqqBk0KhUCgUvQi7y4PbK8NLTAYpkCgFlCIctCbg\nqTp4CkU3YYkwBvy6FQqFQqFQ9D5CkThEoQg2PdOnUKFQKBQKhUKhUCgUHUYJeAqFQqFQKBQKhULR\nR1ACnkKhUCgUCoVCoVD0EZSAp1AoFAqFQqFQKBR9BCXgKRQKhUKhUCgUCkUfQQl4CoVCoVAoFAqF\nQtFHUAKeQqFQKBQKhUKhUPQRlICnUCgUCoVCoVAoFH0EJeApFAqFQqFQKBQKRR9BCXgKhUKhUCgU\nCoVC0UfQhBDh7kOH0DStAtgW7n60QCpQGabjVdt7VttdPV61rdpWbffdtrt6vGpbta3a7rttd/V4\n1XbPIlcIkdbiFiGEmoIwAcvCdbxqe89quzf3XbWt2lZt9+zjVduqbdV23227N/e9N7cdjkm5aCoU\nCoVCoVAoFApFH0EJeAqFQqFQKBQKhULRR1ACXvCYE8bjVdt7VttdPV61rdpWbffdtrt6vGpbta3a\n7rttd/V41XYvodclWVEoFAqFQqFQKBQKRcsoC55CoVAoFAqFQqFQ9BGUgKdQKBQKhUKhUCgUfQQl\n4CkUCoVCoVAoFApFH0EJeGFC07QRmqYdomla7E7rj2zHsftqmvYP3/JITdOu1zRtZif78UZnjvMd\nu7+v7cPbuf9kTdPifctRmqbdrWnaIk3THtY0LaGNY6/RNC27C301a5p2nqZph/o+n6Vp2mxN02Zp\nmhbRjuMHa5p2g6Zp/9M07XFN0y73fxeFQqFQKBQKhaKnoJKsBBlN0y4UQrzaxj7XALOAv4HxwLVC\niAW+bSuEEBNbOfZO4CjABHwNTAa+Bw4DvhRC3N/KsQt3XgUcBHwHIIQ4ro1+/y6E2Ne3/E/fd5gP\nHA4sEkI81Mbxa4FxQgiPpmlzADvwIXCIb/1JrRxrBWzAFuAd4AMhREVr7e10/FvI3ywaqAVigY98\nbWtCiPNbOfYa4BhgMTATWOk7x4nAlUKIH9rbD4VC0T1omtZPCFEeprZThBBV4Wi7u9A0zQRcjHwO\nZvhWFwELgJeFEO5w9a0tNE2LBq4CBPA0cAZwErAeuEcI0dDB820UQuwV9I72MDRNGwzcDhQDDwFP\nAFOQY5kbhRD5IWpXXWtN51PXWgivtT5FuCut97UJKGjHPn8Bsb7lgcAypJAHsLIdxxqRgkodEO9b\nHwWsbuPYFcBc4EDgAN+8xLd8QDv6vbLZ8h9Amm85BvirHcf/3bwvO21b1VbbSIvz4cDLQAXwBXA+\nENeOtlf75iagDDD6Pmvt+N3+arZ/NPCDbzmnrf9LTbv8lv3C2HZKuL9/N3zHBOTLcD1QDVQhX4gP\nAYldPPfnbWyPBx4E3gTO2mnbs+04/wDgOeAZIAW4y3fvvQ+kt3Fs8k5TCpAPJAHJ7Wj7yJ1+w5eB\n1cDbQP82jn0ISPUtTwLygM3AtnY+V1cgBzJDOvGfTEIq+OYC2Uiln9X3fJ7QjuNjgXuAtb7jKoCl\nwAXtOPYd3/+1H5Dlm/bzrXuvi9fanDa2G4HLgHuBaTttu70d538feAx4FvgWmA1MBx4B3mzj2Hrk\nu7fOt1wPeP3r29H22GbLEb7/fiH/3965x9pR1HH887u0FhCspCIFQaq0tVChFWh5FWwEsQqBoiWA\nCgFEBKVVhACBaCNBgqggaPxDGlorKIaHxfBqgzwKhT5suX1AKSiXR4GWIiAUCI/25x8zN90ez7k7\n5+y5d2/v+X6Sydkzu9/9zez+dnZmdnYWLge2zdGek/G1oYROxzeABcDeCbZvA75NrH80cF7mAmcD\nFwErgPOi330HuC9H2wacDtwJLI1+fxMwXr4mX+stvhb13XYf7clQegK2xEC48VcLy4H3EvSPV/zf\njtBYuYqEhk615fg/T9sGnEuoBIyOcc/Uke+lhArTIOCftdLVhf5m4LS4PB3YPy4PBxblaCsbhP2B\nYwgF/7oE2yuAj8T0v0Ws9AFbk2l41tAuBwbE5R2yeQdWJNhWpVuV7p6qdM8GLgQGV5zDC4E5Cfp9\na4T9gJdztLfG4z6RUIm4NXPdLEmwfQ8wmXBDXxbTvFuMuz1HuxHoqAgfxN/cMi6bPmAacBmwO6G8\nnJWjXZ5Zvh8YE5eHU1FO1tB3AL8CngcWRpu7JPraQsKIjpOAF4BJMf5w4NEE/e3AqYQK84+BnwDD\ngD8Cl+don2pkXWabyvIhW06sztFOI5QDPwIWA1dVO5dd6NvjrwFr2DSaKaXD71pgJpkyCOhIOV9V\nfO3XwAxCJ+vVwMwc7eOZ5TuB4+LyeGBegu0XCaNmXiOU8DMjQwAACjZJREFU4ccBH6kj7dn6x/O1\n1tXQTifcP8YBvyGUcV8G7gUmy9fka73B16K+0H20t4TSE7AlBsIToNGECkA2DAFeStDfR2xgZeL6\nxQt5Q452AbHnBWjLxA9MKWzitrsSGlu/q7xwcnTPEirKHfF35xi/HTmNy0waZxCGWS4gVMCeAR4k\nDNHsSlvzgianJypuc2609RwwhdCTdh2hsTI1R/tDQoXzOkIjrbORuiMwN8G2Kt2qdEPPVLpXNbIu\ns80GQvl0f5Xwbo62veL/JcA8QiUqxde6uqHndV6dF31170xcR8r5quJrlfnIs70S6BeX59fyw0Tb\nhxJ6+tfEY35mgWOW0um2tOL/ovjbBjyZo50PHM/m96E24ARgQaKvdd5POkPn//dztMsyy/0IHyG+\nDRiQmO/2zPL1XR2TGvr94nUyJea5no7S7DlrB/rH5ZQK/6rM8qKKdV1qs7YJHX8nA3cROpCmA0cm\n6BcTytCxwKts6qQdmpD2ZRX/58ffAeR3ssrXWtfXxvSkr1XmvZ51vS2UnoAtMRCeJIyrse7PCfpd\nyVT2K9YdkqMdUCP+EyQ8Nq/QHEVOhTFxP9sCn6lj+48Bo2LB1eWTmIxmeBPSuQuxkg58HJgEjE3U\njozbj2jArirdm+I66jhuqnR73ZXuOcAFbN7juxOhYX5vgu0VwLAa615IOOZtFXGnEp5EPldPvoHL\nGjhnnR1XVwHbU19FaDWhMX0eoeJnmXV5lYnJ8bh/idBrfA2hl/xn5AzBqvS1TNxWwARgeo72UcKw\n9eMJnVcTY/wXSevIeIR4LyOMiJidWddl2UTo0Pwr8ArwVAyvxLjc+wHwNPDpBn3t/64DYCqhbHs6\nwfY0qgwdA/YAHk70mTZCpfshEjp2M7pnCO9gfYOKymbltV9F+3NCJ+lngYsJT5V2B04D7mjQ1wYB\nZ5Ez7C1ueziwKl7r4wgdhk/H835sjnYxcUQEoYNybmbdE4m+ti76WadN+Vq+rx3XB31tYnf5Wtym\n0H20t4TSE6Cg0NdD0cICVbpV6d60Lq/SvQPwC8KT5tcJw2NWxriUYbGTgM/VWJd3U70SOKJK/ATS\nKkKXUr0iNBS4pQ6/OYbQ47+mDs3UitD5fvFgcoYyxe3GEyqbjxFGBdwFnEnsMc/R3pSaziraUYQR\nAncDI6KfvxGv74MT9Qujrzzcee4JoxOmJOgPIDzNGQQcApwPfC0x7T+gxsgN8ofs3UBmCHcm/gzg\ng0T7Y9n0ZH8vQllzFJlyJlF7KPDTOvI9vSLslPG1fyToTyWMgHmV8LrBE4R3qgYmaHNHnCSe8868\nj0w954Sy+HlCJb0DOCDja1fWYX9QDDfUoSnV16poZ8bfXF+r0O0M/KeO7WcU9LXTyvS1Kvu8g4r6\nTI6v/Sv62oH1+BoF76O9JWgWTSG6GTPbgTDE8VjgkzF6LWHI5BXu/nqOfhKhMbWqyrqJ7j6rC+2V\nhGGg91bETwB+6+7DcmxfSigQ11fED41pn9SVPrP9MYRewCHuPjhRM7Ui6vfuvs7MBsc0nZKjH094\nSXs4YWjNC8AswjCZD3O0N7n7iSnprKIdRWjsbCQM7TybMBnQi8B33f2RHP0+hF7fYYSK+unu/pSZ\n7Qic5O7X5uhHEBrW87PnzcwmuPs9CekfAXyKMPSpLn0X2q+6+909ZZvw1HsPd19Rcr57wvaehNEJ\njdreM9quy1+qzOg8FniAhBmdM/sYC7i7LzKzvQidAU+6+13drK1Mez2zUTcj3wcAG5uQ75FRuzJF\nW0Vf9LjVlXczOwj4sF7bVWYAh1CJT5oBvMY+Z+bdQ5qhLTJ7eS/M95/c/eRGtPXaLpp3MzPCxGqv\n1mu7yr4OJfj6cnef08g+ykANPCFKJOWzGt2l72nbZrYNmyrdLZPvnrRd5BMsRfVmNpkw81qjthvW\nNyHfW7Lt7xN6mhs93w3pzWx51AwgDF/e1d3fjNf5AnffJ8d2MxtZydqiae+GfCc3kprQwCrzuBXJ\n9xLC06NphM8NGGGCtRMB3P3BnHQ3s5FV7+elHiN01NWd9m7INyQ2kprQwCrzuBVNe/aTYGcQyvdZ\nJH4SrNfgJT06VFBQcKhjkptm62W779mmwCdYiuplu+VsNzyjc8Z2o5/8aVhbNO1beL7LPG5F8l10\nBvDHaPATUUW0RdNecr4Lf1arxONW1HahT4L1ltAPIUS3YmbLaq0ivIvXbXrZbi3bhPcT1gO4+7Nx\nmOotZrZ71OdRRC/brWX7fTPb1t3fIUyYBYCZDSQMT87jQ3ffALxjZv929zdjOt41szx9EW3RtG/J\n+S7zuDVs2903Aleb2c3xdy3UVX/djzAb9iWEj2S3m9m7nvMErAnaQmkvOd/7F9AWtV0074VsA20W\nXq1pI4x0XBfT9LaZdfl6R29CDTwhup+dgK8QXtbNYoQJNbpTL9utZXutmY1293YAd19vZkcD1wN7\nJ9guopft1rJ9mLu/F3XZCnp/wjuneZTZyCqS9i0532Uet6K2cffVwPFmdhThKWASJTeyCqW9iLbM\nfJd53JpgeyBhJk4D3Mx2dveXzWw70jrOegfd+XhQQUHBofhnNRrWy3bL2W74EyxF9bLdWraLBgp8\n8qeItuxQZr7LPG696ZxR4BNRRbRlhzLzXeZxa5Zt6vwkWNlBk6wIIYQQQgghRB+hrewECCGEEEII\nIYRoDmrgCSGEEEIIIUQfQQ08IYQQfR4zWx9/h5jZN5u874sr/qdMpiOEEEJ0C2rgCSGEaCWGAHU1\n8Mwsbwa2zRp47n5wnWkSQgghmoYaeEIIIVqJK4BDzazdzM41s63M7JdmtsjMlpnZ9wDMbLyZPWRm\nfweeiHGzzGyxmT1uZmfGuCuAbeL+boxxnU8LLe57hZktN7MTMvt+wMxuMbMnzexGM9typt8WQgjR\nq9F38IQQQrQSFwHnu/vRALGh9l93H2NmA4B5ZjYnbrsv8Hl374j/T3f318xsG2CRmd3q7heZ2Tnu\nPrqKra8Do4FRhOngF5nZ3LjuC8BI4CVgHnAI8HDzsyuEEKLV0BM8IYQQrcyRwClm1g4sAAYBw+K6\nhZnGHcAUM1sKzAd2y2xXi3HAX9x9g7uvBR4ExmT2vdrDR3nbCUNHhRBCiMLoCZ4QQohWxoDJ7j57\ns0iz8cDbFf+PAA5y93fM7AFg6wJ238ssb0D3YyGEEE1CT/CEEEK0Em8B22f+zwbONrP+AGY23Mw+\nWkU3EHg9Nu5GAAdm1n3Qqa/gIeCE+J7fjsBhwMKm5EIIIYSogXoMhRBCtBLLgA1xqOUM4BrC8Mgl\ncaKTdcDEKrp7gLPMbCWwijBMs5M/AMvMbIm7fysT/zfgIGAp4MAF7r4mNhCFEEKIbsHcvew0CCGE\nEEIIIYRoAhqiKYQQQgghhBB9BDXwhBBCCCGEEKKPoAaeEEIIIYQQQvQR1MATQgghhBBCiD6CGnhC\nCCGEEEII0UdQA08IIYQQQggh+ghq4AkhhBBCCCFEH+F/sVwBI2ScAQcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4omcpkiBMwiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = dataset.training_set()\n",
        "\n",
        "tmodel = build_discriminator_supervised(build_discriminator_net(img_shape, depth))\n",
        "tmodel.compile(loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'],\n",
        "                         optimizer=Adam())\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/teacher-50.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the training set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftgecc1jMwfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = dataset.test_set()\n",
        "\n",
        "tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/teacher-50.h5\", by_name=False)\n",
        "\n",
        "# Compute classification accuracy on the test set\n",
        "_, accuracy = tmodel.evaluate(x, y)\n",
        "print(\"Test Accuracy: %.2f%%\" % (100 * accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aDJmNbdMwce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f6a6b17-321d-4b77-fa5f-85066a6fc238"
      },
      "source": [
        "accs = []\n",
        "# tx = [x for x in range(1,51,1)]\n",
        "tx = [x for x in range(1, len(iteration_checkpoints)+1, 1)]\n",
        "acc_max = [0,0]\n",
        "\n",
        "for e in tx:\n",
        "  tmodel.load_weights(\"./models/models-label-\" + str(num_labeled) + \"/teacher-\"+ str(e) +\".h5\", by_name=False)\n",
        "  _, acc = tmodel.evaluate(x, y)\n",
        "  accs.append(acc)\n",
        "print(max(accs))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(tx, accs, label=\"accs\", color='blue')\n",
        "plt.xticks(tx, rotation=90)\n",
        "plt.title(\"Mean Teacher's accs with epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accs\")\n",
        "plt.legend()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 450us/step\n",
            "10000/10000 [==============================] - 4s 445us/step\n",
            "10000/10000 [==============================] - 4s 421us/step\n",
            "10000/10000 [==============================] - 4s 421us/step\n",
            "10000/10000 [==============================] - 4s 422us/step\n",
            "10000/10000 [==============================] - 4s 423us/step\n",
            "10000/10000 [==============================] - 4s 422us/step\n",
            "10000/10000 [==============================] - 4s 425us/step\n",
            "10000/10000 [==============================] - 4s 428us/step\n",
            "10000/10000 [==============================] - 4s 427us/step\n",
            "10000/10000 [==============================] - 4s 425us/step\n",
            "10000/10000 [==============================] - 4s 426us/step\n",
            "10000/10000 [==============================] - 4s 424us/step\n",
            "10000/10000 [==============================] - 4s 428us/step\n",
            "10000/10000 [==============================] - 4s 424us/step\n",
            "10000/10000 [==============================] - 4s 429us/step\n",
            "10000/10000 [==============================] - 4s 426us/step\n",
            "10000/10000 [==============================] - 4s 428us/step\n",
            "10000/10000 [==============================] - 4s 428us/step\n",
            "10000/10000 [==============================] - 4s 431us/step\n",
            "10000/10000 [==============================] - 4s 429us/step\n",
            "10000/10000 [==============================] - 4s 446us/step\n",
            "10000/10000 [==============================] - 5s 452us/step\n",
            "10000/10000 [==============================] - 5s 454us/step\n",
            "10000/10000 [==============================] - 5s 458us/step\n",
            "10000/10000 [==============================] - 5s 457us/step\n",
            "10000/10000 [==============================] - 5s 472us/step\n",
            "10000/10000 [==============================] - 5s 495us/step\n",
            "10000/10000 [==============================] - 5s 491us/step\n",
            "10000/10000 [==============================] - 5s 460us/step\n",
            "10000/10000 [==============================] - 5s 458us/step\n",
            "10000/10000 [==============================] - 5s 457us/step\n",
            "10000/10000 [==============================] - 5s 451us/step\n",
            "10000/10000 [==============================] - 5s 452us/step\n",
            "10000/10000 [==============================] - 4s 443us/step\n",
            "10000/10000 [==============================] - 4s 443us/step\n",
            "10000/10000 [==============================] - 4s 443us/step\n",
            "10000/10000 [==============================] - 5s 451us/step\n",
            "10000/10000 [==============================] - 4s 450us/step\n",
            "10000/10000 [==============================] - 5s 450us/step\n",
            "10000/10000 [==============================] - 4s 447us/step\n",
            "10000/10000 [==============================] - 4s 438us/step\n",
            "10000/10000 [==============================] - 4s 443us/step\n",
            "10000/10000 [==============================] - 4s 443us/step\n",
            "10000/10000 [==============================] - 4s 440us/step\n",
            "10000/10000 [==============================] - 4s 442us/step\n",
            "10000/10000 [==============================] - 4s 441us/step\n",
            "10000/10000 [==============================] - 4s 443us/step\n",
            "10000/10000 [==============================] - 4s 445us/step\n",
            "10000/10000 [==============================] - 5s 451us/step\n",
            "0.8724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29c64b2eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFPCAYAAAASkBw1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBoARWcsIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2feQLXtMwY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0ae4b98f-b38f-42a9-e475-d0b5dea5d9af"
      },
      "source": [
        "print(max(accs[3:]))\n",
        "# for acc in accs:\n",
        "#   print(acc)\n",
        "mt_accs = accs\n",
        "print(mt_accs)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8528\n",
            "[0.8681, 0.8724, 0.8691, 0.8528, 0.8417, 0.8329, 0.7994, 0.7877, 0.777, 0.764, 0.7771, 0.7646, 0.7683, 0.7536, 0.7282, 0.7139, 0.7145, 0.7228, 0.7292, 0.7184, 0.7719, 0.7829, 0.7829, 0.7834, 0.7866, 0.789, 0.7739, 0.7469, 0.7207, 0.6709, 0.6394, 0.7037, 0.7558, 0.7858, 0.7948, 0.7568, 0.7546, 0.7612, 0.7958, 0.795, 0.7884, 0.7812, 0.7832, 0.7436, 0.7493, 0.7316, 0.7043, 0.7002, 0.733, 0.739]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECv8TookUzDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}